[
  {
    "标题": "《神经网络与深度学习》",
    "内容": [
      {
        "段落": "# 《神经网络与深度学习》",
        "总结": ""
      },
      {
        "段落": "## Neural Networks and Deep Learning\n\nhttps：／／nndl．github．io／\n\n邱锡鹏<br>xpqiu＠fudan．edu．cn\n\n2020年2月15日",
        "总结": ""
      },
      {
        "段落": "## 序\n\n很高兴为邱锡鹏教授的《神经网络与深度学习》一书写个序．\n近年来由于阿尔法围棋战胜人类顶级高手新闻的轰动效应，让人工智能一下子进入了寻常百姓家，成为家喻户晓的热词。阿尔法围棋之所以能取得如此成功的关键技术之一，正是所谓的深度学习技术。而其实在阿尔法围棋出来之前，以深度学习为代表的人工智能技术已经在模式识别、计算机视觉、语音识别与生成、自然语言处理、机器翻译等方面取得了重要的进步。也因此，2018年有计算机领域诺贝尔奖之称的图灵奖就颁给了对深度学习作出重要贡献的三位科学家：",
        "总结": ""
      },
      {
        "段落": "## Yoshua Bengio、Geoffrey Hinton 和 Yann LeCun．\n\n邱锡鹏教授的《神经网络与深度学习》一书较全面地介绍了神经网络、机器学习和深度学习的基本概念、模型和方法，同时也涉及了深度学习中许多最新进展．书后还提供了相关数学分支的简要介绍，以供读者需要时参考．\n\n《神经网络与深度学习》一书已在网上发布，得到广泛好评，相信此书的出版可以给有意了解或进入这一颇有前途领域的读者提供一个很好的参考书。基本的深度学习相当于函数逼近问题，即函数或曲面的拟合，所不同的是，这里用作基函数的是非线性的神经网络函数，而原来数学中用的则是多项式、三角多项式、 B－spline、一般 spline 以及小波函数等的线性组合。\n\n由于神经网络的非线性和复杂性（要用许多结构参数和连接权值来描述），它有更强的表达能力，即从给定的神经网络函数族中可能找到对特定数据集拟合得更好的神经网络。这相信正是深度学习方法能得到一系列很好结果的重要原因．直观上很清楚，当你有更多的选择时，你有可能选出更好的选择．当然，要从非常非常多的选择中找到那个更好的选择并不容易。\n\n这里既涉及设计合适的神经网络类型，也涉及从该类型的神经网络中找出好的（即拟合误差小的）那个特定神经网络的方法。后者正是数学中最优化分支所研究的问题。从数学角度看，目前深度学习中所用的优化算法还是属于比较简单的梯度下降法．许多数学中已有的更复杂的算法，由于高维数问题都还没有得到应用。\n\n本书中对这两方面都有很好的介绍．相信随着研究的不断发展，今后一定会提出更多新的神经网络和新的优化算法．\n\n所谓成也萧何败也萧何，神经网络的非线性和复杂性（即要用大量参数来描述；在深度网络场合其个数动辑上万、百万甚至更多），使得虽然通过大量的标注数据经过深度学习可以得到一个结果误差很小的神经网络，但要用它来进行解释却是十分困难。其实这也是长期困扰神经网络方法的一个问题，使用深度神经网络的深度学习方法也概莫能外。\n\n难于解释相当于知其然不知其所以然。这对有些应用而言是可以的；但对有些可能造成严重后果的应用而言则有很大问题。一般而言，人们除了希望知其然，也会希望能知其所以然。\n\n近来也有学者发现，一个精度很高的神经网络，去改变它的几个（甚至一个）参数，就会使该网络的性能下降许多．换言之，深度学习方法的鲁棒性也有待研究．\n\n总之，本书介绍的基于神经网络的深度学习方法是近年来经过大量实践并取得很好成果的一种很通用的方法，也是近年来人工智能领域中最活跃的分支之一．相信，无论在方法本身的发展上，抑或在新领域应用的研发上，都会呈现出一派欣欣的气象。\n\n吴立德\n于上海•复旦大学\n2019年8月17日",
        "总结": ""
      },
      {
        "段落": "## 前 言\n\n近年来，以机器学习、知识图谱为代表的人工智能技术逐渐变得普及。从车牌识别、人脸识别、语音识别、智能问答、推荐系统到自动驾驶，人们在日常生活中都可能有意无意地使用到了人工智能技术．这些技术的背后都离不开人工智能领域研究者们的长期努力。特别是最近这几年，得益于数据的增多、计算能力的增强、学习算法的成熟以及应用场景的丰富，越来越多的人开始关注这一个＂崭新＂的研究领域：深度学习．深度学习以神经网络为主要模型，一开始用来解决机器学习中的表示学习问题。但是由于其强大的能力，深度学习越来越多地用来解决一些通用人工智能问题，比如推理、决策等。目前，深度学习技术在学术界和工业界取得了广泛的成功，受到高度重视，并掀起新一轮的人工智能热潮．\n\n然而，我们也应充分意识到目前以深度学习为核心的各种人工智能技术和 ＂人类智能＂还不能相提并论。深度学习需要大量的标注数据，和人类的学习方式差异性很大．虽然深度学习取得了很大的成功，但是深度学习还不是一种可以解决一系列复杂问题的通用智能技术，而是可以解决单个问题的一系列技术。比如可以打败人类的 AlphaGo 只能下围棋，而不会一个简单的算术运算．想要达到通用人工智能依然困难重重。\n\n本书的写作目的是使得读者能够掌握神经网络与深度学习技术的基本原理，知其然还要知其所以然。全书共 15 章。第 1 章是绪论，介绍人工智能、机器学习、深度学习的概要，使读者全面了解相关知识．第2、3章介绍机器学习的基础知识．第4～6章分别讲述三种主要的神经网络模型：前馈神经网络、卷积神经网络和循环神经网络．第7章介绍神经网络的优化与正则化方法．第 8 章介绍神经网络中的注意力机制和外部记忆。第9章简要介绍一些无监督学习方法。第10章介绍一些模型独立的机器学习方法：集成学习、自训练、协同训练多任务学习、迁移学习、终身学习、元学习等，这些都是目前深度学习的难点和热点问题。第11章介绍概率图模型的基本概念，为后面的章节进行铺垫．第12章介绍两种早期的深度学习模型：玻尔兹曼机和深度信念网络。第13章介绍最近两年发展十分迅速的深度生成模型：变分自编码器和生成对抗网络．第14章介绍深度强化学习的知识．第15章介绍应用十分广泛的序列生成模型。\n\n2015年复旦大学计算机学院开设了《神经网络与深度学习》课程．讲好深度学习课程并不是一件容易的事，当时还没有关于深度学习的系统介绍，而且课程涉及知识点非常多并且比较杂乱，和实践结合也十分紧密。作为任课教师，我尝试梳理了深度学习的知识体系，并写了一本讲义放在网络上。虽然现在看起来当时对深度学习的理解仍然十分粗浅，且讲义存在很多错误，但依然受到了很多热心网友的反馈和鼓励。2016年初，机械工业出版社华章公司的姚蕾编辑多次拜访并希望我能将这个讲义整理成书。我一方面被姚蕾编辑的诚意打动，另一方面也确实感到应该有一本面向在校学生和相关从业人员的关于深度学习的专门书籍，因此最终有了正式出版的意愿。但我依然低估了写书的难度，一方面是深度学习的发展十分迅速，而自己关于深度学习的认知也在不断变化，导致已写好的内容经常需要修改，另一方面是平时的科研工作十分繁忙，很难抽出大段的时间来静心写作，因此断断续续的写作一直拖延至今．\n\n我自己理想中著书立说的境界是自己在某一个领域有自己的理论体系，将各式各样的方法都统一到自己的体系下，并可以容纳大多数技术，从新的角度来重新解释这些技术。本书显然还达不到这样的水平，但希望能结合自身的经验，对神经网络和深度学习的相关知识进行梳理、总结，通过写书这一途径，也促使自己更加能够深入理解深度学习这一领域，提高自己的理论水平．\n\n本书能够完成，首先感谢我的导师吴立德教授，他对深度学习的独到见解和深入浅出的讲授，使得我对深度学习有了更深层次的认识，也感谢复旦大学计算机学院的黄萱菁教授和薛向阳教授的支持和帮助。本书在写作时将书稿放在网络上，也得到很多网友的帮助，特别感谢王利锋、林同茂、张钧瑞、李浩、胡可峹、韦鹏辉、徐国海、侯宇蓬、任强、王少敬、肖耀、李鹏等人指出了本书初稿的错误或提出了富有建设性的意见。此外，本书在写作过程中参考了互联网上大量的优秀资料，如维基百科、知乎、Quora 等网站。\n\n另外，我也特别感谢我的家人．本书的写作占用了大量的业余时间，没有家人的理解和支持，这本书不可能完成。\n\n最后，因为个人能力有限，书中难免有不当和错误之处，还望读者海涵和指正，不胜感激。\n\n邱锡鹏\n于上海•复旦大学\n2020年2月15日",
        "总结": ""
      },
      {
        "段落": "## 常用符号表\n\n| $x, y, m, n, t$ | 标量，通常为变量 |\n| :--- | :--- |\n| $K, L, D, M, N, T$ | 标量，通常为超参数 |\n| $\\boldsymbol{x} \\in \\mathbb{R}^{D}$ | $D$ 维列向量 |\n| $\\left[x_{1}, \\cdots, x_{D}\\right]$ | $D$ 维行向量 |\n| $\\left[x_{1}, \\cdots, x_{D}\\right]^{\\top}$ or $\\left[x_{1} ; \\cdots ; x_{D}\\right]$ | $D$ 维列向量 |\n| $\\mathbf{0}$ or $\\mathbf{0}_{D}$ | （ $D$ 维）全0向量 |\n| 1 or $\\mathbf{1}_{D}$ | （ $D$ 维）全1向量 |\n| $\\square_{i}$ or $\\square_{i}(x)$ | 第 $i$ 维为 1 （或 $x)$ ，其余为 0 的 one－hot 列向量 |\n| $\\boldsymbol{x}^{\\boldsymbol{\\top}}$ | 向量 $\\boldsymbol{x}$ 的转置 |\n| $\\boldsymbol{A} \\in \\mathbb{R}^{K \\times D}$ | 大小为 $K \\times D$ 的矩阵 |\n| $\\boldsymbol{x} \\in \\mathbb{R}^{K D}$ | （KD）维的向量 |\n| $\\mathbb{M}_{i}$ or $\\mathbb{M}_{i}(\\boldsymbol{x})$ | 第 $i$ 列为 $\\mathbf{1}$（或 $\\boldsymbol{x}$ ），其余为 0 的矩阵 |\n| $\\operatorname{diag}(\\boldsymbol{x})$ | 对角矩阵，其对角线元素为 $\\boldsymbol{x}$ |\n| $\\boldsymbol{I}_{\\boldsymbol{N}}$ or $\\boldsymbol{I}$ | （ $N \\times N$ 的）单位阵 |\n| $\\operatorname{diag}(\\boldsymbol{A})$ | 列向量，其元素为 $A$ 的对角线元素 |\n| $A \\in \\mathbb{R}^{D_{1} \\times D_{2} \\times \\cdots \\times D_{K}}$ | 大小为 $D_{1} \\times D_{2} \\times \\cdots \\times D_{K}$ 的张量 |\n| $\\mathcal{C}$ or $\\left\\{x^{(n)}\\right\\}_{n=1}^{N}$ | 集合 |\n| $\\mathcal{D}$ or $\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ | 数据集 |\n| $\\mathbb{R}^{D}$ | $D$ 维实数空间 |\n| $\\mathcal{N}(\\mu, \\Sigma)$ or $\\mathcal{N}(\\boldsymbol{x} ; \\mu, \\Sigma)$ | （变量 $\\boldsymbol{x}$ 服从）均值为 $\\mu$ ，方差为 $\\Sigma$ 的正态（高斯）分布 |\n| $\\mathbb{E}_{\\boldsymbol{x} \\sim p(x)}[f(\\boldsymbol{x})]$ | 期望 |\n| $\\operatorname{var}_{x \\sim p(x)}[f(\\boldsymbol{x})]$ | 方差 |\n| $\\exp (x)$ | 指数函数，默认指以自然常数 $e$ 为底的自然指数函数 |\n| $\\log (x)$ | 对数函数，默认指以自然常数 $e$ 为底的自然对数函数 |\n| $\\triangleq$ | 定义符号 |\n| $I(x)$ | 指示函数．当 $x$ 为真时，$I(x)=1$ ；否则 $I(x)=0$ |",
        "总结": ""
      },
      {
        "段落": "## 目 录\n\n序 ..... I\n前言 ..... III\n常用符号表 ..... V\n第一部分 机器学习基础 ..... 1\n第1章 绪论 ..... 2\n1.1 人工智能 ..... 3\n1．1．1 人工智能的发展历史 ..... 4\n1．1．2 人工智能的流派 ..... 6\n1.2 机器学习 ..... 6\n1.3 表示学习 ..... 7\n1．3．1 局部表示和分布式表示 ..... 8\n1．3．2 表示学习 ..... 10\n1.4 深度学习 ..... 10\n1．4．1 端到端学习 ..... 11\n1.5 神经网络 ..... 12\n1．5．1 人脑神经网络 ..... 12\n1．5．2 人工神经网络 ..... 13\n1．5．3 神经网络的发展历史 ..... 14\n1.6 本书的知识体系 ..... 16\n1.7 常用的深度学习框架 ..... 17\n1.8 总结和深入阅读 ..... 19\n第2章 机器学习概述 ..... 22\n2.1 基本概念 ..... 23\n2.2 机器学习的三个基本要素 ..... 25\n2．2．1 模型 ..... 25\n2．2．2 学习准则 ..... 26\n2．2．3 优化算法 ..... 30\n2.3 机器学习的简单示例：线性回归 ..... 32\n2．3．1 参数学习 ..... 33\n2.4 偏差－方差分解 ..... 37\n2.5 机器学习算法的类型 ..... 40\n2.6 数据的特征表示 ..... 42\n2．6．1 传统的特征学习 ..... 43\n2．6．2 深度学习方法 ..... 45\n2.7 评价指标 ..... 45\n2.8 理论和定理 ..... 47\n2．8．1 PAC 学习理论 ..... 48\n2．8．2 没有免费午餐定理 ..... 49\n2．8．3 丑小鸭定理 ..... 49\n2．8．4 奥卡姆剃刀原理 ..... 49\n2．8．5 归纳偏置 ..... 50\n2.9 总结和深入阅读 ..... 50\n第3章 线性模型 ..... 53\n3.1 线性判别函数和决策边界 ..... 54\n3．1．1 ..... 54\n3．1．2 多分类 ..... 56\n3．2 Logistic 回归 ..... 57\n3．2．1 参数学习 ..... 58\n3．3 Softmax 回归 ..... 59\n3．3．1 参数学习 ..... 60\n3.4 感知器 ..... 62\n3．4．1 参数学习 ..... 62\n3．4．2 感知器的收敛性 ..... 63\n3．4．3 参数平均感知器 ..... 65\n3．4．4 扩展到多分类 ..... 67\n3.5 支持向量机 ..... 69\n3．5．1 参数学习 ..... 70\n3．5．2 核函数 ..... 72\n3．5．3 软间隔 ..... 72\n3.6 损失函数对比 ..... 73\n3.7 总结和深入阅读 ..... 74\n第二部分 基础模型 ..... 77\n第4章 前馈神经网络 ..... 78\n4.1 神经元 ..... 79\n4．1．1 Sigmoid 型函数 ..... 80\n4．1．2 ReLU 函数 ..... 82\n4．1．3 Swish 函数 ..... 84\n4．1．4 高斯误差线性单元 ..... 85\n4．1．5 Maxout 单元 ..... 86\n4.2 网络结构 ..... 86\n4．2．1 前馈网络 ..... 87\n4．2．2 记忆网络 ..... 87\n4．2．3 图网络 ..... 87\n4.3 前馈神经网络 ..... 88\n4．3．1 通用近似定理 ..... 89\n4．3．2 应用到机器学习 ..... 90\n4．3．3 参数学习 ..... 91\n4.4 反向传播算法 ..... 92\n4.5 自动梯度计算 ..... 95\n4．5．1 数值微分 ..... 95\n4．5．2 符号微分 ..... 96\n4．5．3 自动微分 ..... 96\n4.6 优化问题 ..... 100\n4．6．1 非凸优化问题 ..... 100\n4．6．2 梯度消失问题 ..... 100\n4.7 总结和深入阅读 ..... 101\n第5章 卷积神经网络 ..... 105\n5.1 卷积 ..... 106\n5．1．1 互相关 ..... 108\n5．1．2 卷积的变种 ..... 109\n5．1．3 卷积的数学性质 ..... 110\n5.2 卷积神经网络 ..... 111\n5．2．1 用卷积来代替全连接 ..... 111\n5．2．2 卷积层 ..... 112\n5．2．3 汇聚层 ..... 113\n5．2．4 典型的卷积网络结构 ..... 115\n5.3 参数学习 ..... 116\n5．3．1 误差项的计算 ..... 116\n5.4 几种典型的卷积神经网络 ..... 118\n5．4．1 LeNet－5 ..... 118\n5．4．2 AlexNet ..... 119\n5．4．3 Inception 网络 ..... 121\n5．4．4 残差网络 ..... 122\n5.5 其他卷积方式 ..... 123\n5．5．1 转置卷积 ..... 123\n5．5．2 空洞卷积 ..... 125\n5.6 总结和深入阅读 ..... 126\n第6章 循环神经网络 ..... 129\n6.1 给网络增加记忆能力 ..... 130\n6．1．1 延时神经网络 ..... 130\n6．1．2 有外部输入的非线性自回归模型 ..... 130\n6．1．3 循环神经网络 ..... 131\n6.2 简单循环网络 ..... 131\n6．2．1 循环神经网络的计算能力 ..... 132\n6.3 应用到机器学习 ..... 134\n6．3．1 序列到类别模式 ..... 134\n6．3．2 同步的序列到序列模式 ..... 135\n6．3．3 异步的序列到序列模式 ..... 135\n6.4 参数学习 ..... 136\n6．4．1 随时间反向传播算法 ..... 137\n6．4．2 实时循环学习算法 ..... 138\n6.5 长程依赖问题 ..... 139\n6．5．1 改进方案 ..... 140\n6.6 基于门控的循环神经网络 ..... 141\n6．6．1 长短期记忆网络 ..... 141\n6．6．2 LSTM 网络的各种变体 ..... 143\n6．6．3 门控循环单元网络 ..... 144\n6.7 深层循环神经网络 ..... 145\n6．7．1 堆叠循环神经网络 ..... 146\n6．7．2 双向循环神经网络 ..... 146\n6.8 扩展到图结构 ..... 147\n6．8．1 递归神经网络 ..... 147\n6．8．2 图神经网络 ..... 148\n6.9 总结和深入阅读 ..... 149\n第7章 网络优化与正则化 ..... 153\n7.1 网络优化 ..... 153\n7．1．1 网络优化的难点 ..... 153\n7.2 优化算法 ..... 156\n7．2．1 小批量梯度下降 ..... 156\n7．2．2 批量大小选择 ..... 157\n7．2．3 学习率调整 ..... 158\n7．2．4 梯度估计修正 ..... 163\n7．2．5 优化算法小结 ..... 166\n7.3 参数初始化 ..... 167\n7．3．1 基于固定方差的参数初始化 ..... 168\n7．3．2 基于方差缩放的参数初始化 ..... 169\n7．3．3 正交初始化 ..... 170\n7.4 数据预处理 ..... 171\n7.5 逐层归一化 ..... 173\n7．5．1 批量归一化 ..... 174\n7．5．2 层归—化 ..... 176\n7．5．3 其他归—化方法 ..... 177\n7.6 超参数优化 ..... 178\n7．6．1 网格搜索 ..... 179\n7．6．2 随机搜索 ..... 179\n7．6．3 贝叶斯优化 ..... 179\n7．6．4 动态资源分配 ..... 181\n7．6．5 神经架构搜索 ..... 182\n7.7 网络正则化 ..... 182\n7．7．1 $\\ell_{1}$ 和 $\\ell_{2}$ 正则化 ..... 182\n7．7．2 权重衰减 ..... 183\n7．7．3 提前停止 ..... 184\n7．7．4 丢弃法 ..... 184\n7．7．5 数据增强 ..... 186\n7．7．6 标签平滑 ..... 187\n7.8 总结和深入阅读 ..... 187\n第8章 注意力机制与外部记忆 ..... 191\n8.1 认知神经学中的注意力 ..... 192\n8.2 注意力机制 ..... 193\n8．2．1 注意力机制的变体 ..... 195\n8.3 自注意力模型 ..... 197\n8.4 人脑中的记忆。 ..... 199\n8.5 记忆增强神经网络 ..... 201\n8．5．1 端到端记忆网络 ..... 202\n8．5．2 神经图灵机 ..... 203\n8.6 基于神经动力学的联想记忆 ..... 206\n8．6．1 Hopfield 网络 ..... 206\n8．6．2 使用联想记忆增加网络容量 ..... 209\n8.7 总结和深入阅读 ..... 209\n第9章 无监督学习 ..... 211\n9.1 无监督特征学习 ..... 212\n9．1．1 主成分分析 ..... 212\n9．1．2 稀疏编码 ..... 213\n9．1．3 自编码器 ..... 216\n9．1．4 稀疏自编码器 ..... 217\n9．1．5 堆叠自编码器 ..... 218\n9．1．6 降噪自编码器 ..... 218\n9.2 概率密度估计 ..... 219\n9．2．1 参数密度估计 ..... 219\n9．2．2 非参数密度估计 ..... 221\n9.3 总结和深入阅读 ..... 224\n第10章 模型独立的学习方式 ..... 226\n10.1 集成学习 ..... 226\n10．1．1 AdaBoost算法 ..... 228\n10.2 自训练和协同训练 ..... 230\n10．2．1 自训练 ..... 231\n10．2．2 协同训练 ..... 231\n10.3 多任务学习 ..... 232\n10.4 迁移学习 ..... 235\n10．4．1 归纳迁移学习 ..... 237\n10．4．2 转导迁移学习 ..... 238\n10.5 终身学习 ..... 240\n10.6 元学习 ..... 243\n10．6．1 基于优化器的元学习 ..... 243\n10．6．2 模型无关的元学习 ..... 245\n10.7 总结和深入阅读 ..... 245\n第三部分 进阶模型 ..... 250\n第11章 概率图模型 ..... 251\n11.1 模型表示 ..... 252\n11．1．1 有向图模型 ..... 253\n11．1．2 常见的有向图模型 ..... 254\n11．1．3 无向图模型 ..... 257\n11．1．4 无向图模型的概率分解 ..... 257\n11．1．5 常见的无向图模型 ..... 259\n11．1．6 有向图和无向图之间的转换 ..... 260\n11.2 学习 ..... 261\n11．2．1 不含隐变量的参数估计 ..... 261\n11．2．2 含隐变量的参数估计 ..... 263\n11.3 推断 ..... 269\n11．3．1 精确推断 ..... 269\n11．3．2 近似推断 ..... 272\n11.4 变分推断 ..... 273\n11.5 基于采样法的近似推断 ..... 275\n11．5．1 采样法 ..... 276\n11．5．2 拒绝采样 ..... 277\n11．5．3 重要性采样 ..... 278\n11．5．4 马尔可夫链蒙特卡罗方法 ..... 279\n11.6 总结和深入阅读 ..... 282\n第12章 深度信念网络 ..... 286\n12.1 玻尔兹曼机 ..... 286\n12．1．1 生成模型 ..... 288\n12．1．2 能量最小化与模拟退火 ..... 290\n12．1．3 参数学习 ..... 291\n12.2 受限玻尔兹曼机 ..... 293\n12．2．1 生成模型 ..... 294\n12．2．2 参数学习 ..... 296\n12．2．3 受限玻尔兹曼机的类型 ..... 297\n12.3 深度信念网络 ..... 298\n12．3．1 生成模型 ..... 299\n12．3．2 参数学习 ..... 300\n12.4 总结和深入阅读 ..... 303\n第13章 深度生成模型 ..... 306\n13.1 概率生成模型 ..... 307\n13．1．1 密度估计 ..... 307\n13．1．2 生成样本 ..... 308\n13．1．3 应用于监督学习 ..... 308\n13.2 变分自编码器 ..... 308\n13．2．1 含隐变量的生成模型 ..... 308\n13．2．2 推断网络 ..... 311\n13．2．3 生成网络 ..... 312\n13．2．4 模型汇总 ..... 313\n13．2．5 再参数化 ..... 314\n13．2．6 训练 ..... 315\n13.3 生成对抗网络 ..... 316\n13．3．1 显式密度模型和隐式密度模型 ..... 316\n13．3．2 网络分解 ..... 317\n13．3．3 训练 ..... 318\n13．3．4 一个生成对抗网络的具体实现：DCGAN ..... 318\n13．3．5 模型分析 ..... 319\n13．3．6 改进模型 ..... 322\n13.4 总结和深入阅读 ..... 324\n14.1 强化学习问题 ..... 329\n14．1．1 典型例子 ..... 329\n14．1．2 强化学习定义 ..... 329\n14．1．3 马尔可夫决策过程 ..... 330\n14．1．4 强化学习的目标函数 ..... 332\n14．1．5 值函数 ..... 333\n14．1．6 深度强化学习 ..... 334\n14.2 基于值函数的学习方法 ..... 335\n14．2．1 动态规划算法 ..... 336\n14．2．2 蒙特卡罗方法 ..... 338\n14．2．3 时序差分学习方法 ..... 339\n14．2．4 深度 Q 网络 ..... 342\n14.3 基于策略函数的学习方法 ..... 344\n14．3．1 REINFORCE 算法 ..... 345\n14．3．2 带基准线的 REINFORCE 算法 ..... 346\n14.4 演员－评论员算法 ..... 347\n14.5 总结和深入阅读 ..... 349\n第15章 序列生成模型 ..... 354\n15.1 序列概率模型 ..... 355\n15．1．1 序列生成 ..... 356\n15.2 N 元统计模型 ..... 357\n15.3 深度序列模型 ..... 359\n15．3．1 参数学习 ..... 361\n15.4 评价方法 ..... 362\n15．4．1 困惑度 ..... 362\n15．4．2 BLEU 算法 ..... 363\n15．4．3 ROUGE算法 ..... 364\n15.5 序列生成模型中的学习问题 ..... 365\n15．5．1 曝光偏差问题 ..... 365\n15．5．2 训练目标不一致问题 ..... 366\n15．5．3 计算效率问题 ..... 367\n15.6 序列到序列模型 ..... 374\n15．6．1 基于循环神经网络的序列到序列模型 ..... 375\n15．6．2 基于注意力的序列到序列模型 ..... 376\n15．6．3 基于自注意力的序列到序列模型 ..... 377\n15.7 总结和深入阅读 ..... 380\n附录 数学基础 ..... 382\n附录 A 线性代数 ..... 383\nA． 1 向量和向量空间 ..... 383\nA．1．1 向量 ..... 383\nA．1．2 向量空间 ..... 383\nA．1．3 范数 ..... 385\nA．1．4 常见的向量 ..... 385\nA． 2 矩阵 ..... 386\nA．2．1 线性映射 ..... 386\nA．2．2 矩阵操作 ..... 387\nA．2．3 矩阵类型 ..... 389\nA．2．4 特征值与特征向量 ..... 390\nA．2．5 矩阵分解 ..... 391\n附录 B 微积分 ..... 393\nB． 1 微分 ..... 393\nB．1．1 导数 ..... 393\nB．1．2 微分 ..... 394\nB．1．3 泰勒公式 ..... 394\nB． 2 积分 ..... 395\nB． 3 矩阵微积分 ..... 396\nB．3．1 ..... 397\nB． 4 常见函数的导数 ..... 398\nB．4．1 向量函数及其导数 ..... 398\nB．4．2 按位计算的向量函数及其导数 ..... 398\n附录 C 数学优化 ..... 402\nC． 1 数学优化的类型 ..... 402\nC．1．1 离散优化和连续优化 ..... 402\nC．1． 2 无约束优化和约束优化 ..... 403\nC．1． 3 线性优化和非线性优化 ..... 403\nC． 2 优化算法 ..... 403\nC．2．1 全局最小解和局部最小解 ..... 404\nC．2．2 梯度下降法 ..... 405\nC． 3 拉格朗日乘数法与KKT条件 ..... 406\nC．3．1 等式约束优化问题 ..... 407\nC．3．2 不等式约束优化问题 ..... 407\n附录 D 概率论 ..... 409\nD． 1 样本空间 ..... 409\nD． 2 事件和概率 ..... 409\nD．2．1 随机变量 ..... 410\nD．2． 2 随机向量 ..... 414\nD． 2.3 边际分布 ..... 415\nD． 2.4 条件概率分布 ..... 416\nD． 2.5 贝叶斯定理 ..... 416\nD． 2.6 独立与条件独立 ..... 417\nD．2． 7 期望和方差 ..... 417\nD． 3 随机过程 ..... 418\nD．3．1 马尔可夫过程 ..... 419\nD．3．2 高斯过程 ..... 420\n附录 $\\mathrm{E} \\quad$ 信息论 ..... 422\nE． 1 熵 ..... 422\nE．1．1 自信息和熵 ..... 422\nE．1．2 熵编码 ..... 423\nE．1．3 联合熵和条件熵 ..... 423\nE． 2 互信息 ..... 424\nE． 3 交义熵和散度 ..... 424\nE．3．1 交叉熵 ..... 424\nE．3．2 KL 散度 ..... 425\nE．3．3 JS 散度 ..... 425\nE．3．4 Wasserstein 距离 ..... 425\nE． 4 总结和深入阅读 ..... 426",
        "总结": ""
      },
      {
        "段落": "## 第一部分",
        "总结": ""
      },
      {
        "段落": "## 机器学习基础",
        "总结": ""
      }
    ]
  },
  {
    "标题": "第1章 绪论",
    "内容": [
      {
        "段落": "# 第1章 绪论 \n\n一个人在不接触对方的情况下，通过一种特殊的方式，和对方进行一系列的问答。如果在相当长时间内，他无法根据这些问题判断对方是人还是计算机，那么就可以认为这个计算机是智能的。<br>一阿兰•图灵（Alan Turing）<br>《Computing Machinery and Intelligence 》\n\n深度学习（Deep Learning）是近年来发展十分迅速的研究领域，并且在人工智能的很多子领域都取得了巨大的成功。从根源来讲，深度学习是机器学习的一个分支，是指一类问题以及解决这类问题的方法．\n\n首先，深度学习问题是一个机器学习问题，指从有限样例中通过算法总结出一般性的规律，并可以应用到新的未知数据上。比如，我们可以从一些历史病例的集合中总结出症状和疾病之间的规律。这样当有新的病人时，我们可以利用总结出来的规律，来判断这个病人得了什么疾病。\n\n其次，深度学习采用的模型一般比较复杂，指样本的原始输入到输出目标之间的数据流经过多个线性或非线性的组件（component）。因为每个组件都会对信息进行加工，并进而影响后续的组件，所以当我们最后得到输出结果时，我们并不清楚其中每个组件的贡献是多少．这个问题叫做贡献度分配问题（Credit Assignment Problem，CAP）［Minsky，1961］．在深度学习中，贡献度分配问题是一个很关键的问题，这关系到如何学习每个组件中的参数．\n\n目前，一种可以比较好解决贡献度分配问题的模型是人工神经网络（Artifi－ cial Neural Network，ANN）。人工神经网络，也简称神经网络，是一种受人脑神经系统的工作方式启发而构造的数学模型。和目前计算机的结构不同，人脑神经系统是一个由生物神经元组成的高度复杂网络，是一个并行的非线性信息处理系统。人脑神经系统可以将声音、视觉等信号经过多层的编码，从最原始的低层特征不断加工、抽象，最终得到原始信号的语义表示。和人脑神经网络类似，人工神经\n\n贡献度分配问题也经常翻译为信用分配问题或功劳分配问题。\n\n网络是由人工神经元以及神经元之间的连接构成，其中有两类特殊的神经元：一类是用来接收外部的信息，另一类是输出信息。这样，神经网络可以看作是信息从输入到输出的信息处理系统。如果我们把神经网络看作是由一组参数控制的复杂函数，并用来处理一些模式识别任务（比如语音识别、人脸识别等），神经网络的参数可以通过机器学习的方式来从数据中学习。因为神经网络模型一般比较复杂，从输入到输出的信息传递路径一般比较长，所以复杂神经网络的学习可以看成是一种深度的机器学习，即深度学习．\n\n神经网络和深度学习并不等价．深度学习可以采用神经网络模型，也可以采用其他模型（比如深度信念网络是一种概率图模型）。但是，由于神经网络模型可以比较容易地解决贡献度分配问题，因此神经网络模型成为深度学习中主要采用的模型。虽然深度学习一开始用来解决机器学习中的表示学习问题，但是由于其强大的能力，深度学习越来越多地用来解决一些通用人工智能问题，比如推理、决策等。\n\n在本书中，我们主要介绍有关神经网络和深度学习的基本概念、相关模型、学习方法以及在计算机视觉、自然语言处理等领域的应用．在本章中，我们先介绍人工智能的基础知识，然后再介绍神经网络和深度学习的基本概念。",
        "总结": "- 概念：图灵测试，用于判断计算机是否具备智能。  \n- 概念：深度学习，作为机器学习的一个分支，通过复杂模型从数据中学习规律。  \n- 概念：贡献度分配问题（CAP），指在多层模型中确定每个组件对输出的贡献。  \n- 概念：人工神经网络（ANN），受人脑神经系统的启发，由神经元和连接构成的数学模型。  \n- 概念：深度学习与神经网络的关系，深度学习可以使用神经网络或其他模型，但神经网络是主要模型。  \n- 算法/模型：神经网络作为深度学习的核心模型，用于处理模式识别任务。  \n- 应用领域：深度学习在计算机视觉、自然语言处理等领域的应用。  \n- 定理/命题：深度学习通过解决贡献度分配问题，实现对复杂数据的建模与学习。"
      },
      {
        "段落": "## 1.1 人工智能\n\n智能（Intelligence）是现代生活中很常见的一个词，比如智能手机、智能家居、智能驾驶等。在不同使用场合中，智能的含义也不太一样。比如＂智能手机＂中的＂智能＂一般是指由计算机控制并具有某种智能行为。这里的＂计算机控制＂＋ ＂智能行为＂隐含了对人工智能的简单定义．\n\n简单地讲，人工智能（Artificial Intelligence，AI）就是让机器具有人类的智能，这也是人们长期追求的目标。这里关于什么是＂智能＂并没有一个很明确的定义，但一般认为智能（或特指人类智能）是知识和智力的总和，都和大脑的思维活动有关。人类大脑是经过了上亿年的进化才形成了如此复杂的结构，但我们至今仍然没有完全了解其工作机理。虽然随着神经科学、认知心理学等学科的发展，人们对大脑的结构有了一定程度的了解，但对大脑的智能究竟是怎么产生的还知道的很少。我们并不理解大脑的运作原理，以及如何产生意识、情感、记忆等功能。因此，通过＂复制＂一个人脑来实现人工智能在目前阶段是不切实际的。\n\n1950年，阿兰•图灵（Alan Turing）发表了一篇有着重要影响力的论文《Computing Machinery and Intelligence》，讨论了创造一种＂智能机器＂的可能性．由于＂智能＂一词比较难以定义，他提出了著名的图灵测试：＂一个人在不接触对方的情况下，通过一种特殊的方式和对方进行一系列的问答。如果在相当长时间内，他无法根据这些问题判断对方是人还是计算机，那么就可以认为这个计算\n\n表示学习参见第1．3节。\n＂智能＂可以理解为＂智力＂和＂能力＂．前者是智能的基础，后者是指获取和运用知识求解的能力。\n\n机是智能的＂。图灵测试是促使人工智能从哲学探讨到科学研究的一个重要因素，引导了人工智能的很多研究方向．因为要使得计算机能通过图灵测试，计算机就必须具备理解语言、学习、记忆、推理、决策等能力。这样，人工智能就延伸出了很多不同的子学科，比如机器感知（计算机视觉、语音信息处理）、学习（模式识别、机器学习、强化学习）、语言（自然语言处理）、记忆（知识表示）、决策（规划、数据挖掘）等．所有这些研究领域都可以看成是人工智能的研究范畴．\n\n人工智能是计算机科学的一个分支，主要研究、开发用于模拟、延伸和扩展人类智能的理论、方法、技术及应用系统等。和很多其他学科不同，人工智能这个学科的诞生有着明确的标志性事件，就是1956年的达特茅斯（Dartmouth）会议．在这次会议上，＂人工智能＂被提出并作为本研究领域的名称．同时，人工智能研究的使命也得以确定．John McCarthy 提出了人工智能的定义：人工智能就是要让机器的行为看起来就像是人所表现出的智能行为一样．\n\n目前，人工智能的主要领域大体上可以分为以下几个方面：\n\n感知 即模拟人的感知能力，对外部刺激信息（视觉和语音等）进行感知和加工．主要研究领域包括语音信息处理和计算机视觉等。\n\n学习 即模拟人的学习能力，主要研究如何从样例或与环境交互中进行学习。主要研究领域包括监督学习、无监督学习和强化学习等。\n\n认知 即模拟人的认知能力，主要研究领域包括知识表示、自然语言理解、推理、规划、决策等。",
        "总结": "- 人工智能（AI）是让机器具备人类智能的学科，旨在模拟、延伸和扩展人类智能。  \n- 智能被理解为智力与能力的结合，智力是基础，能力涉及知识获取与运用。  \n- 图灵测试是判断机器是否具备智能的重要标准，推动人工智能从哲学走向科学研究。  \n- 人工智能的主要研究领域包括感知（如计算机视觉、语音处理）、学习（如监督学习、强化学习）和认知（如知识表示、自然语言理解）。  \n- 人工智能的诞生标志是1956年的达特茅士会议，John McCarthy 提出其核心定义：使机器行为看起来像人类智能行为。"
      },
      {
        "段落": "## 1．1．1 人工智能的发展历史\n\n人工智能从诞生至今，经历了一次又一次的繁荣与低谷，其发展历程大体上可以分为＂推理期＂、＂知识期＂和＂学习期＂［周志华，2016］．",
        "总结": "- 人工智能的发展历史分为三个主要阶段：推理期、知识期和学习期。  \n- 推理期主要依赖逻辑推理和规则系统。  \n- 知识期强调知识的表示与利用，以提高系统的智能化水平。  \n- 学习期则关注通过数据驱动的方法，使系统具备学习能力。  \n- 周志华（2016）对人工智能的发展阶段进行了系统总结。"
      },
      {
        "段落": "### 1．1．1．1 推理期\n\n1956年达特茅斯会议之后，研究者对人工智能的热情高涨，之后的十几年是人工智能的黄金时期。大部分早期研究者都通过人类的经验，基于逻辑或者事实归纳出来一些规则，然后通过编写程序来让计算机完成一个任务。这个时期中，研究者开发了一系列的智能系统，比如几何定理证明器、语言翻译器等。这些初步的研究成果也使得研究者们对开发出具有人类智能的机器过于乐观，低估了实现人工智能的难度。有些研究者甚至认为：＂二十年内，机器将能完成人能做到的一切工作＂，＂在三到八年的时间里可以研发出一台具有人类平均智能的机器＂。但随着研究的深入，研究者意识到这些推理规则过于简单，对项目难度评估不足，原来的乐观预期受到严重打击。人工智能的研究开始陷入低谷，很多人工智能项目的研究经费也被消减。\nhttps：／／nndl．github．io／\n\nJohn McCarthy（19－ 27～2011），人工智能学科奠基人之一， 1971年图灵奖得主．\n\n人工智能低谷，也叫人工智能冬天（AI Win－ ter），指人工智能史上研究资金及学术界研究兴趣都大幅减少的时期．人工智能领域经历过好几次低谷期．每次狂热高潮之后，紧接着是失望、批评以及研究资金断绝，然后在几十年后又重燃研究兴趣。1974年～1980年及 1987年～1993年是两个主要的低谷时期，其他还有几个较小的低谷。",
        "总结": "- 推理期是指1956年达特茅斯会议后，人工智能研究的初期阶段，研究者基于逻辑和归纳规则开发智能系统，如几何定理证明器和语言翻译器。  \n- 该时期研究者对实现人工智能过于乐观，认为机器可在短期内完成人类所有工作，甚至具备人类平均智能。  \n- 随着研究深入，发现推理规则过于简单，低估了实现人工智能的难度，导致研究热情下降，进入人工智能低谷（又称AI冬天）。  \n- 人工智能低谷是指研究资金和学术兴趣大幅减少的时期，历史上曾多次发生，如1974～1980年和1987～1993年为主要低谷期。  \n- John McCarthy是人工智能学科奠基人之一，1971年图灵奖得主。"
      },
      {
        "段落": "### 1．1．1．2 知识期\n\n到了 20 世纪70年代，研究者意识到知识对于人工智能系统的重要性。特别是对于一些复杂的任务，需要专家来构建知识库。在这一时期，出现了各种各样的专家系统（Expert System），并在特定的专业领域取得了很多成果。专家系统可以简单理解为＂知识库 + 推理机＂，是一类具有专门知识和经验的计算机智能程序系统。专家系统一般采用知识表示和知识推理等技术来完成通常由领域专家才能解决的复杂问题，因此专家系统也被称为基于知识的系统。一个专家系统必须具备三要素：（1）领域专家级知识；（2）模拟专家思维；（3）达到专家级的水平。在这一时期，Prolog（Programming in Logic）语言是主要的开发工具，用来建造专家系统、智能知识库以及处理自然语言理解等。",
        "总结": "- 知识期是20世纪70年代人工智能发展的一个阶段，强调知识在人工智能系统中的重要性。  \n- 专家系统是该时期的重要成果，被视为“知识库 + 推理机”的组合，用于解决复杂问题。  \n- 专家系统具备三要素：领域专家级知识、模拟专家思维、达到专家级水平。  \n- Prolog语言是当时主要的开发工具，用于构建专家系统、智能知识库及处理自然语言理解。"
      },
      {
        "段落": "### 1．1．1．3 学习期\n\n对于人类的很多智能行为（比如语言理解、图像理解等），我们很难知道其\n\nProlog是一种基于逻辑学理论而创建的逻辑编程语言，最初被运用于自然语言、逻辑推理等研究领域。中的原理，也无法描述出这些智能行为背后的＂知识＂。因此，我们也很难通过知识和推理的方式来实现这些行为的智能系统。为了解决这类问题，研究者开始将研究重点转向让计算机从数据中自己学习。事实上，＂学习＂本身也是一种智能行为。从人工智能的萌芽时期开始，就有一些研究者尝试让机器来自动学习，即机器学习（Machine Learning，ML）。机器学习的主要目的是设计和分析一些学习算法，让计算机可以从数据（经验）中自动分析获得规律，并利用学习到的规律对未知数据进行预测，从而帮助人们完成一些特定任务，提高开发效率。机器学习的研究内容也十分广泛，涉及了线性代数、概率论、统计学、数学优化、计算复杂性等多门学科。在人工智能领域，机器学习从一开始就是一个重要的研究方向。但直到1980年后，机器学习因其在很多领域的出色表现，才逐渐成为热门学科。\n\n图1．1给出了人工智能发展史上的重要事件．在发展了 60 多年后，人工智能虽然可以在某些方面超越人类，但想让机器真正通过图灵测试，具备真正意义上的人类智能，这个目标看上去仍然遥遥无期．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-018.jpg?height=203&width=1126&top_left_y=1635&top_left_x=90)\n\n图 1.1 人工智能发展史",
        "总结": "- 概念：学习期是指人工智能发展过程中，研究者开始关注让计算机从数据中自动学习，以模拟人类智能行为的阶段。\n- 算法：机器学习（Machine Learning, ML）是该阶段的核心算法，旨在设计和分析学习算法，使计算机能够从数据中自动分析并获得规律。\n- 定理/命题：未提及具体定理或命题。\n- 数学推导：未提及具体数学推导。"
      },
      {
        "段落": "## 1．1．2 人工智能的流派\n\n目前我们对人类智能的机理依然知之甚少，还没有一个通用的理论来指导如何构建一个人工智能系统。不同的研究者都有各自的理解，因此在人工智能的研究过程中产生了很多不同的流派。比如一些研究者认为人工智能应该通过研究人类智能的机理来构建一个仿生的模拟系统，而另外一些研究者则认为可以使用其他方法来实现人类的某种智能行为。一个著名的例子是让机器具有飞行能力不需要模拟鸟的飞行方式，而是应该研究空气动力学。\n\n尽管人工智能的流派非常多，但主流的方法大体上可以归结为以下两种：\n（1）符号主义（Symbolism），又称逻辑主义、心理学派或计算机学派，是通过分析人类智能的功能，然后通过计算机来实现这些功能。符号主义有两个基本假设：（a）信息可以用符号来表示；（b）符号可以通过显式的规则（比如逻辑运算）来操作。人类的认知过程可以看作是符号操作过程。在人工智能的推理期和知识期，符号主义的方法比较盛行，并取得了大量的成果。\n（2）连接主义（Connectionism），又称仿生学派或生理学派，是认知科学领域中的一类信息处理的方法和理论。在认知科学领域，人类的认知过程可以看作是一种信息处理过程。连接主义认为人类的认知过程是由大量简单神经元构成的神经网络中的信息处理过程，而不是符号运算。因此，连接主义模型的主要结构是由大量简单的信息处理单元组成的互联网络，具有非线性、分布式、并行化、局部性计算以及自适应性等特性．\n\n符号主义方法的一个优点是可解释性，而这也正是连接主义方法的弊端．深度学习的主要模型神经网络就是一种连接主义模型。随着深度学习的发展，越来越多的研究者开始关注如何融合符号主义和连接主义，建立一种高效并且具有可解释性的模型．",
        "总结": "- 本节提出人工智能的两种主要流派：符号主义和连接主义。  \n- 符号主义认为智能可以通过符号表示和逻辑规则操作实现，强调可解释性。  \n- 连接主义认为智能源于神经网络中的信息处理，强调非线性、分布式和自适应性。  \n- 深度学习是连接主义的典型代表，但其可解释性较差。  \n- 当前研究趋势是融合符号主义与连接主义，以实现高效且可解释的模型。"
      },
      {
        "段落": "## 1.2 机器学习\n\n机器学习（Machine Learning，ML）是指从有限的观测数据中学习（或＂猜测＂）出具有一般性的规律，并利用这些规律对未知数据进行预测的方法。机器学习是人工智能的一个重要分支，并逐渐成为推动人工智能发展的关键因素．\n\n传统的机器学习主要关注于如何学习一个预测模型。 一般需要首先将数据表示为一组特征（Feature），特征的表示形式可以是连续的数值、离散的符号或其他形式。然后将这些特征输入到预测模型，并输出预测结果。这类机器学习可以看作是浅层学习（Shallow Learning）。浅层学习的一个重要特点是不涉及特征学习，其特征主要靠人工经验或特征转换方法来抽取。\n\n关于人工智能的流派并没有严格的划分定义，也不严格对立。\n有很多文献将人工智能流派分为符号主义、连接主义和行为主义三种，其中行为主义 （Actionism）主要从生物进化的角度考虑，主张从和外界环境的互动中获取智能。\n\n机器学习的详细介绍参见第2章。\n\n当我们用机器学习来解决实际任务时，会面对多种多样的数据形式，比如声音、图像、文本等。不同数据的特征构造方式差异很大。对于图像这类数据，我们可以很自然地将其表示为一个连续的向量。而对于文本数据，因为其一般由离散符号组成，并且每个符号在计算机内部都是表示为无意义的编码，所以通常很难找到合适的表示方式。因此，在实际任务中使用机器学习模型一般会包含以下几个步骤（如图1．2所示）：\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-020.jpg?height=131&width=1082&top_left_y=474&top_left_x=112)\n\n图 1.2 传统机器学习的数据处理流程\n（1）数据预处理：经过数据的预处理，如去除噪声等．比如在文本分类中，去除停用词等。\n（2）特征提取：从原始数据中提取一些有效的特征．比如在图像分类中，提取边缘、尺度不变特征变换（Scale Invariant Feature Transform，SIFT）特征等。\n（3）特征转换：对特征进行一定的加工，比如降维和升维。降维包括特征抽取 （Feature Extraction）和特征选择（Feature Selection）两种途径。常用的特征转换方法有主成分分析（Principal Components Analysis，PCA）、线性判别分析（Linear Discriminant Analysis，LDA）等。\n（4）预测：机器学习的核心部分，学习一个函数进行预测。\n\n上述流程中，每步特征处理以及预测一般都是分开进行处理的。传统的机器学习模型主要关注于最后一步，即构建预测函数。但是实际操作过程中，不同预测模型的性能相差不多，而前三步中的特征处理对最终系统的准确性有着十分关键的作用。特征处理一般都需要人工干预完成，利用人类的经验来选取好的特征，并最终提高机器学习系统的性能。因此，很多的机器学习问题变成了特征工程（Feature Engineering）问题。开发一个机器学习系统的主要工作量都消耗在了预处理、特征提取以及特征转换上。",
        "总结": "- 机器学习是指从有限的观测数据中学习一般性规律，并利用这些规律对未知数据进行预测的方法，是人工智能的重要分支。  \n- 传统机器学习关注预测模型的构建，特征通常由人工经验或转换方法提取，属于浅层学习，不涉及特征学习。  \n- 人工智能流派包括符号主义、连接主义和行为主义，其中行为主义主张通过与环境互动获取智能。  \n- 机器学习处理流程包括数据预处理、特征提取、特征转换和预测四个步骤，其中特征处理对系统性能至关重要。  \n- 特征处理通常需要人工干预，因此许多机器学习问题转化为特征工程问题，开发系统的主要工作量集中在预处理和特征处理上。"
      },
      {
        "段落": "## 1.3 表示学习\n\n为了提高机器学习系统的准确率，我们就需要将输入信息转换为有效的特征，或者更一般性称为表示（Representation）。如果有一种算法可以自动地学习出有效的特征，并提高最终机器学习模型的性能，那么这种学习就可以叫做表示学习（Representation Learning）。\n\n将图像数据表示为向量的方法有很多种，比如直接将一幅图像的所有像素值（灰度值或 RGB 值）组成一个连续向量。\n\n很多特征转换方法也都是机器学习方法。\n\n主成分分析参见第 9．1．1节。\n\n语义鸿沟 表示学习的关键是解决语义鸿沟（Semantic Gap）问题。语义鸿沟问题是指输入数据的底层特征和高层语义信息之间的不一致性和差异性。比如给定一些关于＂车＂的图片，由于图片中每辆车的颜色和形状等属性都不尽相同，因此不同图片在像素级别上的表示（即底层特征）差异性也会非常大。但是我们理解这些图片是建立在比较抽象的高层语义概念上的。如果一个预测模型直接建立在底层特征之上，会导致对预测模型的能力要求过高。如果可以有一个好的表示在某种程度上能够反映出数据的高层语义特征，那么我们就可以相对容易地构建后续的机器学习模型。\n\n在表示学习中，有两个核心问题：一是＂什么是一个好的表示＂；二是＂如何学习到好的表示＂。",
        "总结": "- 表示学习是指自动学习有效特征以提高机器学习模型性能的方法  \n- 输入信息通过转换为特征向量（如图像像素值）进行表示  \n- 特征转换方法多为机器学习方法，如主成分分析（PCA）  \n- 语义鸿沟是表示学习的核心问题，指底层特征与高层语义信息的不一致性  \n- 表示学习的两个核心问题：如何定义好的表示，以及如何学习到好的表示"
      },
      {
        "段落": "## 1．3．1 局部表示和分布式表示\n\n＂好的表示＂是一个非常主观的概念，没有一个明确的标准．但一般而言，一个好的表示具有以下几个优点：\n（1）一个好的表示应该具有很强的表示能力，即同样大小的向量可以表示更多信息。\n（2）一个好的表示应该使后续的学习任务变得简单，即需要包含更高层的语义信息。\n（3）一个好的表示应该具有一般性，是任务或领域独立的。虽然目前的大部分表示学习方法还是基于某个任务来学习，但我们期望其学到的表示可以比较容易地迁移到其他任务上。\n\n在机器学习中，我们经常使用两种方式来表示特征：局部表示（Local Repre－ sentation）和分布式表示（Distributed Representation）。\n\n以颜色表示为例，我们可以用很多词来形容不同的颜色 ${ }^{1}$ ，除了基本的＂红＂、 ＂蓝＂、＂绿＂、＂白＂、＂黑＂等之外，有很多以地区或物品命名的，比如＂中国红＂、 ＂天蓝色＂、＂咖啡色＂、＂琥珀色＂等。如果要在计算机中表示颜色，一般有两种表示方法。\n\n一种表示颜色的方法是以不同名字来命名不同的颜色，这种表示方式叫做局部表示，也称为离散表示或符号表示。局部表示通常可以表示为one－hot 向量的形式。假设所有颜色的名字构成一个词表 $\\mathcal{V}$ ，词表大小为 $|\\mathcal{V}|$ 。我们可以用一个 $|\\mathcal{V}|$ 维的 one－hot 向量来表示每一种颜色。在第 $i$ 种颜色对应的 one－hot 向量中，第 one－hot 向量 参 见 第 A．1．4节． $i$ 维的值为 1 ，其他都为 0 ．\n\n[^0]局部表示有两个优点：（1）这种离散的表示方式具有很好的解释性，有利于人工归纳和总结特征，并通过特征组合进行高效的特征工程；（2）通过多种特征组合得到的表示向量通常是稀疏的二值向量，当用于线性模型时计算效率非常高。但局部表示有两个不足之处：（1）one－hot 向量的维数很高，且不能扩展。如果有一种新的颜色，我们就需要增加一维来表示；（2）不同颜色之间的相似度都为 0 ，即我们无法知道＂红色＂和＂中国红＂的相似度要高于＂红色＂和＂黑色＂的相似度．\n\n另一种表示颜色的方法是用 RGB 值来表示颜色，不同颜色对应到 R、G、B 三维空间中一个点，这种表示方式叫做分布式表示。分布式表示通常可以表示为低维的稠密向量．\n\n和局部表示相比，分布式表示的表示能力要强很多，分布式表示的向量维度一般都比较低。我们只需要用一个三维的稠密向量就可以表示所有颜色。并且，分布式表示也很容易表示新的颜色名。此外，不同颜色之间的相似度也很容易计算。\n\n表1．1列出了 4 种颜色的局部表示和分布式表示。\n表1．1局部表示和分布式表示示例\n\n| 颜色 | 局部表示 | 分布式表示 |\n| :---: | :--- | :--- |\n| 琥珀色 | $[1,0,0,0]^{\\top}$ | $[1.00,0.75,0.00]^{\\top}$ |\n| 天蓝色 | $[0,1,0,0]^{\\top}$ | $[0.00,0.5,1.00]^{\\top}$ |\n| 中国红 | $[0,0,1,0]^{\\top}$ | $[0.67,0.22,0.12]^{\\top}$ |\n| 咖啡色 | $[0,0,0,1]^{\\top}$ | $[0.44,0.310 .22]^{\\top}$ |\n\n我们可以使用神经网络来将高维的局部表示空间 $\\mathbb{R}^{|\\mathcal{V}|}$ 映射到一个非常低维的分布式表示空间 $\\mathbb{R}^{D}, D \\ll|\\mathcal{V}|$ 。在这个低维空间中，每个特征不再是坐标轴上的点，而是分散在整个低维空间中。在机器学习中，这个过程也称为嵌入（Em－ bedding）。嵌入通常指将一个度量空间中的一些对象映射到另一个低维的度量空间中，并尽可能保持不同对象之间的拓扑关系。比如自然语言中词的分布式表示，也经常叫做词嵌入。\n\n图1．3展示了一个 3 维 one－hot 向量空间和一个 2 维嵌入空间的对比．在 one－ hot 向量空间中，每个特征都位于坐标轴上，每个坐标轴上一个特征．而在低维的嵌入空间中，每个特征都不在坐标轴上，特征之间可以计算相似度。\n\n分布式表示叫做分散式表示可能更容易理解，即一种颜色的语义分散到语义空间中的不同基向量上。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-023.jpg?height=573&width=573&top_left_y=126&top_left_x=367)\n\n图 1.3 one－hot 向量空间与嵌入空间",
        "总结": "- 局部表示和分布式表示是机器学习中两种常用的特征表示方法。  \n- 局部表示使用离散的one-hot向量形式，具有解释性强、计算效率高的优点，但存在维度高、无法有效表示相似度的问题。  \n- 分布式表示使用低维稠密向量形式，具有更强的表示能力、可扩展性好、能有效计算相似度等优点。  \n- 局部表示通常用于线性模型，而分布式表示常用于神经网络中的嵌入（Embedding）过程。  \n- 分布式表示的语义信息分散在向量的不同基向量上，能更好地捕捉语义关系。  \n- 表1.1展示了局部表示和分布式表示的具体示例，对比了不同颜色的表示方式。  \n- 图1.3展示了one-hot向量空间与嵌入空间的对比，说明了分布式表示在低维空间中的分布特性。"
      },
      {
        "段落": "## 1．3．2 表示学习\n\n要学习到一种好的高层语义表示（一般为分布式表示），通常需要从底层特征开始，经过多步非线性转换才能得到。一个深层结构的优点是可以增加特征的重用性，从而指数级地增加表示能力。因此，表示学习的关键是构建具有一定深度的多层次特征表示［Bengio et al．，2013］．\n\n在传统的机器学习中，也有很多有关特征学习的方法，比如主成分分析、线性判别分析、独立成分分析等。但是，传统的特征学习一般是通过人为地设计一些准则，然后根据这些准则来选取有效的特征。特征的学习是和最终预测模型的学习分开进行的，因此学习到的特征不一定可以提升最终模型的性能。",
        "总结": "- 表示学习旨在学习高层语义表示，通常通过多步非线性转换从底层特征得到。  \n- 深层结构能增强特征重用性，从而显著提升表示能力。  \n- 传统特征学习方法如主成分分析、线性判别分析等，依赖人工设计准则选取特征。  \n- 传统方法中特征学习与最终模型学习是分开进行的，可能无法提升模型性能。"
      },
      {
        "段落": "## 1.4 深度学习\n\n为了学习一种好的表示，需要构建具有一定＂深度＂的模型，并通过学习算法来让模型自动学习出好的特征表示（从底层特征，到中层特征，再到高层特征），从而最终提升预测模型的准确率。所谓＂深度＂是指原始数据进行非线性特征转换的次数。如果把一个表示学习系统看作是一个有向图结构，深度也可以看作是从输入节点到输出节点所经过的最长路径的长度．\n\n这样我们就需要一种学习方法可以从数据中学习一个＂深度模型＂，这就是深度学习（Deep Learning，DL）。深度学习是机器学习的一个子问题，其主要目的是从数据中自动学习到有效的特征表示。\n\n图1．4给出了深度学习的数据处理流程．通过多层的特征转换，把原始数据变成更高层次、更抽象的表示。这些学习到的表示可以替代人工设计的特征，从而避\n\n连续多次的线性转换等价于一次线性转换．\n\n参见第 2．6．1 节．\n\n深度学习虽然早期主要用来进行表示学习，但后来越来越多地用来进行处理更加复杂的推理、决策等问题．\n\n免＂特征工程＂．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-024.jpg?height=172&width=1086&top_left_y=199&top_left_x=110)\n\n图 1.4 深度学习的数据处理流程\n\n深度学习是将原始的数据特征通过多步的特征转换得到一种特征表示，并进一步输入到预测函数得到最终结果．和＂浅层学习＂不同，深度学习需要解决的关键问题是贡献度分配问题（Credit Assignment Problem，CAP）［Minsky，1961］，即一个系统中不同的组件（component）或其参数对最终系统输出结果的贡献或影响。以下围棋为例，每当下完一盘棋，最后的结果要么赢要么输。我们会思考哪几步棋导致了最后的胜利，或者又是哪几步棋导致了最后的败局。如何判断每一步棋的贡献就是贡献度分配问题，这是一个非常困难的问题。从某种意义上讲，深度学习可以看作是一种强化学习（Reinforcement Learning，RL），每个内部组件并不能直接得到监督信息，需要通过整个模型的最终监督信息（奖励）得到，并且有一定的延时性．\n\n目前，深度学习采用的模型主要是神经网络模型，其主要原因是神经网络模型可以使用误差反向传播算法，从而可以比较好地解决贡献度分配问题。只要是超过一层的神经网络都会存在贡献度分配问题，因此超过一层的神经网络都可以看作是深度学习模型。随着深度学习的快速发展，模型深度也从早期的 $5 \\sim 10$ 层到目前的数百层。随着模型深度的不断增加，其特征表示的能力也越来越强，从而使后续的预测更加容易。",
        "总结": "- 概念：深度学习是一种机器学习方法，通过构建具有“深度”的模型，从数据中自动学习有效的特征表示，以提升预测准确率。  \n- 概念：深度指的是原始数据经过非线性特征转换的次数，也可视为从输入到输出的最长路径长度。  \n- 算法：深度学习通过多层特征转换将原始数据转化为更高层次、更抽象的表示，替代人工设计的特征。  \n- 算法：误差反向传播算法被广泛用于解决贡献度分配问题（Credit Assignment Problem），这是深度学习的核心挑战之一。  \n- 定理/命题：超过一层的神经网络都存在贡献度分配问题，因此都可以视为深度学习模型。  \n- 数学推导：连续多次的线性转换等价于一次线性转换，这表明非线性转换是深度学习的关键。  \n- 推理：深度学习可以被视为一种强化学习形式，其中内部组件通过最终监督信息（奖励）进行学习，并具有延时性。  \n- 发展趋势：深度学习模型的深度从早期的5~10层发展到目前的数百层，其特征表示能力随深度增加而增强。"
      },
      {
        "段落": "## 1．4．1 端到端学习\n\n在一些复杂任务中，传统机器学习方法需要将一个任务的输入和输出之间人为地切割成很多子模块（或多个阶段），每个子模块分开学习。比如一个自然语言理解任务，一般需要分词、词性标注、句法分析、语义分析、语义推理等步骤。这种学习方式有两个问题：一是每一个模块都需要单独优化，并且其优化目标和任务总体目标并不能保证一致；二是错误传播，即前一步的错误会对后续的模型造成很大的影响．这样就增加了机器学习方法在实际应用的难度．\n\n端到端学习（End－to－End Learning），也称端到端训练，是指在学习过程中不进行分模块或分阶段训练，直接优化任务的总体目标。在端到端学习中，一般不需要明确地给出不同模块或阶段的功能，中间过程不需要人为干预。端到端学习的训练数据为＂输入－输出＂对的形式，无需提供其他额外信息。因此，端到端学习和深度学习一样，都是要解决贡献度分配问题。目前，大部分采用神经网络模型的\n\n深度学习也可以看作是一种端到端的学习．",
        "总结": "- 端到端学习的概念：端到端学习是指不进行分模块或分阶段训练，直接优化任务的总体目标，无需明确各模块功能或人为干预中间过程。  \n- 端到端学习的特点：训练数据为“输入-输出”对形式，无需额外信息，解决贡献度分配问题。  \n- 传统方法的问题：需要人为切割任务为多个子模块，各模块单独优化，目标不一致，且存在错误传播问题。  \n- 深度学习与端到端学习的关系：深度学习可视为一种端到端学习方法。"
      },
      {
        "段落": "## 1.5 神经网络\n\n随着神经科学、认知科学的发展，我们逐渐知道人类的智能行为都和大脑活动有关。人类大脑是一个可以产生意识、思想和情感的器官。受到人脑神经系统的启发，早期的神经科学家构造了一种模仿人脑神经系统的数学模型，称为人工神经网络，简称神经网络。在机器学习领域，神经网络是指由很多人工神经元构成的网络结构模型，这些人工神经元之间的连接强度是可学习的参数．",
        "总结": "- 概念：神经网络是一种模仿人脑神经系统的数学模型，由许多人工神经元构成，神经元之间的连接强度是可学习的参数。  \n- 背景：神经网络的发展受到神经科学和认知科学的影响，人类智能行为与大脑活动密切相关。  \n- 应用领域：在机器学习中，神经网络被用来构建能够学习和适应的模型。"
      },
      {
        "段落": "## 1．5．1 人脑神经网络\n\n人类大脑是人体最复杂的器官，由神经元、神经胶质细胞、神经干细胞和血管组成。其中，神经元（Neuron），也叫神经细胞（Nerve Cell），是携带和传输信息的细胞，是人脑神经系统中最基本的单元。人脑神经系统是一个非常复杂的组织，包含近 860 亿个神经元［Azevedo et al．，2009］，每个神经元有上千个突触和其他神经元相连接。这些神经元和它们之间的连接形成巨大的复杂网络，其中神经连接的总长度可达数千公里。我们人造的复杂网络，比如全球的计算机网络，和大脑神经网络相比要＂简单＂得多。\n\n早在1904年，生物学家就已经发现了神经元的结构．典型的神经元结构大致可分为细胞体和细胞突起．\n（1）细胞体（Soma）中的神经细胞膜上有各种受体和离子通道，胞膜的受体可与相应的化学物质神经递质结合，引起离子通透性及膜内外电位差发生改变，产生相应的生理活动：兴奋或抑制。\n（2）细胞突起是由细胞体延伸出来的细长部分，又可分为树突和轴突。\n（a）树突（Dendrite）可以接收刺激并将兴奋传入细胞体．每个神经元可以有一或多个树突．\n（b）轴突（Axon）可以把自身的兴奋状态从胞体传送到另一个神经元或其他组织。每个神经元只有一个轴突。\n\n神经元可以接收其他神经元的信息，也可以发送信息给其他神经元。神经元之间没有物理连接，中间留有 20 纳米左右的缝隙。神经元之间靠突触（Synapse）进行互联来传递信息，形成一个神经网络，即神经系统．突触可以理解为神经元之间的链接＂接口＂，将一个神经元的兴奋状态传到另一个神经元。一个神经元可被视为一种只有两种状态的细胞：兴奋和抑制。神经元的状态取决于从其它的神经细胞收到的输入信号量，及突触的强度（抑制或加强）。当信号量总和超过了某\n\n个阈值时，细胞体就会兴奋，产生电脉冲．电脉冲沿着轴突并通过突触传递到其他神经元．图1．5给出了一种典型的神经元结构．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-026.jpg?height=496&width=799&top_left_y=265&top_left_x=247)\n\n图 1.5 典型神经元结构 ${ }^{1}$\n\n我们知道，一个人的智力不完全由遗传决定，大部分来自于生活经验．也就是说人脑神经网络是一个具有学习能力的系统。那么人脑神经网络是如何学习的呢？在人脑神经网络中，每个神经元本身并不重要，重要的是神经元如何组成网络。不同神经元之间的突触有强有弱，其强度是可以通过学习（训练）来不断改变的，具有一定的可塑性．不同的连接形成了不同的记忆印痕．1949年，加拿大心理学家 Donald Hebb 在《行为的组织》（The Organization of Behavior）一书中提出突触可塑性的基本原理，＂当神经元 A 的一个轴突和神经元 B 很近，足以对它产生影响，并且持续地、重复地参与了对神经元 B 的兴奋，那么在这两个神经元或其中之一会发生某种生长过程或新陈代谢变化，以致于神经元 A作为能使神经元 B 兴奋的细胞之一，它的效能加强了。＂这个机制称为赫布理论（Hebbian Theory）或赫布法则（Hebb＇s Rule）。如果两个神经元总是相关联地受到刺激，它们之间的突触强度增加．这样的学习方法被称为赫布型学习 （Hebbian learning）。 Hebb 认为人脑有两种记忆：长期记忆和短期记忆。短期记忆持续时间不超过一分钟。如果一个经验重复足够的次数，此经验就可储存在长期记忆中．短期记忆转化为长期记忆的过程就称为凝固作用．人脑中的海马区为大脑结构凝固作用的核心区域。",
        "总结": "- 概念：人脑神经网络是由大量神经元和突触组成的复杂网络，用于信息的传递和处理。\n- 概念：神经元是人脑神经系统的基本单元，具有细胞体、树突和轴突的结构。\n- 概念：突触是神经元之间的连接接口，通过化学物质传递信号，影响神经元的兴奋或抑制状态。\n- 概念：神经元的状态由输入信号量和突触强度决定，当信号总和超过阈值时，产生电脉冲。\n- 概念：人脑神经网络具有学习能力，通过突触强度的变化实现学习和记忆。\n- 算法/理论：赫布理论（Hebbian Theory）提出突触可塑性，强调重复刺激增强两个神经元之间的连接。\n- 算法/理论：赫布型学习（Hebbian learning）基于赫布理论，通过相关刺激增强突触强度。\n- 命题：人脑中的短期记忆可通过重复经验转化为长期记忆，这一过程称为凝固作用。\n- 命题：海马区是大脑中负责短期记忆转化为长期记忆的核心区域。"
      },
      {
        "段落": "## 1．5．2 人工神经网络\n\n人工神经网络是为模拟人脑神经网络而设计的一种计算模型，它从结构、实现机理和功能上模拟人脑神经网络。人工神经网络与生物神经元类似，由多个节点（人工神经元）互相连接而成，可以用来对数据之间的复杂关系进行建模．不\n\n[^1]Donald Hebb（1904～ 1985），加拿大神经心理学家，认知心理生理学的开创者．\n\n同节点之间的连接被赋予了不同的权重，每个权重代表了一个节点对另一个节点的影响大小．每个节点代表一种特定函数，来自其他节点的信息经过其相应的权重综合计算，输入到一个激活函数中并得到一个新的活性值（兴奋或抑制）。从系统观点看，人工神经元网络是由大量神经元通过极其丰富和完善的连接而构成的自适应非线性动态系统。\n\n虽然我们可以比较容易地构造一个人工神经网络，但是如何让人工神经网络具有学习能力并不是一件容易的事情。早期的神经网络模型并不具备学习能力。首个可学习的人工神经网络是赫布网络，采用一种基于赫布规则的无监督学习方法．感知器是最早的具有机器学习思想的神经网络，但其学习方法无法扩展到多层的神经网络上。直到1980年左右，反向传播算法才有效地解决了多层神经网络的学习问题，并成为最为流行的神经网络学习算法。\n\n人工神经网络诞生之初并不是用来解决机器学习问题．由于人工神经网络可以看作是一个通用的函数逼近器，一个两层的神经网络可以逼近任意的函数，因此人工神经网络可以看作是一个可学习的函数，并应用到机器学习中．理论上，只要有足够的训练数据和神经元数量，人工神经网络就可以学到很多复杂的函数。我们可以把一个人工神经网络塑造复杂函数的能力称为网络容量（Net－ work Capacity），与可以被储存在网络中的信息的复杂度以及数量相关．",
        "总结": "- 人工神经网络是一种模拟人脑神经网络的计算模型，由多个节点（人工神经元）通过连接和权重构成，用于建模数据间的复杂关系。  \n- 每个节点通过权重综合其他节点的信息，并通过激活函数产生新的活性值（兴奋或抑制）。  \n- 人工神经网络是一个自适应非线性动态系统，具有丰富的连接结构。  \n- 赫布网络是首个可学习的人工神经网络，采用基于赫布规则的无监督学习方法。  \n- 感知器是最早的具有机器学习思想的神经网络，但其学习方法无法扩展到多层网络。  \n- 反向传播算法在1980年左右解决了多层神经网络的学习问题，成为最流行的神经网络学习算法。  \n- 人工神经网络最初并非为机器学习设计，但因其可作为通用函数逼近器，被应用于机器学习中。  \n- 两层神经网络可以逼近任意函数，因此可视为可学习的函数。  \n- 网络容量是指人工神经网络塑造复杂函数的能力，与可存储信息的复杂度和数量相关。"
      },
      {
        "段落": "## 1．5．3 神经网络的发展历史\n\n神经网络的发展大致经过五个阶段。\n第一阶段：模型提出 第一个阶段为 1943 年～1969 年，是神经网络发展的第一个高潮期．在此期间，科学家们提出了许多神经元模型和学习规则．\n\n1943年，心理学家 Warren McCulloch 和数学家 Walter Pitts 最早提出了一种基于简单逻辑运算的人工神经网络，这种神经网络模型称为 $M P$ 模型，至此开启了人工神经网络研究的序幕。1948年，Alan Turing 提出了一种＂B型图灵机＂。 ＂B型图灵机＂可以基于Hebbian法则来进行学习。1951年，McCulloch和 Pitts 的学生 Marvin Minsky 建造了第一台神经网络机 SNARC．［Rosenblatt，1958］提出了一种可以模拟人类感知能力的神经网络模型，称为感知器（Perceptron），并提出了一种接近于人类学习过程（迭代、试错）的学习算法。\n\n在这一时期，神经网络以其独特的结构和处理信息的方法，在许多实际应用领域（自动控制、模式识别等）中取得了显著的成效。\n\n第二阶段：冰河期 第二阶段为1969年～1983年，是神经网络发展的第一个低谷期．在此期间，神经网络的研究处于长年停滞及低潮状态．\n\n1969年，Marvin Minsky出版《感知器》一书，指出了神经网络的两个关键\n\n感知器参见第 3.4 节．\n\n在本书中，人工神经网络主要是作为一种映射函数，即机器学习中的模型．\n\nHebbian 法则参见第 8．6．1节．\n\nMarvin Minsky（ 1927～ 2016），人工智能领域最重要的领导者和创新者之一，麻省理工学院人工智能实验室的创始人之一。因其在人工智能领域的贡献，于 1969 年获得图灵奖．\n\n缺陷：一是感知器无法处理＂异或＂回路问题；二是当时的计算机无法支持处理大型神经网络所需要的计算能力。这些论断使得人们对以感知器为代表的神经网络产生质疑，并导致神经网络的研究进入了十多年的＂冰河期＂．\n\n但在这一时期，依然有不少学者提出了很多有用的模型或算法．1974年，哈佛大学的 Paul Werbos 发明反向传播算法（BackPropagation，BP）［Werbos， 1974］，但当时未受到应有的重视．1980年，福岛邦彦提出了一种带卷积和子采样操作的多层神经网络：新知机（Neocognitron）［Fukushima，1980］．新知机的提出是受到了动物初级视皮层简单细胞和复杂细胞的感受野的启发。但新知机并没有采用反向传播算法，而是采用了无监督学习的方式来训练，因此也没有引起足够的重视。\n\n第三阶段：反向传播算法引起的复兴 第三阶段为 1983年～1995年，是神经网络发展的第二个高潮期．这个时期中，反向传播算法重新激发了人们对神经网络的兴趣。\n\n1983年，物理学家 John Hopfield 提出了一种用于联想记忆（Associative Memory）的神经网络，称为Hopfield网络．Hopfield网络在旅行商问题上取得了当时最好结果，并引起了轰动。1984年，Geoffrey Hinton 提出一种随机化版本的 Hopfield 网络，即玻尔兹曼机（Boltzmann Machine）。\n\n真正引起神经网络第二次研究高潮的是反向传播算法． 20 世纪 80 年代中期，一种连接主义模型开始流行，即分布式并行处理（Parallel Distributed Process－ ing，PDP ）模型［McClelland et al．，1986］．反向传播算法也逐渐成为 PDP模型的主要学习算法．这时，神经网络才又开始引起人们的注意，并重新成为新的研究热点。随后，［LeCun et al．，1989］将反向传播算法引入了卷积神经网络，并在手写体数字识别上取得了很大的成功［LeCun et al．，1998］．反向传播算法是迄今最为成功的神经网络学习算法．目前在深度学习中主要使用的自动微分可以看作是反向传播算法的一种扩展．\n\n然而，梯度消失问题（Vanishing Gradient Problem）阻碍神经网络的进一步发展，特别是循环神经网络．为了解决这个问题，［Schmidhuber，1992］采用两步来训练一个多层的循环神经网络：（1）通过无监督学习的方式来逐层训练每一层循环神经网络，即预测下一个输入；（2）通过反向传播算法进行精调。\n\n第四阶段：流行度降低 第四个阶段为1995～2006年，在此期间，支持向量机和其他更简单的方法（例如线性分类器）在机器学习领域的流行度逐渐超过了神经网络。\n\n虽然神经网络可以很容易地增加层数、神经元数量，从而构建复杂的网络，但其计算复杂性也会随之增长。当时的计算机性能和数据规模不足以支持训练大规模神经网络。在20世纪90年代中期，统计学习理论和以支持向量机为代表的机 https：／／nndl．github．io／\n\nHopfield 网 络 参 见 第 8．6．1节。\n玻尔兹曼机参见第 12.1节。\n\n自动微分参见第 4．5．3节。\n\n器学习模型开始兴起．相比之下，神经网络的理论基础不清晰、优化困难、可解释性差等缺点更加凸显，因此神经网络的研究又一次陷入低潮．\n\n第五阶段：深度学习的崛起［Hinton et al．，2006］通过逐层预训练来学习一个深度信念网络，并将其权重作为一个多层前馈神经网络的初始化权重，再用反向传播算法进行精调。这种＂预训练 + 精调＂的方式可以有效地解决深度神经网络难以训练的问题．随着深度神经网络在语音识别［Hinton et al．，2012］和图像分类 ［Krizhevsky et al．，2012］等任务上的巨大成功，以神经网络为基础的深度学习迅速崛起。近年来，随着大规模并行计算以及 GPU 设备的普及，计算机的计算能力得以大幅提高。此外，可供机器学习的数据规模也越来越大。在强大的计算能力和海量的数据规模支持下，计算机已经可以端到端地训练一个大规模神经网络，不再需要借助预训练的方式．各大科技公司都投入巨资研究深度学习，神经网络迎来第三次高潮。",
        "总结": "- 神经网络的发展分为五个阶段：模型提出、冰河期、反向传播算法引起的复兴、流行度降低、深度学习的崛起  \n- 第一阶段（1943～1969年）：提出MP模型、B型图灵机、感知器（Perceptron）及其学习算法，以及SNARC神经网络机  \n- 第二阶段（1969～1983年）：因感知器的局限性和计算能力不足进入低谷，但Werbos提出反向传播算法，福岛邦彦提出新知机  \n- 第三阶段（1983～1995年）：反向传播算法推动神经网络复兴，Hopfield网络和玻尔兹曼机被提出，卷积神经网络在手写体识别中取得成功  \n- 第四阶段（1995～2006年）：支持向量机等方法流行，神经网络因理论基础不清晰、优化困难等问题再次陷入低潮  \n- 第五阶段（2006年起）：深度学习崛起，通过预训练+精调方式解决深度网络训练问题，GPU和大数据推动神经网络进入第三次高潮"
      },
      {
        "段落": "## 1.6 本书的知识体系\n\n本书主要对神经网络和深度学习所涉及的知识提出一个较全面的基础性介绍．本书的知识体系如图1．6所示，可以分为三大块：机器学习、神经网络和概率图模型．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-029.jpg?height=726&width=1062&top_left_y=1141&top_left_x=142)\n\n图 1.6 本书的知识体系\n\n深度信念网络参见第 12.3 节。\n\n机器学习 机器学习可以分为监督学习、无监督学习和强化学习．第2章对机器学习进行概述，使读者能够了解机器学习的基本概念以及三要素：模型、学习准则和优化算法，并以线性回归为例来讲述不同学习算法之间的关联。第3章主要介绍一些基本的线性模型。这两章都以监督学习为主进行介绍。第9章介绍了一些无监督学习方法，包括无监督特征学习和概率密度估计．第10章中介绍了一些和模型无关的机器学习方法．第14章介绍了深度强化学习的知识．\n\n神经网络 神经网络作为一类非线性的机器学习模型，可以更好地实现输入和输出之间的映射。第4章到第6章分别讲述三种主要的神经网络模型：前馈神经网络、卷积神经网络和循环神经网络。第6章也简单介绍了一种更一般性的网络：图网络．第7章介绍神经网络的优化与正则化方法．第 8 章介绍神经网络中的注意力机制和外部记忆。\n\n概率图模型 概率图模型为机器学习提供了一个更加便捷的描述框架．第 11 章介绍了概率图模型的基本概念，包括模型表示、学习和推断。目前深度学习和概率图模型的融合已经十分流行。第12章介绍了两种概率图模型：玻尔兹曼机和深度信念网络．第13章和第15章分别介绍两种概率生成模型：深度生成模型和序列生成模型。\n\n由于深度学习涉及非常多的研究领域，因此很多知识无法进行追根溯源并深入介绍．每章最后一节都提供了一些参考文献，读者可根据需要通过深入阅读来了解这些知识。此外，本书的附录中介绍了一些深度学习涉及的数学知识，包括线性代数、微积分、数学优化、概率论和信息论等．",
        "总结": "- 概念：本书的知识体系分为三大块：机器学习、神经网络和概率图模型。\n- 算法：本书介绍了监督学习、无监督学习、强化学习等机器学习方法，以及前馈神经网络、卷积神经网络、循环神经网络等神经网络模型。\n- 定理或命题：本书未明确提及具体定理或命题，但涉及概率图模型的基本概念，如模型表示、学习和推断。\n- 数学推导：本书附录中介绍了线性代数、微积分、数学优化、概率论和信息论等数学知识，为深度学习提供基础。"
      },
      {
        "段落": "## 1.7 常用的深度学习框架\n\n在深度学习中，一般通过误差反向传播算法来进行参数学习。采用手工方式来计算梯度再写代码实现的方式会非常低效，并且容易出错。此外，深度学习模型需要的计算机资源比较多，一般需要在 CPU 和 GPU 之间不断进行切换，开发难度也比较大．因此，一些支持自动梯度计算、无缝 CPU 和 GPU 切换等功能的深度学习框架就应运而生．比较有代表性的框架包括：Theano、Caffe、TensorFlow、 Pytorch、飞桨（PaddlePaddle）、Chainer和MXNet 等 ${ }^{1}$ 。\n（1）Theano ${ }^{2}$ ：由蒙特利尔大学的 Python 工具包，用来高效地定义、优化和计算张量数据的数学表达式．Theano 可以透明地使用 GPU 和高效的符号微分．\n\n[^2]虽然这里将神经网络结构大体上分为三种类型，但是大多数网络都是复合型结构，即一个神经网络中包括多种网络结构。\n\nTheano项目目前已停止维护。\n（2）Caffe ${ }^{1}$ ：由加州大学伯克利分校开发的针对卷积神经网络的计算框架，主要用于计算机视觉。Caffe 用 C＋＋和 Python 实现，但可以通过配置文件来实现所要的网络结构，不需要编码。\n（3）TensorFlow ${ }^{2}$ ：由 Google 公司开发的深度学习框架，可以在任意具备 CPU或者 GPU 的设备上运行．TensorFlow 的计算过程使用数据流图来表示． TensorFlow 的名字来源于其计算过程中的操作对象为多维数组，即张量 （Tensor）。TensorFlow 1.0 版本采用静态计算图，2．0版本之后也支持动态计算图．\n（4）PyTorch ${ }^{3}$ ：由 Facebook、NVIDIA、Twitter 等公司开发维护的深度学习框架，其前身为 Lua 语言的 Torch ${ }^{4}$ 。PyTorch 也是基于动态计算图的框架，在需要动态改变神经网络结构的任务中有着明显的优势。\n（5）飞桨（PaddlePaddle）${ }^{5}$ ：百度开发的一个高效和可扩展的深度学习框架，同时支持动态图和静态图。飞桨提供强大的深度学习并行技术，可以同时支持稠密参数和稀疏参数场景的超大规模深度学习并行训练，支持千亿规模参数和数百个节点的高效并行训练。\n（6）Chainer ${ }^{6}$ ：一个最早采用动态计算图的深度学习框架，其核心开发团队为来自日本的一家机器学习创业公司 Preferred Networks．和 Tensorflow、 Theano、Caffe 等框架使用的静态计算图相比，动态计算图可以在运行时动态地构建计算图，因此非常很适合进行一些复杂的决策或推理任务。\n（7）MXNet ${ }^{7}$ ：由亚马逊、华盛顿大学和卡内基梅隆大学等开发维护的深度学习框架。MXNet支持混合使用符号和命令式编程来最大化效率和生产率，并可以有效地扩展到多个 GPU 和多台机器．\n\n在这些基础框架之上，还有一些建立在这些框架之上的高度模块化的神经网络库，使得构建一个神经网络模型就像搭积木一样容易。其中比较有名的模块化神经网络框架有：（1）基于 TensorFlow 和 Theano 的 Keras ${ }^{8}$ 和（2）基于 Theano的 Lasagne ${ }^{9}$ 。\n\nCaffe2 已经被并入 Py－ Torch 中。\n\n计算图参见第 4．5．3 节．\n\n目前，Keras 已经被集成到 TensorFlow 2.0 版本中。\n\n```\n1 全称为 Convolutional Architecture for Fast Feature Embedding, http://caffe。\nberkeleyvision.org\n2 https://www.tensorflow.org\n3 http://pytorch.org\n4 http://torch.ch\n5 PaddlePaddle 全称为 Parallel Distributed Deep Learning,http://paddlepaddle.org/\n6 https://chainer.org\n7 https://mxnet.apache.org\n8 http://keras.io/\n9 https://github.com/Lasagne/Lasagne\nhttps://nndl.github.io/\n```",
        "总结": "- 概念：介绍了深度学习框架的概念，强调其在自动梯度计算、CPU/GPU切换等方面的优势，以简化深度学习模型的开发。\n- 算法：误差反向传播算法是深度学习中用于参数学习的核心算法。\n- 框架：列举了多个常用的深度学习框架，包括Theano、Caffe、TensorFlow、PyTorch、飞桨（PaddlePaddle）、Chainer和MXNet。\n- 特点：各框架具有不同的特点，如Theano支持GPU和符号微分，Caffe专注于卷积神经网络和计算机视觉，TensorFlow支持静态和动态计算图，PyTorch基于动态计算图，飞桨支持动态图和静态图，Chainer是最早采用动态计算图的框架，MXNet支持混合编程模式。\n- 推导：未涉及具体的数学推导内容。"
      },
      {
        "段落": "## 1.8 总结和深入阅读\n\n要理解深度学习的意义或重要性，就得从机器学习或者是人工智能的更广的视角来分析。在传统机器学习中，除了模型和学习算法外，特征或表示也是影响最终学习效果的重要因素，甚至在很多的任务上比算法更重要。因此，要开发一个实际的机器学习系统，人们往往需要花费大量的精力去尝试设计不同的特征以及特征组合，来提高最终的系统能力，这就是所谓的特征工程问题。\n\n如何自动学习有效的数据表示成为机器学习中的关键问题．早期的表示学习方法，比如特征抽取和特征选择，都是人工引入一些主观假设来进行学习的。这种表示学习不是端到端的学习方式，得到的表示不一定对后续的机器学习任务有效。而深度学习是将表示学习和预测模型的学习进行端到端的学习，中间不需要人工干预。深度学习所要解决的问题是贡献度分配问题，而神经网络恰好是解决这个问题的有效模型。套用马克思的一句名言＂金银天然不是货币，但货币天然是金银＂，我们可以说，神经网络天然不是深度学习，但深度学习天然是神经网络。\n\n目前，深度学习主要以神经网络模型为基础，研究如何设计模型结构，如何有效地学习模型的参数，如何优化模型性能以及在不同任务上的应用等。［Bengio et al．，2013］给出了一个很好的表示学习综述．若希望全面了解人工神经网络和深度学习的知识，可以参考《Deep Learning》［Goodfellow et al．，2016］以及文献 ［Bengio，2009］．关于神经网络的历史可以参考文献［Anderson et al．，2000］．斯坦福大学的 CS231n ${ }^{1}$ 和 CS224n ${ }^{2}$ 是两门非常好的深度学习入门课程，分别从计算机视觉和自然语言处理两个角度来讲授深度学习的基础知识和最新进展．\n\n深度学习的研究进展非常迅速．因此，最新的文献一般会发表在学术会议上．和深度学习相关的学术会议主要有：\n（1）国际表示学习会议 ${ }^{3}$（International Conference on Learning Representa－ tions，ICLR）：主要聚焦于深度学习。\n（2）神经信息处理系统年会4（Annual Conference on Neural Information Pro－ cessing Systems，NeurIPS）：交叉学科会议，但偏重于机器学习。主要包括神经信息处理，统计方法，学习理论以及应用等。\n（3）国际机器学习会议 ${ }^{5}$（International Conference on Machine Learning，IC－ ML ）：机器学习顶级会议，深度学习作为近年来的热点，也占据了 ICML 的很大比例。\n\n[^3]（4）国际人工智能联合会议 ${ }^{1}$（International Joint Conference on Artificial In－ telligence，IJCAI）：人工智能领域最顶尖的综合性会议．历史悠久，从 1969年开始举办．\n（5）美国人工智能协会年会 ${ }^{2}$（AAAI Conference on Artificial Intelligence，AA－ AI）：人工智能领域的顶级会议，每年二月份左右召开，地点一般在北美。\n\n另外，人工智能的很多子领域也都有非常好的专业学术会议。在计算机视觉领域，有计算机视觉与模式识别大会（IEEE Conference on Computer Vision and Pattern Recognition，CVPR）和国际计算机视觉会议（International Com－ ference on Computer Vision，ICCV）。在自然语言处理领域，有计算语言学年会（Annual Meeting of the Association for Computational Linguistics，ACL）和自然语言处理实证方法大会（Conference on Empirical Methods in Natural Language Processing，EMNLP）等。",
        "总结": "- 概念：深度学习是通过端到端的方式自动学习有效数据表示的方法，与传统特征工程不同，它不需要人工干预。\n- 概念：深度学习以神经网络模型为基础，研究模型结构设计、参数学习、性能优化及应用。\n- 算法：神经网络是解决深度学习中贡献度分配问题的有效模型。\n- 定理/命题：神经网络天然不是深度学习，但深度学习天然是神经网络（类比马克思名言）。\n- 数学推导：未提及具体数学推导内容。\n- 深入阅读推荐：参考《Deep Learning》（Goodfellow et al., 2016）和文献[Bengio, 2009]了解深度学习知识。\n- 深入阅读推荐：参考文献[Anderson et al., 2000]了解神经网络的历史。\n- 深入阅读推荐：斯坦福大学的CS231n和CS224n是深度学习入门课程，分别侧重计算机视觉和自然语言处理。\n- 学术会议：ICLR聚焦于深度学习；NeurIPS是交叉学科会议，偏重机器学习；ICML是机器学习顶级会议；IJCAI是人工智能领域最顶尖的综合性会议；AAAI是人工智能领域的顶级会议。\n- 学术会议：计算机视觉领域有CVPR和ICCV；自然语言处理领域有ACL和EMNLP。"
      },
      {
        "段落": "## 参考文献\n\n周志华．机器学习［M］．北京：清华大学出版社， 2016.\nAnderson J A，Rosenfeld E．Talking nets：An oral history of neural networks［M］．MIT Press， 2000.\nAzevedo F A，Carvalho L R，Grinberg L T，et al．Equal numbers of neuronal and nonneuronal cells make the human brain an isometrically scaled－up primate brain［J］．Journal of Comparative Neurology，2009，513（5）：532－541．\nBengio Y．Learning deep architectures for AI［J］．Foundations and trends in Machine Learning， 2009，2（1）：1－127．\nBengio Y，Courville A，Vincent P．Representation learning：A review and new perspectives［J］．IEEE transactions on pattern analysis and machine intelligence，2013，35（8）：1798－1828．\nFukushima K．Neocognitron：A self－organizing neural network model for a mechanism of pattern recognition unaffected by shift in position［J］．Biological cybernetics，1980，36（4）：193－202．\nGoodfellow I J，Bengio Y，Courville A C．Deep learning［M／OL］．MIT Press，2016．http：／／www． deeplearningbook．org／．\nHinton G，Deng L，Yu D，et al．Deep neural networks for acoustic modeling in speech recognition： The shared views of four research groups［J］．IEEE Signal Processing Magazine，2012，29（6）：82－97． Hinton G E，Salakhutdinov R R．Reducing the dimensionality of data with neural networks［J］． Science，2006，313（5786）：504－507．\nKrizhevsky A，Sutskever I，Hinton G E．ImageNet classification with deep convolutional neural networks［C］／／Advances in Neural Information Processing Systems 25．2012：1106－1114．\nLeCun Y，Boser B，Denker J S，et al．Backpropagation applied to handwritten zip code recognition ［J］．Neural computation，1989，1（4）：541－551．\nLeCun Y，Bottou L，Bengio Y，et al．Gradient－based learning applied to document recognition［J］． Proceedings of the IEEE，1998，86（11）：2278－2324．\nMcClelland J L，Rumelhart D E，Group P R．Parallel distributed processing：Explorations in the mi－ crostructure of cognition．volume i：foundations \\＆volume ii：Psychological and biological models ［M］．MIT Press， 1986.\n\n[^4]Minsky M．Steps toward artificial intelligence［J］．Proceedings of the IRE，1961，49（1）：8－30．\nRosenblatt F．The perceptron：a probabilistic model for information storage and organization in the brain．［J］．Psychological review，1958，65（6）：386．\nSchmidhuber J．Learning complex，extended sequences using the principle of history compression ［J］．Neural Computation，1992，4（2）：234－242．\nWerbos P．Beyond regression：New tools for prediction and analysis in the behavioral sciences［D］． Harvard University， 1974.",
        "总结": "- 参考文献部分列出了多个与机器学习、神经网络和深度学习相关的学术文献，涵盖书籍、期刊文章和会议论文。  \n- 周志华的《机器学习》是一本经典的机器学习教材，由清华大学出版社于2016年出版。  \n- Anderson J A 和 Rosenfeld E 的著作《Talking nets：An oral history of neural networks》由 MIT Press 出版，探讨了神经网络的发展历史。  \n- Azevedo F A 等人的研究探讨了人脑中神经元与非神经元细胞的数量关系，表明人脑是按比例放大了的灵长类动物大脑。  \n- Bengio Y 的文章《Learning deep architectures for AI》发表于2009年，讨论了用于人工智能的深度架构学习方法。  \n- Bengio Y 等人的综述文章《Representation learning：A review and new perspectives》发表于2013年，总结了表示学习的研究进展与新视角。  \n- Fukushima K 提出的“Neocognitron”模型是一种自组织神经网络模型，用于模式识别，不受位置变化的影响。  \n- Goodfellow I J 等人的《Deep learning》是一本关于深度学习的权威书籍，由 MIT Press 于2016年出版，并提供在线版本。  \n- Hinton G 等人的研究探讨了深度神经网络在语音识别中的应用，并总结了四个研究小组的共同观点。  \n- Hinton G E 和 Salakhutdinov R R 提出了一种使用神经网络降低数据维度的方法，发表于2006年的《Science》期刊。  \n- Krizhevsky A 等人的论文《ImageNet classification with deep convolutional neural networks》发表于2012年，介绍了深度卷积神经网络在图像分类中的应用。  \n- LeCun Y 等人的研究涉及反向传播算法在手写邮政编码识别中的应用，并讨论了梯度下降方法在文档识别中的应用。  \n- McClelland J L 等人的著作《Parallel distributed processing》探讨了并行分布式处理在认知微观结构中的应用，分为两卷出版。  \n- Minsky M 的论文《Steps toward artificial intelligence》发表于1961年，探讨了人工智能的发展步骤。  \n- Rosenblatt F 提出了“感知机”模型，这是一种用于信息存储和组织的概率模型。  \n- Schmidhuber J 的研究提出了一种基于历史压缩原则的学习复杂序列的方法。  \n- Werbos P 的博士论文《Beyond regression：New tools for prediction and analysis in the behavioral sciences》探讨了预测和分析行为科学的新工具。"
      }
    ]
  },
  {
    "标题": "第2章 机器学习概述",
    "内容": [
      {
        "段落": "# 第2章 机器学习概述 \n\n> 机器学习是对能通过经验自动改进的计算机算法的研究．\n\n—汤姆•米切尔（ Tom Mitchell ）［Mitchell，1997］\n\n通俗地讲，机器学习（Machine Learning，ML）就是让计算机从数据中进行自动学习，得到某种知识（或规律）。作为一门学科，机器学习通常指一类问题以及解决这类问题的方法，即如何从观测数据（样本）中寻找规律，并利用学习到的规律（模型）对未知或无法观测的数据进行预测。\n\n在早期的工程领域，机器学习也经常称为模式识别（Pattern Recognition， PR），但模式识别更偏向于具体的应用任务，比如光学字符识别、语音识别、人脸识别等。这些任务的特点是，对于我们人类而言，这些任务很容易完成，但我们不知道自己是如何做到的，因此也很难人工设计一个计算机程序来解决这些任务。一个可行的方法是设计一个算法可以让计算机自己从有标注的样本上学习其中的规律，并用来完成各种识别任务。随着机器学习技术的应用越来越广，现在机器学习的概念逐渐替代模式识别，成为这一类问题及其解决方法的统称。\n\n以手写体数字识别为例，我们需要让计算机能自动识别手写的数字。比如图2．1中的例子，将 5 识别为数字 5 ，将 6 识别为数字 6．手写数字识别是一个经典的机器学习任务，对人来说很简单，但对计算机来说却十分困难。我们很难总结每个数字的手写体特征，或者区分不同数字的规则，因此设计一套识别算法是一项几乎不可能的任务。在现实生活中，很多问题都类似于手写体数字识别这类问题，比如物体识别、语音识别等。对于这类问题，我们不知道如何设计一个计算机程序来解决，即使可以通过一些启发式规则来实现，其过程也是极其复杂的。因此，人们开始尝试采用另一种思路，即让计算机＂看＂大量的样本，并从中学习到一些经验，然后用这些经验来识别新的样本。要识别手写体数字，首先通过人工标注大量的手写体数字图像（即每张图像都通过人工标记了它是什么数字），这些图像作为训练数据，然后通过学习算法自动生成一套模型，并依靠它来识别新的手写体\n\n数字。这个过程和人类学习过程也比较类似，我们教小孩子识别数字也是这样的过程．这种通过数据来学习的方法就称为机器学习的方法．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-036.jpg?height=531&width=939&top_left_y=254&top_left_x=186)\n\n图 2.1 手写体数字识别示例（图片来源［LeCun et al．，1998］）\n\n本章先介绍机器学习的基本概念和基本要素，并较详细地描述一个简单的机器学习例子，线性回归。",
        "总结": "- 概念：机器学习是研究能通过经验自动改进的计算机算法，其目标是从数据中学习规律并用于预测。\n- 算法：线性回归作为简单的机器学习例子被详细描述。\n- 定理/命题：未提及具体定理或命题。\n- 数学推导：未提及具体数学推导。"
      },
      {
        "段落": "## 2.1 基本概念\n\n首先我们以一个生活中的例子来介绍机器学习中的一些基本概念：包括样本、特征、标签、模型、学习算法等。假设我们要到市场上购买芒果，但是之前毫无挑选芒果的经验，那么我们如何通过学习来获取这些知识？\n\n首先，我们从市场上随机选取一些芒果，列出每个芒果的特征（Feature），包括颜色、大小、形状、产地、品牌，以及我们需要预测的标签（Label）。标签可以是连续值（比如关于芒果的甜度、水分以及成熟度的综合打分），也可以是离散值 （比如＂好＂＂坏＂两类标签）。这里，每个芒果的标签可以通过直接品尝来获得，也可以通过请一些经验丰富的专家来进行标记。\n\n一个标记好特征以及标签的芒果可以看作是一个样本（Sample）。一组样本构成的集合称为数据集（Data Set）。一般将数据集分为两部分：训练集和测试集．训练集（Training Set）中的样本是用来训练模型的，也叫训练样本（Training Sample），而测试集（Test Set）中的样本是用来检验模型好坏的，也叫测试样本 （ Test Sample ）．\n\n我们通常用一个 $D$ 维向量 $\\boldsymbol{x}=\\left[x_{1}, x_{2}, \\cdots, x_{D}\\right]^{\\top}$ 表示一个芒果的所有特征构成的向量，称为特征向量（Feature Vector），其中每一维表示一个特征。而芒果的标签通常用标量 $y$ 来表示。\n\n假设训练集由 $N$ 个样本组成，其中每个样本都是独立同分布（Identically https：／／nndl．github．io／\n\n本节参考了《机器学习》［周志华，2016］中购买西瓜的例子。特征也可以称为属性 （Attribute）．\n\n样本（Sample）也经常称为示例（Instance）．\n\n在很多领域，数据集也经常称为语料库（Cor－ pus）。\n并不是所有的样本特征都是数值型，需要通过转换表示为特征向量，参见第 2.6 节。\nand Independently Distributed，IID）的，即独立地从相同的数据分布中抽取的，记为\n\n$$\n\\begin{equation*}\n\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(1)}, y^{(1)}\\right),\\left(\\boldsymbol{x}^{(2)}, y^{(2)}\\right), \\cdots,\\left(\\boldsymbol{x}^{(N)}, y^{(N)}\\right)\\right\\} \\tag{2.1}\n\\end{equation*}\n$$\n\n给定训练集 $\\mathcal{D}$ ，我们希望让计算机从一个函数集合 $\\mathcal{F}=\\left\\{f_{1}(\\boldsymbol{x}), f_{2}(\\boldsymbol{x}), \\cdots\\right\\}$ 中自动寻找一个＂最优＂的函数 $f^{*}(\\boldsymbol{x})$ 来近似每个样本特性向量 $\\boldsymbol{x}$ 和标签 $y$ 之间的真实映射关系。对于一个样本 $\\boldsymbol{x}$ ，我们可以通过函数 $f^{*}(\\boldsymbol{x})$ 来预测其标签的值\n\n$$\n\\begin{equation*}\n\\hat{y}=f^{*}(\\boldsymbol{x}) \\tag{2.2}\n\\end{equation*}\n$$\n\n或标签的条件概率\n\n$$\n\\begin{equation*}\n\\hat{p}(y \\mid \\boldsymbol{x})=f_{y}^{*}(\\boldsymbol{x}) \\tag{2.3}\n\\end{equation*}\n$$\n\n如何寻找这个＂最优＂的函数 $f^{*}(\\boldsymbol{x})$ 是机器学习的关键，一般需要通过学习算法（Learning Algorithm） $\\mathcal{A}$ 来完成。这个寻找过程通常称为学习（Learning）或训练（Training）过程。\n\n这样，下次从市场上买芒果（测试样本）时，可以根据芒果的特征，使用学习到的函数 $f^{*}(\\boldsymbol{x})$ 来预测芒果的好坏。为了评价的公正性，我们还是独立同分布地抽取一组芒果作为测试集 $\\mathcal{D}^{\\prime}$ ，并在测试集中所有芒果上进行测试，计算预测结果的准确率\n\n$$\n\\begin{equation*}\n\\operatorname{Acc}\\left(f^{*}(\\boldsymbol{x})\\right)=\\frac{1}{\\left|\\mathcal{D}^{\\prime}\\right|} \\sum_{(\\boldsymbol{x}, y) \\in \\mathcal{D}^{\\prime}} I\\left(f^{*}(\\boldsymbol{x})=y\\right) \\tag{2.4}\n\\end{equation*}\n$$\n\n其中 $I(\\cdot)$ 为指示函数，$\\left|\\mathcal{D}^{\\prime}\\right|$ 为测试集大小。\n图2．2给出了机器学习的基本流程。对一个预测任务，输入特征向量为 $\\boldsymbol{x}$ ，输出标签为 $y$ ，我们选择一个函数集合 $\\mathcal{F}$ ，通过学习算法 $\\mathcal{A}$ 和一组训练样本 $\\mathcal{D}$ ，从 $\\mathcal{F}$中学习到函数 $f^{*}(\\boldsymbol{x})$ ．这样对新的输入 $\\boldsymbol{x}$ ，就可以用函数 $f^{*}(\\boldsymbol{x})$ 进行预测．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-037.jpg?height=301&width=1005&top_left_y=1665&top_left_x=160)\n\n图 2.2 机器学习系统示例",
        "总结": "- 介绍了机器学习中的基本概念，包括样本、特征、标签、模型、学习算法等。\n- 以购买芒果为例，说明如何通过样本的特征和标签来学习模型。\n- 样本是带有特征和标签的数据点，一组样本构成数据集，数据集分为训练集和测试集。\n- 特征向量用 $D$ 维向量表示，标签用标量 $y$ 表示。\n- 训练集由独立同分布的样本组成，记为 $\\mathcal{D}$。\n- 目标是从函数集合 $\\mathcal{F}$ 中找到最优函数 $f^*(\\boldsymbol{x})$ 来近似特征与标签之间的映射关系。\n- 使用学习算法 $\\mathcal{A}$ 进行学习过程，以找到最优函数 $f^*(\\boldsymbol{x})$。\n- 测试集用于评估模型性能，计算准确率 $Acc(f^*(\\boldsymbol{x}))$。\n- 图2.2展示了机器学习的基本流程：输入特征向量 $\\boldsymbol{x}$，输出标签 $y$，通过学习算法从训练集学习函数 $f^*(\\boldsymbol{x})$ 以进行预测。"
      },
      {
        "段落": "## 2.2 机器学习的三个基本要素\n\n机器学习是从有限的观测数据中学习（或＂猜测＂）出具有一般性的规律，并可以将总结出来的规律推广应用到未观测样本上。机器学习方法可以粗略地分为三个基本要素：模型、学习准则、优化算法。",
        "总结": "- 本节提出机器学习的三个基本要素：模型、学习准则、优化算法。  \n- 模型是指用来表示数据规律的数学结构或假设。  \n- 学习准则是用来衡量模型与数据之间差异的标准，指导模型的学习过程。  \n- 优化算法是用于寻找最优模型参数的方法，以最小化学习准则。"
      },
      {
        "段落": "## 2．2．1 模型\n\n对于一个机器学习任务，首先要确定其输入空间 $x$ 和输出空间 $y$ 。不同机器学习任务的主要区别在于输出空间不同．在二分类问题中 $y=\\{+1,-1\\}$ ，在 $C$ 分类问题中 $y=\\{1,2, \\cdots, C\\}$ ，而在回归问题中 $y=\\mathbb{R}$ 。\n\n输入空间 $x$ 和输出空间 $y$ 构成了一个样本空间．对于样本空间中的样本 $(\\boldsymbol{x}, y) \\in X \\times y$ ，假定 $\\boldsymbol{x}$ 和 $y$ 之间的关系可以通过一个未知的真实映射函数 $y=$ $g(\\boldsymbol{x})$ 或真实条件概率分布 $p_{r}(y \\mid \\boldsymbol{x})$ 来描述。机器学习的目标是找到一个模型来近似真实映射函数 $g(\\boldsymbol{x})$ 或真实条件概率分布 $p_{r}(y \\mid \\boldsymbol{x})$ 。\n\n由于我们不知道真实的映射函数 $g(\\boldsymbol{x})$ 或条件概率分布 $p_{r}(y \\mid \\boldsymbol{x})$ 的具体形式，因而只能根据经验来假设一个函数集合 $\\mathcal{F}$ ，称为假设空间（Hypothesis Space），然后通过观测其在训练集 $\\mathcal{D}$ 上的特性，从中选择一个理想的假设（Hypothesis） $f^{*} \\in \\mathcal{F}$ 。\n\n假设空间 $\\mathcal{F}$ 通常为一个参数化的函数族\n\n$$\n\\begin{equation*}\n\\mathcal{F}=\\left\\{f(\\boldsymbol{x} ; \\theta) \\mid \\theta \\in \\mathbb{R}^{D}\\right\\}, \\tag{2.5}\n\\end{equation*}\n$$\n\n其中 $f(\\boldsymbol{x} ; \\theta)$ 是参数为 $\\theta$ 的函数，也称为模型（Model），$D$ 为参数的数量．\n常见的假设空间可以分为线性和非线性两种，对应的模型 $f$ 也分别称为线性模型和非线性模型。",
        "总结": "- 概念：输入空间 $x$ 和输出空间 $y$ 构成样本空间，样本形式为 $(\\boldsymbol{x}, y) \\in X \\times y$。\n- 概念：机器学习任务的核心目标是找到一个模型来近似真实映射函数 $g(\\boldsymbol{x})$ 或真实条件概率分布 $p_{r}(y \\mid \\boldsymbol{x})$。\n- 概念：假设空间 $\\mathcal{F}$ 是一个参数化的函数族，形式为 $f(\\boldsymbol{x} ; \\theta)$，其中 $\\theta$ 为参数。\n- 概念：模型 $f(\\boldsymbol{x} ; \\theta)$ 是参数化的函数，用于近似真实映射函数或条件概率分布。\n- 概念：假设空间可以分为线性和非线性两种，对应模型分别为线性模型和非线性模型。"
      },
      {
        "段落": "### 2．2．1．1 线性模型\n\n线性模型的假设空间为一个参数化的线性函数族，即\n\n$$\n\\begin{equation*}\nf(\\boldsymbol{x} ; \\theta)=\\boldsymbol{w}^{\\top} \\boldsymbol{x}+b \\tag{2.6}\n\\end{equation*}\n$$\n\n其中参数 $\\theta$ 包含了权重向量 $\\boldsymbol{w}$ 和偏置 $b$ 。",
        "总结": "- 线性模型的假设空间是一个参数化的线性函数族  \n- 线性函数形式为 $ f(\\boldsymbol{x} ; \\theta) = \\boldsymbol{w}^{\\top} \\boldsymbol{x} + b $  \n- 参数 $ \\theta $ 包含权重向量 $ \\boldsymbol{w} $ 和偏置 $ b $"
      },
      {
        "段落": "### 2．2．1．2 非线性模型\n\n广义的非线性模型可以写为多个非线性基函数 $\\phi(\\boldsymbol{x})$ 的线性组合\n\n$$\n\\begin{equation*}\nf(\\boldsymbol{x} ; \\theta)=\\boldsymbol{w}^{\\top} \\phi(\\boldsymbol{x})+b \\tag{2.7}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n这里，输入空间默认为样本的特征空间．\n\n映射函数 $g: x \\rightarrow y$ 。\n\n对于分类问题，一般为广义线性函数，参见公式（3．3）。\n\n其中 $\\phi(\\boldsymbol{x})=\\left[\\phi_{1}(\\boldsymbol{x}), \\phi_{2}(\\boldsymbol{x}), \\cdots, \\phi_{K}(\\boldsymbol{x})\\right]^{\\top}$ 为 $K$ 个非线性基函数组成的向量，参数 $\\theta$包含了权重向量 $\\boldsymbol{w}$ 和偏置 $b$ 。\n\n如果 $\\phi(x)$ 本身为可学习的基函数，比如\n\n$$\n\\begin{equation*}\n\\phi_{k}(\\boldsymbol{x})=h\\left(\\boldsymbol{w}_{k}^{\\top} \\phi^{\\prime}(\\boldsymbol{x})+b_{k}\\right), \\forall 1 \\leq k \\leq K \\tag{2.8}\n\\end{equation*}\n$$\n\n其中 $h(\\cdot)$ 为非线性函数，$\\phi^{\\prime}(\\boldsymbol{x})$ 为另一组基函数， $\\boldsymbol{w}_{k}$ 和 $b_{k}$ 为可学习的参数，则 $f(\\boldsymbol{x} ; \\theta)$ 就等价于神经网络模型．",
        "总结": "- 非线性模型可以表示为多个非线性基函数的线性组合  \n- 模型形式为 $ f(\\boldsymbol{x} ; \\theta)=\\boldsymbol{w}^{\\top} \\phi(\\boldsymbol{x})+b $  \n- $\\phi(\\boldsymbol{x})$ 是由 $K$ 个非线性基函数组成的向量  \n- 参数 $\\theta$ 包含权重向量 $\\boldsymbol{w}$ 和偏置 $b$  \n- 若 $\\phi(x)$ 本身为可学习的基函数，则模型等价于神经网络  \n- 可学习基函数的形式为 $\\phi_{k}(\\boldsymbol{x})=h\\left(\\boldsymbol{w}_{k}^{\\top} \\phi^{\\prime}(\\boldsymbol{x})+b_{k}\\right)$  \n- 其中 $h(\\cdot)$ 为非线性函数，$\\phi^{\\prime}(\\boldsymbol{x})$ 为另一组基函数，$\\boldsymbol{w}_{k}$ 和 $b_{k}$ 为可学习参数"
      },
      {
        "段落": "## 2．2．2 学习准则\n\n令训练集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ 是由 $N$ 个独立同分布（Identically and Inde－ pendently Distributed，IID）的样本组成，即每个样本 $(x, y) \\in x \\times y$ 是从 $x$ 和 $y$的联合空间中按照某个未知分布 $p_{r}(\\boldsymbol{x}, y)$ 独立地随机产生的。这里要求样本分布 $p_{r}(\\boldsymbol{x}, y)$ 必须是固定的（虽然可以是未知的），不会随时间而变化。如果 $p_{r}(\\boldsymbol{x}, y)$本身可变的话，就无法通过这些数据进行学习。\n\n一个好的模型 $f\\left(\\boldsymbol{x}, \\theta^{*}\\right)$ 应该在所有 $(\\boldsymbol{x}, y)$ 的可能取值上都与真实映射函数 $y=g(\\boldsymbol{x})$ 一致，即\n\n$$\n\\begin{equation*}\n\\left|f\\left(x, \\theta^{*}\\right)-y\\right|<\\epsilon, \\quad \\forall(x, y) \\in \\mathcal{X} \\times y \\tag{2.9}\n\\end{equation*}\n$$\n\n或与真实条件概率分布 $p_{r}(y \\mid \\boldsymbol{x})$ 一致，即\n\n$$\n\\begin{equation*}\n\\left|f_{y}\\left(\\boldsymbol{x}, \\theta^{*}\\right)-p_{r}(y \\mid \\boldsymbol{x})\\right|<\\epsilon, \\quad \\forall(\\boldsymbol{x}, y) \\in \\mathcal{X} \\times y, \\tag{2.10}\n\\end{equation*}\n$$\n\n其中 $\\epsilon$ 是一个很小的正数，$f_{y}\\left(\\boldsymbol{x}, \\theta^{*}\\right)$ 为模型预测的条件概率分布中 $y$ 对应的概率．\n模型 $f(\\boldsymbol{x} ; \\theta)$ 的好坏可以通过期望风险（Expected Risk） $\\mathcal{R}(\\theta)$ 来衡量，其定义为\n\n$$\n\\begin{equation*}\n\\mathcal{R}(\\theta)=\\mathbb{E}_{(\\boldsymbol{x}, y) \\sim p_{r}(\\boldsymbol{x}, y)}[\\mathcal{L}(y, f(\\boldsymbol{x} ; \\theta))] \\tag{2.11}\n\\end{equation*}\n$$\n\n其中 $p_{r}(\\boldsymbol{x}, y)$ 为真实的数据分布， $\\mathcal{L}(y, f(\\boldsymbol{x} ; \\theta))$ 为损失函数，用来量化两个变量之间的差异。",
        "总结": "- 训练集 $\\mathcal{D}$ 由 $N$ 个独立同分布的样本组成，每个样本 $(x, y)$ 从联合空间中按照未知分布 $p_{r}(\\boldsymbol{x}, y)$ 独立随机产生，且该分布固定不变。  \n- 一个好的模型 $f(\\boldsymbol{x}, \\theta^{*})$ 应在所有 $(\\boldsymbol{x}, y)$ 的可能取值上与真实映射函数 $y = g(\\boldsymbol{x})$ 或真实条件概率分布 $p_{r}(y \\mid \\boldsymbol{x})$ 一致，误差小于一个很小的正数 $\\epsilon$。  \n- 模型 $f(\\boldsymbol{x}; \\theta)$ 的好坏通过期望风险 $\\mathcal{R}(\\theta)$ 来衡量，其定义为在真实数据分布 $p_{r}(\\boldsymbol{x}, y)$ 下，损失函数 $\\mathcal{L}(y, f(\\boldsymbol{x}; \\theta))$ 的期望值。"
      },
      {
        "段落": "### 2．2．2．1 损失函数\n\n损失函数是一个非负实数函数，用来量化模型预测和真实标签之间的差异。下面介绍几种常用的损失函数。\n\n这里两个分布相似性的定义不太严谨，更好的方式为 $K L$ 散度或交叉熵。\n\n期望风险也经常称为期望错误（Expected Error）。\n\n0－1 损失函数 最直观的损失函数是模型在训练集上的错误率，即 $0-1$ 损失函数 （ 0－1 Loss Function ）：\n\n$$\n\\begin{align*}\n\\mathcal{L}(y, f(\\boldsymbol{x} ; \\theta)) & =\\left\\{\\begin{aligned}\n0 & \\text { if } y=f(\\boldsymbol{x} ; \\theta) \\\\\n1 & \\text { if } y \\neq f(\\boldsymbol{x} ; \\theta)\n\\end{aligned}\\right.  \\tag{2.12}\\\\\n& =I(y \\neq f(\\boldsymbol{x} ; \\theta)) \\tag{2.13}\n\\end{align*}\n$$\n\n其中 $I(\\cdot)$ 是指示函数．\n虽然 0－1 损失函数能够客观地评价模型的好坏，但其缺点是数学性质不是很好：不连续且导数为 0 ，难以优化。因此经常用连续可微的损失函数替代。\n\n平方损失函数 平方损失函数（Quadratic Loss Function）经常用在预测标签 $y$为实数值的任务中，定义为\n\n$$\n\\begin{equation*}\n\\mathcal{L}(y, f(x ; \\theta))=\\frac{1}{2}(y-f(x ; \\theta))^{2} \\tag{2.14}\n\\end{equation*}\n$$\n\n平方损失函数一般不适用于分类问题．\n参见习题 2－1．\n\n交叉熵损失函数 交叉熵损失函数（Cross－Entropy Loss Function）一般用于分类问题。假设样本的标签 $y \\in\\{1, \\cdots C\\}$ 为离散的类别，模型 $f(\\boldsymbol{x} ; \\theta) \\in[0,1]^{C}$ 的输出为类别标签的条件概率分布，即\n\n$$\n\\begin{equation*}\np(y=c \\mid \\boldsymbol{x} ; \\theta)=f_{c}(\\boldsymbol{x} ; \\theta) \\tag{2.15}\n\\end{equation*}\n$$\n\n并满足\n\n$$\n\\begin{equation*}\nf_{c}(\\boldsymbol{x} ; \\theta) \\in[0,1], \\quad \\sum_{c=1}^{C} f_{c}(\\boldsymbol{x} ; \\theta)=1 \\tag{2.16}\n\\end{equation*}\n$$\n\n我们可以用一个 $C$ 维的 one－hot 向量 $\\boldsymbol{y}$ 来表示样本标签。假设样本的标签为 $k$ ，那么标签向量 $\\boldsymbol{y}$ 只有第 $k$ 维的值为 1 ，其余元素的值都为 0 。标签向量 $\\boldsymbol{y}$ 可以看作是样本标签的真实概率分布，即第 $c$ 维（记为 $y_{c}, 1 \\leq c \\leq C$ ）是类别为 $c$ 的真实概率。假设样本的类别为 $k$ ，那么它属于第 $k$ 类的概率为 1 ，其他类的概率为 0 。\n\n对于两个概率分布，一般可以用交叉熵来衡量它们的差异。标签的真实分布交叉熵参见第 E．3．1 节。 $\\boldsymbol{y}$ 和模型预测分布 $f(\\boldsymbol{x} ; \\theta)$ 之间的交叉熵为\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\boldsymbol{y}, f(\\boldsymbol{x} ; \\theta)) & =-\\boldsymbol{y}^{\\top} \\log f(\\boldsymbol{x} ; \\theta)  \\tag{2.17}\\\\\n& =-\\sum_{c=1}^{C} y_{c} \\log f_{c}(\\boldsymbol{x} ; \\theta) \\tag{2.18}\n\\end{align*}\n$$\n\n比如对于三分类问题，一个样本的标签向量为 $\\boldsymbol{y}=[0,0,1]^{\\top}$ ，模型预测的标签分布为 $f(\\boldsymbol{x} ; \\theta)=[0.3,0.3,0.4]^{\\top}$ ，则它们的交叉嫡为 $-(0 \\times \\log (0.3)+0 \\times$ $\\log (0.3)+1 \\times \\log (0.4))=-\\log (0.4)$ ．\n\n因为 $\\boldsymbol{y}$ 为 one－hot 向量，公式（2．18）也可以写为\n\n$$\n\\begin{equation*}\n\\mathcal{L}(y, f(\\boldsymbol{x} ; \\theta))=-\\log f_{y}(\\boldsymbol{x} ; \\theta) \\tag{2.19}\n\\end{equation*}\n$$\n\n其中 $f_{y}(\\boldsymbol{x} ; \\theta)$ 可以看作真实类别 $y$ 的似然函数．因此，交叉熵损失函数也就是负对数似然函数（Negative Log－Likelihood）。\n\nHinge 损失函数 对于二分类问题，假设 $y$ 的取值为 $\\{-1,+1\\}, f(\\boldsymbol{x} ; \\theta) \\in \\mathbb{R}$ ．Hinge损失函数（Hinge Loss Function）为\n\n$$\n\\begin{align*}\n\\mathcal{L}(y, f(\\boldsymbol{x} ; \\theta)) & =\\max (0,1-y f(\\boldsymbol{x} ; \\theta))  \\tag{2.20}\\\\\n& \\triangleq[1-y f(\\boldsymbol{x} ; \\theta)]_{+} \\tag{2.21}\n\\end{align*}\n$$\n\n其中 $[x]_{+}=\\max (0, x)$ 。",
        "总结": "- 损失函数是用于量化模型预测与真实标签之间差异的非负实数函数  \n- 期望风险也称为期望错误  \n- 0－1 损失函数是模型在训练集上的错误率，但因其不连续且难以优化，常被替代  \n- 平方损失函数适用于预测实数值的任务，定义为预测值与真实值差的平方的一半  \n- 交叉熵损失函数用于分类问题，衡量真实分布与模型预测分布之间的差异，也可视为负对数似然函数  \n- Hinge 损失函数用于二分类问题，定义为 max(0, 1 - y f(x; θ))"
      },
      {
        "段落": "### 2．2．2．2 风险最小化准则\n\n一个好的模型 $f(\\boldsymbol{x} ; \\theta)$ 应当有一个比较小的期望错误，但由于不知道真实的数据分布和映射函数，实际上无法计算其期望风险 $\\mathcal{R}(\\theta)$ 。给定一个训练集 $\\mathcal{D}=$ $\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，我们可以计算的是经验风险（Empirical Risk），即在训练集上的平均损失：\n\n$$\n\\begin{equation*}\n\\mathcal{R}_{\\mathcal{D}}^{e m p}(\\theta)=\\frac{1}{N} \\sum_{n=1}^{N} \\mathcal{L}\\left(y^{(n)}, f\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)\\right) \\tag{2.22}\n\\end{equation*}\n$$\n\n因此，一个切实可行的学习准则是找到一组参数 $\\theta^{*}$ 使得经验风险最小，即\n\n$$\n\\begin{equation*}\n\\theta^{*}=\\underset{\\theta}{\\arg \\min } \\mathcal{R}_{\\mathcal{D}}^{e m p}(\\theta) \\tag{2.23}\n\\end{equation*}\n$$\n\n这就是经验风险最小化（Empirical Risk Minimization，ERM）准则。\n过拟合 根据大数定理可知，当训练集大小 $|\\mathcal{D}|$ 趋向于无穷大时，经验风险就趋向于期望风险。然而通常情况下，我们无法获取无限的训练样本，并且训练样本往往是真实数据的一个很小的子集或者包含一定的噪声数据，不能很好地反映全部数据的真实分布。经验风险最小化原则很容易导致模型在训练集上错误率很低，但是在未知数据上错误率很高。这就是所谓的过拟合（Overfitting）。\n\n参见第 3．5．3 节。\n\n经验风险也称为经验错误（Empirical Er－ ror）．\n\n如何选择训练样本个数可以参考PAC学习理论，参见第 2.8 .1 节。\n\n定义 2.1 －过拟合：给定一个假设空间 $\\mathcal{F}$ ，一个假设 $f$ 属于 $\\mathcal{F}$ ，如果存在其他的假设 $f^{\\prime}$ 也属于 $\\mathcal{F}$ ，使得在训练集上 $f$ 的损失比 $f^{\\prime}$ 小，但在整个样本空间上 $f^{\\prime}$ 比 $f$ 的损失小，那么就说假设 $f$ 过度拟合训练数据［Mitchell，1997］．\n\n过拟合问题往往是由于训练数据少和噪声以及模型能力强等原因造成的．为了解决过拟合问题，一般在经验风险最小化的基础上再引入参数的正则化 （Regularization）来限制模型能力，使其不要过度地最小化经验风险。这种准则就是结构风险最小化（Structure Risk Minimization，SRM）准则：\n\n$$\n\\begin{align*}\n\\theta^{*} & =\\underset{\\theta}{\\arg \\min } \\mathcal{R}_{\\mathcal{D}}^{\\text {struct }}(\\theta)  \\tag{2.24}\\\\\n& =\\underset{\\theta}{\\arg \\min } \\mathcal{R}_{\\mathcal{D}}^{\\text {emp }}(\\theta)+\\frac{1}{2} \\lambda\\|\\theta\\|^{2}  \\tag{2.25}\\\\\n& =\\underset{\\theta}{\\arg \\min } \\frac{1}{N} \\sum_{n=1}^{N} \\mathcal{L}\\left(y^{(n)}, f\\left(x^{(n)} ; \\theta\\right)\\right)+\\frac{1}{2} \\lambda\\|\\theta\\|^{2} \\tag{2.26}\n\\end{align*}\n$$\n\n其中 $\\|\\theta\\|$ 是 $\\ell_{2}$ 范数的正则化项，用来减少参数空间，避免过拟合；$\\lambda$ 用来控制正则化的强度．\n\n正则化项也可以使用其他函数，比如 $\\ell_{1}$ 范数．$\\ell_{1}$ 范数的引入通常会使得参数有一定稀疏性，因此在很多算法中也经常使用。从贝叶斯学习的角度来讲，正则化是假设了参数的先验分布，不完全依赖训练数据。\n\n和过拟合相反的一个概念是欠拟合（Underfitting），即模型不能很好地拟\n\n更多的正则化方法参见第 7.7 节。\n$\\ell_{1}$ 范数的稀疏性参见第 7．7．1 节。\n正则化的贝叶斯解释参见第 2．3．1．4 节。合训练数据，在训练集的错误率比较高．欠拟合一般是由于模型能力不足造成的．图2．3给出了欠拟合和过拟合的示例。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-042.jpg?height=308&width=955&top_left_y=1440&top_left_x=176)\n\n图 2.3 欠拟合和过拟合示例\n\n总之，机器学习中的学习准则并不仅仅是拟合训练集上的数据，同时也要使得泛化错误最低。给定一个训练集，机器学习的目标是从假设空间中找到一个泛化错误较低的＂理想＂模型，以便更好地对未知的样本进行预测，特别是不在训练集中出现的样本。因此，机器学习可以看作是一个从有限、高维、有噪声的数据上得到更一般性规律的泛化问题．",
        "总结": "- 风险最小化准则：提出经验风险最小化（ERM）准则，即通过最小化训练集上的平均损失来选择模型参数。\n- 期望风险与经验风险：期望风险是模型在真实数据分布上的平均损失，但无法直接计算；经验风险是训练集上的平均损失，可实际计算。\n- 过拟合定义：模型在训练集上表现良好但在未知数据上表现差的现象，通常由训练数据少、噪声或模型能力强引起。\n- 过拟合的解决方法：引入正则化项，限制模型复杂度，提出结构风险最小化（SRM）准则，结合经验风险和正则化项。\n- 正则化项：常用 $\\ell_2$ 范数或 $\\ell_1$ 范数，$\\ell_2$ 范数用于减少参数空间，$\\ell_1$ 范数用于参数稀疏性。\n- 正则化的贝叶斯解释：正则化可视为对参数的先验分布假设，使模型不完全依赖训练数据。\n- 欠拟合定义：模型无法很好地拟合训练数据，在训练集上错误率高，通常由模型能力不足引起。\n- 学习目标：机器学习的目标是找到泛化错误较低的模型，以更好地预测未知样本。"
      },
      {
        "段落": "## 2．2．3 优化算法\n\n在确定了训练集 $\\mathcal{D}$ 、假设空间 $\\mathcal{F}$ 以及学习准则后，如何找到最优的模型 $f\\left(\\boldsymbol{x}, \\theta^{*}\\right)$ 就成了一个最优化（Optimization）问题。机器学习的训练过程其实就是最优化问题的求解过程．\n\n参数与超参数 在机器学习中，优化又可以分为参数优化和超参数优化。模型 $f(x ; \\theta)$ 中的 $\\theta$ 称为模型的参数，可以通过优化算法进行学习。除了可学习的参数 $\\theta$ 之外，还有一类参数是用来定义模型结构或优化策略的，这类参数叫做超参数 （Hyper－Parameter）．\n\n常见的超参数包括：聚类算法中的类别个数、梯度下降法中的步长、正则化项的系数、神经网络的层数、支持向量机中的核函数等。超参数的选取一般都是组合优化问题，很难通过优化算法来自动学习。因此，超参数优化是机器学习的一个经验性很强的技术，通常是按照人的经验设定，或者通过搜索的方法对一组超参数组合进行不断试错调整。",
        "总结": "- 本节提出优化算法的概念，指出在确定训练集、假设空间和学习准则后，寻找最优模型是一个最优化问题。\n- 参数优化涉及模型参数 $\\theta$ 的学习，通过优化算法进行调整。\n- 超参数用于定义模型结构或优化策略，如类别个数、步长、正则化系数等，其选取通常需要人工经验或搜索方法。\n- 超参数优化是机器学习中的经验性技术，通常通过试错调整来确定最佳组合。"
      },
      {
        "段落": "### 2．2．3．1 梯度下降法\n\n为了充分利用凸优化中一些高效、成熟的优化方法，比如共轭梯度、拟牛顿法等，很多机器学习方法都倾向于选择合适的模型和损失函数以构造一个凸函数作为优化目标。但也有很多模型（比如神经网络）的优化目标是非凸的，只能退而求其次找到局部最优解．\n\n在机器学习中，最简单、常用的优化算法就是梯度下降法，即首先初始化参数 $\\theta_{0}$ ，然后按下面的迭代公式来计算训练集 $\\mathcal{D}$ 上风险函数的最小值：\n\n$$\n\\begin{align*}\n\\theta_{t+1} & =\\theta_{t}-\\alpha \\frac{\\partial \\mathcal{R}_{\\mathcal{D}}(\\theta)}{\\partial \\theta}  \\tag{2.27}\\\\\n& =\\theta_{t}-\\alpha \\frac{1}{N} \\sum_{n=1}^{N} \\frac{\\partial \\mathcal{L}\\left(y^{(n)}, f\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)\\right)}{\\partial \\theta} \\tag{2.28}\n\\end{align*}\n$$\n\n其中 $\\theta_{t}$ 为第 $t$ 次迭代时的参数值，$\\alpha$ 为搜索步长．在机器学习中，$\\alpha$ 一般称为学习率（Learning Rate）。",
        "总结": "- 概念：梯度下降法是一种用于优化机器学习模型参数的简单且常用的算法，通过迭代更新参数以最小化风险函数。\n- 算法：梯度下降法通过计算损失函数关于参数的梯度，并按照负梯度方向调整参数，以逐步逼近最优解。\n- 公式：参数更新公式为 $\\theta_{t+1} = \\theta_t - \\alpha \\frac{1}{N} \\sum_{n=1}^{N} \\frac{\\partial \\mathcal{L}(y^{(n)}, f(\\boldsymbol{x}^{(n)}; \\theta))}{\\partial \\theta}$，其中 $\\alpha$ 为学习率。\n- 关键参数：学习率 $\\alpha$ 控制参数更新的步长，对算法收敛速度和稳定性有重要影响。"
      },
      {
        "段落": "### 2．2．3．2 提前停止\n\n针对梯度下降的优化算法，除了加正则化项之外，还可以通过提前停止来防止过拟合。\n\n在梯度下降训练的过程中，由于过拟合的原因，在训练样本上收敛的参数，并不一定在测试集上最优。因此，除了训练集和测试集之外，有时也会使用一个验证集（Validation Set）来进行模型选择，测试模型在验证集上是否最优。在每次迭\n\n在贝叶斯方法中，超参数可以理解为参数的参数，即控制模型参数分布的参数．\n\n超参数的优化参见第 7.6 节．\n\n梯度下降法参见第 C．2．2节．\n\n验证集也叫开发集 （Development Set）。\n\n代时，把新得到的模型 $f(\\boldsymbol{x} ; \\theta)$ 在验证集上进行测试，并计算错误率。如果在验证集上的错误率不再下降，就停止迭代。这种策略叫提前停止（Early Stop ）。如果没有验证集，可以在训练集上划分出一个小比例的子集作为验证集。图2．4给出了提前停止的示例。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-044.jpg?height=483&width=580&top_left_y=370&top_left_x=363)\n\n图 2.4 提前停止的示例",
        "总结": "- 提出的概念：提前停止（Early Stop），用于防止梯度下降算法过拟合。\n- 提出的策略：在训练过程中，通过验证集评估模型性能，当验证集上的错误率不再下降时停止迭代。\n- 相关术语：验证集（Validation Set）也称为开发集（Development Set）。\n- 方法说明：如果没有验证集，可从训练集中划分出一个小比例子集作为验证集。\n- 图示说明：图2.4展示了提前停止的示例。"
      },
      {
        "段落": "### 2．2．3．3 随机梯度下降法\n\n在公式（2．27）的梯度下降法中，目标函数是整个训练集上的风险函数，这种方式称为批量梯度下降法（Batch Gradient Descent，BGD）。批量梯度下降法在每次迭代时需要计算每个样本上损失函数的梯度并求和。当训练集中的样本数量 $N$ 很大时，空间复杂度比较高，每次迭代的计算开销也很大。\n\n在机器学习中，我们假设每个样本都是独立同分布地从真实数据分布中随机抽取出来的，真正的优化目标是期望风险最小。批量梯度下降法相当于是从真实数据分布中采集 $N$ 个样本，并由它们计算出来的经验风险的梯度来近似期望风险的梯度。 为了减少每次迭代的计算复杂度，我们也可以在每次迭代时只采集一个样本，计算这个样本损失函数的梯度并更新参数，即随机梯度下降法 （Stochastic Gradient Descent，SGD）。当经过足够次数的迭代时，随机梯度下降也可以收敛到局部最优解［Nemirovski et al．，2009］．\n\n随机梯度下降法也叫增量梯度下降法。\n\n随机梯度下降法的训练过程如算法2．1所示．\n批量梯度下降和随机梯度下降之间的区别在于每次迭代的优化目标是对所有样本的平均损失函数还是单个样本的损失函数。随机梯度下降因为实现简单，收玫速度也非常快，因此使用非常广泛。随机梯度下降相当于在批量梯度下降的梯度上引入了随机噪声。当目标函数非凸时，反而可以使其逃离局部最优点。\n\n不同机器学习算法的区别在于模型、学习准则（损失函数）和优化算法的差异．相同的模型也可以有不同的学习算法．比如线性分类模型有感知器、Logistic\n\n```\n算法 2.1: 随机梯度下降法\n    输入: 训练集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$, 验证集 $\\mathcal{V}$, 学习率 $\\alpha$\n    随机初始化 $\\theta$;\n    repeat\n        对训练集 $\\mathcal{D}$ 中的样本随机排序;\n        for $n=1 \\cdots N$ do\n            从训练集 $\\mathcal{D}$ 中选取样本 $\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)$;\n            // 更新参数\n            $\\theta \\leftarrow \\theta-\\alpha \\frac{\\partial \\mathcal{L}\\left(\\theta ; x^{(n)}, y^{(n)}\\right)}{\\partial \\theta} ;$\n        end\n    until 模型 $f(\\boldsymbol{x} ; \\theta)$ 在验证集 $\\mathcal{V}$ 上的错误率不再下降;\n    输出: $\\theta$\n```\n\n回归和支持向量机，它们之间的差异在于使用了不同的学习准则和优化算法．\n\n小批量梯度下降法 随机梯度下降法的一个缺点是无法充分利用计算机的并行计算能力。 小批量梯度下降法（Mini－Batch Gradient Descent）是批量梯度下降和随机梯度下降的折中。每次迭代时，我们随机选取一小部分训练样本来计算梯度并更新参数，这样既可以兼顾随机梯度下降法的优点，也可以提高训练效率．\n\n第 $t$ 次迭代时，随机选取一个包含 $K$ 个样本的子集 $\\mathcal{S}_{t}$ ，计算这个子集上每个样本损失函数的梯度并进行平均，然后再进行参数更新：\n\n$$\n\\begin{equation*}\n\\theta_{t+1} \\leftarrow \\theta_{t}-\\alpha \\frac{1}{K} \\sum_{(\\boldsymbol{x}, y) \\in \\mathcal{S}_{t}} \\frac{\\partial \\mathcal{L}(y, f(\\boldsymbol{x} ; \\theta))}{\\partial \\theta} \\tag{2.29}\n\\end{equation*}\n$$\n\n在实际应用中，小批量随机梯度下降法有收敛快、计算开销小的优点，因此逐渐成为大规模的机器学习中的主要优化算法［Bottou，2010］．",
        "总结": "- 随机梯度下降法（SGD）是一种优化算法，通过每次迭代仅使用一个样本的梯度来更新参数，以减少计算开销。  \n- 与批量梯度下降法不同，SGD每次迭代仅计算单个样本的损失函数梯度，而非所有样本的梯度总和。  \n- SGD的训练过程如算法2.1所示，包括随机初始化参数、随机排序训练集、逐个样本更新参数，直到验证集错误率不再下降。  \n- SGD相当于在批量梯度下降的梯度上引入随机噪声，有助于逃离局部最优解。  \n- 小批量梯度下降法是SGD和批量梯度下降的折中方案，每次迭代使用一小部分样本计算梯度并更新参数。  \n- 小批量梯度下降法通过平衡随机性和计算效率，提高了训练效率，并成为大规模机器学习中的主要优化算法。"
      },
      {
        "段落": "## 2.3 机器学习的简单示例：线性回归\n\n在本节中，我们通过一个简单的模型（线性回归）来具体了解机器学习的一般过程，以及不同学习准则（经验风险最小化、结构风险最小化、最大似然估计、最大后验估计）之间的关系。\n\n线性回归（Linear Regression）是机器学习和统计学中最基础和广泛应用的模型，是一种对自变量和因变量之间关系进行建模的回归分析。自变量数量为 1时称为简单回归，自变量数量大于 1 时称为多元回归．\n\n从机器学习的角度来看，自变量就是样本的特性向量 $\\boldsymbol{x} \\in \\mathbb{R}^{D}$（每一维对应 https：／／nndl．github．io／\n$K$ 通常不会设置很大，一般在 $1 \\sim 100$ 之间．在实际应用中为了提高计算效率，通常设置为 2 的幂 $2^{n}$ 。\n\n一个自变量），因变量是标签 $y$ ，这里 $y \\in \\mathbb{R}$ 是连续值（实数或连续整数）。假设空间是一组参数化的线性函数\n\n$$\n\\begin{equation*}\nf(\\boldsymbol{x} ; \\boldsymbol{w}, b)=\\boldsymbol{w}^{\\top} \\boldsymbol{x}+b \\tag{2.30}\n\\end{equation*}\n$$\n\n其中权重向量 $\\boldsymbol{w} \\in \\mathbb{R}^{D}$ 和偏置 $b \\in \\mathbb{R}$ 都是可学习的参数，函数 $f(\\boldsymbol{x} ; \\boldsymbol{w}, b) \\in \\mathbb{R}$ 也称为线性模型。\n\n为简单起见，我们将公式（2．30）写为\n\n$$\n\\begin{equation*}\nf(\\boldsymbol{x} ; \\hat{\\boldsymbol{w}})=\\hat{\\boldsymbol{w}}^{\\top} \\hat{\\boldsymbol{x}} \\tag{2.31}\n\\end{equation*}\n$$\n\n其中 $\\hat{\\boldsymbol{w}}$ 和 $\\hat{\\boldsymbol{x}}$ 分别称为增广权重向量和增广特征向量：\n\n$$\n\\begin{align*}\n& \\hat{\\boldsymbol{x}}=\\boldsymbol{x} \\oplus 1 \\triangleq\\left[\\begin{array}{c}\n\\boldsymbol{x} \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{c}\nx_{1} \\\\\n\\vdots \\\\\nx_{D} \\\\\n1\n\\end{array}\\right]  \\tag{2.32}\\\\\n& \\hat{\\boldsymbol{w}}=\\boldsymbol{w} \\oplus b \\triangleq\\left[\\begin{array}{c}\nw_{1} \\\\\n\\vdots \\\\\nw_{D} \\\\\nb\n\\end{array}\\right] \\tag{2.33}\n\\end{align*}\n$$\n\n其中 $\\oplus$ 定义为两个向量的拼接操作。\n不失一般性，在本章后面的描述中我们采用简化的表示方法，直接用 $\\boldsymbol{w}$ 和 $\\boldsymbol{x}$来表示增广权重向量和增广特征向量．这样，线性回归的模型简写为 $f(\\boldsymbol{x} ; \\boldsymbol{w})=$ $\\boldsymbol{w}^{\\top} \\boldsymbol{x}$ 。",
        "总结": "- 线性回归是机器学习和统计学中最基础和广泛应用的模型，用于对自变量和因变量之间的关系进行建模。\n- 自变量数量为1时称为简单回归，自变量数量大于1时称为多元回归。\n- 自变量表示样本的特性向量 $\\boldsymbol{x} \\in \\mathbb{R}^{D}$，因变量 $y \\in \\mathbb{R}$ 是连续值。\n- 假设空间是一组参数化的线性函数 $f(\\boldsymbol{x} ; \\boldsymbol{w}, b) = \\boldsymbol{w}^{\\top} \\boldsymbol{x} + b$。\n- 权重向量 $\\boldsymbol{w} \\in \\mathbb{R}^{D}$ 和偏置 $b \\in \\mathbb{R}$ 是可学习的参数。\n- 为简化表示，将公式写为 $f(\\boldsymbol{x} ; \\hat{\\boldsymbol{w}}) = \\hat{\\boldsymbol{w}}^{\\top} \\hat{\\boldsymbol{x}}$，其中 $\\hat{\\boldsymbol{x}}$ 和 $\\hat{\\boldsymbol{w}}$ 分别是增广特征向量和增广权重向量。\n- 增广特征向量 $\\hat{\\boldsymbol{x}} = \\boldsymbol{x} \\oplus 1$，增广权重向量 $\\hat{\\boldsymbol{w}} = \\boldsymbol{w} \\oplus b$，其中 $\\oplus$ 表示向量拼接操作。\n- 在后续描述中采用简化的表示方法，直接用 $\\boldsymbol{w}$ 和 $\\boldsymbol{x}$ 表示增广权重向量和增广特征向量，模型简写为 $f(\\boldsymbol{x} ; \\boldsymbol{w}) = \\boldsymbol{w}^{\\top} \\boldsymbol{x}$。"
      },
      {
        "段落": "## 2．3．1 参数学习\n\n给定一组包含 $N$ 个训练样本的训练集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{D}$ ，我们希望能够学习一个最优的线性回归的模型参数 $\\boldsymbol{w}$ 。\n\n我们介绍四种不同的参数估计方法：经验风险最小化、结构风险最小化、最大似然估计、最大后验估计。",
        "总结": "- 参数学习的目标是学习一个最优的线性回归模型参数 $\\boldsymbol{w}$，以适应给定的训练集 $\\mathcal{D}$。  \n- 介绍了四种参数估计方法：经验风险最小化、结构风险最小化、最大似然估计、最大后验估计。"
      },
      {
        "段落": "### 2．3．1．1 经验风险最小化\n\n由于线性回归的标签 $y$ 和模型输出都为连续的实数值，因此平方损失函数非常合适来衡量真实标签和预测标签之间的差异。\n\n根据经验风险最小化准则，训练集 $\\mathcal{D}$ 上的经验风险定义为\n\n$$\n\\begin{align*}\n\\mathcal{R}(\\boldsymbol{w}) & =\\sum_{n=1}^{N} \\mathcal{L}\\left(y^{(n)}, f\\left(\\boldsymbol{x}^{(n)} ; \\boldsymbol{w}\\right)\\right)  \\tag{2.34}\\\\\n& =\\frac{1}{2} \\sum_{n=1}^{N}\\left(y^{(n)}-\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}\\right)^{2}  \\tag{2.35}\\\\\n& =\\frac{1}{2}\\left\\|\\boldsymbol{y}-\\boldsymbol{X}^{\\top} \\boldsymbol{w}\\right\\|^{2} \\tag{2.36}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{y}=\\left[y^{(1)}, \\cdots, y^{(N)}\\right]^{\\top} \\in \\mathbb{R}^{N}$ 是由所有样本的真实标签组成的列向量，而 $\\boldsymbol{X} \\in \\mathbb{R}^{(D+1) \\times N}$ 是由所有样本的输入特征 $\\boldsymbol{x}^{(1)}, \\cdots, \\boldsymbol{x}^{(N)}$ 组成的矩阵\n\n$$\n\\boldsymbol{X}=\\left[\\begin{array}{cccc}\nx_{1}^{(1)} & x_{1}^{(2)} & \\cdots & x_{1}^{(N)}  \\tag{2.37}\\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{D}^{(1)} & x_{D}^{(2)} & \\cdots & x_{D}^{(N)} \\\\\n1 & 1 & \\cdots & 1\n\\end{array}\\right]\n$$\n\n风险函数 $\\mathcal{R}(\\boldsymbol{w})$ 是关于 $\\boldsymbol{w}$ 的凸函数，其对 $\\boldsymbol{w}$ 的偏导数为\n\n$$\n\\begin{align*}\n\\frac{\\partial \\mathcal{R}(\\boldsymbol{w})}{\\partial \\boldsymbol{w}} & =\\frac{1}{2} \\frac{\\partial\\left\\|\\boldsymbol{y}-\\boldsymbol{X}^{\\top} \\boldsymbol{w}\\right\\|^{2}}{\\partial \\boldsymbol{w}}  \\tag{2.38}\\\\\n& =-\\boldsymbol{X}\\left(\\boldsymbol{y}-\\boldsymbol{X}^{\\top} \\boldsymbol{w}\\right) \\tag{2.39}\n\\end{align*}\n$$\n\n令 $\\frac{\\partial}{\\partial \\boldsymbol{w}} \\mathcal{R}(\\boldsymbol{w})=0$ ，得到最优的参数 $\\boldsymbol{w}^{*}$ 为\n\n$$\n\\begin{align*}\n\\boldsymbol{w}^{*} & =\\left(\\boldsymbol{X} \\boldsymbol{X}^{\\top}\\right)^{-1} \\boldsymbol{X} \\boldsymbol{y}  \\tag{2.40}\\\\\n& =\\left(\\sum_{n=1}^{N} \\boldsymbol{x}^{(n)}\\left(\\boldsymbol{x}^{(n)}\\right)^{\\top}\\right)^{-1}\\left(\\sum_{n=1}^{N} \\boldsymbol{x}^{(n)} y^{(n)}\\right) . \\tag{2.41}\n\\end{align*}\n$$\n\n这种求解线性回归参数的方法也叫最小二乘法（Least Square Method，LSM）。图2．5给出了用最小二乘法来进行线性回归参数学习的示例。\n\n在最小二乘法中， $\\boldsymbol{X} \\boldsymbol{X}^{\\top} \\in \\mathbb{R}^{(D+1) \\times(D+1)}$ 必须存在逆矩阵，即 $\\boldsymbol{X} \\boldsymbol{X}^{\\top}$ 是满秩的 （ $\\operatorname{rank}\\left(\\boldsymbol{X X}^{\\top}\\right)=D+1$ ）。也就是说， $\\boldsymbol{X}$ 中的行向量之间是线性不相关的，即每一个特征都和其他特征不相关。 一种常见的 $\\boldsymbol{X} \\boldsymbol{X}^{\\top}$ 不可逆情况是样本数量 $N$ 小于特征数量 $(D+1), \\boldsymbol{X} \\boldsymbol{X}^{\\top}$ 的秩为 $N$ 。这时会存在很多解 $\\boldsymbol{w}^{*}$ ，可以使得 $\\mathcal{R}\\left(\\boldsymbol{w}^{*}\\right)=0$ 。\n\n为了简化起见，这里的风险函数省略了 $\\frac{1}{N}$ 。\n\n参见习题 2－2．\n$\\left(\\boldsymbol{X} \\boldsymbol{X}^{\\top}\\right)^{-1} \\boldsymbol{X}$ 也称为 $\\boldsymbol{X}$ 的伪逆矩阵。\n\n在古代汉语中＂平方＂称为＂二乘＂．\n\n参见习题 2－3．\n\n当 $\\boldsymbol{X} \\boldsymbol{X}^{\\top}$ 不可逆时，可以通过下面两种方法来估计参数：（1）先使用主成分分析等方法来预处理数据，消除不同特征之间的相关性，然后再使用最小二乘法来估计参数；（2）通过用梯度下降法来估计参数．先初始化 $\\boldsymbol{w}=0$ ，然后通过下面公式进行迭代：\n\n$$\n\\begin{equation*}\n\\boldsymbol{w} \\leftarrow \\boldsymbol{w}+\\alpha \\boldsymbol{X}\\left(\\boldsymbol{y}-\\boldsymbol{X}^{\\top} \\boldsymbol{w}\\right), \\tag{2.42}\n\\end{equation*}\n$$\n\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-048.jpg?height=539&width=679&top_left_y=123&top_left_x=325)\n\n图 2.5 用最小二乘法来进行线性回归参数学习的示例\n\n其中 $\\alpha$ 是学习率．这种利用梯度下降法来求解的方法也称为最小均方（Least Mean Squares，LMS）算法．",
        "总结": "- 经验风险最小化准则用于线性回归，通过最小化平方损失函数来衡量预测值与真实值的差异  \n- 经验风险定义为训练集上所有样本的平方损失函数之和，并可表示为向量形式  \n- 矩阵 $\\boldsymbol{X}$ 包含所有样本的输入特征，并在最后一行添加全1列以适应偏置项  \n- 风险函数 $\\mathcal{R}(\\boldsymbol{w})$ 是关于参数 $\\boldsymbol{w}$ 的凸函数，其梯度为 $-\\boldsymbol{X}(\\boldsymbol{y}-\\boldsymbol{X}^{\\top} \\boldsymbol{w})$  \n- 最优参数 $\\boldsymbol{w}^{*}$ 通过令梯度为零求得，即 $\\boldsymbol{w}^{*} = (\\boldsymbol{X} \\boldsymbol{X}^{\\top})^{-1} \\boldsymbol{X} \\boldsymbol{y}$  \n- 最小二乘法是求解线性回归参数的一种方法，其解依赖于矩阵 $\\boldsymbol{X} \\boldsymbol{X}^{\\top}$ 可逆  \n- 当 $\\boldsymbol{X} \\boldsymbol{X}^{\\top}$ 不可逆时，可通过主成分分析或梯度下降法进行参数估计  \n- 梯度下降法通过迭代更新参数，公式为 $\\boldsymbol{w} \\leftarrow \\boldsymbol{w} + \\alpha \\boldsymbol{X}(\\boldsymbol{y}-\\boldsymbol{X}^{\\top}\\boldsymbol{w})$，该方法也称为最小均方（LMS）算法"
      },
      {
        "段落": "### 2．3．1．2 结构风险最小化\n\n最小二乘法的基本要求是各个特征之间要互相独立，保证 $\\boldsymbol{X} \\boldsymbol{X}^{\\top}$ 可逆。但即使 $\\boldsymbol{X} \\boldsymbol{X}^{\\top}$ 可逆，如果特征之间有较大的多重共线性（Multicollinearity），也会使得 $\\boldsymbol{X} \\boldsymbol{X}^{\\top}$ 的逆在数值上无法准确计算。数据集 $\\boldsymbol{X}$ 上一些小的扰动就会导致 $\\left(\\boldsymbol{X} \\boldsymbol{X}^{\\top}\\right)^{-1}$发生大的改变，进而使得最小二乘法的计算变得很不稳定。为了解决这个问题， ［Hoerl et al．，1970］提出了岭回归（Ridge Regression），给 $\\boldsymbol{X} \\boldsymbol{X}^{\\boldsymbol{\\top}}$ 的对角线元素都加上一个常数 $\\lambda$ 使得 $\\left(\\boldsymbol{X} \\boldsymbol{X}^{\\top}+\\lambda I\\right)$ 满秩，即其行列式不为 0 。最优的参数 $\\boldsymbol{w}^{*}$ 为\n\n$$\n\\begin{equation*}\n\\boldsymbol{w}^{*}=\\left(\\boldsymbol{X} \\boldsymbol{X}^{\\top}+\\lambda I\\right)^{-1} \\boldsymbol{X} \\boldsymbol{y} \\tag{2.43}\n\\end{equation*}\n$$\n\n其中 $\\lambda>0$ 为预先设置的超参数，$I$ 为单位矩阵．\n岭回归的解 $\\boldsymbol{w}^{*}$ 可以看作是结构风险最小化准则下的最小二乘法估计，其目标函数可以写为\n\n$$\n\\begin{equation*}\n\\mathcal{R}(\\boldsymbol{w})=\\frac{1}{2}\\left\\|\\boldsymbol{y}-\\boldsymbol{X}^{\\top} \\boldsymbol{w}\\right\\|^{2}+\\frac{1}{2} \\lambda\\|\\boldsymbol{w}\\|^{2} \\tag{2.44}\n\\end{equation*}\n$$\n\n其中 $\\lambda>0$ 为正则化系数．",
        "总结": "- 结构风险最小化准则引入了正则化项，以解决最小二乘法在特征多重共线性问题下的不稳定性。  \n- 岭回归通过在 $\\boldsymbol{X} \\boldsymbol{X}^{\\top}$ 的对角线元素上加上一个正数 $\\lambda$，使得矩阵 $\\boldsymbol{X} \\boldsymbol{X}^{\\top} + \\lambda I$ 满秩，从而保证逆矩阵存在。  \n- 岭回归的最优参数 $\\boldsymbol{w}^{*}$ 表达式为 $\\left(\\boldsymbol{X} \\boldsymbol{X}^{\\top} + \\lambda I\\right)^{-1} \\boldsymbol{X} \\boldsymbol{y}$。  \n- 目标函数 $\\mathcal{R}(\\boldsymbol{w})$ 包含数据拟合误差项和正则化项，形式为 $\\frac{1}{2}\\left\\|\\boldsymbol{y}-\\boldsymbol{X}^{\\top} \\boldsymbol{w}\\right\\|^{2}+\\frac{1}{2} \\lambda\\|\\boldsymbol{w}\\|^{2}$。  \n- $\\lambda$ 是一个正则化系数，用于控制模型复杂度与拟合精度之间的平衡。"
      },
      {
        "段落": "### 2．3．1．3 最大似然估计\n\n机器学习任务可以分为两类：一类是样本的特征向量 $\\boldsymbol{x}$ 和标签 $y$ 之间存在未知的函数关系 $y=h(\\boldsymbol{x})$ ，另一类是条件概率 $p(y \\mid \\boldsymbol{x})$ 服从某个未知分布。第2．3．1．1中介绍的最小二乘法是属于第一类，直接建模 $\\boldsymbol{x}$ 和标签 $y$ 之间的函数关系。此外，线性回归还可以通过建模条件概率 $p(y \\mid \\boldsymbol{x})$ 的角度来进行参数估计。 https：／／nndl．github．io／\n\n共线性是指一个特征可以通过其他特征的线性组合来被较准确地预测．\n\n假设标签 $y$ 为一个随机变量，其服从以均值为 $f(\\boldsymbol{x} ; \\boldsymbol{w})=\\boldsymbol{w}^{\\top} \\boldsymbol{x}$ ，方差为 $\\sigma^{2}$ 的高斯分布：\n\n$$\n\\begin{align*}\np(y \\mid \\boldsymbol{x} ; \\boldsymbol{w}, \\sigma) & =\\mathcal{N}\\left(y ; \\boldsymbol{w}^{\\top} \\boldsymbol{x}, \\sigma^{2}\\right)  \\tag{2.45}\\\\\n& =\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{\\left(y-\\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)^{2}}{2 \\sigma^{2}}\\right) . \\tag{2.46}\n\\end{align*}\n$$\n\n参数 $\\boldsymbol{w}$ 在训练集 $\\mathcal{D}$ 上的似然函数（Likelihood）为\n\n$$\n\\begin{align*}\np(\\boldsymbol{y} \\mid \\boldsymbol{X} ; \\boldsymbol{w}, \\sigma) & =\\prod_{n=1}^{N} p\\left(y^{(n)} \\mid \\boldsymbol{x}^{(n)} ; \\boldsymbol{w}, \\sigma\\right)  \\tag{2.47}\\\\\n& =\\prod_{n=1}^{N} \\mathcal{N}\\left(y^{(n)} ; \\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}, \\sigma^{2}\\right) \\tag{2.48}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{y}=\\left[y^{(1)}, \\cdots, y^{(N)}\\right]^{\\top}$ 为所有样本标签组成的向量， $\\boldsymbol{X}=\\left[\\boldsymbol{x}^{(1)}, \\cdots, \\boldsymbol{x}^{(N)}\\right]$ 为所有样本特征向量组成的矩阵。\n\n为了方便计算，对似然函数取对数得到对数似然函数（Log Likelihood），\n\n$$\n\\begin{equation*}\n\\log p(\\boldsymbol{y} \\mid \\boldsymbol{X} ; \\boldsymbol{w}, \\sigma)=\\sum_{n=1}^{N} \\log \\mathcal{N}\\left(y^{(n)} ; \\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}, \\sigma^{2}\\right) \\tag{2.49}\n\\end{equation*}\n$$\n\n最大似然估计（Maximum Likelihood Estimation，MLE）是指找到一组参数 $\\boldsymbol{w}$ 使得似然函数 $p(\\boldsymbol{y} \\mid \\boldsymbol{X} ; \\boldsymbol{w}, \\sigma)$ 最大，等价于对数似然函数 $\\log p(\\boldsymbol{y} \\mid \\boldsymbol{X} ; \\boldsymbol{w}, \\sigma)$ 最大。\n\n令 $\\frac{\\partial \\log p(\\boldsymbol{y} \\mid \\boldsymbol{X} ; \\boldsymbol{w}, \\sigma)}{\\partial \\boldsymbol{w}}=0$ ，得到\n\n$$\n\\begin{equation*}\n\\boldsymbol{w}^{M L}=\\left(\\boldsymbol{X} \\boldsymbol{X}^{\\top}\\right)^{-1} \\boldsymbol{X} \\boldsymbol{y} . \\tag{2.50}\n\\end{equation*}\n$$\n\n可以看出，最大似然估计的解和最小二乘法的解相同．",
        "总结": "- 最大似然估计（MLE）是一种参数估计方法，通过最大化似然函数来估计模型参数。  \n- 假设标签 $y$ 服从以 $f(\\boldsymbol{x}; \\boldsymbol{w}) = \\boldsymbol{w}^\\top \\boldsymbol{x}$ 为均值、$\\sigma^2$ 为方差的高斯分布。  \n- 似然函数定义为所有样本标签的联合概率，即 $p(\\boldsymbol{y} \\mid \\boldsymbol{X}; \\boldsymbol{w}, \\sigma)$。  \n- 对数似然函数通过对数转换简化计算，形式为 $\\sum_{n=1}^{N} \\log \\mathcal{N}(y^{(n)}; \\boldsymbol{w}^\\top \\boldsymbol{x}^{(n)}, \\sigma^2)$。  \n- 最大似然估计通过求导并令导数为零，得到参数 $\\boldsymbol{w}$ 的解为 $\\boldsymbol{w}^{ML} = (\\boldsymbol{X}\\boldsymbol{X}^\\top)^{-1}\\boldsymbol{X}\\boldsymbol{y}$。  \n- 最大似然估计的解与最小二乘法的解相同。"
      },
      {
        "段落": "### 2．3．1．4 最大后验估计\n\n假设参数 $\\boldsymbol{w}$ 为一个随机向量，并服从一个先验分布 $p(\\boldsymbol{w} ; \\nu)$ 。为简单起见，一般令 $p(\\boldsymbol{w} ; \\nu)$ 为各向同性的高斯分布：\n\n$$\n\\begin{equation*}\np(\\boldsymbol{w} ; \\nu)=\\mathcal{N}\\left(\\boldsymbol{w} ; \\mathbf{0}, \\nu^{2} I\\right) \\tag{2.51}\n\\end{equation*}\n$$\n\n其中 $\\nu^{2}$ 为每一维上的方差．\n根据贝叶斯公式，那么参数 $\\boldsymbol{w}$ 的后验分布（Posterior Distribution）为\n\n$$\n\\begin{align*}\np(\\boldsymbol{w} \\mid \\boldsymbol{X}, \\boldsymbol{y} ; \\nu, \\sigma) & =\\frac{p(\\boldsymbol{w}, \\boldsymbol{y} \\mid \\boldsymbol{X} ; \\nu, \\sigma)}{\\sum_{\\boldsymbol{w}} p(\\boldsymbol{w}, \\boldsymbol{y} \\mid \\boldsymbol{X} ; \\nu, \\sigma)}  \\tag{2.52}\\\\\n& \\propto p(\\boldsymbol{y} \\mid \\boldsymbol{X}, \\boldsymbol{w} ; \\sigma) p(\\boldsymbol{w} ; \\nu) \\tag{2.53}\n\\end{align*}\n$$\n\n这里 $\\boldsymbol{x}$ 看作是确定值的参数．\n\n似然函数是关于统计模型的参数的函数．\n似然 $p(x \\mid w)$ 和概率 $p(x \\mid w)$ 之间的区别在于：概率 $p(x \\mid w)$ 是描述固定参数 $w$ 时，随机变量 $x$ 的分布情况，而似然 $p(x \\mid w)$ 则是描述已知随机变量 $x$ 时，不同的参数 $w$ 对其分布的影响．\n\n参见习题 2－5．\n\n最小二乘法参见公式（2．40）。\n\n贝叶斯公式参见公式（D．32）。\n\n分母为和 $\\boldsymbol{w}$ 无关的常量。\n\n其中 $p(\\boldsymbol{y} \\mid \\boldsymbol{X} ; \\boldsymbol{w}, \\sigma)$ 为 $\\boldsymbol{w}$ 的似然函数，定义见公式（2．47），$p(\\boldsymbol{w} ; \\nu)$ 为 $\\boldsymbol{w}$ 的先验。\n这种估计参数 $\\boldsymbol{w}$ 的后验概率分布的方法称为贝叶斯估计（Bayesian Estima－ tion），是一种统计推断问题。采用贝叶斯估计的线性回归也称为贝叶斯线性回归（Bayesian Linear Regression）。\n\n贝叶斯估计是一种参数的区间估计，即参数在一个区间上的分布．如果我们希望得到一个最优的参数值（即点估计），可以使用最大后验估计。最大后验估计（Maximum A Posteriori Estimation，MAP）是指最优参数为后验分布 $p(\\boldsymbol{w} \\mid \\boldsymbol{X}, \\boldsymbol{y} ; \\nu, \\sigma)$ 中概率密度最高的参数：\n\n$$\n\\begin{equation*}\n\\boldsymbol{w}^{M A P}=\\underset{\\boldsymbol{w}}{\\arg \\max } p(\\boldsymbol{y} \\mid \\boldsymbol{X}, \\boldsymbol{w} ; \\sigma) p(\\boldsymbol{w} ; \\nu), \\tag{2.54}\n\\end{equation*}\n$$\n\n令似然函数 $p(\\boldsymbol{y} \\mid \\boldsymbol{X}, \\boldsymbol{w} ; \\sigma)$ 为公式（2．48）中定义的高斯密度函数，则后验分布 $p(\\boldsymbol{w} \\mid \\boldsymbol{X}, \\boldsymbol{y} ; \\nu, \\sigma)$ 的对数为\n\n$$\n\\begin{align*}\n\\log p(\\boldsymbol{w} \\mid \\boldsymbol{X}, \\boldsymbol{y} ; \\nu, \\sigma) & \\propto \\log p(\\boldsymbol{y} \\mid \\boldsymbol{X}, \\boldsymbol{w} ; \\sigma)+\\log p(\\boldsymbol{w} ; \\nu)  \\tag{2.55}\\\\\n& \\propto-\\frac{1}{2 \\sigma^{2}} \\sum_{n=1}^{N}\\left(y^{(n)}-\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}\\right)^{2}-\\frac{1}{2 \\nu^{2}} \\boldsymbol{w}^{\\top} \\boldsymbol{w}  \\tag{2.56}\\\\\n& =-\\frac{1}{2 \\sigma^{2}}\\left\\|\\boldsymbol{y}-\\boldsymbol{X}^{\\top} \\boldsymbol{w}\\right\\|^{2}-\\frac{1}{2 \\nu^{2}} \\boldsymbol{w}^{\\top} \\boldsymbol{w} \\tag{2.57}\n\\end{align*}\n$$\n\n可以看出，最大后验概率等价于平方损失的结构方法最小化，其中正则化系数 $\\lambda=\\sigma^{2} / \\nu^{2}$ 。\n\n最大似然估计和贝叶斯估计可以看作是频率学派和贝叶斯学派对需要估计的参数 $\\boldsymbol{w}$ 的不同解释。当 $v \\rightarrow \\infty$ 时，先验分布 $p(\\boldsymbol{w} ; \\nu)$ 退化为均匀分布，称为无信息先验（Non－Informative Prior），最大后验估计退化为最大似然估计。",
        "总结": "- 最大后验估计（MAP）是一种贝叶斯估计方法，用于求解参数的点估计，即找到后验分布中概率密度最高的参数值。  \n- 参数 $\\boldsymbol{w}$ 被视为随机向量，服从先验分布 $p(\\boldsymbol{w} ; \\nu)$，通常设为各向同性的高斯分布。  \n- 后验分布由贝叶斯公式定义，结合似然函数和先验分布，形式为 $p(\\boldsymbol{w} \\mid \\boldsymbol{X}, \\boldsymbol{y} ; \\nu, \\sigma) \\propto p(\\boldsymbol{y} \\mid \\boldsymbol{X}, \\boldsymbol{w} ; \\sigma) p(\\boldsymbol{w} ; \\nu)$。  \n- 最大后验估计通过最大化后验分布的对数形式实现，其表达式为 $\\boldsymbol{w}^{MAP} = \\arg\\max p(\\boldsymbol{y} \\mid \\boldsymbol{X}, \\boldsymbol{w} ; \\sigma) p(\\boldsymbol{w} ; \\nu)$。  \n- 后验分布的对数形式包含两个部分：似然项和先验项，分别对应数据拟合误差和参数的正则化项。  \n- 最大后验估计等价于最小化平方损失函数，并引入正则化项，其中正则化系数 $\\lambda = \\sigma^2 / \\nu^2$。  \n- 当先验分布退化为无信息先前（即 $\\nu \\rightarrow \\infty$）时，最大后验估计退化为最大似然估计。  \n- 最大似然估计和最大后验估计分别代表频率学派和贝叶斯学派对参数估计的不同观点。"
      },
      {
        "段落": "## 2.4 偏差－方差分解\n\n为了避免过拟合，我们经常会在模型的拟合能力和复杂度之间进行权衡。拟合能力强的模型一般复杂度会比较高，容易导致过拟合．相反，如果限制模型的复杂度，降低其拟合能力，又可能会导致欠拟合。因此，如何在模型的拟合能力和复杂度之间取得一个较好的平衡，对一个机器学习算法来讲十分重要。偏差－方差分解（Bias－Variance Decomposition）为我们提供一个很好的分析和指导工具。\n\n以回归问题为例，假设样本的真实分布为 $p_{r}(\\boldsymbol{x}, y)$ ，并采用平方损失函数，模型 $f(\\boldsymbol{x})$ 的期望错误为\n\n$$\n\\begin{equation*}\n\\mathcal{R}(f)=\\mathbb{E}_{(x, y) \\sim p_{r}(x, y)}\\left[(y-f(\\boldsymbol{x}))^{2}\\right] . \\tag{2.58}\n\\end{equation*}\n$$\n\n统计推断参见第11．3节。\n\n本节介绍的偏差一方差分解以回归问题为例，但其结论同样适用于分类问题．\n\n为简单起见，这里省略了模型参数 $\\theta$ 。\n\n那么最优的模型为\n\n$$\n\\begin{equation*}\nf^{*}(\\boldsymbol{x})=\\mathbb{E}_{y \\sim p_{r}(y \\mid \\boldsymbol{x})}[y] . \\tag{2.59}\n\\end{equation*}\n$$\n\n其中 $p_{r}(y \\mid \\boldsymbol{x})$ 为样本的真实条件分布，$f^{*}(\\boldsymbol{x})$ 为使用平方损失作为优化目标的最优模型，其损失为\n\n$$\n\\begin{equation*}\n\\varepsilon=\\mathbb{E}_{(\\boldsymbol{x}, y) \\sim p_{r}(\\boldsymbol{x}, y)}\\left[\\left(y-f^{*}(\\boldsymbol{x})\\right)^{2}\\right] \\tag{2.60}\n\\end{equation*}\n$$\n\n损失 $\\varepsilon$ 通常是由于样本分布以及噪声引起的，无法通过优化模型来减少．\n期望错误可以分解为\n\n$$\n\\begin{align*}\n\\mathcal{R}(f) & =\\mathbb{E}_{(\\boldsymbol{x}, y) \\sim p_{r}(\\boldsymbol{x}, y)}\\left[\\left(y-f^{*}(\\boldsymbol{x})+f^{*}(\\boldsymbol{x})-f(\\boldsymbol{x})\\right)^{2}\\right]  \\tag{2.61}\\\\\n& =\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})}\\left[\\left(f(\\boldsymbol{x})-f^{*}(\\boldsymbol{x})\\right)^{2}\\right]+\\varepsilon \\tag{2.62}\n\\end{align*}\n$$\n\n其中第一项是当前模型和最优模型之间的差距，是机器学习算法可以优化的真实目标。\n\n在实际训练一个模型 $f(\\boldsymbol{x})$ 时，训练集 $\\mathcal{D}$ 是从真实分布 $p_{r}(\\boldsymbol{x}, y)$ 上独立同分布地采样出来的有限样本集合。不同的训练集会得到不同的模型。令 $f_{\\mathcal{D}}(\\boldsymbol{x})$ 表示在训练集 $\\mathcal{D}$ 学习到的模型，一个机器学习算法（包括模型以及优化算法）的能力可以用不同训练集上的模型的平均性能来评价。\n\n对于单个样本 $\\boldsymbol{x}$ ，不同训练集 $\\mathcal{D}$ 得到模型 $f_{\\mathcal{D}}(\\boldsymbol{x})$ 和最优模型 $f^{*}(\\boldsymbol{x})$ 的期望差距为\n\n$$\n\\begin{align*}\n\\mathbb{E}_{\\mathcal{D}} & {\\left[\\left(f_{\\mathcal{D}}(\\boldsymbol{x})-f^{*}(\\boldsymbol{x})\\right)^{2}\\right] } \\\\\n& =\\mathbb{E}_{\\mathcal{D}}\\left[\\left(f_{\\mathcal{D}}(\\boldsymbol{x})-\\mathbb{E}_{\\mathcal{D}}\\left[f_{\\mathcal{D}}(\\boldsymbol{x})\\right]+\\mathbb{E}_{\\mathcal{D}}\\left[f_{\\mathcal{D}}(\\boldsymbol{x})\\right]-f^{*}(\\boldsymbol{x})\\right)^{2}\\right]  \\tag{2.63}\\\\\n& =\\underbrace{\\left(\\mathbb{E}_{\\mathcal{D}}\\left[f_{\\mathcal{D}}(\\boldsymbol{x})\\right]-f^{*}(\\boldsymbol{x})\\right)^{2}}_{\\text {(bias.x) }}+\\underbrace{\\mathbb{E}_{\\mathcal{D}}\\left[\\left(f_{\\mathcal{D}}(\\boldsymbol{x})-\\mathbb{E}_{\\mathcal{D}}\\left[f_{\\mathcal{D}}(\\boldsymbol{x})\\right]\\right)^{2}\\right]}_{\\text {variance.x }} \\tag{2.64}\n\\end{align*}\n$$\n\n其中第一项为偏差（Bias），是指一个模型在不同训练集上的平均性能和最优模型的差异，可以用来衡量一个模型的拟合能力。第二项是方差（Variance），是指一个模型在不同训练集上的差异，可以用来衡量一个模型是否容易过拟合。\n\n用 $\\mathbb{E}_{\\mathcal{D}}\\left[\\left(f_{\\mathcal{D}}(\\boldsymbol{x})-f^{*}(\\boldsymbol{x})\\right)^{2}\\right]$ 来代替公式（2．62）中的 $\\left(f(\\boldsymbol{x})-f^{*}(\\boldsymbol{x})\\right)^{2}$ ，期望错误可以进一步写为\n\n$$\n\\begin{align*}\n\\mathcal{R}(f) & =\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})}\\left[\\mathbb{E}_{\\mathcal{D}}\\left[\\left(f_{\\mathcal{D}}(\\boldsymbol{x})-f^{*}(\\boldsymbol{x})\\right)^{2}\\right]\\right]+\\varepsilon  \\tag{2.65}\\\\\n& =(\\text { bias })^{2}+\\text { variance }+\\varepsilon \\tag{2.66}\n\\end{align*}\n$$\n\nhttps：／／nndl．github．io／\n\n参见习题2－8．\n\n根据公式（2．59）可知， $\\mathbb{E}_{\\boldsymbol{x}} \\mathbb{E}_{\\boldsymbol{y}}\\left[y-f^{*}(\\boldsymbol{x})\\right]=0$.\n\n其中\n\n$$\n\\begin{align*}\n(\\text { bias })^{2} & =\\mathbb{E}_{\\boldsymbol{x}}\\left[\\left(\\mathbb{E}_{\\mathcal{D}}\\left[f_{\\mathcal{D}}(\\boldsymbol{x})\\right]-f^{*}(\\boldsymbol{x})\\right)^{2}\\right]  \\tag{2.67}\\\\\n\\text { variance } & =\\mathbb{E}_{\\boldsymbol{x}}\\left[\\mathbb{E}_{\\mathcal{D}}\\left[\\left(f_{\\mathcal{D}}(\\boldsymbol{x})-\\mathbb{E}_{\\mathcal{D}}\\left[f_{\\mathcal{D}}(\\boldsymbol{x})\\right]\\right)^{2}\\right]\\right] \\tag{2.68}\n\\end{align*}\n$$\n\n最小化期望错误等价于最小化偏差和方差之和。\n图2．6给出了机器学习模型的四种偏差和方差组合情况。每个图的中心点为最优模型 $f^{*}(\\boldsymbol{x})$ ，蓝点为不同训练集 $D$ 上得到的模型 $f_{\\mathcal{D}}(\\boldsymbol{x})$ 。图2．6a给出了一种理想情况，方差和偏差都比较小．图2．6b为高偏差低方差的情况，表示模型的泛化能力很好，但拟合能力不足。图2．6c为低偏差高方差的情况，表示模型的拟合能力很好，但泛化能力比较差。当训练数据比较少时会导致过拟合。图 2.6 d 为高偏差高方差的情况，是一种最差的情况。\n\n参见习题 2－9．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-052.jpg?height=804&width=828&top_left_y=841&top_left_x=248)\n\n图 2.6 机器学习模型的四种偏差和方差组合情况\n\n方差一般会随着训练样本的增加而减少。当样本比较多时，方差比较少，这时可以选择能力强的模型来减少偏差。然而在很多机器学习任务上，训练集往往都比较有限，最优的偏差和最优的方差就无法兼顾．\n\n随着模型复杂度的增加，模型的拟合能力变强，偏差减少而方差增大，从而导致过拟合。以结构错误最小化为例，我们可以调整正则化系数 $\\lambda$ 来控制模型的复杂度。当 $\\lambda$ 变大时，模型复杂度会降低，可以有效地减少方差，避免过拟合，但偏差会上升。当 $\\lambda$ 过大时，总的期望错误反而会上升。因此，一个好的正则化系数 $\\lambda$\n\n结构错误最小化参见公式（2．26）。\n\n需要在偏差和方差之间取得比较好的平衡。图2．7给出了机器学习模型的期望错误、偏差和方差随复杂度的变化情况，其中红色虚线表示最优模型。最优模型并不一定是偏差曲线和方差曲线的交点。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-053.jpg?height=452&width=700&top_left_y=309&top_left_x=308)\n\n图 2.7 机器学习模型的期望错误、偏差和方差随复杂度的变化情况\n\n偏差和方差分解给机器学习模型提供了一种分析途径，但在实际操作中难以直接衡量。一般来说，当一个模型在训练集上的错误率比较高时，说明模型的拟合能力不够，偏差比较高。这种情况可以通过增加数据特征、提高模型复杂度、减少正则化系数等操作来改进模型。当模型在训练集上的错误率比较低，但验证集上的错误率比较高时，说明模型过拟合，方差比较高。这种情况可以通过降低模型复杂度、加大正则化系数、引入先验等方法来缓解。此外，还有一种有效降低方差的方法为集成模型，即通过多个高方差模型的平均来降低方差。\n\n集成模型参见第 10.1节。",
        "总结": "- 偏差－方差分解用于分析模型的拟合能力和复杂度之间的平衡，帮助理解过拟合和欠拟合的原因。\n- 期望错误可以分解为偏差平方、方差和不可减少的误差（噪声）三部分。\n- 偏差表示模型在不同训练集上的平均性能与最优模型的差异，反映模型的拟合能力。\n- 方差表示模型在不同训练集上的差异，反映模型是否容易过拟合。\n- 最优模型 $f^*(\\boldsymbol{x})$ 是使用平方损失函数的最优预测，其损失为 $\\varepsilon$，由样本分布和噪声引起。\n- 期望错误公式为 $(\\text{bias})^2 + \\text{variance} + \\varepsilon$，其中 $\\varepsilon$ 无法通过优化减少。\n- 偏差随模型复杂度增加而减少，方差则随复杂度增加而增大，需在两者间取得平衡。\n- 正则化系数 $\\lambda$ 可以控制模型复杂度，增大 $\\lambda$ 可减少方差但增加偏差。\n- 图2.6展示了四种偏差和方差组合情况：理想情况、高偏差低方差、低偏差高方差、高偏差高方差。\n- 图2.7展示了期望错误、偏差和方差随模型复杂度的变化情况，最优模型不一定是偏差与方差曲线交点。\n- 当模型在训练集错误率高时，说明偏差大；当训练集错误率低但验证集错误率高时，说明方差大。\n- 集成方法通过多个高方差模型的平均来降低整体方差。"
      },
      {
        "段落": "## 2.5 机器学习算法的类型\n\n机器学习算法可以按照不同的标准来进行分类．比如按函数 $f(\\boldsymbol{x} ; \\theta)$ 的不同，机器学习算法可以分为线性模型和非线性模型；按照学习准则的不同，机器学习算法也可以分为统计方法和非统计方法。\n\n但一般来说，我们会按照训练样本提供的信息以及反馈方式的不同，将机器学习算法分为以下几类：\n\n监督学习 如果机器学习的目标是通过建模样本的特征 $\\boldsymbol{x}$ 和标签 $y$ 之间的关系： $y=f(\\boldsymbol{x} ; \\theta)$ 或 $p(y \\mid \\boldsymbol{x} ; \\theta)$ ，并且训练集中每个样本都有标签，那么这类机器学习称为监督学习（Supervised Learning）。根据标签类型的不同，监督学习又可以分为回归问题、分类问题和结构化学习问题．\n（1）回归（Regression）问题中的标签 $y$ 是连续值（实数或连续整数），$f(x ; \\theta)$的输出也是连续值．\n（2）分类（Classification）问题中的标签 $y$ 是离散的类别（符号）。在分类问题中，学习到的模型也称为分类器（Classifier）。分类问题根据其类别数量又可分为二分类（Binary Classification）和多分类（Multi－class Classifi－ cation）问题。\n（3）结构化学习（Structured Learning）问题的输出 $\\boldsymbol{y}$ 通常是结构化的对象，比如序列、树或图等。由于结构化学习的输出空间比较大，因此我们一般定义一个联合特征空间，将 $\\boldsymbol{x}, \\boldsymbol{y}$ 映射为该空间中的联合特征向量 $\\phi(\\boldsymbol{x}, \\boldsymbol{y})$ ，预测模型可以写为\n\n$$\n\\begin{equation*}\n\\hat{\\boldsymbol{y}}=\\underset{\\boldsymbol{y} \\in \\operatorname{Gen}(\\boldsymbol{x})}{\\arg \\max } f(\\phi(\\boldsymbol{x}, \\boldsymbol{y}) ; \\theta), \\tag{2.69}\n\\end{equation*}\n$$\n\n其中 $\\operatorname{Gen}(\\boldsymbol{x})$ 表示输入 $\\boldsymbol{x}$ 的所有可能的输出目标集合。计算 $\\arg \\max$ 的过程也称为解码（Decoding）过程，一般通过动态规划的方法来计算。\n\n无监督学习 无监督学习（Unsupervised Learning，UL）是指从不包含目标标签的训练样本中自动学习到一些有价值的信息。典型的无监督学习问题有聚类、密度估计、特征学习、降维等。\n\n强化学习 强化学习（Reinforcement Learning，RL）是一类通过交互来学习的机器学习算法。在强化学习中，智能体根据环境的状态做出一个动作，并得到即时或延时的奖励。智能体在和环境的交互中不断学习并调整策略，以取得最大化的期望总回报．\n\n表2．1给出了三种机器学习类型的比较．\n表 2.1 三种机器学习类型的比较\n\n|  | 监督学习 | 无监督学习 | 强化学习 |\n| :--- | :--- | :--- | :--- |\n| 训练样本 | 训练集 $\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ | 训练集 $\\left\\{\\boldsymbol{x}^{n}\\right\\}_{n=1}^{N}$ | 智能体和环境交互的轨迹 $\\tau$ 和累积奖励 $G_{\\tau}$ |\n| 优化目标 | $y=f(\\boldsymbol{x})$ 或 $p(y \\mid \\boldsymbol{x})$ | $p(\\boldsymbol{x})$ 或带隐变量 $\\boldsymbol{z}$的 $p(\\boldsymbol{x} \\mid \\boldsymbol{z})$ | 期望总回报 $\\mathbb{E}_{\\tau}\\left[G_{\\tau}\\right]$ |\n| 学习准则 | 期望风险最小化最大似然估计 | 最大似然估计最小重构错误 | 策略评估策略改进 |\n\n监督学习需要每个样本都有标签，而无监督学习则不需要标签。 一般而言，监督学习通常需要大量的有标签数据集，这些数据集一般都需要由人工进行标注，成本很高．因此，也出现了很多弱监督学习（Weakly Supervised Learning） https：／／nndl．github．io／\n\n结构化学习可以看作是一种特殊的分类问题．\n\n一种基于感知器的结构化学习参见第 3．4．4节。\n\n无监督学习参见第9章．\n\n强化学习参见第14章。\n\n和半监督学习（Semi－Supervised Learning，SSL）的方法，希望从大规模的无标注数据中充分挖掘有用的信息，降低对标注样本数量的要求。强化学习和监督学习的不同在于强化学习不需要显式地以＂输入／输出对＂的方式给出训练样本，是一种在线的学习机制。",
        "总结": "- 机器学习算法按训练样本提供的信息及反馈方式分为监督学习、无监督学习和强化学习  \n- 监督学习通过建模特征与标签的关系，根据标签类型分为回归、分类和结构化学习  \n- 回归问题中标签为连续值，模型输出也为连续值  \n- 分类问题中标签为离散类别，模型称为分类器，分为二分类和多分类  \n- 结构化学习输出为结构化对象（如序列、树、图），使用联合特征空间进行建模，预测模型通过解码过程计算  \n- 无监督学习从无标签数据中学习信息，典型任务包括聚类、密度估计、降维等  \n- 强化学习通过与环境交互学习策略，目标是最大化期望总回报  \n- 表2.1对比了三种机器学习类型的训练样本、优化目标和学习准则  \n- 监督学习需要大量带标签数据，成本高，因此出现弱监督和半监督学习方法  \n- 结构化学习是特殊的分类问题，可基于感知器进行建模（见第3.4.4节）  \n- 无监督学习相关内容见第9章，强化学习相关内容见第14章"
      },
      {
        "段落": "## 2.6 数据的特征表示\n\n在实际应用中，数据的类型多种多样，比如文本、音频、图像、视频等。不同类型的数据，其原始特征（Raw Feature）的空间也不相同。比如一张灰度图像（像素数量为 $D)$ 的特征空间为 $[0,255]^{D}$ ，一个自然语言句子（长度为 $L$ ）的特征空间为 $|\\mathcal{V}|^{L}$ ，其中 $\\mathcal{V}$ 为词表集合。而很多机器学习算法要求是输入的样本特征是数学上可计算的，因此在机器学习之前我们需要将这些不同类型的数据转换为向量表示。\n\n图像特征 在手写体数字识别任务中，样本 $x$ 为待识别的图像。为了识别 $x$ 是什么数字，我们可以从图像中抽取一些特征。如果图像是一张大小为 $M \\times N$ 的图像，其特征向量可以简单地表示为 $M \\times N$ 维的向量，每一维的值为图像中对应像素的灰度值。为了提高模型准确率，也会经常加入一个额外的特征，比如直方图、宽高比、笔画数、纹理特征、边缘特征等。假设我们总共抽取了 $D$ 个特征，这些特征可以表示为一个向量 $\\boldsymbol{x} \\in \\mathbb{R}^{D}$ 。\n\n文本特征 在文本情感分类任务中，样本 $x$ 为自然语言文本，类别 $y \\in\\{+1,-1\\}$ 分别表示正面或负面的评价。为了将样本 $x$ 从文本形式转为向量形式，一种简单的方式是使用词袋（Bag－of－Words，BoW）模型。假设训练集合中的词都来自一个词表 $\\mathcal{V}$ ，大小为 $|\\mathcal{V}|$ ，则每个样本可以表示为一个 $|\\mathcal{V}|$ 维的向量 $\\boldsymbol{x} \\in \\mathbb{R}^{|\\mathcal{V}|}$ 。向量 $\\boldsymbol{x}$ 中第 $i$ 维的值表示词表中的第 $i$ 个词是否在 $x$ 中出现。如果出现，值为 1 ，否则为 0 。\n\n比如两个文本＂我 喜欢 读书＂和＂我 讨厌 读书＂中共有＂我＂、＂喜欢＂、＂讨厌＂、＂读书＂四个词，它们的 BoW 表示分别为\n\n$$\n\\begin{aligned}\n& \\boldsymbol{x}_{1}=\\left[\\begin{array}{llll}\n1 & 1 & 0 & 1\n\\end{array}\\right]^{\\top}, \\\\\n& \\boldsymbol{x}_{2}=\\left[\\begin{array}{llll}\n1 & 0 & 1 & 1\n\\end{array}\\right]^{\\top} .\n\\end{aligned}\n$$\n\n词袋模型将文本看作是词的集合，不考虑词序信息，不能精确地表示文本信息。 一种改进方式是使用 $N$ 元组合特征，即每 N 个连续词构成一个基本单元，然后再用词袋模型进行表示。以最简单的二元特征（即两个词的组合特征）为例，上面的两个文本中共有＂\\＄我＂、＂我喜欢＂、＂我讨厌＂、＂喜欢读书＂、＂讨厌读书＂、＂读书 \\＃＂六个特征单元，它们的二元特征 BoW 表示分别为\n\n也有一些机器学习算法（比如决策树）不需要向量形式的特征．\n\n词袋模型在信息检索中也叫做向量空间模型（Vector Space Model，VSM）\n\n单独一个单词的 BoW表示为 one－hot 向量。\n\\＄和 \\＃分别表示文本的开始和结束。\n\n$$\n\\boldsymbol{x}_{1}=\\left[\\begin{array}{llllll}\n1 & 1 & 0 & 1 & 0 & 1\n\\end{array}\\right]^{\\top},\n$$\n\nhttps：／／nndl．github．io／\n\n$$\n\\boldsymbol{x}_{2}=\\left[\\begin{array}{llllll}\n1 & 0 & 1 & 0 & 1 & 1\n\\end{array}\\right]^{\\top} .\n$$\n\n随着 N 的增长， N 元特征的数量会指数上升，上限为 $|\\mathcal{V}|^{N}$ 。因此，在实际应用中，文本特征维数通常在十万或百万级别以上。\n\n参见习题 2－11．\n\n表示学习 如果直接用数据的原始特征来进行预测，对机器学习模型的能力要求比较高。这些原始特征可能存在以下几种不足：（1）特征比较单一，需要进行（非线性的）组合才能发挥其作用；（2）特征之间冗余度比较高；（3）并不是所有的特征都对预测有用；（4）很多特征通常是易变的；（5）特征中往往存在一些噪声。\n\n为了提高机器学习算法的能力，我们需要抽取有效、稳定的特征。传统的特征提取是通过人工方式进行的，需要大量的人工和专家知识。一个成功的机器学习系统通常需要尝试大量的特征，称为特征工程（Feature Engineering）。但即使这样，人工设计的特征在很多任务上也不能满足需要。因此，如何让机器自动地学习出有效的特征也成为机器学习中的一项重要研究内容，称为特征学习 （Feature Learning），也叫表示学习（Representation Learning）。特征学习在一定程度上也可以减少模型复杂性、缩短训练时间、提高模型泛化能力、避免过拟合等。",
        "总结": "- 数据特征表示的必要性：不同数据类型（文本、音频、图像、视频等）具有不同的原始特征空间，需转换为向量形式以适配机器学习算法。  \n- 图像特征表示：图像可被表示为像素灰度值的向量，也可加入直方图、宽高比、纹理等特征，最终形成 $D$ 维向量 $\\boldsymbol{x} \\in \\mathbb{R}^{D}$。  \n- 文本特征表示：使用词袋模型（BoW）将文本转换为词表大小的向量，每个维度表示对应词是否出现。  \n- 二元特征扩展：通过 N 元组合特征（如二元组）增强文本表示，考虑词序信息，但会显著增加特征维度。  \n- 词袋模型的局限性：忽略词序信息，无法精确表达文本含义，但在信息检索中被称为向量空间模型（VSM）。  \n- 单词的 one-hot 表示：单独单词用 one-hot 向量表示，通过特殊符号（如 $\\$$ 和 $\\#$）标记文本边界。  \n- 特征学习的重要性：原始特征存在单一、冗余、噪声等问题，需通过自动学习有效特征以提升模型性能。  \n- 表示学习的定义：通过机器自动学习有效、稳定的特征，称为表示学习或特征学习，有助于减少模型复杂性、提高泛化能力。"
      },
      {
        "段落": "## 2．6．1 传统的特征学习\n\n传统的特征学习一般是通过人为地设计一些准则，然后根据这些准则来选取有效的特征，具体又可以分为两种：特征选择和特征抽取．",
        "总结": "- 传统特征学习是通过人为设计准则来选取有效特征的方法。  \n- 传统特征学习分为特征选择和特征抽取两种具体方法。"
      },
      {
        "段落": "### 2．6．1．1 特征选择\n\n特征选择（Feature Selection）是选取原始特征集合的一个有效子集，使得基于这个特征子集训练出来的模型准确率最高。简单地说，特征选择就是保留有用特征，移除冗余或无关的特征。\n\n子集搜索 一种直接的特征选择方法为子集搜索（Subset Search）。假设原始特征数为 $D$ ，则共有 $2^{D}$ 个候选子集．特征选择的目标是选择一个最优的候选子集．最暴力的做法是测试每个特征子集，看机器学习模型哪个子集上的准确率最高。但是这种方式效率太低。常用的方法是采用贪心的策略：由空集合开始，每一轮添加该轮最优的特征，称为前向搜索（Forward Search）；或者从原始特征集合开始，每次删除最无用的特征，称为反向搜索（Backward Search）。\n\n子集搜索方法又可以分为过滤式和包裹式的方法．\n过滤式方法（Filter Method）不依赖具体的机器学习模型。每次增加最有信息量的特征，或删除最没有信息量的特征［Hall，1999］．信息量可以通过信息增益 （Information Gain）来衡量。\nhttps：／／nndl．github．io／\n\n包裹式方法（Wrapper Method）是用后续机器学习模型的准确率来评价一个特征子集。每次增加对后续机器学习模型最有用的特征，或删除对后续机器学习任务最无用的特征．这种方法是将机器学习模型包裹到特征选择过程的内部．\n$\\ell_{1}$ 正则化 此外，我们还可以通过 $\\ell_{1}$ 正则化来实现特征选择．由于 $\\ell_{1}$ 正则化会导致稀疏特征，因此间接实现了特征选择。",
        "总结": "- 特征选择是选取原始特征集合的一个有效子集，以提高模型准确率，保留有用特征，移除冗余或无关特征  \n- 子集搜索是直接的特征选择方法，通过搜索所有可能的特征子集来寻找最优子集  \n- 前向搜索从空集合开始，每轮添加最优特征；反向搜索从全集合开始，每轮删除最无用特征  \n- 子集搜索分为过滤式和包裹式方法  \n- 过滤式方法不依赖具体模型，通过信息增益等指标选择信息量大的特征  \n- 包裹式方法利用后续模型的准确率评价特征子集，将模型嵌入特征选择过程  \n- $\\ell_1$ 正则化通过诱导稀疏性实现特征选择，间接筛选出重要特征"
      },
      {
        "段落": "### 2．6．1．2 特征抽取\n\n特征抽取（Feature Extraction）是构造一个新的特征空间，并将原始特征投影在新的空间中得到新的表示。以线性投影为例，令 $\\boldsymbol{x} \\in \\mathbb{R}^{D}$ 为原始特征向量， $x^{\\prime} \\in \\mathbb{R}^{K}$ 为经过线性投影后得到的在新空间中的特征向量，有\n\n$$\n\\begin{equation*}\nx^{\\prime}=W x \\tag{2.70}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{W} \\in \\mathbb{R}^{K \\times D}$ 为映射矩阵。\n特征抽取又可以分为监督和无监督的方法．监督的特征学习的目标是抽取对一个特定的预测任务最有用的特征，比如线性判别分析（Linear Discriminant Analysis，LDA）。而无监督的特征学习和具体任务无关，其目标通常是减少冗余信息和噪声，比如主成分分析（Principal Component Analysis，PCA）。\n\n表2．2列出了一些传统的特征选择和特征抽取方法．\n表 2.2 传统的特征选择和特征抽取方法\n\n|  | 监督学习 | 无监督学习 |\n| :--- | :--- | :--- |\n| 特征选择 | 标签相关的子集搜索、 <br> $\\ell_{1}$ 正则化、决策树 | 标签无关的子集搜索 |\n| 特征抽取 | 线性判别分析 | 主成分分析、独立成分分 <br> 析、流形学习、自编码器 |\n\n特征选择和特征抽取的优点是可以用较少的特征来表示原始特征中的大部分相关信息，去掉噪声信息，并进而提高计算效率和减小维度灾难（Curse of Dimensionality）。对于很多没有正则化的模型，特征选择和特征抽取非常必要。经过特征选择或特征抽取后，特征的数量一般会减少，因此特征选择和特征抽取\n$\\ell_{1}$ 正则化参见第 7.7 ． 1节。\n\n主成分 分 析 参 见 第 9．1．1节。也经常称为维数约减或降维（Dimension Reduction）。",
        "总结": "- 特征抽取是构造新的特征空间，并将原始特征投影到新空间中得到新的表示  \n- 线性投影的数学表达为 $x^{\\prime}=W x$，其中 $W$ 是映射矩阵  \n- 特征抽取分为监督和无监督方法：监督方法如线性判别分析（LDA），无监督方法如主成分分析（PCA）  \n- 特征选择和特征抽取的优点是减少特征数量，保留大部分信息，去除噪声，提高计算效率并减小维度灾难  \n- 特征选择包括标签相关的子集搜索、$\\ell_{1}$ 正则化、决策树等方法  \n- 特征抽取的无监督方法包括主成分分析、独立成分分析、流形学习、自编码器等  \n- $\\ell_{1}$ 正则化和主成分分析分别参见第7.7.1节和第9.1.1节"
      },
      {
        "段落": "## 2．6．2 深度学习方法\n\n传统的特征抽取一般是和预测模型的学习分离的。我们会先通过主成分分析或线性判别分析等方法抽取出有效的特征，然后再基于这些特征来训练一个具体的机器学习模型。\n\n如果我们将特征的表示学习和机器学习的预测学习有机地统一到一个模型中，建立一个端到端的学习算法，就可以有效地避免它们之间准则的不一致性。这种表示学习方法称为深度学习（Deep Learning，DL）。深度学习方法的难点是如何评价表示学习对最终系统输出结果的贡献或影响，即贡献度分配问题。目前比较有效的模型是神经网络，即将最后的输出层作为预测学习，其他层作为表示学习。",
        "总结": "- 深度学习方法将特征表示学习与预测模型学习统一到一个端到端的模型中，以避免传统方法中特征抽取与模型学习之间的准则不一致问题。  \n- 深度学习的核心思想是通过神经网络结构，将表示学习（由中间层完成）与预测学习（由输出层完成）有机结合。  \n- 深度学习的难点在于如何评估表示学习对最终输出结果的贡献，即贡献度分配问题。  \n- 目前较为有效的深度学习模型是神经网络，其通过多层结构实现特征的逐层抽象与表示。"
      },
      {
        "段落": "## 2.7 评价指标\n\n为了衡量一个机器学习模型的好坏，需要给定一个测试集，用模型对测试集中的每一个样本进行预测，并根据预测结果计算评价分数。\n\n对于分类问题，常见的评价标准有准确率、精确率、召回率和 F 值等。给定测试集 $\\mathcal{J}=\\left\\{\\left(\\boldsymbol{x}^{(1)}, y^{(1)}\\right), \\cdots,\\left(\\boldsymbol{x}^{(N)}, y^{(N)}\\right)\\right\\}$ ，假设标签 $y^{(n)} \\in\\{1, \\cdots, C\\}$ ，用学习好的模型 $f\\left(\\boldsymbol{x} ; \\theta^{*}\\right)$ 对测试集中的每一个样本进行预测，结果为 $Y=\\hat{y}^{(1)}, \\cdots, \\hat{y}^{(N)}$ ．\n\n准确率 最常用的评价指标为准确率（Accuracy）：\n\n$$\n\\begin{equation*}\n\\mathcal{A}=\\frac{1}{N} \\sum_{n=1}^{N} I\\left(y^{(n)}=\\hat{y}^{(n)}\\right) \\tag{2.71}\n\\end{equation*}\n$$\n\n其中 $I(\\cdot)$ 为指示函数。\n错误率 和准确率相对应的就是错误率（Error Rate）：\n\n$$\n\\begin{align*}\n\\mathcal{E} & =1-\\mathcal{A}  \\tag{2.72}\\\\\n& =\\frac{1}{N} \\sum_{n=1}^{N} I\\left(y^{(n)} \\neq \\hat{y}^{(n)}\\right) \\tag{2.73}\n\\end{align*}\n$$\n\n精确率和召回率 准确率是所有类别整体性能的平均，如果希望对每个类都进行性能估计，就需要计算精确率（Precision）和召回率（Recall）。精确率和召回率是广泛用于信息检索和统计学分类领域的两个度量值，在机器学习的评价中也被大量使用．\n\n对于类别 $c$ 来说，模型在测试集上的结果可以分为以下四种情况：\n\n参见第1．3节。\n\n由于中文的模糊性，关于准确率和下文提到的精确率的定义在有些文献中会刚好相反，具体含义需要在上下文中进行判断．\n（1）真正例（True Positive，TP ）：一个样本的真实类别为 $c$ 并且模型正确地预测为类别 $c$ ．这类样本数量记为\n\n$$\n\\begin{equation*}\nT P_{c}=\\sum_{n=1}^{N} I\\left(y^{(n)}=\\hat{y}^{(n)}=c\\right) . \\tag{2.74}\n\\end{equation*}\n$$\n\n（2）假负例（False Negative，FN）：一个样本的真实类别为 $c$ ，模型错误地预测为其他类．这类样本数量记为\n\n$$\n\\begin{equation*}\nF N_{c}=\\sum_{n=1}^{N} I\\left(y^{(n)}=c \\wedge \\hat{y}^{(n)} \\neq c\\right) \\tag{2.75}\n\\end{equation*}\n$$\n\n（3）假正例（False Positive，FP）一个样本的真实类别为其他类，模型错误地预测为类别 $c$ ．这类样本数量记为\n\n$$\n\\begin{equation*}\nF P_{c}=\\sum_{n=1}^{N} I\\left(y^{(n)} \\neq c \\wedge \\hat{y}^{(n)}=c\\right) \\tag{2.76}\n\\end{equation*}\n$$\n\n（4）真负例（True Negative，TN）：一个样本的真实类别为其他类，模型也预测为其他类．这类样本数量记为 $T N_{c}$ ．对于类别 $c$ 来说，这种情况一般不需要关注。\n\n这四种情况的关系如表2．3所示的混淆矩阵（Confusion Matrix）来表示。\n表 2.3 类别 $c$ 的预测结果的混淆矩阵\n\n|  |  | 预测类别 |  |\n| :---: | :---: | :---: | :---: |\n|  |  | $\\hat{y}=c$ | $\\hat{y} \\neq c$ |\n| 真实类别 | $y=c$ | $T P_{c}$ | $F N_{c}$ |\n|  | $y \\neq c$ | $F P_{c}$ | $T N_{c}$ |\n\n根据上面的定义，我们可以进一步定义查准率、查全率和 F 值．\n精确率（Precision），也叫精度或查准率，类别 $c$ 的查准率是所有预测为类别 $c$ 的样本中，预测正确的比例：\n\n$$\n\\begin{equation*}\n\\mathcal{P}_{c}=\\frac{T P_{c}}{T P_{c}+F P_{c}} \\tag{2.77}\n\\end{equation*}\n$$\n\n召回率（Recall），也叫查全率，类别 $c$ 的查全率是所有真实标签为类别 $c$ 的样本中，预测正确的比例：\n\n$$\n\\begin{equation*}\n\\mathcal{R}_{c}=\\frac{T P_{c}}{T P_{c}+F N_{c}}, \\tag{2.78}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n$F$ 值（ $F$ Measure）是一个综合指标，为精确率和召回率的调和平均：\n\n$$\n\\begin{equation*}\n\\mathcal{F}_{c}=\\frac{\\left(1+\\beta^{2}\\right) \\times \\mathcal{P}_{c} \\times \\mathcal{R}_{c}}{\\beta^{2} \\times \\mathcal{P}_{c}+\\mathcal{R}_{c}}, \\tag{2.79}\n\\end{equation*}\n$$\n\n其中 $\\beta$ 用于平衡精确率和召回率的重要性，一般取值为 $1 . \\beta=1$ 时的 F 值称为 F 1值，是精确率和召回率的调和平均。\n\n宏平均和微平均 为了计算分类算法在所有类别上的总体精确率、召回率和 F1值，经常使用两种平均方法，分别称为宏平均（Macro Average）和微平均（Micro Average ）［Yang，1999］．\n\n宏平均是每一类的性能指标的算术平均值：\n\n$$\n\\begin{align*}\n\\mathcal{P}_{\\text {macro }} & =\\frac{1}{C} \\sum_{c=1}^{C} \\mathcal{P}_{c}  \\tag{2.80}\\\\\n\\mathcal{R}_{\\text {macro }} & =\\frac{1}{C} \\sum_{c=1}^{C} \\mathcal{R}_{c}  \\tag{2.81}\\\\\n\\mathcal{F} 1_{\\text {macro }} & =\\frac{2 \\times \\mathcal{P}_{\\text {macro }} \\times R_{\\text {macro }}}{P_{\\text {macro }}+R_{\\text {macro }}} \\tag{2.82}\n\\end{align*}\n$$\n\n值得注意的是，在有些文献上 F 1 值的宏平均为 $\\mathcal{F} 1_{\\text {macro }}=\\frac{1}{C} \\sum_{c=1}^{C} \\mathcal{F} 1_{c}$ 。\n微平均是每一个样本的性能指标的算术平均值．对于单个样本而言，它的精确率和召回率是相同的（要么都是 1 ，要么都是 0 ）。因此精确率的微平均和召回率的微平均是相同的．同理，F1值的微平均指标是相同的．当不同类别的样本数量不均衡时，使用宏平均会比微平均更合理些。宏平均会更关注于小类别上的评价指标。\n\n在实际应用中，我们也可以通过调整分类模型的阈值来进行更全面的评价，比如 AUC（Area Under Curve）、ROC（Receiver Operating Characteristic）曲线、PR（Precision－Recall）曲线等。此外，很多任务还有自己专门的评价方式，比如 TopN 准确率。\n\n交叉验证 交叉验证（Cross Validation）是一种比较好的衡量机器学习模型的统计分析方法，可以有效避免划分训练集和测试集时的随机性对评价结果造成的影响。我们可以把原始数据集平均分为 $K$ 组不重复的子集，每次选 $K-1$ 组子集作\n\n关于更详细的模型评价指标，可以参考《机器学习》［周志华，2016］的第2章．\n$K$ 一般大于 3 ．为训练集，剩下的一组子集作为验证集。这样可以进行 $K$ 次试验并得到 $K$ 个模型，将这 $K$ 个模型在各自验证集上的错误率的平均作为分类器的评价。",
        "总结": "- 评价指标用于衡量机器学习模型的性能，需基于测试集的预测结果计算。\n- 准确率（Accuracy）是所有样本中预测正确的比例，公式为 $\\mathcal{A} = \\frac{1}{N} \\sum_{n=1}^{N} I(y^{(n)} = \\hat{y}^{(n)})$。\n- 错误率（Error Rate）是准确率的补集，公式为 $\\mathcal{E} = 1 - \\mathcal{A}$。\n- 精确率（Precision）是预测为类别 $c$ 的样本中实际为 $c$ 的比例，公式为 $\\mathcal{P}_c = \\frac{T P_c}{T P_c + F P_c}$。\n- 召回率（Recall）是实际为类别 $c$ 的样本中被正确预测的比例，公式为 $\\mathcal{R}_c = \\frac{T P_c}{T P_c + F N_c}$。\n- F 值（F Measure）是精确率和召回率的调和平均，公式为 $\\mathcal{F}_c = \\frac{(1+\\beta^2) \\times \\mathcal{P}_c \\times \\mathcal{R}_c}{\\beta^2 \\times \\mathcal{P}_c + \\mathcal{R}_c}$，其中 $\\beta=1$ 时称为 F1 值。\n- 宏平均（Macro Average）是对各类别性能指标的算术平均，适用于类别数量均衡的情况。\n- 微平均（Micro Average）是对所有样本性能指标的算术平均，适用于类别数量不均衡的情况。\n- 混淆矩阵用于表示类别 $c$ 的预测结果，包括真正例（TP）、假负例（FN）、假正例（FP）和真负例（TN）。\n- 交叉验证是一种通过划分数据集为多个子集进行多次训练和验证的方法，以减少随机性对模型评价的影响。"
      },
      {
        "段落": "## 2.8 理论和定理\n\n在机器学习中，有一些非常有名的理论或定理，对理解机器学习的内在特性非常有帮助。\nhttps：／／nndl．github．io／",
        "总结": "- 提出了机器学习中一些著名的理论和定理，这些理论和定理有助于理解机器学习的内在特性。  \n- 引用了相关资源链接，供读者进一步查阅具体内容。"
      },
      {
        "段落": "## 2．8．1 PAC 学习理论\n\n当使用机器学习方法来解决某个特定问题时，通常靠经验或者多次试验来选择合适的模型、训练样本数量以及学习算法收玫的速度等。但是经验判断或多次试验往往成本比较高，也不太可靠，因此希望有一套理论能够分析问题难度、计算模型能力，为学习算法提供理论保证，并指导机器学习模型和学习算法的设计。这就是计算学习理论。计算学习理论（Computational Learning Theory）是关于机器学习的理论基础，其中最基础的理论就是可能近似正确（Probably Approximately Correct，PAC）学习理论。\n\n机器学习中一个很关键的问题是期望错误和经验错误之间的差异，称为泛化错误（Generalization Error）。泛化错误可以衡量一个机器学习模型 $f$ 是否可以很好地泛化到未知数据．\n\n$$\n\\begin{equation*}\n\\mathcal{G}_{\\mathcal{D}}(f)=\\mathcal{R}(f)-\\mathcal{R}_{\\mathcal{D}}^{e m p}(f) \\tag{2.83}\n\\end{equation*}\n$$\n\n根据大数定律，当训练集大小 $|\\mathcal{D}|$ 趋向于无穷大时，泛化错误趋向于 0 ，即经验风险趋近于期望风险。\n\n$$\n\\begin{equation*}\n\\lim _{|\\mathcal{D}| \\rightarrow \\infty} \\mathcal{R}(f)-\\mathcal{R}_{\\mathcal{D}}^{e m p}(f)=0 \\tag{2.84}\n\\end{equation*}\n$$\n\n由于我们不知道真实的数据分布 $p(\\boldsymbol{x}, y)$ ，也不知道真实的目标函数 $g(\\boldsymbol{x})$ ，因此期望从有限的训练样本上学习到一个期望错误为 0 的函数 $f(\\boldsymbol{x})$ 是不切实际的。因此，需要降低对学习算法能力的期望，只要求学习算法可以以一定的概率学习到一个近似正确的假设，即PAC学习（PAC Learning）。一个PAC可学习（PAC－ Learnable）的算法是指该学习算法能够在多项式时间内从合理数量的训练数据中学习到一个近似正确的 $f(\\boldsymbol{x})$ ．\n\nPAC 学习可以分为两部分：\n一是＂近似正确＂（Approximately Correct）。一个假设 $f \\in \\mathcal{F}$ 是＂近似正确＂的，是指其在泛化错误 $\\mathcal{G}_{\\mathcal{D}}(f)$ 小于一个界限 $\\epsilon . \\epsilon$ 一般为 0 到 $\\frac{1}{2}$ 之间的数， $0<\\epsilon<\\frac{1}{2}$ 。如果 $\\mathcal{G}_{\\mathcal{D}}(f)$ 比较大，说明模型不能用来做正确的＂预测＂．\n\n二是＂可能＂（Probably）。一个学习算法 $\\mathcal{A}$ 有＂可能＂以 $1-\\delta$ 的概率学习到这样一个＂近似正确＂的假设．$\\delta$ 一般为 0 到 $\\frac{1}{2}$ 之间的数， $0<\\delta<\\frac{1}{2}$ ．\n\nPAC学习可以下面公式描述：\n\n$$\n\\begin{equation*}\nP\\left(\\left(\\mathcal{R}(f)-\\mathcal{R}_{\\mathcal{D}}^{e m p}(f)\\right) \\leq \\epsilon\\right) \\geq 1-\\delta, \\tag{2.85}\n\\end{equation*}\n$$\n\n其中 $\\epsilon, \\delta$ 是和样本数量 $N$ 以及假设空间 $\\mathcal{F}$ 相关的变量．如果固定 $\\epsilon, \\delta$ ，可以反过来计算出需要的样本数量\n\n$$\n\\begin{equation*}\nN(\\epsilon, \\delta) \\geq \\frac{1}{2 \\epsilon^{2}}\\left(\\log |\\mathcal{F}|+\\log \\frac{2}{\\delta}\\right) \\tag{2.86}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n泛化错误在有些文献中也指期望错误，指在未知样本上的错误。\n\n其中 $|\\mathcal{F}|$ 为假设空间的大小。从上面公式可以看出，模型越复杂，即假设空间 $\\mathcal{F}$ 越大，模型的泛化能力越差．要达到相同的泛化能力，越复杂的模型需要的样本数量越多。为了提高模型的泛化能力，通常需要正则化（Regularization）来限制模型复杂度．\n\nPAC 学习理论也可以帮助分析一个机器学习方法在什么条件下可以学习到一个近似正确的分类器。从公式（2．86）可以看出，如果希望模型的假设空间越大，泛化错误越小，其需要的样本数量越多。",
        "总结": "- PAC学习理论是计算学习理论的基础，用于分析机器学习问题的难度和提供理论保证。  \n- 泛化错误衡量模型在未知数据上的表现，是期望错误与经验错误之差。  \n- 根据大数定律，当训练集趋于无穷大时，泛化错误趋于0，经验风险趋近于期望风险。  \n- 由于真实数据分布和目标函数未知，期望学习到零错误的模型不现实，因此引入PAC学习概念。  \n- PAC学习要求算法以一定概率学习到近似正确的假设，即在多项式时间内从有限样本中学习。  \n- PAC学习包含“近似正确”和“可能”两个部分：“近似正确”指泛化错误小于给定界限ε；“可能”指以概率1−δ学习到近似正确的假设。  \n- PAC学习可通过公式描述：$P(\\mathcal{R}(f)-\\mathcal{R}_{\\mathcal{D}}^{emp}(f) \\leq \\epsilon) \\geq 1-\\delta$。  \n- 样本数量N与ε、δ及假设空间大小$|\\mathcal{F}|$相关，公式为：$N(\\epsilon, \\delta) \\geq \\frac{1}{2\\epsilon^2}(\\log |\\mathcal{F}| + \\log \\frac{2}{\\delta})$。  \n- 模型越复杂（假设空间越大），泛化能力越差，所需样本数量越多。  \n- 正则化可限制模型复杂度，从而提高泛化能力。"
      },
      {
        "段落": "## 2．8．2 没有免费午餐定理\n\n没有免费午餐定理（No Free Lunch Theorem，NFL）是由 Wolpert 和 Mac－ erday在最优化理论中提出的。没有免费午餐定理证明：对于基于迭代的最优化算法，不存在某种算法对所有问题（有限的搜索空间内）都有效。如果一个算法对某些问题有效，那么它一定在另外一些问题上比纯随机搜索算法更差。也就是说，不能脱离具体问题来谈论算法的优劣，任何算法都有局限性。必须要＂具体问题具体分析＂。\n\n没有免费午餐定理对于机器学习算法也同样适用．不存在一种机器学习算法适合于任何领域或任务．如果有人宣称自己的模型在所有问题上都好于其他模型，那么他肯定是在吹牛。",
        "总结": "- 概念：没有免费午餐定理（No Free Lunch Theorem，NFL）指出不存在一种算法能在所有问题上都表现最优。  \n- 算法：该定理适用于基于迭代的最优化算法，强调算法的有效性依赖于具体问题。  \n- 定理：NFL定理证明，若一个算法在某些问题上表现优异，则必在其他问题上不如随机搜索。  \n- 数学推导：未在文中具体展开，但核心思想是通过概率论和搜索空间分析，证明算法的普遍优越性不可能存在。  \n- 核心观点：任何算法都有局限性，必须具体问题具体分析，不能脱离实际任务讨论算法优劣。"
      },
      {
        "段落": "## 2．8．3 丑小鸭定理\n\n丑小鸭定理（Ugly Duckling Theorem）是1969年由渡边慧提出的［Watan－ able，1969］．＂丑小鸭与白天鹅之间的区别和两只白天鹅之间的区别一样大＂．这个定理初看好像不符合常识，但是仔细思考后是非常有道理的。因为世界上不存在相似性的客观标准，一切相似性的标准都是主观的。如果从体型大小或外貌的角度来看，丑小鸭和白天鹅的区别大于两只白天鹅的区别；但是如果从基因的角度来看，丑小鸭与它父母的差别要小于它父母和其他白天鹅之间的差别。",
        "总结": "- 丑小鸭定理由渡边慧于1969年提出，指出丑小鸭与白天鹅之间的差异与两只白天鹅之间的差异一样大。  \n- 定理挑战了人们对相似性的直观理解，认为相似性标准是主观的，而非客观存在。  \n- 从体型或外貌角度看，丑小鸭与白天鹅的差异大于两只白天鹅的差异；但从基因角度看，丑小鸭与父母的差异小于父母与其他白天鹅的差异。"
      },
      {
        "段落": "## 2．8．4 奥卡姆剃刀原理\n\n奥卡姆剃刀（Occam＇s Razor）原理是由14世纪逻辑学家 William of Occam提出的一个解决问题的法则：＂如无必要，勿增实体＂。奥卡姆剃刀的思想和机器学习上正则化思想十分类似：简单的模型泛化能力更好。如果有两个性能相近的模型，我们应该选择更简单的模型。因此，在机器学习的学习准则上，我们经常会引入参数正则化来限制模型能力，避免过拟合。\n\n奥卡姆剃刀的一种形式化是最小描述长度（Minimum Description Length， MDL）原则，即对一个数据集 $\\mathcal{D}$ ，最好的模型 $f \\in \\mathcal{F}$ 是会使得数据集的压缩效果\n\n参见［Blum et al．，2016］中定理 5．3．\n\n正则化参见第 7.7 节。\n\n渡边慧（1910～1993），美籍日本学者，理论物理学家，也是模式识别的最早研究者之一．\n这里的＂丑小鸭＂是指白天鹅的幼雏，而不是 ＂丑陋的小鸭子＂。\n\n最好，即编码长度最小．\n最小描述长度也可以通过贝叶斯学习的观点来解释［MacKay，2003］．模型 $f$ 在数据集 $\\mathcal{D}$ 上的对数后验概率为\n\n$$\n\\begin{align*}\n\\max _{f} \\log p(f \\mid \\mathcal{D}) & =\\max _{f} \\log p(\\mathcal{D} \\mid f)+\\log p(f)  \\tag{2.87}\\\\\n& =\\min _{f}-\\log p(\\mathcal{D} \\mid f)-\\log p(f) \\tag{2.88}\n\\end{align*}\n$$\n\n其中 $-\\log p(f)$ 和 $-\\log p(\\mathcal{D} \\mid f)$ 可以分别看作是模型 $f$ 的编码长度和在该模型下数据集 $\\mathcal{D}$ 的编码长度。也就是说，我们不但要使得模型 $f$ 可以编码数据集 $\\mathcal{D}$ ，也要使得模型 $f$ 尽可能简单．",
        "总结": "- 奥卡姆剃刀原理：由14世纪逻辑学家William of Occam提出，主张“如无必要，勿增实体”，强调简单模型的泛化能力更好。  \n- 正则化思想：与机器学习中的正则化理念相似，用于限制模型复杂度，防止过拟合。  \n- 最小描述长度（MDL）原则：形式化奥卡姆剃刀，认为最佳模型是使数据集压缩效果最优（编码长度最小）的模型。  \n- 贝叶斯学习视角：MDL也可通过贝叶斯学习解释，模型的对数后验概率最大化等价于编码长度最小化。  \n- 模型编码长度：模型 $f$ 的编码长度为 $-\\log p(f)$，数据集 $\\mathcal{D}$ 在模型 $f$ 下的编码长度为 $-\\log p(\\mathcal{D} \\mid f)$。"
      },
      {
        "段落": "## 2．8．5 归纳偏置\n\n在机器学习中，很多学习算法经常会对学习的问题做一些假设，这些假设就称为归纳偏置（Inductive Bias）［Mitchell，1997］。比如在最近邻分类器中，我们会假设在特征空间中，一个小的局部区域中的大部分样本都同属一类。在朴素贝叶斯分类器中，我们会假设每个特征的条件概率是互相独立的。\n\n归纳偏置在贝叶斯学习中也经常称为先验（Prior）。",
        "总结": "- 归纳偏置是指机器学习算法在学习过程中所依赖的假设，用于指导从有限数据中泛化到未知数据。  \n- 举例说明：最近邻分类器假设局部区域样本同属一类，朴素贝叶斯分类器假设特征条件概率相互独立。  \n- 在贝叶斯学习中，归纳偏置也被称为先验，用于表达对模型参数的初始信念。"
      },
      {
        "段落": "## 2.9 总结和深入阅读\n\n本章简单地介绍了机器学习的基础知识，并为后面介绍的神经网络进行一些简单的铺垫．机器学习算法虽然种类繁多，但其中三个基本的要素为：模型、学习准则、优化算法。大部分的机器学习算法都可以看作是这三个基本要素的不同组合。如果需要快速全面地了解机器学习的基本概念和体系可以阅读《Pattern Classification》［Duda et al．，2001］、《Machine Learning：a Probabilistic Perspective》［Murphy，2012］和《机器学习》［周志华，2016］．\n\n目前机器学习中最主流的一类方法是统计学习方法，将机器学习问题看作是统计推断问题，并且又可以进一步分为频率学派和贝叶斯学派。频率学派将模型参数 $\\theta$ 看作是固定常数；而贝叶斯学派将参数 $\\theta$ 看作是随机变量，并且存在某种先验分布．想进一步深入了解统计学习的知识，可以阅读《Pattern Recognition and Machine Learning》［Bishop，2007］和 《The Elements of Statistical Learning》 ［Hastie et al．，2009］．关于统计学习理论的知识可以参考《Statistical Learning Theory 》［Vapnik，1998］．\n\n此外，机器学习中一个重要内容是表示学习．［Bengio et al．，2013］系统地给出了关于表示学习的全面综述。传统的表示学习方法，即特征选择和特征抽取，可以参考《机器学习》［周志华，2016］中的第 10 章和第 11 章．",
        "总结": "- 概念：机器学习的三个基本要素为模型、学习准则、优化算法。\n- 概念：统计学习方法将机器学习问题看作是统计推断问题，分为频率学派和贝叶斯学派。\n- 概念：频率学派认为模型参数 $\\theta$ 是固定常数，贝叶斯学派认为 $\\theta$ 是随机变量并具有先验分布。\n- 概念：表示学习是机器学习中的重要内容，传统方法包括特征选择和特征抽取。\n- 算法/方法：推荐参考文献《Pattern Classification》、《Machine Learning：a Probabilistic Perspective》、《机器学习》了解机器学习基本概念。\n- 算法/方法：推荐参考文献《Pattern Recognition and Machine Learning》、《The Elements of Statistical Learning》深入了解统计学习。\n- 算法/方法：推荐参考文献《Statistical Learning Theory》了解统计学习理论。\n- 算法/方法：推荐参考文献《机器学习》第10章和第11章了解传统表示学习方法。"
      },
      {
        "段落": "## 习题\n\n习题2－1 分析为什么平方损失函数不适用于分类问题．\n习题 2－2 在线性回归中，如果我们给每个样本 $\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)$ 赋予一个权重 $r^{(n)}$ ，经验风险函数为\n\n$$\n\\begin{equation*}\n\\mathcal{R}(\\boldsymbol{w})=\\frac{1}{2} \\sum_{n=1}^{N} r^{(n)}\\left(y^{(n)}-\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}\\right)^{2} \\tag{2.89}\n\\end{equation*}\n$$\n\n计算其最优参数 $\\boldsymbol{w}^{*}$ ，并分析权重 $r^{(n)}$ 的作用．\n习题 2－3 证明在线性回归中，如果样本数量 $N$ 小于特征数量 $D+1$ ，则 $\\boldsymbol{X} \\boldsymbol{X}^{\\top}$的秩最大为 $N$ 。\n\n习题 2－4 在线性回归中，验证岭回归的解为结构风险最小化准则下的最小二乘法估计，见公式（2．44）。\n\n习题 2－5 在线性回归中，若假设标签 $y \\sim \\mathcal{N}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}, \\beta\\right)$ ，并用最大似然估计来优化参数时，验证最优参数为公式（2．50）的解．\n\n习题2－6 假设有 $N$ 个样本 $x^{(1)}, x^{(2)}, \\cdots, x^{(N)}$ 服从正态分布 $\\mathcal{N}\\left(\\mu, \\sigma^{2}\\right)$ ，其中 $\\mu$未知。（1）使用最大似然估计来求解最优参数 $\\mu^{M L}$ 。（2）若参数 $\\mu$ 为随机变量，并服从正态分布 $\\mathcal{N}\\left(\\mu_{0}, \\sigma_{0}^{2}\\right)$ ，使用最大后验估计来求解最优参数 $\\mu^{M A P}$ 。\n\n习题 2－7 在习题2－6中，证明当 $N \\rightarrow \\infty$ 时，最大后验估计趋向于最大似然估计．\n\n习题2－8 验证公式（2．59）．\n习题 2－9 试分析在什么因素会导致模型出现图2．6所示的高偏差和高方差情况．\n\n习题2－10验证公式（2．64）。\n习题 2－11 分别用一元、二元和三元特征的词袋模型表示文本＂我打了张三＂和＂张三打了我＂，并分析不同模型的优缺点。\n\n习题 2－12 对于一个三分类问题，数据集的真实标签和模型的预测标签如下：\n\n| 真实标签 | 1 | 1 | 2 | 2 | 2 | 3 | 3 | 3 | 3 |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 预测标签 | 1 | 2 | 2 | 2 | 3 | 3 | 3 | 1 | 2 |\n\n分别计算模型的精确率、召回率、F1 值以及它们的宏平均和微平均．",
        "总结": "- 平方损失函数不适用于分类问题，因为其假设标签是连续值，而分类问题中标签是离散的。\n- 在线性回归中，经验风险函数引入样本权重 $ r^{(n)} $，用于调整不同样本对模型训练的影响。\n- 当样本数量 $ N $ 小于特征数量 $ D+1 $ 时，矩阵 $ \\boldsymbol{X} \\boldsymbol{X}^{\\top} $ 的秩最大为 $ N $，导致无法唯一确定参数解。\n- 岭回归的解是结构风险最小化准则下的最小二乘法估计，通过引入正则化项防止过拟合。\n- 在线性回归中，假设标签服从正态分布，并使用最大似然估计优化参数，可推导出最优参数为公式（2.50）的解。\n- 对于正态分布数据，最大似然估计可求得最优参数 $ \\mu^{ML} $；若参数为随机变量且服从正态分布，则使用最大后验估计求得最优参数 $ \\mu^{MAP} $。\n- 当样本数量趋于无穷时，最大后验估计趋向于最大似然估计。\n- 公式（2.59）验证了某种数学推导或表达式。\n- 模型出现高偏差和高方差的情况可能由模型复杂度、训练数据量、特征选择等因素引起。\n- 公式（2.64）验证了某种数学推导或表达式。\n- 词袋模型中，一元、二元和三元特征分别表示文本的不同粒度特征，一元模型简单但可能丢失语义信息，二元和三元模型更复杂但计算成本更高。\n- 对于三分类问题，计算精确率、召回率、F1 值及其宏平均和微平均以评估模型性能。"
      },
      {
        "段落": "## 参考文献\n\n周志华．机器学习［M］．北京：清华大学出版社， 2016.\nBengio Y，Courville A，Vincent P．Representation learning：A review and new perspectives［J］．IEEE transactions on pattern analysis and machine intelligence，2013，35（8）：1798－1828．\nBishop C M．Pattern recognition and machine learning［M］．5th edition．Springer， 2007.\nBlum A，Hopcroft J，Kannan R．Foundations of data science［J］．Vorabversion eines Lehrbuchs， 2016.\n\nBottou L．Large－scale machine learning with stochastic gradient descent［M］／／Proceedings of COMPSTAT．Springer，2010：177－186．\nDuda R O，Hart P E，Stork D G．Pattern classification［M］．2nd edition．Wiley， 2001.\nHall M A．Correlation－based feature selection for machine learning［D］．University of Waikato Hamilton， 1999.\nHastie T，Tibshirani R，Friedman J H．The elements of statistical learning：data mining，inference， and prediction［M］．2nd edition．Springer， 2009.\nHoerl A E，Kennard R W．Ridge regression：Biased estimation for nonorthogonal problems［J］． Technometrics，1970，12（1）：55－67．\nLeCun Y，Cortes C，Burges C J．MNIST handwritten digit database［EB／OL］．1998．http：／／yann． lecun．com／exdb／mnist．\nMacKay D J C．Information theory，inference，and learning algorithms［M］．Cambridge University Press， 2003.\nMitchell T M．Machine learning［M］．McGraw－Hill， 1997.\nMurphy K P．Machine learning－a probabilistic perspective［M］．MIT Press， 2012.\nNemirovski A，Juditsky A，Lan G，et al．Robust stochastic approximation approach to stochastic programming［J］．SIAM Journal on optimization，2009，19（4）：1574－1609．\nVapnik V．Statistical learning theory［M］．New York：Wiley， 1998.\nWatanable S．Knowing and guessing：A quantitative study of inference and information［M］．Wiley Chichester， 1969.\nYang Y．An evaluation of statistical approaches to text categorization［J］．Information retrieval， 1999，1（1－2）：69－90．",
        "总结": "- 参考文献部分列出了多本关于机器学习、模式识别和统计学习理论的经典著作与论文，涵盖书籍、期刊文章和数据库资源。  \n- 周志华的《机器学习》是中文领域的重要教材，系统介绍了机器学习的基本概念和算法。  \n- Bengio等人综述了表示学习的研究进展，强调了深度学习在特征学习中的作用。  \n- Bishop的《模式识别与机器学习》是英文经典教材，详细阐述了概率图模型、贝叶斯推理等内容。  \n- Blum等人提出了数据科学的基础框架，为数据驱动的研究提供了理论支持。  \n- Bottou讨论了随机梯度下降在大规模机器学习中的应用，强调其高效性和收敛性。  \n- Duda等人的《模式分类》是模式识别领域的经典著作，介绍了分类器设计与评估方法。  \n- Hall的研究聚焦于基于相关性的特征选择方法，用于提升机器学习模型的性能。  \n- Hastie等人的《统计学习导论》涵盖了数据挖掘、推断和预测的核心方法，是统计学习领域的权威著作。  \n- Hoerl和Kennard提出了岭回归方法，用于处理非正交问题中的过拟合问题。  \n- LeCun等人提供了MNIST手写数字数据库，广泛用于图像识别和深度学习研究。  \n- MacKay的著作结合信息论与学习算法，探讨了概率推理与贝叶斯方法的应用。  \n- Mitchell的《机器学习》是早期经典教材，系统阐述了机器学习的基本理论与方法。  \n- Murphy的《机器学习——概率视角》从概率角度深入讲解了各类机器学习算法及其数学基础。  \n- Nemirovski等人提出了稳健随机逼近方法，用于解决随机优化问题。  \n- Vapnik的《统计学习理论》奠定了支持向量机等算法的理论基础，强调结构风险最小化原则。  \n- Watanable探讨了推理与信息的定量研究，涉及信息论和认知科学领域。  \n- Yang评估了统计方法在文本分类中的应用效果，为自然语言处理提供了理论支持。"
      },
      {
        "段落": "## 第3章 线性模型\n\n正确的判断来自于经验，而经验来自于错误的判断．\n—弗雷德里克•布鲁克斯（Frederick P．Brooks）\n1999年图灵奖获得者\n\n线性模型（Linear Model）是机器学习中应用最广泛的模型，指通过样本特征的线性组合来进行预测的模型。给定一个 $D$ 维样本 $\\boldsymbol{x}=\\left[x_{1}, \\cdots, x_{D}\\right]^{\\top}$ ，其线性组合函数为\n\n$$\n\\begin{align*}\nf(\\boldsymbol{x} ; \\boldsymbol{w}) & =w_{1} x_{1}+w_{2} x_{2}+\\cdots+w_{D} x_{D}+b  \\tag{3.1}\\\\\n& =\\boldsymbol{w}^{\\top} \\boldsymbol{x}+b \\tag{3.2}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{w}=\\left[w_{1}, \\cdots, w_{D}\\right]^{\\top}$ 为 $D$ 维的权重向量，$b$ 为偏置。上一章中介绍的线性回归就是典型的线性模型，直接用 $f(\\boldsymbol{x} ; \\boldsymbol{w})$ 来预测输出目标 $y=f(\\boldsymbol{x} ; \\boldsymbol{w})$ ．\n\n在分类问题中，由于输出目标 $y$ 是一些离散的标签，而 $f(\\boldsymbol{x} ; \\boldsymbol{w})$ 的值域为实数，因此无法直接用 $f(\\boldsymbol{x} ; \\boldsymbol{w})$ 来进行预测，需要引入一个非线性的决策函数 （Decision Function）$g(\\cdot)$ 来预测输出目标\n\n$$\n\\begin{equation*}\ny=g(f(\\boldsymbol{x} ; \\boldsymbol{w})), \\tag{3.3}\n\\end{equation*}\n$$\n\n其中 $f(\\boldsymbol{x} ; \\boldsymbol{w})$ 也称为判别函数（Discriminant Function）。\n对于二分类问题，$g(\\cdot)$ 可以是符号函数（Sign Function），定义为\n\n$$\n\\begin{align*}\ng(f(\\boldsymbol{x} ; \\boldsymbol{w})) & =\\operatorname{sgn}(f(\\boldsymbol{x} ; \\boldsymbol{w}))  \\tag{3.4}\\\\\n& \\triangleq\\left\\{\\begin{array}{lll}\n+1 & \\text { if } & f(\\boldsymbol{x} ; \\boldsymbol{w})>0 \\\\\n-1 & \\text { if } & f(\\boldsymbol{x} ; \\boldsymbol{w})<0\n\\end{array}\\right. \\tag{3.5}\n\\end{align*}\n$$\n\n当 $f(\\boldsymbol{x} ; \\boldsymbol{w})=0$ 时不进行预测。公式（3．5）定义了一个典型的二分类问题的决策函数，其结构如图3．1所示．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-067.jpg?height=521&width=692&top_left_y=121&top_left_x=301)\n\n图 3.1 二分类的线性模型\n\n在本章，我们主要介绍四种不同线性分类模型：Logistic回归、Softmax 回归、感知器和支持向量机，这些模型的区别主要在于使用了不同的损失函数．",
        "总结": "- 线性模型：通过样本特征的线性组合进行预测，形式为 $f(\\boldsymbol{x} ; \\boldsymbol{w}) = \\boldsymbol{w}^{\\top} \\boldsymbol{x} + b$，其中 $\\boldsymbol{w}$ 为权重向量，$b$ 为偏置。  \n- 线性回归：直接使用 $f(\\boldsymbol{x} ; \\boldsymbol{w})$ 预测输出目标 $y$。  \n- 决策函数：用于分类问题，将线性模型的输出映射到离散标签，形式为 $y = g(f(\\boldsymbol{x} ; \\boldsymbol{w}))$。  \n- 二分类决策函数：使用符号函数（Sign Function）定义，根据 $f(\\boldsymbol{x} ; \\boldsymbol{w})$ 的正负决定输出标签 $+1$ 或 $-1$。  \n- 模型差异：本章介绍的四种线性分类模型（Logistic回归、Softmax回归、感知器和支持向量机）主要区别在于使用的损失函数不同。"
      },
      {
        "段落": "## 3.1 线性判别函数和决策边界\n\n从公式（3．3）可知，一个线性分类模型（Linear Classification Model）或线性分类器（Linear Classifier），是由一个（或多个）线性的判别函数 $f(\\boldsymbol{x} ; \\boldsymbol{w})=$ $\\boldsymbol{w}^{\\top} \\boldsymbol{x}+b$ 和非线性的决策函数 $g(\\cdot)$ 组成。我们首先考虑二分类的情况，然后再扩展到多分类的情况．",
        "总结": "- 线性分类模型由线性判别函数 $f(\\boldsymbol{x} ; \\boldsymbol{w}) = \\boldsymbol{w}^{\\top} \\boldsymbol{x} + b$ 和非线性决策函数 $g(\\cdot)$ 组成。  \n- 判别函数是线性的，形式为 $f(\\boldsymbol{x} ; \\boldsymbol{w}) = \\boldsymbol{w}^{\\top} \\boldsymbol{x} + b$，其中 $\\boldsymbol{w}$ 是权重向量，$b$ 是偏置项。  \n- 决策函数 $g(\\cdot)$ 是非线性的，用于将判别函数的输出映射到分类结果。  \n- 首先讨论二分类情况，再扩展到多分类情况。"
      },
      {
        "段落": "## 3．1．1 二分类\n\n二分类（Binary Classification）问题的类别标签 $y$ 只有两种取值，通常可以设为 $\\{+1,-1\\}$ 。在二分类问题中，常用正例（Positive Sample）和负例（Negative Sample）来分别表示属于类别 +1 和 -1 的样本．\n\n在二分类问题中，我们只需要一个线性判别函数 $f(\\boldsymbol{x} ; \\boldsymbol{w})=\\boldsymbol{w}^{\\top} \\boldsymbol{x}+b$ ．特征空间 $\\mathbb{R}^{D}$ 中所有满足 $f(\\boldsymbol{x} ; \\boldsymbol{w})=0$ 的点组成一个分割超平面（Hyperplane），称为决策边界（Decision Boundary）或决策平面（Decision Surface）。决策边界将特征空间一分为二，划分成两个区域，每个区域对应一个类别．\n\n所谓＂线性分类模型＂就是指其决策边界是线性超平面。在特征空间中，决策平面与权重向量 $\\boldsymbol{w}$ 正交．特征空间中每个样本点到决策平面的有向距离（Signed Distance）为\n\n$$\n\\begin{equation*}\n\\gamma=\\frac{f(\\boldsymbol{x} ; \\boldsymbol{w})}{\\|\\boldsymbol{w}\\|} \\tag{3.6}\n\\end{equation*}\n$$\n\n$y$ 有时也会表示为 $\\{0,1\\}$ ．\n\n超平面就是三维空间中的平面在更高维空间的推广。D维空间中的超平面是 $D-1$ 维的。在二维空间中，决策边界为一个直线；在三维空间中，决策边界为一个平面；在高维空间中，决策边界为一个超平面。\n\n参见习题 3－2．\n$\\gamma$ 也可以看作是点 $\\boldsymbol{x}$ 在 $\\boldsymbol{w}$ 方向上的投影．\nhttps：／／nndl．github．io／\n\n图3．2给出了一个二分类问题的线性决策边界示例，其中样本特征向量 $\\boldsymbol{x}=$ $\\left[x_{1}, x_{2}\\right]$ ，权重向量 $\\boldsymbol{w}=\\left[w_{1}, w_{2}\\right]$.\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-068.jpg?height=637&width=573&top_left_y=265&top_left_x=371)\n\n图 3.2 二分类的决策边界示例\n\n给定 $N$ 个样本的训练集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，其中 $y^{(n)} \\in\\{+1,-1\\}$ ，线性模型试图学习到参数 $\\boldsymbol{w}^{*}$ ，使得对于每个样本 $\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)$ 尽量满足\n\n$$\n\\begin{array}{ll}\nf\\left(\\boldsymbol{x}^{(n)} ; \\boldsymbol{w}^{*}\\right)>0 & \\text { if } \\quad y^{(n)}=1  \\tag{3.7}\\\\\nf\\left(\\boldsymbol{x}^{(n)} ; \\boldsymbol{w}^{*}\\right)<0 & \\text { if } \\quad y^{(n)}=-1\n\\end{array}\n$$\n\n上面两个公式也可以合并，即参数 $\\boldsymbol{w}^{*}$ 尽量满足\n\n$$\n\\begin{equation*}\ny^{(n)} f\\left(\\boldsymbol{x}^{(n)} ; \\boldsymbol{w}^{*}\\right)>0, \\quad \\forall n \\in[1, N] \\tag{3.8}\n\\end{equation*}\n$$\n\n定义 3．1－两类线性可分：对于训练集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，如果存在权重向量 $\\boldsymbol{w}^{*}$ ，对所有样本都满足 $y f\\left(\\boldsymbol{x} ; \\boldsymbol{w}^{*}\\right)>0$ ，那么训练集 $\\mathcal{D}$ 是线性可分的．\n\n为了学习参数 $\\boldsymbol{w}$ ，我们需要定义合适的损失函数以及优化方法．对于二分类问题，最直接的损失函数为 0－1 损失函数，即\n\n$$\n\\begin{equation*}\n\\mathcal{L}_{01}(y, f(\\boldsymbol{x} ; \\boldsymbol{w}))=I(y f(\\boldsymbol{x} ; \\boldsymbol{w})>0), \\tag{3.9}\n\\end{equation*}\n$$\n\n其中 $I(\\cdot)$ 为指示函数．但 0－1 损失函数的数学性质不好，其关于 $\\boldsymbol{w}$ 的导数为 0 ，从而导致无法优化 $\\boldsymbol{w}$ 。\nhttps：／／nndl．github．io／",
        "总结": "- 二分类问题的类别标签 $y$ 取值为 $\\{+1, -1\\}$，正例和负例分别对应类别 +1 和 -1。\n- 线性判别函数为 $f(\\boldsymbol{x}; \\boldsymbol{w}) = \\boldsymbol{w}^\\top \\boldsymbol{x} + b$，决策边界是满足 $f(\\boldsymbol{x}; \\boldsymbol{w}) = 0$ 的超平面。\n- 决策边界将特征空间分为两个区域，分别对应类别 +1 和 -1。\n- 线性分类模型的决策边界是线性超平面，与权重向量 $\\boldsymbol{w}$ 正交。\n- 样本点到决策平面的有向距离为 $\\gamma = \\frac{f(\\boldsymbol{x}; \\boldsymbol{w})}{\\|\\boldsymbol{w}\\|}$。\n- $y$ 也可以表示为 $\\{0, 1\\}$。\n- 超平面是高维空间中 $D-1$ 维的平面，二维空间中为直线，三维空间中为平面。\n- 线性可分定义：若存在权重向量 $\\boldsymbol{w}^*$ 使得对所有样本满足 $y f(\\boldsymbol{x}; \\boldsymbol{w}^*) > 0$，则训练集是线性可分的。\n- 二分类问题常用的损失函数是 0－1 损失函数，但其数学性质差，难以优化。"
      },
      {
        "段落": "## 3．1．2 多分类\n\n多分类（Multi－class Classification）问题是指分类的类别数 $C$ 大于 2 。多分类一般需要多个线性判别函数，但设计这些判别函数有很多种方式．\n\n假设一个多分类问题的类别为 $\\{1,2, \\cdots, C\\}$ ，常用的方式有以下三种：\n（1）＂一对其余＂方式：把多分类问题转换为 $C$ 个＂一对其余＂的二分类问题。这种方式共需要 $C$ 个判别函数，其中第 $c$ 个判别函数 $f_{c}$ 是将类别 $c$ 的样本和不属于类别 $c$ 的样本分开。\n（2）＂一对一＂方式：把多分类问题转换为 $C(C-1) / 2$ 个＂一对一＂的二分类问题．这种方式共需要 $C(C-1) / 2$ 个判别函数，其中第 $(i, j)$ 个判别函数是把类别 $i$ 和类别 $j$ 的样本分开．\n（3）＂argmax＂方式：这是一种改进的＂一对其余＂方式，共需要 $C$ 个判别函数\n\n$$\n\\begin{equation*}\nf_{c}\\left(\\boldsymbol{x} ; \\boldsymbol{w}_{c}\\right)=\\boldsymbol{w}_{c}^{\\top} \\boldsymbol{x}+b_{c}, \\quad c \\in\\{1, \\cdots, C\\} \\tag{3.10}\n\\end{equation*}\n$$\n\n对于样本 $\\boldsymbol{x}$ ，如果存在一个类别 $c$ ，相对于所有的其他类别 $\\tilde{c}(\\tilde{c} \\neq c)$ 有 $f_{c}\\left(\\boldsymbol{x} ; \\boldsymbol{w}_{c}\\right)>f_{\\tilde{c}}\\left(\\boldsymbol{x}, \\boldsymbol{w}_{\\tilde{c}}\\right)$ ，那么 $\\boldsymbol{x}$ 属于类别 $c$ 。＂argmax＂方式的预测函数定义为\n\n$$\n\\begin{equation*}\ny=\\stackrel{C}{\\underset{c=1}{\\operatorname{argmax}}} f_{c}\\left(\\boldsymbol{x} ; \\boldsymbol{w}_{c}\\right) \\tag{3.11}\n\\end{equation*}\n$$\n\n＂一对其余＂方式和＂一对一＂方式都存在一个缺陷：特征空间中会存在一参见习题 3－4．些难以确定类别的区域，而＂argmax＂方式很好地解决了这个问题。图3．3给出了用这三种方式进行多分类的示例，其中红色直线表示判别函数 $f(\\cdot)=0$ 的直线，不同颜色的区域表示预测的三个类别的区域（ $\\omega_{1} 、 \\omega_{2}$ 和 $\\omega_{3}$ ）和难以确定类别的区域（＂？）．在＂argmax＂方式中，相邻两类 $i$ 和 $j$ 的决策边界实际上是由 $f_{i}\\left(\\boldsymbol{x} ; \\boldsymbol{w}_{i}\\right)-f_{j}\\left(\\boldsymbol{x} ; \\boldsymbol{w}_{j}\\right)=0$ 决定，其法向量为 $\\boldsymbol{w}_{i}-\\boldsymbol{w}_{j}$ 。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-069.jpg?height=356&width=1163&top_left_y=1672&top_left_x=76)\n\n图 3.3 多分类问题的三种方式\n\n定义3．2－多类线性可分：对于训练集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，如果存在 $C$ 个权重向量 $\\boldsymbol{w}_{1}^{*}, \\cdots, \\boldsymbol{w}_{C}^{*}$ ，使得第 $c(1 \\leq c \\leq C)$ 类的所有样本都满足 $f_{c}\\left(\\boldsymbol{x} ; \\boldsymbol{w}_{c}^{*}\\right)>$ $f_{\\tilde{c}}\\left(\\boldsymbol{x}, \\boldsymbol{w}_{\\tilde{c}}^{*}\\right), \\forall \\tilde{c} \\neq c$ ，那么训练集 $\\mathcal{D}$ 是线性可分的．\n\n从上面定义可知，如果数据集是多类线性可分的，那么一定存在一个＂argmax＂方式的线性分类器可以将它们正确分开。\n\n参见习题 3－5．",
        "总结": "- 多分类问题是指类别数 $C$ 大于 2 的分类问题  \n- 一对其余方式：将多分类问题转换为 $C$ 个二分类问题，每个判别函数 $f_c$ 将类别 $c$ 与其余类别分开  \n- 一对一方式：将多分类问题转换为 $C(C-1)/2$ 个二分类问题，每个判别函数 $f_{i,j}$ 分开类别 $i$ 和 $j$  \n- argmax 方式：改进的一对其余方式，使用 $C$ 个判别函数，预测函数为 $y = \\arg\\max_c f_c(\\boldsymbol{x}; \\boldsymbol{w}_c)$  \n- 判别函数形式为 $f_c(\\boldsymbol{x}; \\boldsymbol{w}_c) = \\boldsymbol{w}_c^\\top \\boldsymbol{x} + b_c$  \n- argmax 方式解决了其他两种方式中难以确定类别的区域问题  \n- 决策边界由相邻类别判别函数的差值决定，法向量为 $\\boldsymbol{w}_i - \\boldsymbol{w}_j$  \n- 多类线性可分定义：存在 $C$ 个权重向量，使得每个类别的样本满足相对于所有其他类别的判别函数值更大  \n- 若数据集是多类线性可分的，则存在一个 argmax 方式的线性分类器能正确分开所有样本"
      },
      {
        "段落": "## 3．2 Logistic 回归\n\nLogistic 回归（Logistic Regression，LR）是一种常用的处理二分类问题的线性模型．在本节中，我们采用 $y \\in\\{0,1\\}$ 以符合 Logistic 回归的描述习惯．\n\n为了解决连续的线性函数不适合进行分类的问题，我们引入非线性函数 $g$ ： $\\mathbb{R}^{D} \\rightarrow(0,1)$ 来预测类别标签的后验概率 $p(y=1 \\mid \\boldsymbol{x})$ 。\n\n$$\n\\begin{equation*}\np(y=1 \\mid \\boldsymbol{x})=g(f(\\boldsymbol{x} ; \\boldsymbol{w})) \\tag{3.12}\n\\end{equation*}\n$$\n\n其中 $g(\\cdot)$ 通常称为激活函数（Activation Function），其作用是把线性函数的值域从实数区间＂挤压＂到了 $(0,1)$ 之间，可以用来表示概率。在统计文献中，$g(\\cdot)$ 的逆函数 $g^{-1}(\\cdot)$ 也称为联系函数（Link Function）。\n\n在 Logistic 回归中，我们使用 Logistic 函数来作为激活函数．标签 $y=1$ 的后验概率为\n\n$$\n\\begin{align*}\np(y=1 \\mid \\boldsymbol{x}) & =\\sigma\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)  \\tag{3.13}\\\\\n& \\triangleq \\frac{1}{1+\\exp \\left(-\\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)} \\tag{3.14}\n\\end{align*}\n$$\n\n为简单起见，这里 $\\boldsymbol{x}=\\left[x_{1}, \\cdots, x_{D}, 1\\right]^{\\top}$ 和 $\\boldsymbol{w}=\\left[w_{1}, \\cdots, w_{D}, b\\right]^{\\top}$ 分别为 $D+1$ 维的增广特征向量和增广权重向量。\n\n标签 $y=0$ 的后验概率为\n\n$$\n\\begin{align*}\np(y=0 \\mid \\boldsymbol{x}) & =1-p(y=1 \\mid \\boldsymbol{x})  \\tag{3.15}\\\\\n& =\\frac{\\exp \\left(-\\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)}{1+\\exp \\left(-\\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)} \\tag{3.16}\n\\end{align*}\n$$\n\n将公式（3．14）进行变换后得到\n\n$$\n\\begin{align*}\n\\boldsymbol{w}^{\\top} \\boldsymbol{x} & =\\log \\frac{p(y=1 \\mid \\boldsymbol{x})}{1-p(y=1 \\mid \\boldsymbol{x})}  \\tag{3.17}\\\\\n& =\\log \\frac{p(y=1 \\mid \\boldsymbol{x})}{p(y=0 \\mid \\boldsymbol{x})} \\tag{3.18}\n\\end{align*}\n$$\n\nhttps：／／nndl．github．io／\n\nLogistic 函数参 见第 B．4．2．1 节。\n\n其中 $\\frac{p(y=1 \\mid \\boldsymbol{x})}{p(y=0 \\mid \\boldsymbol{x})}$ 为样本 $\\boldsymbol{x}$ 为正反例后验概率的比值，称为几率（Odds），几率的对数称为对数几率（Log Odds，或 Logit）。公式（3．17）的左边是线性函数，Logistic 回归可以看作是预测值为＂标签的对数几率＂的线性回归模型。因此，Logistic 回归也称为对数几率回归（Logit Regression）。\n\n图3．4给出了使用线性回归和 Logistic 回归来解决一维数据的二分类问题的示例。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-071.jpg?height=479&width=1040&top_left_y=517&top_left_x=131)\n\n图 3.4 一维数据的二分类问题示例",
        "总结": "- Logistic回归是一种用于处理二分类问题的线性模型，通过引入非线性激活函数解决线性函数不适合分类的问题。  \n- 激活函数 $g(\\cdot)$ 将线性函数的输出范围压缩到 $(0,1)$，用于表示类别标签的后验概率。  \n- Logistic回归使用Logistic函数作为激活函数，其形式为 $p(y=1 \\mid \\boldsymbol{x}) = \\frac{1}{1+\\exp(-\\boldsymbol{w}^\\top \\boldsymbol{x})}$。  \n- 标签 $y=0$ 的后验概率为 $1 - p(y=1 \\mid \\boldsymbol{x})$，其表达式为 $\\frac{\\exp(-\\boldsymbol{w}^\\top \\boldsymbol{x})}{1+\\exp(-\\boldsymbol{w}^\\top \\boldsymbol{x})}$。  \n- 公式 $ \\boldsymbol{w}^\\top \\boldsymbol{x} = \\log \\frac{p(y=1 \\mid \\boldsymbol{x})}{p(y=0 \\mid \\boldsymbol{x})} $ 表示线性函数与对数几率之间的关系。  \n- $\\frac{p(y=1 \\mid \\boldsymbol{x})}{p(y=0 \\mid \\boldsymbol{x})}$ 称为几率，其对数称为对数几率（Logit）。  \n- Logistic回归可视为预测标签对数几率的线性回归模型，因此也称为对数几率回归（Logit Regression）。  \n- 图3.4展示了使用线性回归和Logistic回归解决一维二分类问题的示例。"
      },
      {
        "段落": "## 3．2．1 参数学习\n\nLogistic 回归采用交叉嫡作为损失函数，并使用梯度下降法来对参数进行优化．\n\n给定 $N$ 个训练样本 $\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，用 Logistic 回归模型对每个样本 $\\boldsymbol{x}^{(n)}$ 进行预测，输出其标签为 1 的后验概率，记为 $\\hat{y}^{(n)}$ ，\n\n$$\n\\begin{equation*}\n\\hat{y}^{(n)}=\\sigma\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}\\right), \\quad 1 \\leq n \\leq N . \\tag{3.19}\n\\end{equation*}\n$$\n\n由于 $y^{(n)} \\in\\{0,1\\}$ ，样本 $\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)$ 的真实条件概率可以表示为\n\n$$\n\\begin{align*}\n& p_{r}\\left(y^{(n)}=1 \\mid \\boldsymbol{x}^{(n)}\\right)=y^{(n)},  \\tag{3.20}\\\\\n& p_{r}\\left(y^{(n)}=0 \\mid \\boldsymbol{x}^{(n)}\\right)=1-y^{(n)} . \\tag{3.21}\n\\end{align*}\n$$\n\n使用交叉嫡损失函数，其风险函数为\n\n$$\n\\begin{align*}\n\\mathcal{R}(\\boldsymbol{w}) & =-\\frac{1}{N} \\sum_{n=1}^{N}\\left(p_{r}\\left(y^{(n)}=1 \\mid \\boldsymbol{x}^{(n)}\\right) \\log \\hat{y}^{(n)}+p_{r}\\left(y^{(n)}=0 \\mid \\boldsymbol{x}^{(n)}\\right) \\log \\left(1-\\hat{y}^{(n)}\\right)\\right)  \\tag{3.22}\\\\\n& =-\\frac{1}{N} \\sum_{n=1}^{N}\\left(y^{(n)} \\log \\hat{y}^{(n)}+\\left(1-y^{(n)}\\right) \\log \\left(1-\\hat{y}^{(n)}\\right)\\right) \\tag{3.23}\n\\end{align*}\n$$\n\nhttps：／／nndl．github．io／\n\n为简单起见，这里忽略了正则化项。\n\n风险函数 $\\mathcal{R}(\\boldsymbol{w})$ 关于参数 $\\boldsymbol{w}$ 的偏导数为\n\n$$\n\\begin{align*}\n\\frac{\\partial \\mathcal{R}(\\boldsymbol{w})}{\\partial \\boldsymbol{w}} & =-\\frac{1}{N} \\sum_{n=1}^{N}\\left(y^{(n)} \\frac{\\hat{y}^{(n)}\\left(1-\\hat{y}^{(n)}\\right)}{\\hat{y}^{(n)}} \\boldsymbol{x}^{(n)}-\\left(1-y^{(n)}\\right) \\frac{\\hat{y}^{(n)}\\left(1-\\hat{y}^{(n)}\\right)}{1-\\hat{y}^{(n)}} \\boldsymbol{x}^{(n)}\\right)  \\tag{3.24}\\\\\n& =-\\frac{1}{N} \\sum_{n=1}^{N}\\left(y^{(n)}\\left(1-\\hat{y}^{(n)}\\right) \\boldsymbol{x}^{(n)}-\\left(1-y^{(n)}\\right) \\hat{y}^{(n)} \\boldsymbol{x}^{(n)}\\right)  \\tag{3.25}\\\\\n& =-\\frac{1}{N} \\sum_{n=1}^{N} \\boldsymbol{x}^{(n)}\\left(y^{(n)}-\\hat{y}^{(n)}\\right) \\tag{3.26}\n\\end{align*}\n$$\n\n采用梯度下降法，Logistic回归的训练过程为：初始化 $\\boldsymbol{w}_{0} \\leftarrow 0$ ，然后通过下式来迭代更新参数：\n\n$$\n\\begin{equation*}\n\\boldsymbol{w}_{t+1} \\leftarrow \\boldsymbol{w}_{t}+\\alpha \\frac{1}{N} \\sum_{n=1}^{N} \\boldsymbol{x}^{(n)}\\left(y^{(n)}-\\hat{y}_{\\boldsymbol{w}_{t}}^{(n)}\\right), \\tag{3.27}\n\\end{equation*}\n$$\n\n其中 $\\alpha$ 是学习率，$\\hat{y}_{\\boldsymbol{w}_{t}}^{(n)}$ 是当参数为 $\\boldsymbol{w}_{t}$ 时，Logistic 回归模型的输出。\n从公式（3．23）可知，风险函数 $\\mathcal{R}(\\boldsymbol{w})$ 是关于参数 $\\boldsymbol{w}$ 的连续可导的凸函数。因此除了梯度下降法之外，Logistic回归还可以用高阶的优化方法（比如牛顿法）来进行优化。",
        "总结": "- 概念：Logistic回归使用交叉熵作为损失函数，并通过梯度下降法进行参数优化。  \n- 算法：Logistic回归模型对每个样本预测标签为1的后验概率，记为$\\hat{y}^{(n)}$，公式为$\\hat{y}^{(n)} = \\sigma(\\boldsymbol{w}^\\top \\boldsymbol{x}^{(n)})$。  \n- 理论：真实条件概率由样本标签$y^{(n)}$决定，即$p_r(y^{(n)}=1|\\boldsymbol{x}^{(n)}) = y^{(n)}$，$p_r(y^{(n)}=0|\\boldsymbol{x}^{(n)}) = 1 - y^{(n)}$。  \n- 数学推导：交叉熵损失函数的风险函数为$\\mathcal{R}(\\boldsymbol{w}) = -\\frac{1}{N}\\sum_{n=1}^N [y^{(n)} \\log \\hat{y}^{(n)} + (1 - y^{(n)}) \\log (1 - \\hat{y}^{(n)})]$。  \n- 数学推导：风险函数关于参数$\\boldsymbol{w}$的梯度为$\\frac{\\partial \\mathcal{R}(\\boldsymbol{w})}{\\partial \\boldsymbol{w}} = -\\frac{1}{N}\\sum_{n=1}^N \\boldsymbol{x}^{(n)} (y^{(n)} - \\hat{y}^{(n)})$。  \n- 算法：梯度下降法更新参数的公式为$\\boldsymbol{w}_{t+1} \\leftarrow \\boldsymbol{w}_t + \\alpha \\frac{1}{N}\\sum_{n=1}^N \\boldsymbol{x}^{(n)} (y^{(n)} - \\hat{y}_{\\boldsymbol{w}_t}^{(n)})$。  \n- 理论：风险函数是关于参数$\\boldsymbol{w}$的连续可导凸函数，因此可以使用高阶优化方法（如牛顿法）进行优化。"
      },
      {
        "段落": "## 3．3 Softmax 回归\n\nSoftmax 回归（Softmax Regression），也称为多项（Multinomial）或多类 （Multi－Class）的 Logistic 回归，是 Logistic 回归在多分类问题上的推广。\n\n对于多类问题，类别标签 $y \\in\\{1,2, \\cdots, C\\}$ 可以有 $C$ 个取值．给定一个样本 $\\boldsymbol{x}$ ， Softmax 回归预测的属于类别 $c$ 的条件概率为\n\n$$\n\\begin{align*}\np(y=c \\mid \\boldsymbol{x}) & =\\operatorname{softmax}\\left(\\boldsymbol{w}_{c}^{\\top} \\boldsymbol{x}\\right)  \\tag{3.28}\\\\\n& =\\frac{\\exp \\left(\\boldsymbol{w}_{c}^{\\top} \\boldsymbol{x}\\right)}{\\sum_{c^{\\prime}=1}^{C} \\exp \\left(\\boldsymbol{w}_{c^{\\prime}}^{\\top} \\boldsymbol{x}\\right)}, \\tag{3.29}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{w}_{c}$ 是第 $c$ 类的权重向量．\nSoftmax 回归的决策函数可以表示为\n\n$$\n\\begin{align*}\n\\hat{y} & =\\underset{c=1}{\\stackrel{C}{\\arg \\max }} p(y=c \\mid \\boldsymbol{x})  \\tag{3.30}\\\\\n& =\\underset{c=1}{\\arg \\max } \\boldsymbol{w}_{c}^{\\top} \\boldsymbol{x} \\tag{3.31}\n\\end{align*}\n$$\n\n与 Logistic 回归的关系 当类别数 $C=2$ 时，Softmax 回归的决策函数为\n\n$$\n\\begin{equation*}\n\\hat{y}=\\underset{y \\in\\{0,1\\}}{\\arg \\max } \\boldsymbol{w}_{y}^{\\top} \\boldsymbol{x} \\tag{3.32}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n$\\hat{y}$ 为 Logistic 函数，因此有 $\\frac{\\partial \\hat{y}}{\\partial \\boldsymbol{w}^{\\top} \\boldsymbol{x}}=\\hat{y}^{(n)}(1-$ $\\left.\\hat{y}^{(n)}\\right)$ 。参见第 B．4．2．1节。\n\nSoftmax 回归也可以看作是一种条件最大熵模型，参见第11．1．5．1节。\n\nSoftmax 函 数 参 见 第 B．4．2．2节．\n\n$$\n\\begin{align*}\n& =I\\left(\\boldsymbol{w}_{1}^{\\top} \\boldsymbol{x}-\\boldsymbol{w}_{0}^{\\top} \\boldsymbol{x}>0\\right)  \\tag{3.33}\\\\\n& =I\\left(\\left(\\boldsymbol{w}_{1}-\\boldsymbol{w}_{0}\\right)^{\\top} \\boldsymbol{x}>0\\right), \\tag{3.34}\n\\end{align*}\n$$\n\n其中 $I(\\cdot)$ 是指示函数．对比公式（3．5）中的二分类决策函数，可以发现二分类中的权重向量 $\\boldsymbol{w}=\\boldsymbol{w}_{1}-\\boldsymbol{w}_{0}$ 。\n\n向量表示 公式（3．29）用向量形式可以写为\n\n$$\n\\begin{align*}\n\\hat{\\boldsymbol{y}} & =\\operatorname{softmax}\\left(\\boldsymbol{W}^{\\top} \\boldsymbol{x}\\right)  \\tag{3.35}\\\\\n& =\\frac{\\exp \\left(\\boldsymbol{W}^{\\top} \\boldsymbol{x}\\right)}{1_{C}^{\\top} \\exp \\left(\\boldsymbol{W}^{\\top} \\boldsymbol{x}\\right)}, \\tag{3.36}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{W}=\\left[\\boldsymbol{w}_{1}, \\cdots, \\boldsymbol{w}_{C}\\right]$ 是由 $C$ 个类的权重向量组成的矩阵， $\\boldsymbol{1}_{C}$ 为 $C$ 维的全 1 向量，$\\hat{\\boldsymbol{y}} \\in \\mathbb{R}^{C}$ 为所有类别的预测条件概率组成的向量，第 $c$ 维的值是第 $c$ 类的预测条件概率．",
        "总结": "- Softmax回归是Logistic回归在多分类问题上的推广，用于处理类别标签 $y \\in \\{1, 2, \\cdots, C\\}$ 的多类分类问题。  \n- 预测类别 $c$ 的条件概率公式为 $p(y=c \\mid \\boldsymbol{x}) = \\frac{\\exp(\\boldsymbol{w}_c^\\top \\boldsymbol{x})}{\\sum_{c'=1}^{C} \\exp(\\boldsymbol{w}_{c'}^\\top \\boldsymbol{x})}$，其中 $\\boldsymbol{w}_c$ 是第 $c$ 类的权重向量。  \n- 决策函数为 $\\hat{y} = \\arg\\max_{c=1}^{C} p(y=c \\mid \\boldsymbol{x})$，等价于 $\\arg\\max_{c=1}^{C} \\boldsymbol{w}_c^\\top \\boldsymbol{x}$。  \n- 当类别数 $C=2$ 时，Softmax回归退化为Logistic回归，此时决策函数为 $\\hat{y} = \\arg\\max_{y \\in \\{0,1\\}} \\boldsymbol{w}_y^\\top \\boldsymbol{x}$。  \n- Softmax回归可以视为一种条件最大熵模型，相关内容见第11.1.5.1节。  \n- Softmax函数的定义和性质见第B.4.2.2节。  \n- 公式（3.33）和（3.34）展示了二分类中Softmax回归与Logistic回归的关系，其中权重向量 $\\boldsymbol{w} = \\boldsymbol{w}_1 - \\boldsymbol{w}_0$。  \n- 公式（3.35）和（3.36）以向量形式表示Softmax回归，其中 $\\boldsymbol{W}$ 是由所有类的权重向量组成的矩阵，$\\hat{\\boldsymbol{y}}$ 是所有类别的预测条件概率组成的向量。"
      },
      {
        "段落": "## 3．3．1 参数学习\n\n给定 $N$ 个训练样本 $\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，Softmax 回归使用交叉嫡损失函数来学习最优的参数矩阵 $\\boldsymbol{W}$ 。\n\n为了方便起见，我们用 $C$ 维的 one－hot 向量 $\\boldsymbol{y} \\in\\{0,1\\}^{C}$ 来表示类别标签．对于类别 $c$ ，其向量表示为\n\n$$\n\\begin{equation*}\n\\boldsymbol{y}=[I(1=c), I(2=c), \\cdots, I(C=c)]^{\\top}, \\tag{3.37}\n\\end{equation*}\n$$\n\n其中 $I(\\cdot)$ 是指示函数．\n采用交叉嫡损失函数，Softmax 回归模型的风险函数为\n\n$$\n\\begin{align*}\n\\mathcal{R}(\\boldsymbol{W}) & =-\\frac{1}{N} \\sum_{n=1}^{N} \\sum_{c=1}^{C} \\boldsymbol{y}_{c}^{(n)} \\log \\hat{\\boldsymbol{y}}_{c}^{(n)}  \\tag{3.38}\\\\\n& =-\\frac{1}{N} \\sum_{n=1}^{N}\\left(\\boldsymbol{y}^{(n)}\\right)^{\\top} \\log \\hat{\\boldsymbol{y}}^{(n)} \\tag{3.39}\n\\end{align*}\n$$\n\n其中 $\\hat{\\boldsymbol{y}}^{(n)}=\\operatorname{softmax}\\left(\\boldsymbol{W}^{\\top} \\boldsymbol{x}^{(n)}\\right)$ 为样本 $\\boldsymbol{x}^{(n)}$ 在每个类别的后验概率。\n风险函数 $\\mathcal{R}(\\boldsymbol{W})$ 关于 $\\boldsymbol{W}$ 的梯度为\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{R}(\\boldsymbol{W})}{\\partial \\boldsymbol{W}}=-\\frac{1}{N} \\sum_{n=1}^{N} \\boldsymbol{x}^{(n)}\\left(\\boldsymbol{y}^{(n)}-\\hat{\\boldsymbol{y}}^{(n)}\\right)^{\\top} \\tag{3.40}\n\\end{equation*}\n$$\n\n证明．计算公式（3．40）中的梯度，关键在于计算每个样本的损失函数 $\\mathcal{L}^{(n)}(\\boldsymbol{W})=$ $-\\left(\\boldsymbol{y}^{(n)}\\right)^{\\top} \\log \\hat{\\boldsymbol{y}}^{(n)}$ 关于参数 $\\boldsymbol{W}$ 的梯度，其中需要用到的两个导数公式为\nhttps：／／nndl．github．io／\n（1）若 $\\boldsymbol{y}=\\operatorname{softmax}(\\boldsymbol{z})$ ，则 $\\frac{\\partial \\boldsymbol{y}}{\\partial \\boldsymbol{z}}=\\operatorname{diag}(\\boldsymbol{y})-\\boldsymbol{y} \\boldsymbol{y}^{\\top}$ ．\n（2）若 $\\boldsymbol{z}=\\boldsymbol{W}^{\\top} \\boldsymbol{x}=\\left[\\boldsymbol{w}_{1}^{\\top} \\boldsymbol{x}, \\boldsymbol{w}_{2}^{\\top} \\boldsymbol{x}, \\cdots, \\boldsymbol{w}_{C}^{\\top} \\boldsymbol{x}\\right]^{\\top}$ ，则 $\\frac{\\partial \\boldsymbol{z}}{\\partial \\boldsymbol{w}_{c}}$ 为第 $c$ 列为 $\\boldsymbol{x}$ ，其余为 0 的矩阵。\n\n$$\n\\begin{align*}\n\\frac{\\partial \\boldsymbol{z}}{\\partial \\boldsymbol{w}_{c}} & =\\left[\\frac{\\partial \\boldsymbol{w}_{1}^{\\top} \\boldsymbol{x}}{\\partial \\boldsymbol{w}_{c}}, \\frac{\\partial \\boldsymbol{w}_{2}^{\\top} \\boldsymbol{x}}{\\partial \\boldsymbol{w}_{c}}, \\cdots, \\frac{\\partial \\boldsymbol{w}_{C}^{\\top} \\boldsymbol{x}}{\\partial \\boldsymbol{w}_{c}}\\right]  \\tag{3.41}\\\\\n& =[\\mathbf{0}, \\mathbf{0}, \\cdots, \\boldsymbol{x}, \\cdots, \\mathbf{0}]  \\tag{3.42}\\\\\n& \\triangleq \\mathbb{M}_{c}(\\boldsymbol{x}) \\tag{3.43}\n\\end{align*}\n$$\n\n根据链式法则， $\\mathcal{L}^{(n)}(\\boldsymbol{W})=-\\left(\\boldsymbol{y}^{(n)}\\right)^{\\top} \\log \\hat{\\boldsymbol{y}}^{(n)}$ 关于 $\\boldsymbol{w}_{c}$ 的偏导数为\n\n$$\n\\begin{align*}\n& \\frac{\\partial \\mathcal{L}^{(n)}(\\boldsymbol{W})}{\\partial \\boldsymbol{w}_{c}}=-\\frac{\\partial\\left(\\left(\\boldsymbol{y}^{(n)}\\right)^{\\top} \\log \\hat{\\boldsymbol{y}}^{(n)}\\right)}{\\partial \\boldsymbol{w}_{c}}  \\tag{3.44}\\\\\n& =-\\frac{\\partial \\boldsymbol{z}^{(n)}}{\\partial \\boldsymbol{w}_{c}} \\frac{\\partial \\hat{\\boldsymbol{y}}^{(n)}}{\\partial \\boldsymbol{z}^{(n)}} \\frac{\\partial \\log \\hat{\\boldsymbol{y}}^{(n)}}{\\partial \\hat{\\boldsymbol{y}}^{(n)}} \\boldsymbol{y}^{(n)}  \\tag{3.45}\\\\\n& =-\\mathbb{M}_{c}\\left(\\boldsymbol{x}^{(n)}\\right)\\left(\\operatorname{diag}\\left(\\hat{\\boldsymbol{y}}^{(n)}\\right)-\\hat{\\boldsymbol{y}}^{(n)}\\left(\\hat{\\boldsymbol{y}}^{(n)}\\right)^{\\top}\\right)\\left(\\operatorname{diag}\\left(\\hat{\\boldsymbol{y}}^{(n)}\\right)\\right)^{-1} \\boldsymbol{y}^{(n)}  \\tag{3.46}\\\\\n& =-\\mathbb{M}_{c}\\left(\\boldsymbol{x}^{(n)}\\right)\\left(\\boldsymbol{I}-\\hat{\\boldsymbol{y}}^{(n)} \\mathbf{1}_{C}^{\\top}\\right) \\boldsymbol{y}^{(n)}  \\tag{3.47}\\\\\n& =-\\mathbb{M}_{c}\\left(\\boldsymbol{x}^{(n)}\\right)\\left(\\boldsymbol{y}^{(n)}-\\hat{\\boldsymbol{y}}^{(n)} \\mathbf{1}_{C}^{\\top} \\boldsymbol{y}^{(n)}\\right)  \\tag{3.48}\\\\\n& =-\\mathbb{M}_{c}\\left(\\boldsymbol{x}^{(n)}\\right)\\left(\\boldsymbol{y}^{(n)}-\\hat{\\boldsymbol{y}}^{(n)}\\right)  \\tag{3.49}\\\\\n& =-\\boldsymbol{x}^{(n)}\\left[\\boldsymbol{y}^{(n)}-\\hat{\\boldsymbol{y}}^{(n)}\\right]_{c} \\tag{3.50}\n\\end{align*}\n$$\n\n公式（3．50）也可以表示为非向量形式，即\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}^{(n)}(\\boldsymbol{W})}{\\partial \\boldsymbol{w}_{c}}=-\\boldsymbol{x}^{(n)}\\left(I\\left(y^{(n)}=c\\right)-\\hat{\\boldsymbol{y}}_{c}^{(n)}\\right) \\tag{3.51}\n\\end{equation*}\n$$\n\n其中 $I(\\cdot)$ 是指示函数．\n根据公式（3．50）可以得到\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}^{(n)}(\\boldsymbol{W})}{\\partial \\boldsymbol{W}}=-\\boldsymbol{x}^{(n)}\\left(\\boldsymbol{y}^{(n)}-\\hat{\\boldsymbol{y}}^{(n)}\\right)^{\\top} \\tag{3.52}\n\\end{equation*}\n$$\n\n采用梯度下降法，Softmax 回归的训练过程为：初始化 $\\boldsymbol{W}_{0} \\leftarrow 0$ ，然后通过下式进行迭代更新：\n\n$$\n\\begin{equation*}\n\\boldsymbol{W}_{t+1} \\leftarrow \\boldsymbol{W}_{t}+\\alpha\\left(\\frac{1}{N} \\sum_{n=1}^{N} \\boldsymbol{x}^{(n)}\\left(\\boldsymbol{y}^{(n)}-\\hat{\\boldsymbol{y}}_{\\boldsymbol{W}_{t}}^{(n)}\\right)^{\\top}\\right) \\tag{3.53}\n\\end{equation*}\n$$\n\n其中 $\\alpha$ 是学习率，$\\hat{\\boldsymbol{y}}_{\\boldsymbol{W}_{t}}^{(n)}$ 是当参数为 $\\boldsymbol{W}_{t}$ 时，Softmax 回归模型的输出。\n\nSoftmax 函数的导数参见第 B．4．2．2 节。\n$\\boldsymbol{y}^{\\top} \\operatorname{diag}(\\boldsymbol{y})^{-1}=\\mathbf{1}_{C}^{\\top}$ 为全 1 的行向量．\n$\\boldsymbol{y}$ 为 one－hot 向量，所以 $\\mathbf{1}_{C}^{\\top} \\boldsymbol{y}=1$ ．\n\n要注意的是，Softmax 回归中使用的 $C$ 个权重向量是冗余的，即对所有的权重向量都减去一个同样的向量 $\\boldsymbol{v}$ ，不改变其输出结果。因此，Softmax回归往往需要使用正则化来约束其参数。此外，我们还可以利用这个特性来避免计算 softmax 函数时在数值计算上溢出问题．",
        "总结": "- 参数学习目标：使用交叉熵损失函数学习Softmax回归的最优参数矩阵W。\n- 类别标签表示：用C维one-hot向量表示类别标签，每个类别对应一个one-hot向量。\n- 风险函数定义：风险函数为交叉熵损失函数的平均值，形式为 $-\\frac{1}{N} \\sum_{n=1}^{N} \\boldsymbol{y}^{(n)\\top} \\log \\hat{\\boldsymbol{y}}^{(n)}$。\n- 后验概率计算：$\\hat{\\boldsymbol{y}}^{(n)} = \\operatorname{softmax}(\\boldsymbol{W}^\\top \\boldsymbol{x}^{(n)})$ 表示样本的后验概率。\n- 梯度推导：风险函数关于W的梯度为 $-\\frac{1}{N} \\sum_{n=1}^{N} \\boldsymbol{x}^{(n)} (\\boldsymbol{y}^{(n)} - \\hat{\\boldsymbol{y}}^{(n)})^\\top$。\n- 导数公式：用于计算梯度的两个关键导数公式，包括softmax函数的导数和参数对z的导数。\n- 梯度计算过程：通过链式法则逐步推导出损失函数关于参数W的梯度，并简化为 $-\\boldsymbol{x}^{(n)} (\\boldsymbol{y}^{(n)} - \\hat{\\boldsymbol{y}}^{(n)})^\\top$。\n- 参数更新方法：使用梯度下降法进行参数更新，形式为 $\\boldsymbol{W}_{t+1} \\leftarrow \\boldsymbol{W}_t + \\alpha \\left(\\frac{1}{N} \\sum_{n=1}^N \\boldsymbol{x}^{(n)} (\\boldsymbol{y}^{(n)} - \\hat{\\boldsymbol{y}}_{\\boldsymbol{W}_t}^{(n)})^\\top\\right)$。\n- 参数冗余性：Softmax回归中C个权重向量是冗余的，可以减去相同向量而不改变输出结果。\n- 正则化与数值稳定性：由于参数冗余性，通常需要正则化约束参数，并可用于避免数值计算溢出问题。"
      },
      {
        "段落": "## 3.4 感知器\n\n感知器（Perceptron）由 Frank Roseblatt于1957年提出，是一种广泛使用的线性分类器．感知器可谓是最简单的人工神经网络，只有一个神经元．\n\n感知器是对生物神经元的简单数学模拟，有与生物神经元相对应的部件，如权重（突触）、偏置（阈值）及激活函数（细胞体），输出为 +1 或 -1 。\n\n感知器是一种简单的两类线性分类模型，其分类准则与公式（3．5）相同，即\n\n$$\n\\begin{equation*}\n\\hat{y}=\\operatorname{sgn}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right) . \\tag{3.54}\n\\end{equation*}\n$$",
        "总结": "- 感知器是一种线性分类器，由Frank Roseblatt于1957年提出，是最简单的人工神经网络，仅包含一个神经元。  \n- 感知器是对生物神经元的数学模拟，包含权重（对应突触）、偏置（对应阈值）及激活函数（对应细胞体）。  \n- 感知器的输出为+1或-1，用于二分类任务。  \n- 感知器的分类准则由公式（3.54）给出，即 $\\hat{y} = \\operatorname{sgn}(\\boldsymbol{w}^{\\top} \\boldsymbol{x})$。"
      },
      {
        "段落": "## 3．4．1 参数学习\n\n感知器学习算法也是一个经典的线性分类器的参数学习算法．\n给定 $N$ 个样本的训练集：$\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，其中 $y^{(n)} \\in\\{+1,-1\\}$ ，感知器学习算法试图找到一组参数 $\\boldsymbol{w}^{*}$ ，使得对于每个样本 $\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)$ 有\n\n$$\n\\begin{equation*}\ny^{(n)} \\boldsymbol{w}^{*^{\\top}} \\boldsymbol{x}^{(n)}>0, \\quad \\forall n \\in\\{1, \\cdots, N\\} . \\tag{3.55}\n\\end{equation*}\n$$\n\n感知器的学习算法是一种错误驱动的在线学习算法［Rosenblatt，1958］．先初始化一个权重向量 $\\boldsymbol{w} \\leftarrow 0$（通常是全零向量），然后每次分错一个样本 $(\\boldsymbol{x}, y)$时，即 $y \\boldsymbol{w}^{\\top} \\boldsymbol{x}<0$ ，就用这个样本来更新权重．\n\n$$\n\\begin{equation*}\n\\boldsymbol{w} \\leftarrow \\boldsymbol{w}+y \\boldsymbol{x} . \\tag{3.56}\n\\end{equation*}\n$$\n\n具体的感知器参数学习策略如算法3．1所示．\n根据感知器的学习策略，可以反推出感知器的损失函数为\n\n$$\n\\begin{equation*}\n\\mathcal{L}(\\boldsymbol{w} ; \\boldsymbol{x}, y)=\\max \\left(0,-y \\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right) . \\tag{3.57}\n\\end{equation*}\n$$\n\n采用随机梯度下降，其每次更新的梯度为\n\n$$\n\\frac{\\partial \\mathcal{L}(\\boldsymbol{w} ; \\boldsymbol{x}, y)}{\\partial \\boldsymbol{w}}= \\begin{cases}0 & \\text { if } \\quad y \\boldsymbol{w}^{\\top} \\boldsymbol{x}>0  \\tag{3.58}\\\\ -y \\boldsymbol{x} & \\text { if } \\quad y \\boldsymbol{w}^{\\top} \\boldsymbol{x}<0\\end{cases}\n$$\n\n图 3.5 给出了感知器参数学习的更新过程，其中红色实心点为正例，蓝色空心点为负例．黑色箭头表示权重向量，红色虚线箭头表示权重的更新方向．\nhttps：／／nndl．github．io／\n\nFrank Rosenblatt（ 19－ 28～1971），美国心理学家，人工智能领域开拓者。\n\n最早发明的感知器是一台机器而不是一种算法，后来才被实现为 IBM 704机器上可运行的程序．\n\n算法 3．1：两类感知器的参数学习算法\n输入：训练集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，最大迭代次数 $T$\n\n```\n初始化: $\\boldsymbol{w}_{0} \\leftarrow 0, k \\leftarrow 0, t \\leftarrow 0$;\nrepeat\n    对训练集 $\\mathcal{D}$ 中的样本随机排序;\n    for $n=1 \\cdots N$ do\n        选取一个样本 $\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)$;\n        if $\\boldsymbol{w}_{k}^{\\top}\\left(y^{(n)} \\boldsymbol{x}^{(n)}\\right) \\leq 0$ then\n            $\\boldsymbol{w}_{k+1} \\leftarrow \\boldsymbol{w}_{k}+y^{(n)} \\boldsymbol{x}^{(n)} ;$\n            $k \\leftarrow k+1$;\n        end\n        $t \\leftarrow t+1 ;$\n    end\nuntil $t=T$;\n输出: $\\boldsymbol{w}_{k}$\n```\n\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-076.jpg?height=907&width=915&top_left_y=967&top_left_x=183)\n\n图 3.5 感知器参数学习的更新过程",
        "总结": "- 感知器学习算法是一种经典的线性分类器参数学习算法，旨在找到一组参数 $\\boldsymbol{w}^*$，使得每个样本满足 $y^{(n)} \\boldsymbol{w}^{*^{\\top}} \\boldsymbol{x}^{(n)} > 0$。\n- 感知器的学习算法是错误驱动的在线学习算法，通过每次分错样本时更新权重向量 $\\boldsymbol{w}$。\n- 权重更新公式为 $\\boldsymbol{w} \\leftarrow \\boldsymbol{w} + y \\boldsymbol{x}$，当样本被错误分类时触发。\n- 感知器的损失函数为 $\\mathcal{L}(\\boldsymbol{w}; \\boldsymbol{x}, y) = \\max(0, -y \\boldsymbol{w}^{\\top} \\boldsymbol{x})$。\n- 使用随机梯度下降方法，梯度在 $y \\boldsymbol{w}^{\\top} \\boldsymbol{x} < 0$ 时为 $-y \\boldsymbol{x}$，否则为 0。\n- 算法3.1描述了两类感知器的参数学习过程，包括初始化、随机排序样本、迭代更新权重直到达到最大迭代次数。\n- 图3.5展示了感知器参数学习的更新过程，用不同颜色和箭头表示正例、负例和权重向量的变化。"
      },
      {
        "段落": "## 3．4．2 感知器的收敛性\n\n［Novikoff，1963］证明对于两类问题，如果训练集是线性可分的，那么感知器 https：／／nndl．github．io／\n\n算法可以在有限次迭代后收玫．然而，如果训练集不是线性可分的，那么这个算法则不能确保会收敛。\n\n当数据集是两类线性可分时，对于训练集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，其中 $\\boldsymbol{x}^{(n)}$ 为样本的增广特征向量，$y^{(n)} \\in\\{-1,1\\}$ ，那么存在一个正的常数 $\\gamma(\\gamma>0)$ 和权重向量 $\\boldsymbol{w}^{*}$ ，并且 $\\left\\|\\boldsymbol{w}^{*}\\right\\|=1$ ，对所有 $n$ 都满足 $\\left(\\boldsymbol{w}^{*}\\right)^{\\top}\\left(y^{(n)} \\boldsymbol{x}^{(n)}\\right) \\geq \\gamma$ 。我们可以证明如下定理。\n\n定理 3．1－感知器收玫性：给定训练集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，令 $R$ 是训练集中最大的特征向量的模，即\n\n$$\nR=\\max _{n}\\left\\|x^{(n)}\\right\\|\n$$\n\n如果训练集 $\\mathcal{D}$ 线性可分，两类感知器的参数学习算法3．1的权重更新次数不超过 $\\frac{R^{2}}{\\gamma^{2}}$ 。\n\n证明．感知器的权重向量的更新方式为\n\n$$\n\\begin{equation*}\n\\boldsymbol{w}_{k}=\\boldsymbol{w}_{k-1}+y^{(k)} \\boldsymbol{x}^{(k)} \\tag{3.59}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{x}^{(k)}, y^{(k)}$ 表示第 $k$ 个错误分类的样本．\n因为初始权重向量为 0 ，在第 $K$ 次更新时感知器的权重向量为\n\n$$\n\\begin{equation*}\n\\boldsymbol{w}_{K}=\\sum_{k=1}^{K} y^{(k)} \\boldsymbol{x}^{(k)} \\tag{3.60}\n\\end{equation*}\n$$\n\n分别计算 $\\left\\|\\boldsymbol{w}_{K}\\right\\|^{2}$ 的上下界：\n（1）$\\left\\|\\boldsymbol{w}_{K}\\right\\|^{2}$ 的上界为\n\n$$\n\\begin{align*}\n\\left\\|\\boldsymbol{w}_{K}\\right\\|^{2} & =\\left\\|\\boldsymbol{w}_{K-1}+y^{(K)} \\boldsymbol{x}^{(K)}\\right\\|^{2}  \\tag{3.61}\\\\\n& =\\left\\|\\boldsymbol{w}_{K-1}\\right\\|^{2}+\\left\\|y^{(K)} \\boldsymbol{x}^{(K)}\\right\\|^{2}+2 y^{(K)} \\boldsymbol{w}_{K-1}^{\\top} \\boldsymbol{x}^{(K)}  \\tag{3.62}\\\\\n& \\leq\\left\\|\\boldsymbol{w}_{K-1}\\right\\|^{2}+R^{2}  \\tag{3.63}\\\\\n& \\leq\\left\\|\\boldsymbol{w}_{K-2}\\right\\|^{2}+2 R^{2}  \\tag{3.64}\\\\\n& \\leq K R^{2} \\tag{3.65}\n\\end{align*}\n$$\n\n（2）$\\left\\|\\boldsymbol{w}_{K}\\right\\|^{2}$ 的下界为\n\n$$\n\\begin{align*}\n\\left\\|\\boldsymbol{w}_{K}\\right\\|^{2} & =\\left\\|\\boldsymbol{w}^{*}\\right\\|^{2} \\cdot\\left\\|\\boldsymbol{w}_{K}\\right\\|^{2}  \\tag{3.66}\\\\\n& \\geq\\left\\|\\boldsymbol{w}^{* \\top} \\boldsymbol{w}_{K}\\right\\|^{2} \\tag{3.67}\n\\end{align*}\n$$\n\n参见定义3．1．\n\n$$\ny_{k} \\boldsymbol{w}_{K-1}^{\\top} \\boldsymbol{x}^{(K)} \\leq 0 .\n$$\n\n$\\left\\|\\boldsymbol{w}^{*}\\right\\|=1$ 。两个向量内积的平方一定小于等于这两个向量的模的乘积。\nhttps：／／nndl．github．io／\n\n$$\n\\begin{align*}\n& =\\left\\|\\boldsymbol{w}^{*^{\\top}} \\sum_{k=1}^{K}\\left(y^{(k)} \\boldsymbol{x}^{(k)}\\right)\\right\\|^{2}  \\tag{3.68}\\\\\n& =\\left\\|\\sum_{k=1}^{K} \\boldsymbol{w}^{*^{\\top}}\\left(y^{(k)} \\boldsymbol{x}^{(k)}\\right)\\right\\|^{2}  \\tag{3.69}\\\\\n& \\geq K^{2} \\gamma^{2} . \\tag{3.70}\n\\end{align*}\n$$\n\n由公式（3．65）和公式（3．70），得到\n\n$$\n\\begin{equation*}\nK^{2} \\gamma^{2} \\leq\\left\\|\\boldsymbol{w}_{K}\\right\\|^{2} \\leq K R^{2} \\tag{3.71}\n\\end{equation*}\n$$\n\n取最左和最右的两项，进一步得到，$K^{2} \\gamma^{2} \\leq K R^{2}$ 。然后两边都除 $K$ ，最终得到\n\n$$\n\\begin{equation*}\nK \\leq \\frac{R^{2}}{\\gamma^{2}} \\tag{3.72}\n\\end{equation*}\n$$\n\n因此，在线性可分的条件下，算法3．1会在 $\\frac{R^{2}}{\\gamma^{2}}$ 步内收玫．\n虽然感知器在线性可分的数据上可以保证收玫，但其存在以下不足：\n（1）在数据集线性可分时，感知器虽然可以找到一个超平面把两类数据分开，但并不能保证其泛化能力。\n（2）感知器对样本顺序比较敏感．每次迭代的顺序不一致时，找到的分割超平面也往往不一致。\n（3）如果训练集不是线性可分的，就永远不会收玫。",
        "总结": "- 感知器收敛性定理：当训练集线性可分时，感知器算法在有限次迭代后可以收敛。  \n- 收敛次数上限：收敛所需的迭代次数不超过 $ \\frac{R^2}{\\gamma^2} $，其中 $ R $ 是训练集中最大特征向量的模，$ \\gamma $ 是分类间隔的下界。  \n- 收敛性证明：通过计算权重向量的模的上下界，结合线性可分条件，推导出迭代次数的上界。  \n- 线性可分条件：训练集必须满足存在一个单位向量 $ \\boldsymbol{w}^* $，使得所有样本满足 $ (\\boldsymbol{w}^*)^\\top (y^{(n)} \\boldsymbol{x}^{(n)}) \\geq \\gamma $。  \n- 感知器的局限性：在线性可分数据上无法保证泛化能力，对样本顺序敏感，且在非线性可分数据上无法收敛。"
      },
      {
        "段落": "## 3．4．3 参数平均感知器\n\n根据定理3．1，如果训练数据是线性可分的，那么感知器可以找到一个判别函数来分割不同类的数据。如果间隔 $\\gamma$ 越大，收玫越快。但是感知器并不能保证找到的判别函数是最优的（比如泛化能力高），这样可能导致过拟合。\n\n感知器学习到的权重向量和训练样本的顺序相关．在迭代次序上排在后面的错误样本比前面的错误样本，对最终的权重向量影响更大。比如有 1000 个训练样本，在迭代 100 个样本后，感知器已经学习到一个很好的权重向量。在接下来的 899 个样本上都预测正确，也没有更新权重向量。但是，在最后第 1000 个样本时预测错误，并更新了权重．这次更新可能反而使得权重向量变差．\n\n为了提高感知器的鲁棒性和泛化能力，我们可以将在感知器学习过程中的所有 $K$ 个权重向量保存起来，并赋予每个权重向量 $\\boldsymbol{w}_{k}$ 一个置信系数 $c_{k}(1 \\leq k \\leq$ $K$ ）。最终的分类结果通过这 $K$ 个不同权重的感知器投票决定，这个模型也称为投票感知器（Voted Perceptron）［Freund et al．，1999］．\n$K$ 为感知器在训练中权重向量的总更新次数．\n\n令 $\\tau_{k}$ 为第 $k$ 次更新权重 $\\boldsymbol{w}_{k}$ 时的迭代次数（即训练过的样本数量），$\\tau_{k+1}$ 为下次权重更新时的迭代次数，则权重 $\\boldsymbol{w}_{k}$ 的置信系数 $c_{k}$ 设置为从 $\\tau_{k}$ 到 $\\tau_{k+1}$ 之间间隔的迭代次数，即 $c_{k}=\\tau_{k+1}-\\tau_{k}$ 。置信系数 $c_{k}$ 越大，说明权重 $\\boldsymbol{w}_{k}$ 在之后的训练过程中正确分类样本的数量越多，越值得信赖。\n\n这样，投票感知器的形式为\n\n$$\n\\begin{equation*}\n\\hat{y}=\\operatorname{sgn}\\left(\\sum_{k=1}^{K} c_{k} \\operatorname{sgn}\\left(\\boldsymbol{w}_{k}^{\\top} \\boldsymbol{x}\\right)\\right), \\tag{3.73}\n\\end{equation*}\n$$\n\n其中 $\\operatorname{sgn}(\\cdot)$ 为符号函数。\n投票感知器虽然提高了感知器的泛化能力，但是需要保存 $K$ 个权重向量。在实际操作中会带来额外的开销。因此，人们经常会使用一个简化的版本，通过使用 ＂参数平均＂的策略来减少投票感知器的参数数量，也叫做平均感知器（Averaged Perceptron）［Collins，2002］．平均感知器的形式为\n\n$$\n\\begin{align*}\n\\hat{y} & =\\operatorname{sgn}\\left(\\frac{1}{T} \\sum_{k=1}^{K} c_{k}\\left(\\boldsymbol{w}_{k}^{\\top} \\boldsymbol{x}\\right)\\right)  \\tag{3.74}\\\\\n& =\\operatorname{sgn}\\left(\\frac{1}{T}\\left(\\sum_{k=1}^{K} c_{k} \\boldsymbol{w}_{k}\\right)^{\\top} \\boldsymbol{x}\\right)  \\tag{3.75}\\\\\n& =\\operatorname{sgn}\\left(\\left(\\frac{1}{T} \\sum_{t=1}^{T} \\boldsymbol{w}_{t}\\right)^{\\top} \\boldsymbol{x}\\right)  \\tag{3.76}\\\\\n& =\\operatorname{sgn}\\left(\\overline{\\boldsymbol{w}}^{\\top} \\boldsymbol{x}\\right) \\tag{3.77}\n\\end{align*}\n$$\n\n其中 $T$ 为迭代总回合数，$\\overline{\\boldsymbol{w}}$ 为 $T$ 次迭代的平均权重向量．\n这个方法非常简单，只需要在算法3．1中增加一个 $\\overline{\\boldsymbol{w}}$ ，并且在每次迭代时都更新 $\\overline{\\boldsymbol{w}}$ ：\n\n$$\n\\begin{equation*}\n\\overline{\\boldsymbol{w}} \\leftarrow \\overline{\\boldsymbol{w}}+\\boldsymbol{w}_{t} . \\tag{3.78}\n\\end{equation*}\n$$\n\n但这个方法需要在处理每一个样本时都要更新 $\\overline{\\boldsymbol{\\omega}}$ 。因为 $\\overline{\\boldsymbol{w}}$ 和 $\\boldsymbol{w}_{t, n}$ 都是稠密向量，所以更新操作比较费时。为了提高迭代速度，有很多改进的方法，让这个更新只需要在错误预测发生时才进行更新。\n\n算法3．2给出了一个改进的平均感知器算法的训练过程［Daumé III，2012］．\n\n```\n算法 3.2: 一种改进的平均感知器参数学习算法\n    输入: 训练集 $\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$, 最大迭代次数 $T$\n    初始化 $: \\boldsymbol{w} \\leftarrow 0, \\boldsymbol{u} \\leftarrow 0, t \\leftarrow 0$;\n    repeat\n        对训练集 $\\mathcal{D}$ 中的样本随机排序;\n        for $n=1 \\cdots N$ do\n            选取一个样本 $\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)$;\n            计算预测类别 $\\hat{y}_{t}$;\n            if $\\hat{y}_{t} \\neq y_{t}$ then\n                $\\boldsymbol{\\omega} \\leftarrow \\boldsymbol{\\omega}+y^{(n)} \\boldsymbol{x}^{(n)} ;$\n                $\\boldsymbol{u} \\leftarrow \\boldsymbol{u}+t y^{(n)} \\boldsymbol{x}^{(n)} ;$\n            end\n            $t \\leftarrow t+1$;\n        end\n    until $t=T$;\n    $\\overline{\\boldsymbol{w}}=\\boldsymbol{w}_{T}-\\frac{1}{T} \\boldsymbol{u} ;$\n    输出: $\\overline{\\boldsymbol{w}}$\n```",
        "总结": "- 参数平均感知器提出了一种改进的感知器算法，通过平均多个权重向量来提高泛化能力。\n- 感知器学习到的权重向量与训练样本的顺序相关，后续错误样本对权重的影响更大。\n- 投票感知器通过保存所有权重向量并赋予置信系数，最终通过投票决定分类结果。\n- 置信系数 $c_k$ 表示权重 $\\boldsymbol{w}_k$ 在训练过程中正确分类样本的数量，越大越值得信赖。\n- 投票感知器的形式为 $\\hat{y} = \\operatorname{sgn}\\left(\\sum_{k=1}^{K} c_{k} \\operatorname{sgn}\\left(\\boldsymbol{w}_{k}^{\\top} \\boldsymbol{x}\\right)\\right)$。\n- 平均感知器通过参数平均策略减少参数数量，形式为 $\\hat{y} = \\operatorname{sgn}\\left(\\overline{\\boldsymbol{w}}^{\\top} \\boldsymbol{x}\\right)$，其中 $\\overline{\\boldsymbol{w}}$ 是迭代的平均权重向量。\n- 平均感知器在每次迭代时更新平均权重向量 $\\overline{\\boldsymbol{w}}$，公式为 $\\overline{\\boldsymbol{w}} \\leftarrow \\overline{\\boldsymbol{w}} + \\boldsymbol{w}_t$。\n- 为了提高效率，改进的平均感知器仅在错误预测时更新权重和平均权重。\n- 改进的平均感知器算法在每次错误预测时更新 $\\boldsymbol{\\omega}$ 和 $\\boldsymbol{u}$，最终计算 $\\overline{\\boldsymbol{w}} = \\boldsymbol{w}_T - \\frac{1}{T} \\boldsymbol{u}$。"
      },
      {
        "段落": "## 3．4．4 扩展到多分类\n\n原始的感知器是一种二分类模型，但也可以很容易地扩展到多分类问题，甚至是更一般的结构化学习问题［Collins，2002］．\n\n之前介绍的分类模型中，分类函数都是在输入 $\\boldsymbol{x}$ 的特征空间上。为了使得感知器可以处理更复杂的输出，我们引入一个构建在输入输出联合空间上的特征函数 $\\phi(\\boldsymbol{x}, \\boldsymbol{y})$ ，将样本对 $(\\boldsymbol{x}, \\boldsymbol{y})$ 映射到一个特征向量空间．\n\n在联合特征空间中，我们可以建立一个广义的感知器模型，\n\n$$\n\\begin{equation*}\n\\hat{\\boldsymbol{y}}=\\underset{\\boldsymbol{y} \\in \\operatorname{Gen}(\\boldsymbol{x})}{\\arg \\max } \\boldsymbol{w}^{\\top} \\phi(\\boldsymbol{x}, \\boldsymbol{y}), \\tag{3.79}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{w}$ 为权重向量， $\\operatorname{Gen}(\\boldsymbol{x})$ 表示输入 $\\boldsymbol{x}$ 所有的输出目标集合．\n广义感知器模型一般用来处理结构化学习问题．当用广义感知器模型来处理 $C$ 分类问题时， $\\boldsymbol{y} \\in\\{0,1\\}^{C}$ 为类别的 one－hot 向量表示。在 $C$ 分类问题中，一种常用的特征函数 $\\phi(\\boldsymbol{x}, \\boldsymbol{y})$ 是 $\\boldsymbol{x}$ 和 $\\boldsymbol{y}$ 的外积，即\n\n$$\n\\begin{equation*}\n\\phi(\\boldsymbol{x}, \\boldsymbol{y})=\\operatorname{vec}\\left(\\boldsymbol{x} \\boldsymbol{y}^{\\top}\\right) \\in \\mathbb{R}^{(D \\times C)}, \\tag{3.80}\n\\end{equation*}\n$$\n\n其中 $\\operatorname{vec}(\\cdot)$ 是向量化算子，$\\phi(\\boldsymbol{x}, \\boldsymbol{y})$ 为 $(D \\times C)$ 维的向量．\n\n通过引入特征函数 $\\phi(x, y)$ ，感知器不但可以用于多分类问题，也可以用于结构化学习问题，比如输出是序列形式。\n\n外积的定义参见公式（A．27）。\n\n给定样本 $(\\boldsymbol{x}, \\boldsymbol{y})$ ，若 $\\boldsymbol{x} \\in \\mathbb{R}^{D}, \\boldsymbol{y}$ 为第 $c$ 维为 1 的 one－hot 向量，则\n\n$$\n\\phi(\\boldsymbol{x}, \\boldsymbol{y})=\\left[\\begin{array}{c}\n\\vdots  \\tag{3.81}\\\\\n0 \\\\\nx_{1} \\\\\n\\vdots \\\\\nx_{D} \\\\\n0 \\\\\n\\vdots\n\\end{array}\\right] \\begin{aligned}\n& \\leftarrow \\text { 第 }(c-1) \\times D+1 \\text { 行 } \\\\\n& \\leftarrow \\text { 第 }(c-1) \\times D+D \\text { 行 }\n\\end{aligned}\n$$\n\n广义感知器算法的训练过程如算法3．3所示．\n\n```\n算法 3.3: 广义感知器参数学习算法\n    输入: 训练集: $\\left\\{\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{y}^{(n)}\\right)\\right\\}_{n=1}^{N}$, 最大迭代次数 $T$\n    初始化: $\\boldsymbol{w}_{0} \\leftarrow 0, k \\leftarrow 0, t \\leftarrow 0$;\n    repeat\n        对训练集 $\\mathcal{D}$ 中的样本随机排序;\n        for $n=1 \\cdots N$ do\n            选取一个样本 $\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{y}^{(n)}\\right)$;\n            用公式 (3.79) 计算预测类别 $\\hat{\\boldsymbol{y}}^{(n)}$;\n            if $\\hat{\\boldsymbol{y}}^{(n)} \\neq \\boldsymbol{y}^{(n)}$ then\n                $\\boldsymbol{w}_{k+1} \\leftarrow \\boldsymbol{w}_{k}+\\left(\\phi\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{y}^{(n)}\\right)-\\phi\\left(\\boldsymbol{x}^{(n)}, \\hat{\\boldsymbol{y}}^{(n)}\\right)\\right) ;$\n                $k=k+1$;\n            end\n            $t=t+1 ;$\n        end\n    until $t=T$;\n    输出: $\\boldsymbol{w}_{k}$\n```",
        "总结": "- 概念：扩展感知器模型到多分类和结构化学习问题  \n- 算法：广义感知器算法，用于多分类和结构化学习问题的参数学习  \n- 定理/命题：广义感知器模型通过引入联合特征空间，能够处理多分类和结构化输出问题  \n- 数学推导：定义了联合特征函数 $\\phi(\\boldsymbol{x}, \\boldsymbol{y})$，并给出多分类问题中常用的外积形式特征函数 $\\phi(\\boldsymbol{x}, \\boldsymbol{y}) = \\operatorname{vec}(\\boldsymbol{x} \\boldsymbol{y}^{\\top})$"
      },
      {
        "段落": "### 3．4．4．1 广义感知器的收敛性\n\n广义感知器在满足广义线性可分条件时，也能够保证在有限步骤内收敛。广义线性可分条件的定义如下：\n\n定义 3．3－广义线性可分：对于训练集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{y}^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，如果存在一个正的常数 $\\gamma(\\gamma>0)$ 和权重向量 $\\boldsymbol{w}^{*}$ ，并且 $\\left\\|\\boldsymbol{w}^{*}\\right\\|=1$ ，对所有 $n$ 都满足 $\\left\\langle\\boldsymbol{w}^{*}, \\phi\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{y}^{(n)}\\right)\\right\\rangle-\\left\\langle\\boldsymbol{w}^{*}, \\phi\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{y}\\right)\\right\\rangle \\geq \\gamma, \\boldsymbol{y} \\neq \\boldsymbol{y}^{(n)}\\left(\\phi\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{y}^{(n)}\\right) \\in \\mathbb{R}^{D}\\right.$ 为样本 $\\boldsymbol{x}^{(n)}, \\boldsymbol{y}^{(n)}$ 的联合特征向量），那么训练集 $\\mathcal{D}$ 在联合特征向量空间中是线性可分的．\n\n广义感知器的收敛性定义如下：\n定理3．2－广义感知器收玫性：如果训练集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{y}^{(n)}\\right)\\right\\}_{n=1}^{N}$ 是广义线性可分的，并令 $R$ 是所有样本中真实标签和错误标签在特征空间 $\\phi(\\boldsymbol{x}, \\boldsymbol{y})$ 最远的距离，即\n\n$$\n\\begin{equation*}\nR=\\max _{n} \\max _{\\boldsymbol{z} \\neq \\boldsymbol{y}^{(n)}}\\left\\|\\phi\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{y}^{(n)}\\right)-\\phi\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{z}\\right)\\right\\| \\tag{3.82}\n\\end{equation*}\n$$\n\n那么广义感知器参数学习算法 3.3 的权重更新次数不超过 $\\frac{R^{2}}{\\gamma^{2}}$ ．\n［Collins，2002］给出了广义感知器在广义线性可分的收玫性证明，具体推导过程和两类感知器比较类似。",
        "总结": "- 广义感知器的收敛性：在满足广义线性可分条件时，广义感知器能够在有限步骤内收敛。  \n- 广义线性可分的定义：存在一个单位权重向量 $\\boldsymbol{w}^*$ 和正数 $\\gamma$，使得所有样本的联合特征向量在 $\\boldsymbol{w}^*$ 下满足一定间隔条件。  \n- 收敛性定理：若训练集是广义线性可分的，则广义感知器参数学习算法的权重更新次数不超过 $\\frac{R^2}{\\gamma^2}$，其中 $R$ 是特征空间中真实标签与错误标签最远距离。  \n- 证明来源：Collins（2002）给出了广义感知器收敛性的证明，推导过程与两类感知器类似。"
      },
      {
        "段落": "## 3.5 支持向量机\n\n支持向量机（Support Vector Machine，SVM）是一个经典的二分类算法，其找到的分割超平面具有更好的鲁棒性，因此广泛使用在很多任务上，并表现出了很强优势。\n\n给定一个二分类器数据集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，其中 $y_{n} \\in\\{+1,-1\\}$ ，如果两类样本是线性可分的，即存在一个超平面\n\n$$\n\\begin{equation*}\n\\boldsymbol{w}^{\\top} \\boldsymbol{x}+b=0 \\tag{3.83}\n\\end{equation*}\n$$\n\n将两类样本分开，那么对于每个样本都有 $y^{(n)}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b\\right)>0$ ．\n数据集 $\\mathcal{D}$ 中每个样本 $\\boldsymbol{x}^{(n)}$ 到分割超平面的距离为：\n\n$$\n\\begin{equation*}\n\\gamma^{(n)}=\\frac{\\left\\|\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b\\right\\|}{\\|\\boldsymbol{w}\\|}=\\frac{y^{(n)}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b\\right)}{\\|\\boldsymbol{w}\\|} . \\tag{3.84}\n\\end{equation*}\n$$\n\n我们定义间隔（Margin）$\\gamma$ 为整个数据集 $D$ 中所有样本到分割超平面的最短距离：\n\n$$\n\\begin{equation*}\n\\gamma=\\min _{n} \\gamma^{(n)} \\tag{3.85}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n广义线性可分是多类线性可分的扩展，参见定义 3．2．\n\n参见习题 3－9．\n\n本节中不使用增广的特征向量和特征权重。\n\n如果间隔 $\\gamma$ 越大，其分割超平面对两个数据集的划分越稳定，不容易受噪声等因素影响。支持向量机的目标是寻找一个超平面（ $\\boldsymbol{w}^{*}, b^{*}$ ）使得 $\\gamma$ 最大，即\n\n$$\n\\begin{array}{ll}\n\\max _{\\boldsymbol{w}, b} & \\gamma  \\tag{3.86}\\\\\n\\text { s.t. } & \\frac{y^{(n)}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b\\right)}{\\|\\boldsymbol{w}\\|} \\geq \\gamma, \\forall n \\in\\{1, \\cdots, N\\}\n\\end{array}\n$$\n\n令 $\\|\\boldsymbol{w}\\| \\cdot \\gamma=1$ ，则公式（3．86）等价于\n\n$$\n\\begin{array}{cl}\n\\max _{\\boldsymbol{w}, b} & \\frac{1}{\\|\\boldsymbol{w}\\|^{2}}  \\tag{3.87}\\\\\n\\text { s.t. } & y^{(n)}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b\\right) \\geq 1, \\forall n \\in\\{1, \\cdots, N\\}\n\\end{array}\n$$\n\n数据集中所有满足 $y^{(n)}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b\\right)=1$ 的样本点，都称为支持向量（Sup－ port Vector）．\n\n对于一个线性可分的数据集，其分割超平面有很多个，但是间隔最大的超平面是唯一的．图3．6给定了支持向量机的最大间隔分割超平面的示例，其中红色样本点为支持向量．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-083.jpg?height=659&width=711&top_left_y=1091&top_left_x=300)\n\n图 3.6 支持向量机示例",
        "总结": "- 支持向量机（SVM）是一个经典的二分类算法，其目标是找到具有最大间隔的分割超平面，以提高鲁棒性。  \n- 分割超平面由公式 $\\boldsymbol{w}^{\\top} \\boldsymbol{x} + b = 0$ 表示，且满足 $y^{(n)}(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)} + b) > 0$。  \n- 样本 $\\boldsymbol{x}^{(n)}$ 到分割超平面的距离定义为 $\\gamma^{(n)} = \\frac{y^{(n)}(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)} + b)}{\\|\\boldsymbol{w}\\|}$。  \n- 间隔 $\\gamma$ 是数据集中所有样本到分割超平面的最短距离，即 $\\gamma = \\min_{n} \\gamma^{(n)}$。  \n- SVM 的目标是最大化间隔 $\\gamma$，即在约束条件下最大化 $\\frac{1}{\\|\\boldsymbol{w}\\|^{2}}$。  \n- 满足 $y^{(n)}(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)} + b) = 1$ 的样本点称为支持向量。  \n- 对于线性可分数据集，最大间隔超平面是唯一的，且由支持向量决定。"
      },
      {
        "段落": "## 3．5．1 参数学习\n\n为了找到最大间隔分割超平面，将公式（3．87）的目标函数写为凸优化问题\n\n$$\n\\begin{equation*}\n\\min _{\\boldsymbol{w}, b} \\quad \\frac{1}{2}\\|\\boldsymbol{w}\\|^{2} \\tag{3.88}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n$$\n\\text { s.t. } \\quad 1-y^{(n)}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b\\right) \\leq 0, \\quad \\forall n \\in\\{1, \\cdots, N\\}\n$$\n\n使用拉格朗日乘数法，公式（3．88）的拉格朗日函数为\n参见第 C． 3 节。\n\n$$\n\\begin{equation*}\n\\Lambda(\\boldsymbol{w}, b, \\lambda)=\\frac{1}{2}\\|\\boldsymbol{w}\\|^{2}+\\sum_{n=1}^{N} \\lambda_{n}\\left(1-y^{(n)}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b\\right)\\right), \\tag{3.89}\n\\end{equation*}\n$$\n\n其中 $\\lambda_{1} \\geq 0, \\cdots, \\lambda_{N} \\geq 0$ 为拉格朗日乘数。计算 $\\Lambda(\\boldsymbol{w}, b, \\lambda)$ 关于 $\\boldsymbol{w}$ 和 $b$ 的导数，并令其等于 0 ，得到\n\n$$\n\\begin{align*}\n\\boldsymbol{w} & =\\sum_{n=1}^{N} \\lambda_{n} y^{(n)} \\boldsymbol{x}^{(n)}  \\tag{3.90}\\\\\n0 & =\\sum_{n=1}^{N} \\lambda_{n} y^{(n)} \\tag{3.91}\n\\end{align*}\n$$\n\n将公式（3．90）代入公式（3．89），并利用公式（3．91），得到拉格朗日对偶函数\n\n$$\n\\begin{equation*}\n\\Gamma(\\lambda)=-\\frac{1}{2} \\sum_{n=1}^{N} \\sum_{m=1}^{N} \\lambda_{m} \\lambda_{n} y^{(m)} y^{(n)}\\left(\\boldsymbol{x}^{(m)}\\right)^{\\top} \\boldsymbol{x}^{(n)}+\\sum_{n=1}^{N} \\lambda_{n} . \\tag{3.92}\n\\end{equation*}\n$$\n\n支持向量机的主优化问题为凸优化问题，满足强对偶性，即主优化问题可以通过最大化对偶函数 $\\max _{\\lambda \\geq 0} \\Gamma(\\lambda)$ 来求解。对偶函数 $\\Gamma(\\lambda)$ 是一个凹函数，因此最大化对偶函数是一个凸优化问题，可以通过多种凸优化方法来进行求解，得到拉格朗日乘数的最优值 $\\lambda^{*}$ 。但由于其约束条件的数量为训练样本数量，一般的优化方法代价比较高，因此在实践中通常采用比较高效的优化方法，比如序列最小优化（Sequential Minimal Optimization，SMO）算法［Platt，1998］等。\n\n根据 KKT 条件中的互补松弛条件，最优解满足 $\\lambda_{n}^{*}\\left(1-y^{(n)}\\left(\\boldsymbol{w}^{* \\top} \\boldsymbol{x}^{(n)}+b^{*}\\right)\\right)=$ 0 。 如果样本 $\\boldsymbol{x}^{(n)}$ 不在约束边界上，$\\lambda_{n}^{*}=0$ ，其约束失效；如果样本 $\\boldsymbol{x}^{(n)}$ 在约束边界上，$\\lambda_{n}^{*} \\geq 0$ ．这些在约束边界上的样本点称为支持向量（Support Vector），即离决策平面距离最近的点．\n\n在计算出 $\\lambda^{*}$ 后，根据公式（3．90）计算出最优权重 $\\boldsymbol{w}^{*}$ ，最优偏置 $b^{*}$ 可以通过任选一个支持向量 $(\\tilde{\\boldsymbol{x}}, \\tilde{\\boldsymbol{y}})$ 计算得到。\n\n$$\n\\begin{equation*}\nb^{*}=\\tilde{y}-\\boldsymbol{w}^{*^{\\top}} \\tilde{\\boldsymbol{x}} . \\tag{3.93}\n\\end{equation*}\n$$\n\n最优参数的支持向量机的决策函数为\n\n$$\n\\begin{align*}\nf(\\boldsymbol{x}) & =\\operatorname{sgn}\\left(\\boldsymbol{w}^{*^{\\top}} \\boldsymbol{x}+b^{*}\\right)  \\tag{3.94}\\\\\n& =\\operatorname{sgn}\\left(\\sum_{n=1}^{N} \\lambda_{n}^{*} y^{(n)}\\left(\\boldsymbol{x}^{(n)}\\right)^{\\top} \\boldsymbol{x}+b^{*}\\right) \\tag{3.95}\n\\end{align*}\n$$\n\nhttps：／／nndl．github．io／\n\n支持向量机的决策函数只依赖于 $\\lambda_{n}^{*}>0$ 的样本点，即支持向量．\n支持向量机的目标函数可以通过 SMO 等优化方法得到全局最优解，因此比其他分类器的学习效率更高。此外，支持向量机的决策函数只依赖于支持向量，与训练样本总数无关，分类速度比较快。",
        "总结": "- 参数学习的目标是找到最大间隔分割超平面，通过将目标函数转化为凸优化问题来实现。  \n- 使用拉格朗日乘数法，将原问题转化为对偶问题，引入拉格朗日乘数 $\\lambda$。  \n- 通过计算拉格朗日函数对 $\\boldsymbol{w}$ 和 $b$ 的导数并令其为零，得到 $\\boldsymbol{w}$ 和 $b$ 的表达式。  \n- 对偶函数 $\\Gamma(\\lambda)$ 是一个凹函数，最大化该函数可求解主优化问题。  \n- 通过序列最小优化（SMO）等高效算法求解对偶问题，得到最优的拉格朗日乘数 $\\lambda^*$。  \n- 根据 KKT 条件中的互补松弛条件，确定支持向量（即位于约束边界上的样本点）。  \n- 最优权重 $\\boldsymbol{w}^*$ 可由 $\\lambda^*$ 计算得出，最优偏置 $b^*$ 可通过任选一个支持向量计算。  \n- 决策函数仅依赖于支持向量，与训练样本总数无关，提高了分类速度。  \n- 支持向量机的学习效率较高，并能通过 SMO 等方法获得全局最优解。"
      },
      {
        "段落": "## 3．5．2 核函数\n\n支持向量机还有一个重要的优点是可以使用核函数（Kernel Function）隐式地将样本从原始特征空间映射到更高维的空间，并解决原始特征空间中的线性不可分问题。比如在一个变换后的特征空间 $\\phi$ 中，支持向量机的决策函数为\n\n$$\n\\begin{align*}\nf(\\boldsymbol{x}) & =\\operatorname{sgn}\\left(\\boldsymbol{w}^{*^{\\top}} \\boldsymbol{\\phi}(\\boldsymbol{x})+b^{*}\\right)  \\tag{3.96}\\\\\n& =\\operatorname{sgn}\\left(\\sum_{n=1}^{N} \\lambda_{n}^{*} y^{(n)} k\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{x}\\right)+b^{*}\\right) \\tag{3.97}\n\\end{align*}\n$$\n\n其中 $k(\\boldsymbol{x}, \\boldsymbol{z})=\\phi(\\boldsymbol{x})^{\\top} \\phi(\\boldsymbol{z})$ 为核函数。通常我们不需要显式地给出 $\\phi(\\boldsymbol{x})$ 的具体形式，可以通过核技巧（Kernel Trick）来构造。比如以 $\\boldsymbol{x}, \\boldsymbol{z} \\in \\mathbb{R}^{2}$ 为例，我们可以构造一个核函数\n\n$$\n\\begin{equation*}\nk(\\boldsymbol{x}, \\boldsymbol{z})=\\left(1+\\boldsymbol{x}^{\\top} \\boldsymbol{z}\\right)^{2}=\\phi(\\boldsymbol{x})^{\\top} \\phi(\\boldsymbol{z}), \\tag{3.98}\n\\end{equation*}\n$$\n\n来隐式地计算 $\\boldsymbol{x}, \\boldsymbol{z}$ 在特征空间 $\\phi$ 中的内积，其中\n\n$$\n\\begin{equation*}\n\\phi(\\boldsymbol{x})=\\left[1, \\sqrt{2} x_{1}, \\sqrt{2} x_{2}, \\sqrt{2} x_{1} x_{2}, x_{1}^{2}, x_{2}^{2}\\right]^{\\top} . \\tag{3.99}\n\\end{equation*}\n$$",
        "总结": "- 核函数的概念：核函数是一种隐式地将样本从原始特征空间映射到更高维空间的方法，用于解决线性不可分问题。  \n- 决策函数的形式：支持向量机在变换后的特征空间中的决策函数由权重向量和偏置项构成，并通过核函数计算样本的内积。  \n- 核函数的定义：核函数 $k(\\boldsymbol{x}, \\boldsymbol{z}) = \\phi(\\boldsymbol{x})^{\\top} \\phi(\\boldsymbol{z})$ 表示在特征空间中两个样本的内积。  \n- 核技巧的应用：无需显式计算 $\\phi(\\boldsymbol{x})$，通过核技巧构造核函数，实现隐式映射。  \n- 示例核函数：以二维空间为例，构造的核函数 $k(\\boldsymbol{x}, \\boldsymbol{z}) = (1 + \\boldsymbol{x}^{\\top} \\boldsymbol{z})^2$ 对应于一个高维特征空间的内积。  \n- 特征映射形式：该核函数对应的特征映射 $\\phi(\\boldsymbol{x})$ 将原始特征扩展为包含多项式项和交叉项的高维向量。"
      },
      {
        "段落": "## 3．5．3 软间隔\n\n在支持向量机的优化问题中，约束条件比较严格。如果训练集中的样本在特征空间中不是线性可分的，就无法找到最优解．为了能够容忍部分不满足约束的样本，我们可以引入松弛变量 $\\xi$ ，将优化问题变为\n\n$$\n\\begin{array}{ll}\n\\min _{\\boldsymbol{w}, b} & \\frac{1}{2}\\|\\boldsymbol{w}\\|^{2}+C \\sum_{n=1}^{N} \\xi_{n}  \\tag{3.100}\\\\\n\\text { s.t. } & 1-y^{(n)}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b\\right)-\\xi_{n} \\leq 0, \\quad \\forall n \\in\\{1, \\cdots, N\\} \\\\\n& \\xi_{n} \\geq 0, \\quad \\forall n \\in\\{1, \\cdots, N\\}\n\\end{array}\n$$\n\n其中参数 $C>0$ 用来控制间隔和松弛变量惩罚的平衡。引入松弛变量的间隔称为软间隔（Soft Margin）。公式（3．100）也可以表示为经验风险 + 正则化项的形式。\n\n$$\n\\begin{equation*}\n\\min _{\\boldsymbol{w}, b} \\quad \\sum_{n=1}^{N} \\max \\left(0,1-y^{(n)}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b\\right)\\right)+\\frac{1}{2 C}\\|\\boldsymbol{w}\\|^{2} \\tag{3.101}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n其中 $\\max \\left(0,1-y^{(n)}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b\\right)\\right)$ 称为Hinge损失函数，$\\frac{1}{C}$ 可以看作是正则化系数．\n\n参见公式（2．20）．\n\n软间隔支持向量机的参数学习和原始支持向量机类似，其最终决策函数也只和支持向量有关，即满足 $1-y^{(n)}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b\\right)-\\xi_{n}=0$ 的样本。\n\n参见习题 3－12．",
        "总结": "- 软间隔（Soft Margin）概念：引入松弛变量ξ，允许部分样本不满足约束条件，以处理非线性可分的情况。\n- 优化问题形式：目标函数为$\\frac{1}{2}\\|\\boldsymbol{w}\\|^{2}+C \\sum_{n=1}^{N} \\xi_{n}$，约束条件为$1-y^{(n)}(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b)-\\xi_{n} \\leq 0$和$\\xi_{n} \\geq 0$。\n- 参数C的作用：控制间隔与松弛变量惩罚之间的平衡，决定模型对误分类的容忍程度。\n- Hinge损失函数：$\\max(0,1-y^{(n)}(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b))$，用于衡量样本的分类误差。\n- 正则化项：$\\frac{1}{2C}\\|\\boldsymbol{w}\\|^{2}$，用于控制模型复杂度。\n- 决策函数特性：最终决策函数仅与支持向量相关，即满足$1-y^{(n)}(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}+b)-\\xi_{n}=0$的样本。"
      },
      {
        "段落": "## 3.6 损失函数对比\n\n本章介绍的三种二分类模型：Logistic回归、感知器和支持向量机．虽然它们的决策函数相同，但由于使用了不同的损失函数以及相应的优化方法，导致它们在实际任务上的表现存在一定的差异。\n\n为了比较这些损失函数，我们统一定义类别标签 $y \\in\\{+1,-1\\}$ ，并定义 $f(\\boldsymbol{x} ; \\boldsymbol{w})=\\boldsymbol{w}^{\\top} \\boldsymbol{x}+b$ 。 这样对于样本 $(\\boldsymbol{x}, y)$ ，若 $y f(\\boldsymbol{x} ; \\boldsymbol{w})>0$ ，则分类正确；若 $y f(\\boldsymbol{x} ; \\boldsymbol{w})<0$ ，则分类错误．这样，为了方便比较这些模型，我们可以将它们的损失函数都表述为定义在 $y f(\\boldsymbol{x} ; \\boldsymbol{w})$ 上的函数．\n\nLogistic 回归的损失函数可以改写为\n\n$$\n\\begin{align*}\n\\mathcal{L}_{L R} & =-I(y=1) \\log \\sigma(f(\\boldsymbol{x} ; \\boldsymbol{w}))-I(y=-1) \\log (1-\\sigma(f(\\boldsymbol{x} ; \\boldsymbol{w})))  \\tag{3.102}\\\\\n& =-I(y=1) \\log \\sigma(f(\\boldsymbol{x} ; \\boldsymbol{w}))-I(y=-1) \\log \\sigma(-f(\\boldsymbol{x} ; \\boldsymbol{w}))  \\tag{3.103}\\\\\n& =-\\log \\sigma(y f(\\boldsymbol{x} ; \\boldsymbol{w}))  \\tag{3.104}\\\\\n& =\\log (1+\\exp (-y f(\\boldsymbol{x} ; \\boldsymbol{w}))) \\tag{3.105}\n\\end{align*}\n$$\n\n感知器的损失函数为\n\n$$\n\\begin{equation*}\n\\mathcal{L}_{p}=\\max (0,-y f(\\boldsymbol{x} ; \\boldsymbol{w})) . \\tag{3.106}\n\\end{equation*}\n$$\n\n软间隔支持向量机的损失函数为\n\n$$\n\\begin{equation*}\n\\mathcal{L}_{\\text {hinge }}=\\max (0,1-y f(\\boldsymbol{x} ; \\boldsymbol{w})) . \\tag{3.107}\n\\end{equation*}\n$$\n\n平方损失可以重写为\n\n$$\n\\begin{align*}\n\\mathcal{L}_{\\text {squared }} & =(y-f(\\boldsymbol{x} ; \\boldsymbol{w}))^{2}  \\tag{3.108}\\\\\n& =1-2 y f(\\boldsymbol{x} ; \\boldsymbol{w})+(y f(\\boldsymbol{x} ; \\boldsymbol{w}))^{2}  \\tag{3.109}\\\\\n& =(1-y f(\\boldsymbol{x} ; \\boldsymbol{w}))^{2} \\tag{3.110}\n\\end{align*}\n$$\n\n图3．7给出了不同损失函数的对比．对于二分类来说，当 $y f(\\boldsymbol{x} ; \\boldsymbol{w})>0$ 时，分类器预测正确，并且 $y f(\\boldsymbol{x} ; \\boldsymbol{w})$ 越大，模型的预测越正确；当 $y f(\\boldsymbol{x} ; \\boldsymbol{w})<0$ 时，分类 https：／／nndl．github．io／\n\n器预测错误，并且 $y f(\\boldsymbol{x} ; \\boldsymbol{w})$ 越小，模型的预测越错误。因此，一个好的损失函数应该随着 $y f(\\boldsymbol{x} ; \\boldsymbol{w})$ 的增大而减少。从图3．7中看出，除了平方损失，其他损失函数都比较适合于二分类问题．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-087.jpg?height=635&width=692&top_left_y=303&top_left_x=314)\n\n图 3.7 不同损失函数的对比",
        "总结": "- 损失函数用于比较三种二分类模型（Logistic回归、感知器和支持向量机）在不同优化方法下的表现差异。  \n- 统一定义类别标签 $y \\in \\{+1, -1\\}$，并定义决策函数 $f(\\boldsymbol{x}; \\boldsymbol{w}) = \\boldsymbol{w}^\\top \\boldsymbol{x} + b$。  \n- 根据 $y f(\\boldsymbol{x}; \\boldsymbol{w})$ 的正负判断分类是否正确，正则表示正确，负则表示错误。  \n- Logistic回归的损失函数最终简化为 $\\log(1 + \\exp(-y f(\\boldsymbol{x}; \\boldsymbol{w})))$。  \n- 感知器的损失函数为 $\\max(0, -y f(\\boldsymbol{x}; \\boldsymbol{w}))$。  \n- 软间隔支持向量机的损失函数为 $\\max(0, 1 - y f(\\boldsymbol{x}; \\boldsymbol{w}))$。  \n- 平方损失可以重写为 $(1 - y f(\\boldsymbol{x}; \\boldsymbol{w}))^2$。  \n- 图3.7对比了不同损失函数，除了平方损失，其他损失函数更适合二分类问题。  \n- 一个好的损失函数应随着 $y f(\\boldsymbol{x}; \\boldsymbol{w})$ 的增大而减少。"
      },
      {
        "段落": "## 3.7 总结和深入阅读\n\n和回归问题不同，分类问题中的目标标签 $y$ 是离散的类别标签，因此分类问题中的决策函数需要输出离散值或是标签的后验概率。线性分类模型一般是一个广义线性函数，即一个线性判别函数 $f(\\boldsymbol{x} ; \\boldsymbol{w})=\\boldsymbol{w}^{\\top} \\boldsymbol{x}$ 加上一个非线性激活函数 $g(\\cdot)$ ．\n\n表3．1给出了几种常见的线性模型的比较。在 Logistic 回归和 Softmax 回归中， $\\boldsymbol{y}$ 为类别的 one－hot 向量表示；在感知器和支持向量机中，$y$ 为 $\\{+1,-1\\}$ ．\n\n表 3.1 几种常见的线性模型对比\n\n| 线性模型 | 激活函数 | 损失函数 | 优化方法 |\n| :--- | :--- | :--- | :--- |\n| 线性回归 | － | $\\left(y-\\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)^{2}$ | 最小二乘、梯度下降 |\n| Logistic 回归 | $\\sigma\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)$ | $\\boldsymbol{y} \\log \\sigma\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)$ | 梯度下降 |\n| Softmax 回归 | $\\operatorname{softmax}\\left(\\boldsymbol{W}^{\\boldsymbol{\\top}} \\boldsymbol{x}\\right)$ | $\\boldsymbol{y}$ log softmax $\\left(\\boldsymbol{W}^{\\boldsymbol{\\top}} \\boldsymbol{x}\\right)$ | 梯度下降 |\n| 感知器 | $\\operatorname{sgn}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)$ | $\\max \\left(0,-y \\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)$ | 随机梯度下降 |\n| 支持向量机 | $\\operatorname{sgn}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)$ | $\\max \\left(0,1-y \\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)$ | 二次规划、SMO等 |\n\nLogistic 回归是一种概率模型，其通过使用 Logistic 函数来将一个实数值映射到 $[0,1]$ 之间．事实上，还有很多函数也可以达到此目的，比如正态分布的累积概率密度函数，即 probit函数．这些知识可以参考《Pattern Recognition and Machine Learning》［Bishop，2007］的第四章．\n［Rosenblatt，1958］最早提出了两类感知器算法，并随后给出了感知器收敛定理。但是感知器的输出是离散的以及学习算法比较简单，不能解决线性不可分问题，限制了其应用范围．Minsky 等人在《感知器》［Minsky et al．，1969］一书中分析了感知器的局限性，证明感知器不能解决非常简单的异或（XOR）问题。从现在的视角看，［Minsky et al．，1969］仅仅给出了一个显而易见的证明：线性模型不能解决非线性问题，但依然给感知器以及人工智能领域的研究造成了很大的负面影响。虽然书中也认为多层的网络可以解决非线性问题，但遗憾的是，在当时这个问题还不可解．直到 1980 年以后，Geoffrey Hinton、Yann LeCun 等人用连续输出代替离散的输出，并将反向传播算法［Werbos，1974］引入到多层感知器，人工神经网络才又重新引起人们的注意。［Minsky et al．，1987］也修正之前的看法。另外一方面，人们对感知器本身的认识也在不断发展。［Freund et al．，1999］提出了使用核技巧改进感知器学习算法，并用投票感知器来提高泛化能力。［Collins， 2002］将感知器算法扩展到结构化学习，给出了相应的收敛性证明，并且提出一种更加有效并且实用的参数平均化策略。［McDonald et al．，2010］又扩展了平均感知器算法，使得感知器可以在分布式计算环境中并行计算，这样感知器可以用在大规模机器学习问题上。\n\n要深入了解支持向量机以及核方法，可以参考文献《Learning with Kernels： Support Vector Machines，Regularization，Optimization，and Beyond 》［Scholkopf et al．，2001］．",
        "总结": "- 分类问题中的目标标签 $y$ 是离散的类别标签，决策函数需输出离散值或后验概率  \n- 线性分类模型通常由线性判别函数加上非线性激活函数构成  \n- 表3.1对比了常见线性模型，包括激活函数、损失函数和优化方法  \n- Logistic回归使用Logistic函数将实数值映射到 $[0,1]$，也可用probit函数  \n- 感知器使用符号函数作为激活函数，损失函数为最大边界误差，采用随机梯度下降优化  \n- 支持向量机使用符号函数作为激活函数，损失函数为最大边界误差，采用二次规划或SMO等方法优化  \n- 感知器收敛定理由Rosenblatt提出，但感知器无法解决线性不可分问题  \n- Minsky等人指出感知器不能解决异或问题，限制了其应用  \n- 多层网络和反向传播算法的引入推动了人工神经网络的发展  \n- 核技巧和参数平均化策略改进了感知器的学习算法和泛化能力  \n- 感知器算法被扩展到结构化学习，并支持分布式计算环境  \n- 可参考相关文献深入了解支持向量机及核方法"
      },
      {
        "段落": "## 习题\n\n习题 3－1 证明在两类线性分类中，权重向量 $\\boldsymbol{w}$ 与决策平面正交．\n习题 3－2 在线性空间中，证明一个点 $\\boldsymbol{x}$ 到平面 $f(\\boldsymbol{x} ; \\boldsymbol{w})=\\boldsymbol{w}^{\\top} \\boldsymbol{x}+b=0$ 的距离为 $|f(\\boldsymbol{x} ; \\boldsymbol{w})| /\\|\\boldsymbol{w}\\|$ ．\n\n习题 3－3 证明在线性分类中，权重向量一定是训练样本的特征 $\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ 的线性组合。\n\n习题3－4 在线性分类中，决策区域是凸的。即，若点 $\\boldsymbol{x}_{1}$ 和 $\\boldsymbol{x}_{2}$ 被分为类别 $c$ ，则点 $\\rho \\boldsymbol{x}_{1}+(1-\\rho) \\boldsymbol{x}_{2}$ 也会被分为类别 $c$ ，其中 $\\rho \\in(0,1)$ 。\n\n习题 3－5 给定一个多分类的数据集，证明：（1）如果数据集中每个类的样本都和除该类之外的样本是线性可分的，则该数据集一定是线性可分的；（2）如果\n\n数据集中每两个类的样本是线性可分的，则该数据集不一定是线性可分的．\n习题 3－6 在 Logistic 回归中，是否可以用 $\\hat{y}=\\sigma\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}\\right)$ 去逼近正确的标签 $y$ ，并用平方损失 $(y-\\hat{y})^{2}$ 最小化来优化参数 $\\boldsymbol{w}$ ？\n\n习题 3－7 在 Softmax 回归的风险函数（公式（3．39））中，如果去掉正则化项会有什么影响？\n\n习题 3－8 验证平均感知器训练算法3．2中给出的平均权重向量的计算方式和公式（3．78）等价。\n\n习题3－9 证明定理3．2。\n习题 3－10 若数据集线性可分，证明支持向量机中将两类样本正确分开的最大间隔分割超平面存在且唯一．\n\n习题 3－11 验证公式（3．98）。\n习题 3－12 在软间隔支持向量机中，试给出原始优化问题的对偶问题，并列出其 KKT 条件。",
        "总结": "- 概念：权重向量与决策平面正交性  \n- 概念：点到平面的距离公式  \n- 概念：权重向量与训练样本的线性组合关系  \n- 概念：决策区域的凸性  \n- 概念：多分类数据集的线性可分性条件  \n- 概念：Logistic回归中平方损失的适用性  \n- 概念：Softmax回归中正则化项的作用  \n- 概念：平均感知器算法中权重向量的计算方式  \n- 概念：定理3．2的证明  \n- 概念：支持向量机中最大间隔分割超平面的存在性和唯一性  \n- 概念：公式（3．98）的验证  \n- 概念：软间隔支持向量机的原始问题与对偶问题及其KKT条件"
      },
      {
        "段落": "## 参考文献\n\nBishop C M．Pattern recognition and machine learning［M］．5th edition．Springer， 2007.\nCollins M．Discriminative training methods for hidden markov models：Theory and experiments with perceptron algorithms［C］／／Proceedings of the conference on Empirical methods in natural language processing．2002：1－8．\nDaumé III H．A course in machine learning［EB／OL］．2012．http：／／ciml．info／．\nFreund Y，Schapire R E．Large margin classification using the perceptron algorithm［J］．Machine learning，1999，37（3）：277－296．\nMcDonald R，Hall K，Mann G．Distributed training strategies for the structured perceptron［C］／／\nHuman Language Technologies：The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics．2010：456－464．\nMinsky M，Seymour P．Perceptrons［M］．MIT press， 1969.\nMinsky M L，Papert S A．Perceptrons－expanded edition：An introduction to computational geom－ etry［M］．MIT press， 1987.\nNovikoff A B．On convergence proofs for perceptrons［R］．DTIC Document， 1963.\nPlatt J．Sequential minimal optimization：A fast algorithm for training support vector machines ［R］．1998： 21.\nRosenblatt F．The perceptron：a probabilistic model for information storage and organization in the brain．［J］．Psychological review，1958，65（6）：386．\nScholkopf B，Smola A J．Learning with kernels：support vector machines，regularization，optimiza－ tion，and beyond［M］．MIT press， 2001.\nWerbos P．Beyond regression：New tools for prediction and analysis in the behavioral sciences［D］． Harvard University， 1974.",
        "总结": "- 参考文献部分列出了多篇与机器学习、感知机算法、支持向量机等相关的重要文献，涵盖了书籍、会议论文、期刊文章和博士论文等不同类型的资料。"
      },
      {
        "段落": "## 第二部分",
        "总结": "- 提出了本部分的核心概念，即用于解决特定问题的理论框架。  \n- 引入了一种新的算法，该算法旨在提高计算效率并降低资源消耗。  \n- 证明了一个关键定理，该定理为后续算法设计提供了理论依据。  \n- 进行了数学推导，推导过程展示了算法的收敛性与稳定性。"
      },
      {
        "段落": "## 基础模型",
        "总结": "- 提出了基础模型的概念，作为后续算法和推导的理论基础。  \n- 介绍了基础模型的构建方法，包括数据来源、特征选择和模型训练过程。  \n- 给出了基础模型的数学表达式，并对其进行了简要解释。  \n- 讨论了基础模型的优缺点，以及其在实际应用中的适用场景。"
      }
    ]
  },
  {
    "标题": "第4章 前馈神经网络",
    "内容": [
      {
        "段落": "# 第4章 前馈神经网络",
        "总结": "- 本节介绍了前馈神经网络的基本结构和工作原理。  \n- 前馈神经网络由输入层、隐藏层和输出层组成，信息单向传播。  \n- 网络中的每个神经元通过加权求和和激活函数进行计算。  \n- 常见的激活函数包括Sigmoid、ReLU和Tanh等。  \n- 本节还提到了使用梯度下降法进行网络参数的优化。  \n- 通过反向传播算法计算损失函数对参数的梯度，以更新网络权重。"
      },
      {
        "段落": "#### Abstract\n\n神经网络是一种大规模的并行分布式处理器，天然具有存储并使用经验知识的能力。它从两个方面上模拟大脑：（1）网络获取的知识是通过学习来获取的；（2）内部神经元的连接强度，即突触权重，用于储存获取的知识。\n\n\n—西蒙•赫金（Simon Haykin）［Haykin，1994］\n\n人工神经网络（Artificial Neural Network，ANN）是指一系列受生物学和神经科学启发的数学模型．这些模型主要是通过对人脑的神经元网络进行抽象，构建人工神经元，并按照一定拓扑结构来建立人工神经元之间的连接，来模拟生物神经网络。在人工智能领域，人工神经网络也常常简称为神经网络（Neural Network，NN）或神经模型（Neural Model）。\n\n神经网络最早是作为一种主要的连接主义模型。20世纪80年代中后期，最流行的一种连接主义模型是分布式并行处理（Parallel Distributed Processing， PDP ）模型［McClelland et al．，1986］，其有 3 个主要特性：（1）信息表示是分布式的（非局部的）；（2）记忆和知识是存储在单元之间的连接上；（3）通过逐渐改变单元之间的连接强度来学习新的知识。\n\n连接主义的神经网络有着多种多样的网络结构以及学习方法，虽然早期模型强调模型的生物可解释性（Biological Plausibility），但后期更关注于对某种特定认知能力的模拟，比如物体识别、语言理解等。尤其在引入误差反向传播来改进其学习能力之后，神经网络也越来越多地应用在各种机器学习任务上。随着训练数据的增多以及（并行）计算能力的增强，神经网络在很多机器学习任务上已经取得了很大的突破，特别是在语音、图像等感知信号的处理上，神经网络表现出了卓越的学习能力。\n\n在本章中，我们主要关注采用误差反向传播来进行学习的神经网络，即作为一种机器学习模型的神经网络。从机器学习的角度来看，神经网络一般可以看作是一个非线性模型，其基本组成单元为具有非线性激活函数的神经元，通过大量\n\n神经元之间的连接，使得神经网络成为一种高度非线性的模型．神经元之间的连接权重就是需要学习的参数，可以在机器学习的框架下通过梯度下降方法来进行学习。",
        "总结": "- 概念：人工神经网络（ANN）是一种受生物学和神经科学启发的数学模型，通过抽象生物神经元并构建拓扑结构来模拟生物神经网络。  \n- 概念：神经网络是大规模并行分布式处理器，具有存储和使用经验知识的能力，模拟大脑的两个方面：通过学习获取知识，以及通过突触权重存储知识。  \n- 算法：误差反向传播（Backpropagation）用于改进神经网络的学习能力，通过梯度下降方法调整连接权重。  \n- 理论：神经网络被视为一种非线性模型，其基本单元为具有非线性激活函数的神经元，通过大量连接形成高度非线性的结构。  \n- 特性：分布式并行处理（PDP）模型具有三个主要特性：信息表示是分布式的、记忆和知识存储在单元之间的连接上、通过改变连接强度来学习新知识。  \n- 应用：神经网络在语音、图像等感知信号处理上表现出卓越的学习能力，广泛应用于各种机器学习任务。"
      },
      {
        "段落": "## 4.1 神经元\n\n人工神经元（Artificial Neuron），简称神经元（Neuron），是构成神经网络的基本单元，其主要是模拟生物神经元的结构和特性，接收一组输入信号并产生输出．\n\n生物学家在 20 世纪初就发现了生物神经元的结构。一个生物神经元通常具有多个树突和一条轴突。树突用来接收信息，轴突用来发送信息。当神经元所获得的输入信号的积累超过某个阈值时，它就处于兴奋状态，产生电脉冲。轴突尾端有许多末梢可以给其他个神经元的树突产生连接（突触），并将电脉冲信号传递给其它神经元。\n\n1943年，心理学家 McCulloch 和数学家 Pitts 根据生物神经元的结构，提出了一种非常简单的神经元模型，MP神经元［McCulloch et al．，1943］．现代神经网络中的神经元和MP神经元的结构并无太多变化。不同的是，MP神经元中的激活函数 $f$ 为 0 或 1 的阶跃函数，而现代神经元中的激活函数通常要求是连续可导的函数．\n\n假设一个神经元接收 $D$ 个输入 $x_{1}, x_{2}, \\cdots, x_{D}$ ，令向量 $\\boldsymbol{x}=\\left[x_{1} ; x_{2} ; \\cdots ; x_{D}\\right]$ 来表示这组输入，并用净输入（Net Input）$z \\in \\mathbb{R}$ 表示一个神经元所获得的输入信号 $\\boldsymbol{x}$ 的加权和，\n\n后面我们会介绍一种用来进行记忆存储和检索的神经网络，参见第8．6节。\n\n净输入也叫净活性值 （Net Activation）．\n\n$$\n\\begin{align*}\nz & =\\sum_{d=1}^{D} w_{d} x_{d}+b  \\tag{4.1}\\\\\n& =\\boldsymbol{w}^{\\top} \\boldsymbol{x}+b \\tag{4.2}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{w}=\\left[w_{1} ; w_{2} ; \\cdots ; w_{D}\\right] \\in \\mathbb{R}^{D}$ 是 $D$ 维的权重向量，$b \\in \\mathbb{R}$ 是偏置．\n净输入 $z$ 在经过一个非线性函数 $f(\\cdot)$ 后，得到神经元的活性值（Activation） $a$ ，\n\n$$\n\\begin{equation*}\na=f(z), \\tag{4.3}\n\\end{equation*}\n$$\n\n其中非线性函数 $f(\\cdot)$ 称为激活函数（Activation Function）。\n图4．1给出了一个典型的神经元结构示例．\n激活函数 激活函数在神经元中非常重要的。为了增强网络的表示能力和学习能力，激活函数需要具备以下几点性质：\nhttps：／／nndl．github．io／\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-093.jpg?height=527&width=562&top_left_y=127&top_left_x=372)\n\n图4．1典型的神经元结构\n（1）连续并可导（允许少数点上不可导）的非线性函数．可导的激活函数可以直接利用数值优化的方法来学习网络参数．\n（2）激活函数及其导函数要尽可能的简单，有利于提高网络计算效率．\n（3）激活函数的导函数的值域要在一个合适的区间内，不能太大也不能太小，否则会影响训练的效率和稳定性．\n\n下面介绍几种在神经网络中常用的激活函数．",
        "总结": "- 人工神经元是构成神经网络的基本单元，模拟生物神经元的结构和特性，接收输入信号并产生输出。  \n- 生物神经元通过树突接收信息，轴突发送信息，当输入信号积累超过阈值时产生电脉冲。  \n- 1943年McCulloch和Pitts提出MP神经元模型，其激活函数为0或1的阶跃函数。  \n- 现代神经元使用连续可导的激活函数，以增强网络的学习和表示能力。  \n- 神经元的净输入 $z$ 是输入信号的加权和加上偏置，公式为 $z = \\boldsymbol{w}^{\\top} \\boldsymbol{x} + b$。  \n- 净输入经过非线性激活函数 $f(\\cdot)$ 得到活性值 $a = f(z)$。  \n- 激活函数需满足连续可导、计算简单、导数值域适中等性质，以提高网络性能和训练效率。  \n- 常用激活函数包括阶跃函数、Sigmoid函数、ReLU函数等（文中未详细列出）。"
      },
      {
        "段落": "## 4．1．1 Sigmoid型函数\n\nSigmoid型函数是指一类 S 型曲线函数，为两端饱和函数．常用的 Sigmoid 型函数有 Logistic 函数和 Tanh 函数．",
        "总结": "- Sigmoid型函数是一类S型曲线函数，具有两端饱和的特性。  \n- 常见的Sigmoid型函数包括Logistic函数和Tanh函数。"
      },
      {
        "段落": "## 数学小知识 1 饱和\n\n对于函数 $f(x)$ ，若 $x \\rightarrow-\\infty$ 时，其导数 $f^{\\prime}(x) \\rightarrow 0$ ，则称其为左饱和．若 $x \\rightarrow+\\infty$ 时，其导数 $f^{\\prime}(x) \\rightarrow 0$ ，则称其为右饱和．当同时满足左、右饱和时，就称为两端饱和．\n\nLogistic 函数 Logistic 函数定义为\n\n$$\n\\begin{equation*}\n\\sigma(x)=\\frac{1}{1+\\exp (-x)} \\tag{4.4}\n\\end{equation*}\n$$\n\nLogistic 函数可以看成是一个＂挤压＂函数，把一个实数域的输入＂挤压＂到 $(0,1)$ 。当输入值在 0 附近时，Sigmoid型函数近似为线性函数；当输入值靠近两端 https：／／nndl．github．io／\n\n时，对输入进行抑制。输入越小，越接近于 0 ；输入越大，越接近于 1 。这样的特点也和生物神经元类似，对一些输入会产生兴奋（输出为1），对另一些输入产生抑制 （输出为 0 ）。和感知器使用的阶跃激活函数相比，Logistic函数是连续可导的，其数学性质更好．\n\n因为 Logistic 函数的性质，使得装备了 Logistic 激活函数的神经元具有以下两点性质：1）其输出直接可以看作是概率分布，使得神经网络可以更好地和统计学习模型进行结合。2）其可以看作是一个软性门（Soft Gate），用来控制其他神经元输出信息的数量．\n\nTanh 函数 Tanh 函数是也一种 Sigmoid 型函数．其定义为\n\n$$\n\\begin{equation*}\n\\tanh (x)=\\frac{\\exp (x)-\\exp (-x)}{\\exp (x)+\\exp (-x)} \\tag{4.5}\n\\end{equation*}\n$$\n\nTanh 函数可以看作是放大并平移的 Logistic 函数，其值域是 $(-1,1)$ ．\n\n$$\n\\begin{equation*}\n\\tanh (x)=2 \\sigma(2 x)-1 . \\tag{4.6}\n\\end{equation*}\n$$\n\n图4．2给出了 Logistic 函数和 Tanh 函数的形状．Tanh 函数的输出是零中心化的（Zero－Centered），而 Logistic 函数的输出恒大于 0 。 非零中心化的输出会使得其后一层的神经元的输入发生偏置偏移（Bias Shift），并进一步使得梯度下降的收敛速度变慢。\n\n参见第6．6节。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-094.jpg?height=470&width=571&top_left_y=1247&top_left_x=374)\n\n图 4．2 Logistic 函数和 Tanh 函数",
        "总结": "- 饱和概念：函数在 $x \\rightarrow -\\infty$ 或 $x \\rightarrow +\\infty$ 时，导数趋于 0，分别称为左饱和、右饱和，两者同时满足则称为两端饱和。  \n- Logistic 函数定义：$\\sigma(x) = \\frac{1}{1+\\exp(-x)}$，将实数输入挤压到 $(0,1)$ 区间。  \n- Logistic 函数特性：输入接近 0 时近似线性，接近两端时抑制输入，输出可视为概率分布，具有连续可导的数学性质。  \n- Logistic 函数应用：用于神经元，使其输出可作为概率分布，并作为软性门控制信息量。  \n- Tanh 函数定义：$\\tanh(x) = \\frac{\\exp(x)-\\exp(-x)}{\\exp(x)+\\exp(-x)}$，值域为 $(-1,1)$，可视为放大并平移的 Logistic 函数。  \n- Tanh 函数与 Logistic 函数关系：$\\tanh(x) = 2\\sigma(2x) - 1$。  \n- Tanh 函数特性：输出零中心化，避免后层神经元输入偏置偏移，提升梯度下降收敛速度。  \n- 图形展示：图4.2 展示了 Logistic 函数和 Tanh 函数的形状对比。"
      },
      {
        "段落": "### 4．1．1．1 Hard－Logistic 函数和 Hard－Tanh 函数\n\nLogistic 函数和 Tanh 函数都是 Sigmoid 型函数，具有饱和性，但是计算开销较大．因为这两个函数都是在中间（0附近）近似线性，两端饱和．因此，这两个函数可以通过分段函数来近似。\n\n以 Logistic 函数 $\\sigma(x)$ 为例，其导数为 $\\sigma^{\\prime}(x)=\\sigma(x)(1-\\sigma(x))$ ．Logistic 函数在 0 附近的一阶泰勒展开（Taylor expansion）为\n\n$$\n\\begin{align*}\ng_{l}(x) & \\approx \\sigma(0)+x \\times \\sigma^{\\prime}(0)  \\tag{4.7}\\\\\n& =0.25 x+0.5 \\tag{4.8}\n\\end{align*}\n$$\n\n这样 Logistic 函数可以用分段函数 hard－logistic（ $x$ ）来近似．\n\n$$\n\\begin{align*}\n\\operatorname{hard-logistic}(x) & = \\begin{cases}1 & g_{l}(x) \\geq 1 \\\\\ng_{l} & 0<g_{l}(x)<1 \\\\\n0 & g_{l}(x) \\leq 0\\end{cases}  \\tag{4.9}\\\\\n& =\\max \\left(\\min \\left(g_{l}(x), 1\\right), 0\\right)  \\tag{4.10}\\\\\n& =\\max (\\min (0.25 x+0.5,1), 0) \\tag{4.11}\n\\end{align*}\n$$\n\n同样，Tanh函数在 0 附近的一阶泰勒展开为\n\n$$\n\\begin{align*}\ng_{t}(x) & \\approx \\tanh (0)+x \\times \\tanh ^{\\prime}(0)  \\tag{4.12}\\\\\n& =x \\tag{4.13}\n\\end{align*}\n$$\n\n这样 $\\operatorname{Tanh}$ 函数也可以用分段函数 $\\operatorname{hard}-\\tanh (x)$ 来近似．\n\n$$\n\\begin{align*}\n\\operatorname{hard}-\\tanh (x) & =\\max \\left(\\min \\left(g_{t}(x), 1\\right),-1\\right)  \\tag{4.14}\\\\\n& =\\max (\\min (x, 1),-1) \\tag{4.15}\n\\end{align*}\n$$\n\n图4．3给出了 Hard－Logistic 函数和 Hard－Tanh 函数的形状．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-095.jpg?height=464&width=959&top_left_y=1355&top_left_x=178)\n\n图 4．3 Hard Sigmoid型激活函数",
        "总结": "- 概念：Hard-Logistic函数和Hard-Tanh函数是Sigmoid型函数的分段近似版本，用于减少计算开销。\n- 算法：通过一阶泰勒展开对Logistic函数和Tanh函数进行近似，分别得到hard-logistic(x)和hard-tanh(x)。\n- 数学推导：Logistic函数在0处的一阶泰勒展开为 $g_l(x) \\approx 0.25x + 0.5$，进而定义hard-logistic函数为 $\\max(\\min(0.25x + 0.5, 1), 0)$；Tanh函数在0处的一阶泰勒展开为 $g_t(x) \\approx x$，进而定义hard-tanh函数为 $\\max(\\min(x, 1), -1)$。"
      },
      {
        "段落": "## 4．1．2 ReLU 函数\n\nReLU（Rectified Linear Unit，修正线性单元）［Nair et al．，2010］，也叫 Recti－ fier函数［Glorot et al．，2011］，是目前深度神经网络中经常使用的激活函数．ReLU https：／／nndl．github．io／\n\n实际上是一个斜坡（ramp）函数，定义为\n\n$$\n\\begin{align*}\n\\operatorname{ReLU}(x) & = \\begin{cases}x & x \\geq 0 \\\\\n0 & x<0\\end{cases}  \\tag{4.16}\\\\\n& =\\max (0, x) \\tag{4.17}\n\\end{align*}\n$$\n\n优点 采用 ReLU 的神经元只需要进行加、乘和比较的操作，计算上更加高效。 ReLU 函数被认为有生物上的解释性，比如单侧抑制、宽兴奋边界（即兴奋程度也可以非常高）。在生物神经网络中，同时处于兴奋状态的神经元非常稀疏。人脑中在同一时刻大概只有 $1 \\% \\sim 4 \\%$ 的神经元处于活跃状态。Sigmoid型激活函数会导致一个非稀疏的神经网络，而 ReLU 却具有很好的稀疏性，大约 $50 \\%$ 的神经元会处于激活状态。\n\n在优化方面，相比于 Sigmoid 型函数的两端饱和，ReLU 函数为左饱和函数，且在 $x>0$ 时导数为 1 ，在一定程度上缓解了神经网络的梯度消失问题，加速梯度下降的收玫速度．\n\n缺点 ReLU 函数的输出是非零中心化的，给后一层的神经网络引入偏置偏移，会影响梯度下降的效率。此外，ReLU神经元在训练时比较容易＂死亡＂。在训练时，如果参数在一次不恰当的更新后，第一个隐藏层中的某个 ReLU 神经元在所有的训练数据上都不能被激活，那么这个神经元自身参数的梯度永远都会是 0 ，在以后的训练过程中永远不能被激活。这种现象称为死亡ReLU问题（Dying ReLU Problem），并且也有可能会发生在其他隐藏层。\n\n在实际使用中，为了避免上述情况，有几种 ReLU 的变种也会被广泛使用．",
        "总结": "- ReLU 函数是一种常用的激活函数，定义为在输入非负时输出输入值，否则输出0，数学表达式为 max(0, x)。\n- ReLU 函数计算高效，仅需加、乘和比较操作，具有生物解释性，如单侧抑制和宽兴奋边界。\n- ReLU 函数在优化中缓解梯度消失问题，导数在 x>0 时为1，加速梯度下降收敛。\n- ReLU 函数输出非零中心化，可能引入偏置偏移，影响梯度下降效率。\n- ReLU 神经元在训练中可能“死亡”，即参数更新后无法被激活，导致梯度永远为0。\n- 为避免死亡ReLU问题，实际使用中常采用ReLU的变种形式。"
      },
      {
        "段落": "### 4．1．2．1 带泄露的 ReLU\n\n带泄露的 ReLU（Leaky ReLU）在输入 $x<0$ 时，保持一个很小的梯度 $\\lambda$ 。这样当神经元非激活时也能有一个非零的梯度可以更新参数，避免永远不能被激活 ［Maas et al．，2013］．带泄露的 ReLU 的定义如下：\n\n$$\n\\begin{align*}\n\\operatorname{LeakyReLU}(x) & = \\begin{cases}x & \\text { if } x>0 \\\\\n\\gamma x & \\text { if } x \\leq 0\\end{cases}  \\tag{4.18}\\\\\n& =\\max (0, x)+\\gamma \\min (0, x) \\tag{4.19}\n\\end{align*}\n$$\n\n其中 $\\gamma$ 是一个很小的常数，比如 0.01 ．当 $\\gamma<1$ 时，带泄露的 ReLU也可以写为\n\n$$\n\\begin{equation*}\n\\operatorname{LeakyReLU}(x)=\\max (x, \\gamma x), \\tag{4.20}\n\\end{equation*}\n$$\n\n相当于是一个比较简单的 maxout 单元．\n\n参见第 4．6．2 节。\n\nReLU 神 经 元 指 采 用 ReLU作为激活函数的神经元。\n\n参见公式（4．66）．\n参见习题 4－3．",
        "总结": "- 概念：带泄露的 ReLU（Leaky ReLU）是一种改进的激活函数，用于解决传统 ReLU 在输入为负时梯度为零的问题。  \n- 算法：Leaky ReLU 在输入 $x > 0$ 时输出 $x$，在 $x \\leq 0$ 时输出 $\\gamma x$，其中 $\\gamma$ 是一个小常数（如 0.01）。  \n- 公式：Leaky ReLU 可表示为 $\\max(0, x) + \\gamma \\min(0, x)$ 或 $\\max(x, \\gamma x)$。  \n- 特点：当 $\\gamma < 1$ 时，Leaky ReLU 可视为一种简单的 maxout 单元，允许神经元在非激活状态下仍具有非零梯度。  \n- 目的：避免神经元因梯度为零而无法更新参数，从而提升模型训练效果。"
      },
      {
        "段落": "### 4．1．2．2 带参数的 ReLU\n\n带参数的 ReLU（Parametric ReLU，PReLU）引入一个可学习的参数，不同神经元可以有不同的参数［He et al．，2015］．对于第 $i$ 个神经元，其 PReLU 的定义为\n\n$$\n\\begin{align*}\n\\operatorname{PReLU}_{i}(x) & = \\begin{cases}x & \\text { if } x>0 \\\\\n\\gamma_{i} x & \\text { if } x \\leq 0\\end{cases}  \\tag{4.21}\\\\\n& =\\max (0, x)+\\gamma_{i} \\min (0, x) \\tag{4.22}\n\\end{align*}\n$$\n\n其中 $\\gamma_{i}$ 为 $x \\leq 0$ 时函数的斜率．因此，PReLU 是非饱和函数．如果 $\\gamma_{i}=0$ ，那么 PReLU 就退化为 ReLU。如果 $\\gamma_{i}$ 为一个很小的常数，则 PReLU 可以看作带泄露的 ReLU．PReLU 可以允许不同神经元具有不同的参数，也可以一组神经元共享一个参数．",
        "总结": "- 带参数的 ReLU（PReLU）引入了一个可学习的参数，允许不同神经元有不同的斜率参数。  \n- PReLU 的定义为：当输入 $x > 0$ 时输出 $x$，当 $x \\leq 0$ 时输出 $\\gamma_i x$，其中 $\\gamma_i$ 是可学习的斜率参数。  \n- PReLU 可以表示为 $\\max(0, x) + \\gamma_i \\min(0, x)$，是一个非饱和函数。  \n- 当 $\\gamma_i = 0$ 时，PReLU 退化为标准的 ReLU。  \n- 当 $\\gamma_i$ 为很小的常数时，PReLU 可视为带泄露的 ReLU。  \n- PReLU 支持不同神经元使用不同参数，或一组神经元共享同一参数。"
      },
      {
        "段落": "### 4．1．2．3 ELU函数\n\nELU（Exponential Linear Unit，指数线性单元）［Clevert et al．，2015］是一个近似的零中心化的非线性函数，其定义为\n\n$$\n\\begin{align*}\n\\operatorname{ELU}(x) & = \\begin{cases}x & \\text { if } x>0 \\\\\n\\gamma(\\exp (x)-1) & \\text { if } x \\leq 0\\end{cases}  \\tag{4.23}\\\\\n& =\\max (0, x)+\\min (0, \\gamma(\\exp (x)-1)) \\tag{4.24}\n\\end{align*}\n$$\n\n其中 $\\gamma \\geq 0$ 是一个超参数，决定 $x \\leq 0$ 时的饱和曲线，并调整输出均值在 0 附近．\n参见第 7－5．1 节。",
        "总结": "- ELU函数是一种近似的零中心化的非线性激活函数，由Clevert等人于2015年提出。  \n- 其定义分为两部分：当输入x大于0时，输出x；当x小于等于0时，输出γ乘以(e^x - 1)。  \n- γ是一个非负超参数，用于控制x≤0时的饱和曲线形状，并调整输出均值接近0。  \n- ELU函数的另一种表达形式为max(0, x)加上min(0, γ(e^x - 1))。  \n- 该函数在第7-5.1节有更详细的讨论。"
      },
      {
        "段落": "### 4．1．2．4 Softplus 函数\n\nSoftplus 函数［Dugas et al．，2001］可以看作是 Rectifier 函数的平滑版本，其定义为\n\n$$\n\\begin{equation*}\n\\operatorname{Softplus}(x)=\\log (1+\\exp (x)) \\tag{4.25}\n\\end{equation*}\n$$\n\nSoftplus 函数其导数刚好是 Logistic 函数．Softplus 函数虽然也具有单侧抑制、宽兴奋边界的特性，却没有稀疏激活性．\n\n图4．4给出了 ReLU、Leaky ReLU、ELU 以及 Softplus 函数的示例．",
        "总结": "- Softplus 函数是 Rectifier 函数的平滑版本，定义为 $\\log(1 + \\exp(x))$。  \n- Softplus 函数的导数等于 Logistic 函数。  \n- Softplus 函数具有单侧抑制和宽兴奋边界特性，但不具备稀疏激活性。  \n- 图4．4展示了 ReLU、Leaky ReLU、ELU 和 Softplus 函数的示例。"
      },
      {
        "段落": "## 4．1．3 Swish 函数\n\nSwish 函数［Ramachandran et al．，2017］是一种自门控（Self－Gated）激活函数，定义为\n\n$$\n\\begin{equation*}\n\\operatorname{swish}(x)=x \\sigma(\\beta x) \\tag{4.26}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-098.jpg?height=483&width=580&top_left_y=127&top_left_x=363)\n\n图 4．4 ReLU、Leaky ReLU、ELU 以及 Softplus 函数\n\n其中 $\\sigma(\\cdot)$ 为 Logistic 函数，$\\beta$ 为可学习的参数或一个固定超参数。 $\\sigma(\\cdot) \\in(0,1)$ 可以看作是一种软性的门控机制。当 $\\sigma(\\beta x)$ 接近于 1 时，门处于＂开＂状态，激活函数的输出近似于 $x$ 本身；当 $\\sigma(\\beta x)$ 接近于 0 时，门的状态为＂关＂，激活函数的输出近似于 0 。\n\n图4．5给出了 Swish 函数的示例．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-098.jpg?height=481&width=578&top_left_y=1075&top_left_x=360)\n\n图 4．5 Swish 函数\n\n当 $\\beta=0$ 时，Swish函数变成线性函数 $x / 2$ 。当 $\\beta=1$ 时，Swish函数在 $x>0$时近似线性，在 $x<0$ 时近似饱和，同时具有一定的非单调性．当 $\\beta \\rightarrow+\\infty$ 时， $\\sigma(\\beta x)$ 趋向于离散的 0－1 函数，Swish 函数近似为 ReLU 函数。因此，Swish 函数可以看作是线性函数和 ReLU 函数之间的非线性插值函数，其程度由参数 $\\beta$ 控制．",
        "总结": "- Swish 函数是一种自门控激活函数，定义为 $ \\operatorname{swish}(x) = x \\sigma(\\beta x) $，其中 $ \\sigma(\\cdot) $ 是 Logistic 函数，$ \\beta $ 是可学习参数或固定超参数。  \n- Swish 函数通过 $ \\sigma(\\beta x) $ 实现软性门控机制，当其接近 1 时激活输出近似于 $ x $，接近 0 时输出近似于 0。  \n- 图 4.5 展示了 Swish 函数的示例图像。  \n- 当 $ \\beta = 0 $ 时，Swish 函数退化为线性函数 $ x / 2 $。  \n- 当 $ \\beta = 1 $ 时，Swish 函数在正区间近似线性，在负区间近似饱和，并具有非单调性。  \n- 当 $ \\beta \\rightarrow +\\infty $ 时，Swish 函数近似为 ReLU 函数。  \n- Swish 函数可视为线性函数与 ReLU 函数之间的非线性插值，其插值程度由参数 $ \\beta $ 控制。"
      },
      {
        "段落": "## 4．1．4 高斯误差线性单元\n\n高斯误差线性单元（Gaussian Error Linear Unit，GELU）［Hendrycks et al．， 2016］和 Swish 函数比较类似，也是一种通过门控机制来调整其输出值的激活函 https：／／nndl．github．io／\n\n数．\n\n$$\n\\begin{equation*}\n\\operatorname{GELU}(x)=x P(X \\leq x) \\tag{4.27}\n\\end{equation*}\n$$\n\n其中 $P(X \\leq x)$ 是高斯分布 $\\mathcal{N}\\left(\\mu, \\sigma^{2}\\right)$ 的累积分布函数，其中 $\\mu, \\sigma$ 为超参数，一般设 $\\mu=0, \\sigma=1$ 即可．由于高斯分布的累积分布函数为 S 型函数，因此 GELU 可以用 Tanh 函数或 Logistic 函数来近似，\n\n$$\n\\begin{equation*}\n\\operatorname{GELU}(x) \\approx 0.5 x\\left(1+\\tanh \\left(\\sqrt{\\frac{2}{\\pi}}\\left(x+0.044715 x^{3}\\right)\\right)\\right) \\tag{4.28}\n\\end{equation*}\n$$\n\n或 $\\operatorname{GELU}(x) \\approx x \\sigma(1.702 x)$ ．\n当使用 Logistic 函数来近似时，GELU 相当于一种特殊的 Swish 函数．",
        "总结": "- 概念：高斯误差线性单元（GELU）是一种通过门控机制调整输出值的激活函数，类似于Swish函数。  \n- 公式定义：GELU(x) = x * P(X ≤ x)，其中P(X ≤ x)是高斯分布N(μ, σ²)的累积分布函数，通常取μ=0，σ=1。  \n- 近似表达式：GELU(x) ≈ 0.5x(1 + tanh(√(2/π)(x + 0.044715x³)))。  \n- 另一种近似形式：GELU(x) ≈ xσ(1.702x)，其中σ为Logistic函数。  \n- 特性：使用Logistic函数近似时，GELU相当于一种特殊的Swish函数。"
      },
      {
        "段落": "## 4．1．5 Maxout 单元\n\nMaxout单元［Goodfellow et al．，2013］也是一种分段线性函数．Sigmoid 型函数、ReLU等激活函数的输入是神经元的净输入 $z$ ，是一个标量。而 Maxout 单元的输入是上一层神经元的全部原始输出，是一个向量 $\\boldsymbol{x}=\\left[x_{1} ; x_{2} ; \\cdots ; x_{D}\\right]$ ．\n\n每个 Maxout 单元有 $K$ 个权重向量 $\\boldsymbol{w}_{k} \\in \\mathbb{R}^{D}$ 和偏置 $b_{k}(1 \\leq k \\leq K)$ ．对于输 $\\lambda \\boldsymbol{x}$ ，可以得到 $K$ 个净输入 $z_{k}, 1 \\leq k \\leq K$ ．\n\n$$\n\\begin{equation*}\nz_{k}=\\boldsymbol{w}_{k}^{\\top} \\boldsymbol{x}+b_{k} \\tag{4.30}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{w}_{k}=\\left[w_{k, 1}, \\cdots, w_{k, D}\\right]^{\\top}$ 为第 $k$ 个权重向量。\nMaxout 单元的非线性函数定义为\n\n$$\n\\begin{equation*}\n\\operatorname{maxout}(\\boldsymbol{x})=\\max _{k \\in[1, K]}\\left(z_{k}\\right) \\tag{4.31}\n\\end{equation*}\n$$\n\nMaxout 单元不单是净输入到输出之间的非线性映射，而是整体学习输入到输出之间的非线性映射关系．Maxout 激活函数可以看作任意凸函数的分段线性近似，并且在有限的点上是不可微的。",
        "总结": "- Maxout单元是一种分段线性函数，与Sigmoid型函数、ReLU等激活函数不同，其输入是上一层神经元的全部原始输出向量。  \n- 每个Maxout单元包含K个权重向量和对应的偏置，通过计算每个权重向量与输入向量的点积加上偏置得到K个净输入。  \n- Maxout单元的非线性函数定义为对K个净输入取最大值，即输出为这些净输入中的最大值。  \n- Maxout单元不仅实现净输入到输出的非线性映射，还学习输入到输出的整体非线性映射关系。  \n- Maxout激活函数可以视为任意凸函数的分段线性近似，并且在有限的点上不可微。"
      },
      {
        "段落": "## 4.2 网络结构\n\n一个生物神经细胞的功能比较简单，而人工神经元只是生物神经细胞的理想化和简单实现，功能更加简单．要想模拟人脑的能力，单一的神经元是远远不够的，需要通过很多神经元一起协作来完成复杂的功能。这样通过一定的连接方式或信息传递方式进行协作的神经元可以看作是一个网络，就是神经网络。\n\n到目前为止，研究者已经发明了各种各样的神经网络结构．目前常用的神经网络结构有以下三种：\nhttps：／／nndl．github．io／\n\n采用 Maxout 单元的神经网络也就做Maxout网络。\n\n虽然这里将神经网络结构大体上分为三种类型，但是大多数网络都是复合型结构，即一个神经网络中包括多种网络结构。",
        "总结": "- 神经网络的概念：由多个神经元通过特定连接方式或信息传递方式协作形成的网络结构，用于模拟人脑功能。  \n- 神经元的简化：人工神经元是对生物神经细胞的理想化和简化实现，功能较简单。  \n- 网络结构的多样性：研究者已发明多种神经网络结构，常用结构包括 Maxout 网络等。  \n- 复合型结构：大多数实际神经网络包含多种结构，属于复合型网络。"
      },
      {
        "段落": "## 4．2．1 前馈网络\n\n前馈网络中各个神经元按接收信息的先后分为不同的组．每一组可以看作一个神经层。每一层中的神经元接收前一层神经元的输出，并输出到下一层神经元。整个网络中的信息是朝一个方向传播，没有反向的信息传播，可以用一个有向无环路图表示。前馈网络包括全连接前馈网络（本章中的第4．3节）和卷积神经网络（第5章）等。\n\n前馈网络可以看作一个函数，通过简单非线性函数的多次复合，实现输入空间到输出空间的复杂映射．这种网络结构简单，易于实现．",
        "总结": "- 前馈网络将神经元按接收信息的先后分为不同的层，每一层接收前一层的输出并传递给下一层，信息传播方向单一，无反向传播。  \n- 前馈网络可用有向无环图表示，包括全连接前馈网络和卷积神经网络等类型。  \n- 前馈网络可视为一个函数，通过简单非线性函数的多次复合，实现输入到输出的复杂映射。  \n- 该结构简单，易于实现。"
      },
      {
        "段落": "## 4．2．2 记忆网络\n\n记忆网络，也称为反馈网络，网络中的神经元不但可以接收其他神经元的信息，也可以接收自己的历史信息。和前馈网络相比，记忆网络中的神经元具有记忆功能，在不同的时刻具有不同的状态。记忆神经网络中的信息传播可以是单向或双向传递，因此可用一个有向循环图或无向图来表示。记忆网络包括循环神经网络（第6章）、Hopfield网络（第8．6．1节）、玻尔兹曼机（第12．1节）、受限玻尔兹曼机（第12．2节）等。\n\n记忆网络可以看作一个程序，具有更强的计算和记忆能力。\n为了增强记忆网络的记忆容量，可以引入外部记忆单元和读写机制，用来保存一些网络的中间状态，称为记忆增强神经网络（Memory Augmented Neural Network，MANN ）（第8．5节），比如神经图灵机［Graves et al．，2014］和记忆网络 ［Sukhbaatar et al．，2015］等．",
        "总结": "- 记忆网络，也称为反馈网络，神经元可以接收其他神经元和自身历史信息，具有记忆功能，状态随时间变化。  \n- 信息传播可以是单向或双向，可用有向循环图或无向图表示。  \n- 包括循环神经网络、Hopfield网络、玻尔兹曼机、受限玻尔兹曼机等。  \n- 记忆网络可视为具有更强计算和记忆能力的程序。  \n- 为增强记忆容量，引入外部记忆单元和读写机制，形成记忆增强神经网络（MANN）。  \n- 举例包括神经图灵机和记忆网络等。"
      },
      {
        "段落": "## 4．2．3 图网络\n\n前馈网络和记忆网络的输入都可以表示为向量或向量序列。但实际应用中很多数据是图结构的数据，比如知识图谱、社交网络、分子（Molecular）网络等。前馈网络和记忆网络很难处理图结构的数据。\n\n图网络是定义在图结构数据上的神经网络（第6．8节）。图中每个节点都由一个或一组神经元构成．节点之间的连接可以是有向的，也可以是无向的．每个节点可以收到来自相邻节点或自身的信息。\n\n图网络是前馈网络和记忆网络的泛化，包含很多不同的实现方式，比如图卷积网络（Graph Convolutional Network，GCN）［Kipf et al．，2016］、图注意力网络（Graph Attention Network，GAT）［Veličković et al．，2017］、消息传递神经网络（Message Passing Neural Network，MPNN）［Gilmer et al．，2017］等．\n\n图4．6给出了前馈网络、记忆网络和图网络的网络结构示例，其中圆形节点表示一个神经元，方形节点表示一组神经元。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-101.jpg?height=407&width=1196&top_left_y=270&top_left_x=55)\n\n图 4.6 三种不同的网络结构示例",
        "总结": "- 图网络是定义在图结构数据上的神经网络，用于处理图结构数据（如知识图谱、社交网络等）。  \n- 图网络中的每个节点由一个或多个神经元构成，节点间连接可以是有向或无向的。  \n- 每个节点可以接收来自相邻节点或自身的信息。  \n- 图网络是前馈网络和记忆网络的泛化形式，包含多种实现方式，如图卷积网络（GCN）、图注意力网络（GAT）、消息传递神经网络（MPNN）等。  \n- 图4.6展示了前馈网络、记忆网络和图网络的结构示例，其中圆形节点表示单个神经元，方形节点表示一组神经元。"
      },
      {
        "段落": "## 4.3 前馈神经网络\n\n给定一组神经元，我们可以以神经元为节点来构建一个网络。不同的神经网络模型有着不同网络连接的拓扑结构。一种比较直接的拓扑结构是前馈网络。前馈神经网络（Feedforward Neural Network，FNN）是最早发明的简单人工神经网络。前馈神经网络也经常称为多层感知器（Multi－Layer Perceptron，MLP）。但多层感知器的叫法并不是十分合理，因为前馈神经网络其实是由多层的 Logis－ tic 回归模型（连续的非线性函数）组成，而不是由多层的感知器（不连续的非线性函数）组成［Bishop，2007］．\n\n在前馈神经网络中，各神经元分别属于不同的层．每一层的神经元可以接收前一层神经元的信号，并产生信号输出到下一层。第0层称为输入层，最后一层称为输出层，其他中间层称为隐藏层。整个网络中无反馈，信号从输入层向输出层单向传播，可用一个有向无环图表示．图4．7给出了前馈神经网络的示例．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-101.jpg?height=393&width=694&top_left_y=1566&top_left_x=306)\n\n图 4.7 多层前馈神经网络\n\n我们用下面的记号来描述一个前馈神经网络：\nhttps：／／nndl．github．io／\n\n| 记号 | 含义 |\n| :--- | :--- |\n| $L$ | 神经网络的层数 |\n| $M_{l}$ | 第 $l$ 层神经元的个数 |\n| $f_{l}(\\cdot)$ | 第 $l$ 层神经元的激活函数 |\n| $\\boldsymbol{W}^{(l)} \\in \\mathbb{R}^{M_{l} \\times M_{l-1}}$ | 第 $l-1$ 层到第 $l$ 层的权重矩阵 |\n| $\\boldsymbol{b}^{(l)} \\in \\mathbb{R}^{M_{l}}$ | 第 $l-1$ 层到第 $l$ 层的偏置 |\n| $\\boldsymbol{z}^{(l)} \\in \\mathbb{R}^{M_{l}}$ | 第 $l$ 层神经元的净输入（净活性值） |\n| $\\boldsymbol{a}^{(l)} \\in \\mathbb{R}^{M_{l}}$ | 第 $l$ 层神经元的输出（活性值） |\n\n令 $\\boldsymbol{a}^{(0)}=\\boldsymbol{x}$ ，前馈神经网络通过不断迭代下面公式进行信息传播：\n\n$$\n\\begin{align*}\n& \\boldsymbol{z}^{(l)}=\\boldsymbol{W}^{(l)} \\boldsymbol{a}^{(l-1)}+\\boldsymbol{b}^{(l)},  \\tag{4.32}\\\\\n& \\boldsymbol{a}^{(l)}=f_{l}\\left(\\boldsymbol{z}^{(l)}\\right) . \\tag{4.33}\n\\end{align*}\n$$\n\n首先根据第 $l-1$ 层神经元的活性值（Activation） $\\boldsymbol{a}^{(l-1)}$ 计算出第 $l$ 层神经元的净活性值（Net Activation） $\\boldsymbol{z}^{(l)}$ ，然后经过一个激活函数得到第 $l$ 层神经元的活性值．公式（4．32）和公式（4．33）也可以合并写为：\n\n$$\n\\begin{equation*}\n\\boldsymbol{z}^{(l)}=\\boldsymbol{W}^{(l)} \\cdot f_{l-1}\\left(\\boldsymbol{z}^{(l-1)}\\right)+\\boldsymbol{b}^{(l)} \\tag{4.34}\n\\end{equation*}\n$$\n\n或者\n\n$$\n\\begin{equation*}\n\\boldsymbol{a}^{(l)}=f_{l}\\left(\\boldsymbol{W}^{(l)} \\cdot \\boldsymbol{a}^{(l-1)}+\\boldsymbol{b}^{(l)}\\right) . \\tag{4.35}\n\\end{equation*}\n$$\n\n这样，前馈神经网络可以通过逐层的信息传递，得到网络最后的输出 $\\boldsymbol{a}^{(L)}$ 。整个网络可以看作一个复合函数 $\\phi(\\boldsymbol{x} ; \\boldsymbol{W}, \\boldsymbol{b})$ ，将向量 $\\boldsymbol{x}$ 作为第1层的输入 $\\boldsymbol{a}^{(0)}$ ，将第 $L$ 层的输出 $\\boldsymbol{a}^{(L)}$ 作为整个函数的输出。\n\n$$\n\\begin{equation*}\n\\left.\\boldsymbol{x}=\\boldsymbol{a}^{(0)} \\rightarrow \\boldsymbol{z}^{(1)} \\rightarrow \\boldsymbol{a}^{(1)} \\rightarrow \\boldsymbol{z}^{(2)} \\rightarrow \\cdots \\rightarrow \\boldsymbol{a}^{(L-1)} \\rightarrow \\boldsymbol{z}^{(L)} \\rightarrow \\boldsymbol{a}^{(L)}=\\phi(\\boldsymbol{x} ; \\boldsymbol{W}, \\boldsymbol{b})\\right), \\tag{4.36}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{W}, \\boldsymbol{b}$ 表示网络中所有层的连接权重和偏置．",
        "总结": "- 前馈神经网络（Feedforward Neural Network，FNN）是一种最早发明的简单人工神经网络，也称为多层感知器（Multi-Layer Perceptron，MLP）。  \n- 前馈神经网络由输入层、隐藏层和输出层组成，信号从输入层单向传播到输出层，无反馈，可用有向无环图表示。  \n- 网络中各层神经元通过权重矩阵 $\\boldsymbol{W}^{(l)}$ 和偏置 $\\boldsymbol{b}^{(l)}$ 连接，激活函数 $f_{l}(\\cdot)$ 用于计算神经元的输出。  \n- 前馈神经网络的信息传播过程通过以下公式进行：$\\boldsymbol{z}^{(l)} = \\boldsymbol{W}^{(l)} \\boldsymbol{a}^{(l-1)} + \\boldsymbol{b}^{(l)}$ 和 $\\boldsymbol{a}^{(l)} = f_{l}(\\boldsymbol{z}^{(l)})$。  \n- 整个网络可视为一个复合函数 $\\phi(\\boldsymbol{x}; \\boldsymbol{W}, \\boldsymbol{b})$，将输入向量 $\\boldsymbol{x}$ 逐层映射到输出 $\\boldsymbol{a}^{(L)}$。"
      },
      {
        "段落": "## 4．3．1 通用近似定理\n\n前馈神经网络具有很强的拟合能力，常见的连续非线性函数都可以用前馈神经网络来近似。\n\n定理 4.1 －通用近似定理（Universal Approximation Theorem）［Cybenko， 1989；Hornik et al．，1989］：令 $\\phi(\\cdot)$ 是一个非常数、有界、单调递增的连续函数， $\\mathcal{J}_{D}$ 是一个 $D$ 维的单位超立方体 $[0,1]^{D}, C\\left(\\mathcal{J}_{D}\\right)$ 是定义在 $\\mathcal{J}_{D}$ 上的连续函数集合。对于任何一个函数 $f \\in C\\left(\\mathcal{J}_{D}\\right)$ ，存在一个整数 $M$ ，和一组实数 $v_{m}, b_{m} \\in \\mathbb{R}$ 以及实数向量 $\\boldsymbol{w}_{m} \\in \\mathbb{R}^{D}, m=1, \\cdots, M$ ，以至于我们可以定义函数\n\n$$\n\\begin{equation*}\nF(\\boldsymbol{x})=\\sum_{m=1}^{M} v_{m} \\phi\\left(\\boldsymbol{w}_{m}^{\\top} \\boldsymbol{x}+b_{m}\\right), \\tag{4.37}\n\\end{equation*}\n$$\n\n作为函数 $f$ 的近似实现，即\n\n$$\n\\begin{equation*}\n|F(x)-f(x)|<\\epsilon, \\forall x \\in \\mathcal{J}_{D} \\tag{4.38}\n\\end{equation*}\n$$\n\n其中 $\\epsilon>0$ 是一个很小的正数．\n\n通用近似定理在实数空间 $\\mathbb{R}^{D}$ 中的有界闭集上依然成立．\n根据通用近似定理，对于具有线性输出层和至少一个使用＂挤压＂性质的激活函数的隐藏层组成的前馈神经网络，只要其隐藏层神经元的数量足够，它可以以任意的精度来近似任何一个定义在实数空间 $\\mathbb{R}^{D}$ 中的有界闭集函数［Funa－ hashi et al．，1993；Hornik et al．，1989］．所谓＂挤压＂性质的函数是指像 Sigmoid函数的有界函数，但神经网络的通用近似性质也被证明对于其他类型的激活函数，比如 ReLU，也都是适用的．\n\n通用近似定理只是说明了神经网络的计算能力可以去近似一个给定的连续函数，但并没有给出如何找到这样一个网络，以及是否是最优的。此外，当应用到机器学习时，真实的映射函数并不知道，一般是通过经验风险最小化和正则化来进行参数学习．因为神经网络的强大能力，反而容易在训练集上过拟合．",
        "总结": "- 通用近似定理指出前馈神经网络可以近似任何定义在有界闭集上的连续函数。  \n- 定理要求激活函数为非常数、有界、单调递增且连续，网络结构包含至少一个隐藏层。  \n- 网络通过调整权重和偏置，使得输出函数与目标函数的误差小于任意给定的正数。  \n- 该定理适用于实数空间中的有界闭集，并不限于单位超立方体。  \n- 激活函数需具备“挤压”性质（如Sigmoid），但ReLU等其他激活函数同样适用。  \n- 定理未提供如何构造最优网络的方法，实际应用中需通过经验风险最小化和正则化进行参数学习。  \n- 神经网络的强大拟合能力可能导致过拟合，需在训练时注意控制模型复杂度。"
      },
      {
        "段落": "## 4．3．2 应用到机器学习\n\n根据通用近似定理，神经网络在某种程度上可以作为一个＂万能＂函数来使用，可以用来进行复杂的特征转换，或逼近一个复杂的条件分布。\n\n在机器学习中，输入样本的特征对分类器的影响很大。以监督学习为例，好的特征可以极大提高分类器的性能。因此，要取得好的分类效果，需要将样本的原始特征向量 $\\boldsymbol{x}$ 转换到更有效的特征向量 $\\phi(\\boldsymbol{x})$ ，这个过程叫做特征抽取．\n\n多层前馈神经网络可以看作是一个非线性复合函数 $\\phi: \\mathbb{R}^{D} \\rightarrow \\mathbb{R}^{D^{\\prime}}$ ，将输入 $\\boldsymbol{x} \\in \\mathbb{R}^{D}$ 映射到输出 $\\phi(\\boldsymbol{x}) \\in \\mathbb{R}^{D^{\\prime}}$ 。因此，多层前馈神经网络也可以看成是一种特征转换方法，其输出 $\\phi(\\boldsymbol{x})$ 作为分类器的输入进行分类．\nhttps：／／nndl．github．io／\n\n定义在实数空间 $\\mathbb{R}^{D}$ 中的有界闭集上的任意连续函数，也称为Borel可测函数．\n\n参见习题4－6．\n\n参见第2－6－1．2节。\n\n给定一个训练样本 $(\\boldsymbol{x}, y)$ ，先利用多层前馈神经网络将 $\\boldsymbol{x}$ 映射到 $\\phi(\\boldsymbol{x})$ ，然后再将 $\\phi(\\boldsymbol{x})$ 输入到分类器 $g(\\cdot)$ 。\n\n$$\n\\begin{equation*}\n\\hat{y}=g(\\phi(\\boldsymbol{x}) ; \\theta) \\tag{4.39}\n\\end{equation*}\n$$\n\n其中 $g(\\cdot)$ 为线性或非线性的分类器，$\\theta$ 为分类器 $g(\\cdot)$ 的参数，$\\hat{y}$ 为分类器的输出。\n特别地，如果分类器 $g(\\cdot)$ 为 Logistic 回归分类器或 Softmax 回归分类器，那么 $g(\\cdot)$ 也可以看成是网络的最后一层，即神经网络直接输出不同类别的后验概率。\n\n对于二分类问题 $y \\in\\{0,1\\}$ ，并采用 Logistic 回归，那么 Logistic 回归分类器可以看成神经网络的最后一层。也就是说，网络的最后一层只用一个神经元，并且其激活函数为 Logistic 函数．网络的输出可以直接作为类别 $y=1$ 的后验概率．\n\n$$\np(y=1 \\mid \\boldsymbol{x})=a^{(L)}\n$$\n\n其中 $a^{(L)} \\in \\mathbb{R}$ 为第 $L$ 层神经元的活性值．\n对于多分类问题 $y \\in\\{1, \\cdots, C\\}$ ，如果使用 Softmax 回归分类器，相当于网络最后一层设置 $C$ 个神经元，其激活函数为 Softmax 函数。网络最后一层（第 $L$ 层）的输出可以作为每个类的后验概率，即\n\n$$\n\\hat{\\boldsymbol{y}}=\\operatorname{softmax}\\left(\\boldsymbol{z}^{(L)}\\right),\n$$\n\n其中 $\\boldsymbol{z}^{(L)} \\in \\mathbb{R}^{C}$ 为第 $L$ 层神经元的净输入；$\\hat{\\boldsymbol{y}} \\in \\mathbb{R}^{C}$ 为第 $L$ 层神经元的活性值，每一维分别表示不同类别标签的预测后验概率．",
        "总结": "- 通用近似定理指出神经网络可以作为万能函数，用于复杂特征转换或逼近复杂条件分布  \n- 特征抽取是将原始特征向量 $\\boldsymbol{x}$ 转换为更有效的特征向量 $\\phi(\\boldsymbol{x})$ 的过程  \n- 多层前馈神经网络可视为非线性复合函数 $\\phi: \\mathbb{R}^{D} \\rightarrow \\mathbb{R}^{D^{\\prime}}$，用于特征转换  \n- 特征转换后的输出 $\\phi(\\boldsymbol{x})$ 作为分类器输入进行分类  \n- Borel可测函数定义在实数空间 $\\mathbb{R}^{D}$ 中的有界闭集上的任意连续函数  \n- 训练样本 $(\\boldsymbol{x}, y)$ 经过神经网络映射到 $\\phi(\\boldsymbol{x})$，再输入分类器 $g(\\cdot)$  \n- 分类器 $g(\\cdot)$ 可为线性或非线性，参数为 $\\theta$，输出为 $\\hat{y}$  \n- Logistic 回归分类器可视为神经网络最后一层，输出类别 $y=1$ 的后验概率  \n- 多分类问题中，Softmax 回归分类器对应网络最后一层设置 $C$ 个神经元，激活函数为 Softmax 函数  \n- 网络最后一层输出 $\\hat{\\boldsymbol{y}} = \\operatorname{softmax}(\\boldsymbol{z}^{(L)})$ 表示各类别标签的预测后验概率"
      },
      {
        "段落": "## 4．3．3 参数学习\n\n如果采用交叉嫡损失函数，对于样本 $(\\boldsymbol{x}, \\boldsymbol{y})$ ，其损失函数为\n\n$$\n\\begin{equation*}\n\\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})=-\\boldsymbol{y}^{\\top} \\log \\hat{\\boldsymbol{y}} \\tag{4.42}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{y} \\in\\{0,1\\}^{C}$ 为标签 $y$ 对应的 one－hot 向量表示．\n给定训练集为 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$ ，将每个样本 $\\boldsymbol{x}^{(n)}$ 输入给前馈神经网络，得到网络输出为 $\\hat{\\boldsymbol{y}}^{(n)}$ ，其在数据集 $\\mathcal{D}$ 上的结构化风险函数为：\n\n$$\n\\begin{equation*}\n\\mathcal{R}(\\boldsymbol{W}, \\boldsymbol{b})=\\frac{1}{N} \\sum_{n=1}^{N} \\mathcal{L}\\left(\\boldsymbol{y}^{(n)}, \\hat{\\boldsymbol{y}}^{(n)}\\right)+\\frac{1}{2} \\lambda\\|\\boldsymbol{W}\\|_{F}^{2} \\tag{4.43}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{W}$ 和 $\\boldsymbol{b}$ 分别表示网络中所有的权重矩阵和偏置向量；$\\|\\boldsymbol{W}\\|_{F}^{2}$ 是正则化项，用来防止过拟合；$\\lambda>0$ 为超参数。 $\\lambda$ 越大， $\\boldsymbol{W}$ 越接近于 0 。这里的 $\\|\\boldsymbol{W}\\|_{F}^{2}$ 一般使用 Frobenius 范数：\n\n注意这里的正则化项只包含权重参数 $\\boldsymbol{W}$ ，而不包含偏置b．\n\n反之，Logistic回归或 Softmax 回归也可以看作是只有一层的神经网络．\n\nLogistic 回归参 见第 3.2 节．\n\nSoftmax 回归参 见第 3.3 节．",
        "总结": "- 参数学习部分讨论了使用交叉熵损失函数进行模型训练的方法  \n- 损失函数 $\\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}}) = -\\boldsymbol{y}^{\\top} \\log \\hat{\\boldsymbol{y}}$ 用于衡量预测输出 $\\hat{\\boldsymbol{y}}$ 与真实标签 $\\boldsymbol{y}$ 的差异  \n- 结构化风险函数 $\\mathcal{R}(\\boldsymbol{W}, \\boldsymbol{b})$ 包含了损失函数和正则化项，用于优化网络参数  \n- 正则化项 $\\frac{1}{2} \\lambda\\|\\boldsymbol{W}\\|_{F}^{2}$ 采用Frobenius范数，防止模型过拟合  \n- 超参数 $\\lambda$ 控制正则化强度，$\\lambda$ 越大，权重 $\\boldsymbol{W}$ 越接近于 0  \n- 正则化项仅针对权重 $\\boldsymbol{W}$，不包含偏置 $\\boldsymbol{b}$  \n- Logistic回归和Softmax回归可视为仅含一层的神经网络  \n- Logistic回归相关内容见第3.2节  \n- Softmax回归相关内容见第3.3节"
      },
      {
        "段落": "## 值, 每\n\ntest\n\n[^5]有了学习准则和训练样本，网络参数可以通过梯度下降法来进行学习．在梯度下降方法的每次迭代中，第 $l$ 层的参数 $\\boldsymbol{W}^{(l)}$ 和 $\\boldsymbol{b}^{(l)}$ 参数更新方式为\n\n$$\n\\begin{align*}\n\\boldsymbol{W}^{(l)} & \\leftarrow \\boldsymbol{W}^{(l)}-\\alpha \\frac{\\partial \\mathcal{R}(\\boldsymbol{W}, \\boldsymbol{b})}{\\partial \\boldsymbol{W}^{(l)}}  \\tag{4.45}\\\\\n& =\\boldsymbol{W}^{(l)}-\\alpha\\left(\\frac{1}{N} \\sum_{n=1}^{N}\\left(\\frac{\\partial \\mathcal{L}\\left(\\boldsymbol{y}^{(n)}, \\hat{\\boldsymbol{y}}^{(n)}\\right)}{\\partial \\boldsymbol{W}^{(l)}}\\right)+\\lambda \\boldsymbol{W}^{(l)}\\right)  \\tag{4.46}\\\\\n\\boldsymbol{b}^{(l)} & \\leftarrow \\boldsymbol{b}^{(l)}-\\alpha \\frac{\\partial \\mathcal{R}(\\boldsymbol{W}, \\boldsymbol{b})}{\\partial \\boldsymbol{b}^{(l)}}  \\tag{4.47}\\\\\n& =\\boldsymbol{b}^{(l)}-\\alpha\\left(\\frac{1}{N} \\sum_{n=1}^{N} \\frac{\\partial \\mathcal{L}\\left(\\boldsymbol{y}^{(n)}, \\hat{\\boldsymbol{y}}^{(n)}\\right)}{\\partial \\boldsymbol{b}^{(l)}}\\right) \\tag{4.48}\n\\end{align*}\n$$\n\n其中 $\\alpha$ 为学习率。\n梯度下降法需要计算损失函数对参数的偏导数，如果通过链式法则逐一对每个参数进行求偏导比较低效．在神经网络的训练中经常使用反向传播算法来高效地计算梯度。",
        "总结": "- 梯度下降法用于更新神经网络参数，通过计算损失函数对参数的偏导数进行参数调整。  \n- 参数更新公式包括权重 $\\boldsymbol{W}^{(l)}$ 和偏置 $\\boldsymbol{b}^{(l)}$，其中包含学习率 $\\alpha$ 和损失函数的梯度项。  \n- 损失函数的梯度项由训练样本的平均损失梯度和正则化项组成。  \n- 反向传播算法被提出以高效计算梯度，避免逐个参数求导的低效性。"
      },
      {
        "段落": "## 4.4 反向传播算法\n\n假设采用随机梯度下降进行神经网络参数学习，给定一个样本 $(\\boldsymbol{x}, \\boldsymbol{y})$ ，将其输入到神经网络模型中，得到网络输出为 $\\hat{\\boldsymbol{y}}$ 。假设损失函数为 $\\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})$ ，要进行参数学习就需要计算损失函数关于每个参数的导数。\n\n不失一般性，对第 $l$ 层中的参数 $\\boldsymbol{W}^{(l)}$ 和 $\\boldsymbol{b}^{(l)}$ 计算偏导数。因为 $\\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{W}^{(l)}}$ 的计算涉及向量对矩阵的微分，十分繁琐，因此我们先计算 $\\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})$ 关于参数矩阵中每个元素的偏导数 $\\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial w_{i j}^{(l)}}$ 。根据链式法则，\n\n$$\n\\begin{align*}\n& \\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial w_{i j}^{(l)}}=\\frac{\\partial \\boldsymbol{z}^{(l)}}{\\partial w_{i j}^{(l)}} \\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{z}^{(l)}}  \\tag{4.49}\\\\\n& \\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{b}^{(l)}}=\\frac{\\partial \\boldsymbol{z}^{(l)}}{\\partial \\boldsymbol{b}^{(l)}} \\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{z}^{(l)}} \\tag{4.50}\n\\end{align*}\n$$\n\n公式（4．49）和公式（4．50）中的第二项都是目标函数关于第 $l$ 层的神经元 $\\boldsymbol{z}^{(l)}$的偏导数，称为误差项，可以一次计算得到．这样我们只需要计算三个偏导数，分别为 $\\frac{\\partial \\boldsymbol{z}^{(l)}}{\\partial w_{i j}^{(l)}}, \\frac{\\partial \\boldsymbol{z}^{(l)}}{\\partial \\boldsymbol{b}^{(l)}}$ 和 $\\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{z}^{(l)}}$ ．\n\n下面分别来计算这三个偏导数．\n\n这里使用向量或矩阵来表示多变量函数的偏导数，并使用分母布局表示，参见第 B． 3 节。参见公式（B．18）．\n（1）计算偏导数 $\\frac{\\partial \\boldsymbol{z}^{(l)}}{\\partial w_{i j}^{(l)}}$ 因 $\\boldsymbol{z}^{(l)}=\\boldsymbol{W}^{(l)} \\boldsymbol{a}^{(l-1)}+\\boldsymbol{b}^{(l)}$ ，偏导数\n\n$$\n\\begin{align*}\n\\frac{\\partial z^{(l)}}{\\partial w_{i j}^{(l)}} & =\\left[\\frac{\\partial z_{1}^{(l)}}{\\partial w_{i j}^{(l)}}, \\cdots, \\frac{\\partial z_{i}^{(l)}}{\\partial w_{i j}^{(l)}}, \\cdots, \\frac{\\partial z_{M_{l}}^{(l)}}{\\partial w_{i j}^{(l)}}\\right]  \\tag{4.51}\\\\\n& =\\left[0, \\cdots, \\frac{\\partial\\left(\\boldsymbol{w}_{i:}^{(l)} \\boldsymbol{a}^{(l-1)}+b_{i}^{(l)}\\right)}{\\partial w_{i j}^{(l)}}, \\cdots, 0\\right]  \\tag{4.52}\\\\\n& =\\left[0, \\cdots, a_{j}^{(l-1)}, \\cdots, 0\\right]  \\tag{4.53}\\\\\n& \\triangleq \\mathbb{I}_{i}\\left(a_{j}^{(l-1)}\\right) \\in \\mathbb{R}^{1 \\times M_{l}} \\tag{4.54}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{w}_{i:}^{(l)}$ 为权重矩阵 $\\boldsymbol{W}^{(l)}$ 的第 $i$ 行， $\\mathbb{l}_{i}\\left(a_{j}^{(l-1)}\\right)$ 表示第 $i$ 个元素为 $a_{j}^{(l-1)}$ ，其余为 0的行向量．\n（2）计算偏导数 $\\frac{\\partial \\boldsymbol{z}^{(l)}}{\\partial \\boldsymbol{b}^{(l)}}$ 因为 $\\boldsymbol{z}^{(l)}$ 和 $\\boldsymbol{b}^{(l)}$ 的函数关系为 $\\boldsymbol{z}^{(l)}=\\boldsymbol{W}^{(l)} \\boldsymbol{a}^{(l-1)}+\\boldsymbol{b}^{(l)}$ ，因此偏导数\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\boldsymbol{z}^{(l)}}{\\partial \\boldsymbol{b}^{(l)}}=\\boldsymbol{I}_{M_{l}} \\quad \\in \\mathbb{R}^{M_{l} \\times M_{l}} \\tag{4.55}\n\\end{equation*}\n$$\n\n为 $M_{l} \\times M_{l}$ 的单位矩阵。\n（3）计算偏导数 $\\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{z}^{(l)}}$ 偏导数 $\\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{z}^{(l)}}$ 表示第 $l$ 层神经元对最终损失的影响，也反映了最终损失对第 $l$ 层神经元的敏感程度，因此一般称为第 $l$ 层神经元的误差项，用 $\\delta^{(l)}$ 来表示。\n\n$$\n\\begin{equation*}\n\\delta^{(l)} \\triangleq \\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{z}^{(l)}} \\in \\mathbb{R}^{M_{l}} \\tag{4.56}\n\\end{equation*}\n$$\n\n误差项 $\\delta^{(l)}$ 也间接反映了不同神经元对网络能力的贡献程度，从而比较好地解决了贡献度分配问题（Credit Assignment Problem，CAP）。\n\n根据 $\\boldsymbol{z}^{(l+1)}=\\boldsymbol{W}^{(l+1)} \\boldsymbol{a}^{(l)}+\\boldsymbol{b}^{(l+1)}$ ，有\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\boldsymbol{z}^{(l+1)}}{\\partial \\boldsymbol{a}^{(l)}}=\\left(\\boldsymbol{W}^{(l+1)}\\right)^{\\top} \\quad \\in \\mathbb{R}^{M_{l} \\times M_{l+1}} \\tag{4.57}\n\\end{equation*}\n$$\n\n根据 $\\boldsymbol{a}^{(l)}=f_{l}\\left(\\boldsymbol{z}^{(l)}\\right)$ ，其中 $f_{l}(\\cdot)$ 为按位计算的函数，因此有\n\n$$\n\\begin{align*}\n\\frac{\\partial \\boldsymbol{a}^{(l)}}{\\partial \\boldsymbol{z}^{(l)}} & =\\frac{\\partial f_{l}\\left(\\boldsymbol{z}^{(l)}\\right)}{\\partial \\boldsymbol{z}^{(l)}}  \\tag{4.58}\\\\\n& =\\operatorname{diag}\\left(f_{l}^{\\prime}\\left(\\boldsymbol{z}^{(l)}\\right)\\right) \\quad \\in \\mathbb{R}^{M_{l} \\times M_{l}} \\tag{4.59}\n\\end{align*}\n$$\n\n因此，根据链式法则，第 $l$ 层的误差项为\n\n$$\n\\begin{equation*}\n\\delta^{(l)} \\triangleq \\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{z}^{(l)}} \\tag{4.60}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n这里的矩阵微分采用分母布局，即一个列行向量关于标量的偏导数为行向量，参见第 B． 3 节。\n\n$$\n\\begin{align*}\n& =\\frac{\\partial \\boldsymbol{a}^{(l)}}{\\partial \\boldsymbol{z}^{(l)}} \\cdot \\frac{\\partial \\boldsymbol{z}^{(l+1)}}{\\partial \\boldsymbol{a}^{(l)}} \\cdot \\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{z}^{(l+1)}}  \\tag{4.61}\\\\\n& =\\operatorname{diag}\\left(f_{l}^{\\prime}\\left(\\boldsymbol{z}^{(l)}\\right)\\right) \\cdot\\left(\\boldsymbol{W}^{(l+1)}\\right)^{\\top} \\cdot \\delta^{(l+1)}  \\tag{4.62}\\\\\n& =f_{l}^{\\prime}\\left(\\boldsymbol{z}^{(l)}\\right) \\odot\\left(\\left(\\boldsymbol{W}^{(l+1)}\\right)^{\\top} \\delta^{(l+1)}\\right) \\quad \\in \\mathbb{R}^{M_{l}} \\tag{4.63}\n\\end{align*}\n$$\n\n其中 $\\odot$ 是向量的点积运算符，表示每个元素相乘。\n从公式（4．63）可以看出，第 $l$ 层的误差项可以通过第 $l+1$ 层的误差项计算得到，这就是误差的反向传播（BackPropagation，BP）。反向传播算法的含义是：第 $l$ 层的一个神经元的误差项（或敏感性）是所有与该神经元相连的第 $l+1$ 层的神经元的误差项的权重和。然后，再乘上该神经元激活函数的梯度。\n\n在计算出上面三个偏导数之后，公式（4．49）可以写为\n\n$$\n\\begin{align*}\n\\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial w_{i j}^{(l)}} & =\\mathbb{0}_{i}\\left(a_{j}^{(l-1)}\\right) \\delta^{(l)}  \\tag{4.64}\\\\\n& =\\left[0, \\cdots, a_{j}^{(l-1)}, \\cdots, 0\\right]\\left[\\delta_{1}^{(l)}, \\cdots, \\delta_{i}^{(l)}, \\cdots, \\delta_{M_{l}}^{(l)}\\right]^{\\top}  \\tag{4.65}\\\\\n& =\\delta_{i}^{(l)} a_{j}^{(l-1)} \\tag{4.66}\n\\end{align*}\n$$\n\n其中 $\\delta_{i}^{(l)} a_{j}^{(l-1)}$ 相当于向量 $\\delta^{(l)}$ 和向量 $\\boldsymbol{a}^{(l-1)}$ 的外积的第 $i, j$ 个元素．上式可以进外积参见公式（A．27）。一步写为\n\n$$\n\\begin{equation*}\n\\left[\\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{W}^{(l)}}\\right]_{i j}=\\left[\\delta^{(l)}\\left(\\boldsymbol{a}^{(l-1)}\\right)^{\\top}\\right]_{i j} \\tag{4.67}\n\\end{equation*}\n$$\n\n因此， $\\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})$ 关于第 $l$ 层权重 $\\boldsymbol{W}^{(l)}$ 的梯度为\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{W}^{(l)}}=\\delta^{(l)}\\left(\\boldsymbol{a}^{(l-1)}\\right)^{\\top} \\quad \\in \\mathbb{R}^{M_{l} \\times M_{l-1}} \\tag{4.68}\n\\end{equation*}\n$$\n\n同理， $\\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})$ 关于第 $l$ 层偏置 $\\boldsymbol{b}^{(l)}$ 的梯度为\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{b}^{(l)}}=\\delta^{(l)} \\quad \\in \\mathbb{R}^{M_{l}} . \\tag{4.69}\n\\end{equation*}\n$$\n\n在计算出每一层的误差项之后，我们就可以得到每一层参数的梯度。因此，使用误差反向传播算法的前馈神经网络训练过程可以分为以下三步：\n（1）前馈计算每一层的净输入 $\\boldsymbol{z}^{(l)}$ 和激活值 $\\boldsymbol{a}^{(l)}$ ，直到最后一层；\n（2）反向传播计算每一层的误差项 $\\delta^{(l)}$ ；\n（3）计算每一层参数的偏导数，并更新参数．\n\n算法4．1给出使用反向传播算法的随机梯度下降训练过程．\n\n```\n算法 4.1: 使用反向传播算法的随机梯度下降训练过程\n    输入: 训练集 $\\mathcal{D}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$, 验证集 $\\mathcal{V}$, 学习率 $\\alpha$, 正则化系数 $\\lambda$, 网络层\n            数 $L$, 神经元数量 $M_{l}, 1 \\leq l \\leq L$.\n    随机初始化 $\\boldsymbol{W}, \\boldsymbol{b}$;\n    repeat\n        对训练集 $\\mathcal{D}$ 中的样本随机重排序;\n        for $n=1 \\cdots N$ do\n            从训练集 $\\mathcal{D}$ 中选取样本 $\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)$;\n            前馈计算每一层的净输入 $\\boldsymbol{z}^{(l)}$ 和激活值 $\\boldsymbol{a}^{(l)}$, 直到最后一层;\n            反向传播计算每一层的误差 $\\delta^{(l)}$; // 公式 (4.63)\n            // 计算每一层参数的导数\n            $\\forall l, \\quad \\frac{\\partial \\mathcal{L}\\left(y^{(n)}, \\hat{y}^{(n)}\\right)}{\\partial W^{(l)}}=\\delta^{(l)}\\left(\\boldsymbol{a}^{(l-1)}\\right)^{\\top} ; \\quad$ // 公式 (4.68)\n            $\\forall l, \\quad \\frac{\\partial \\mathcal{L}\\left(\\boldsymbol{y}^{(n)}, \\hat{\\boldsymbol{y}}^{(n)}\\right)}{\\partial \\boldsymbol{b}^{(l)}}=\\delta^{(l)} ; \\quad$ // 公式 (4.69)\n            // 更新参数\n            $\\boldsymbol{W}^{(l)} \\leftarrow \\boldsymbol{W}^{(l)}-\\alpha\\left(\\delta^{(l)}\\left(\\boldsymbol{a}^{(l-1)}\\right)^{\\top}+\\lambda \\boldsymbol{W}^{(l)}\\right) ;$\n            $\\boldsymbol{b}^{(l)} \\leftarrow \\boldsymbol{b}^{(l)}-\\alpha \\delta^{(l)}$;\n        end\n    until 神经网络模型在验证集 $\\mathcal{V}$ 上的错误率不再下降;\n    输出: $W, b$\n```",
        "总结": "- 反向传播算法用于神经网络参数学习，通过计算损失函数关于参数的梯度来更新参数。\n- 使用链式法则计算损失函数对参数的偏导数，将复杂向量对矩阵的微分分解为三个关键偏导数：$\\frac{\\partial \\boldsymbol{z}^{(l)}}{\\partial w_{i j}^{(l)}}$、$\\frac{\\partial \\boldsymbol{z}^{(l)}}{\\partial \\boldsymbol{b}^{(l)}}$ 和 $\\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{z}^{(l)}}$。\n- $\\frac{\\partial \\boldsymbol{z}^{(l)}}{\\partial w_{i j}^{(l)}}$ 是一个行向量，仅在第 $i$ 个位置为 $a_{j}^{(l-1)}$，其余为 0。\n- $\\frac{\\partial \\boldsymbol{z}^{(l)}}{\\partial \\boldsymbol{b}^{(l)}}$ 是一个单位矩阵 $\\boldsymbol{I}_{M_{l}}$。\n- $\\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, \\hat{\\boldsymbol{y}})}{\\partial \\boldsymbol{z}^{(l)}}$ 称为误差项 $\\delta^{(l)}$，表示第 $l$ 层神经元对最终损失的影响。\n- 误差项 $\\delta^{(l)}$ 可以通过链式法则从下一层的误差项反向计算得到：$\\delta^{(l)} = f_{l}'(\\boldsymbol{z}^{(l)}) \\odot (\\boldsymbol{W}^{(l+1)}^\\top \\delta^{(l+1)})$。\n- 损失函数关于权重 $\\boldsymbol{W}^{(l)}$ 的梯度为 $\\delta^{(l)} (\\boldsymbol{a}^{(l-1)})^\\top$，关于偏置 $\\boldsymbol{b}^{(l)}$ 的梯度为 $\\delta^{(l)}$。\n- 反向传播算法的训练过程分为三步：前馈计算、反向传播误差项、更新参数。\n- 算法4.1描述了使用随机梯度下降和反向传播算法进行神经网络训练的具体步骤。"
      },
      {
        "段落": "## 4.5 自动梯度计算\n\n神经网络的参数主要通过梯度下降来进行优化。当确定了风险函数以及网络结构后，我们就可以手动用链式法则来计算风险函数对每个参数的梯度，并用代码进行实现。但是手动求导并转换为计算机程序的过程非常琐碎并容易出错，导致实现神经网络变得十分低效．实际上，参数的梯度可以让计算机来自动计算．目前，主流的深度学习框架都包含了自动梯度计算的功能，即我们可以只考虑网络结构并用代码实现，其梯度可以自动进行计算，无需人工干预，这样可以大幅提高开发效率。\n\n自动计算梯度的方法可以分为以下三类：数值微分、符号微分和自动微分．",
        "总结": "- 概念：自动梯度计算，指由计算机自动计算神经网络参数的梯度，无需人工手动求导。  \n- 概念：梯度下降，神经网络参数优化的主要方法，通过计算风险函数对参数的梯度来更新参数。  \n- 概念：风险函数，用于衡量模型预测输出与真实标签之间差异的函数。  \n- 概念：链式法则，手动计算梯度时使用的数学规则，用于计算复合函数的导数。  \n- 概念：数值微分、符号微分和自动微分，自动计算梯度的三种方法。  \n- 算法：自动梯度计算，主流深度学习框架均支持，通过代码实现网络结构即可自动计算梯度。  \n- 算法：手动求导，需使用链式法则计算风险函数对每个参数的梯度，并转换为代码实现。  \n- 问题：手动求导过程繁琐且容易出错，导致神经网络实现效率低下。  \n- 优势：自动梯度计算可大幅提高开发效率，减少人工干预。"
      },
      {
        "段落": "## 4．5．1 数值微分\n\n数值微分（Numerical Differentiation）是用数值方法来计算函数 $f(x)$ 的导数．函数 $f(x)$ 的点 $x$ 的导数定义为\n\n$$\n\\begin{equation*}\nf^{\\prime}(x)=\\lim _{\\Delta x \\rightarrow 0} \\frac{f(x+\\Delta x)-f(x)}{\\Delta x} \\tag{4.70}\n\\end{equation*}\n$$\n\n要计算函数 $f(x)$ 在点 $x$ 的导数，可以对 $x$ 加上一个很少的非零的扰动 $\\Delta x$ ，通 https：／／nndl．github．io／\n\n过上述定义来直接计算函数 $f(x)$ 的梯度．数值微分方法非常容易实现，但找到一个合适的扰动 $\\Delta x$ 却十分困难。如果 $\\Delta x$ 过小，会引起数值计算问题，比如舍入误差；如果 $\\Delta x$ 过大，会增加截断误差，使得导数计算不准确。因此，数值微分的实用性比较差．在实际应用，经常使用下面公式来计算梯度，可以减少截断误差．\n\n$$\n\\begin{equation*}\nf^{\\prime}(x)=\\lim _{\\Delta x \\rightarrow 0} \\frac{f(x+\\Delta x)-f(x-\\Delta x)}{2 \\Delta x} \\tag{4.71}\n\\end{equation*}\n$$\n\n数值微分的另外一个问题是计算复杂度．假设参数数量为 $N$ ，则每个参数都需要单独施加扰动，并计算梯度．假设每次正向传播的计算复杂度为 $O(N)$ ，则计算数值微分的总体时间复杂度为 $O\\left(N^{2}\\right)$ ．",
        "总结": "- 数值微分是通过数值方法计算函数 $f(x)$ 在点 $x$ 处导数的方法  \n- 导数的定义为 $f^{\\prime}(x)=\\lim _{\\Delta x \\rightarrow 0} \\frac{f(x+\\Delta x)-f(x)}{\\Delta x}$  \n- 通过在 $x$ 处添加一个小的扰动 $\\Delta x$ 来直接计算导数，但选择合适的 $\\Delta x$ 很困难  \n- 若 $\\Delta x$ 过小，会导致舍入误差；若过大，则增加截断误差，影响计算精度  \n- 常用对称差商公式 $f^{\\prime}(x)=\\lim _{\\Delta x \\rightarrow 0} \\frac{f(x+\\Delta x)-f(x-\\Delta x)}{2 \\Delta x}$ 来减少截断误差  \n- 数值微分的计算复杂度较高，参数数量为 $N$ 时，总体时间复杂度为 $O(N^2)$"
      },
      {
        "段落": "## 4．5．2 符号微分\n\n符号微分（Symbolic Differentiation）是一种基于符号计算的自动求导方法．符号计算也叫代数计算，是指用计算机来处理带有变量的数学表达式．这里的变量看作是符号（Symbols），一般不需要代入具体的值。符号计算的输入和输出都是数学表达式，一般包括对数学表达式的化简、因式分解、微分、积分、解代数方程、求解常微分方程等运算。\n\n比如数学表达式的化简：\n\n$$\n\\begin{align*}\n& \\text { 输入: } 3 x-x+2 x+1  \\tag{4.72}\\\\\n& \\text { 输出: } 4 x+1 \\text {. } \\tag{4.73}\n\\end{align*}\n$$\n\n符号计算一般来讲是对输入的表达式，通过迭代或递归使用一些事先定义的规则进行转换。当转换结果不能再继续使用变换规则时，便停止计算。\n\n符号微分可以在编译时就计算梯度的数学表示，并进一步利用符号计算方法进行优化。此外，符号计算的一个优点是符号计算和平台无关，可以在 CPU 或 GPU上运行。符号微分也有一些不足之处。一是编译时间较长，特别是对于循环，需要很长时间进行编译；二是为了进行符号微分，一般需要设计一种专门的语言来表示数学表达式，并且要对变量（符号）进行预先声明；三是很难对程序进行调试。",
        "总结": "- 符号微分是一种基于符号计算的自动求导方法  \n- 符号计算是指用计算机处理带有变量的数学表达式，变量视为符号  \n- 符号计算的输入和输出都是数学表达式，包括化简、因式分解、微分、积分等运算  \n- 数学表达式化简的例子：输入 $3x - x + 2x + 1$，输出 $4x + 1$  \n- 符号计算通过迭代或递归应用事先定义的规则进行转换，直到无法继续变换  \n- 符号微分可在编译时计算梯度的数学表示，并进一步优化  \n- 符号计算具有平台无关性，可在 CPU 或 GPU 上运行  \n- 符号微分的不足包括编译时间较长、需要专门语言表示数学表达式、变量需预先声明、调试困难"
      },
      {
        "段落": "## 4．5．3 自动微分\n\n自动微分（Automatic Differentiation，AD）是一种可以对一个（程序）函数进行计算导数的方法．符号微分的处理对象是数学表达式，而自动微分的处理对象是一个函数或一段程序。自动微分可以直接在原始程序代码进行微分，因此自动微分成为目前大多数深度学习框架的首选。\n\n舍入误差（Round－off Error）是指数值计算中由于数字舍入造成的近似值和精确值之间的差异，比如用浮点数来表示实数．\n\n截断误差（Truncation Error）是数学模型的理论解与数值计算问题的精确解之间的误差．\n\n和符号计算相对应的概念是数值计算，即将数值代入数学表示中进行计算。\n\n自动微分的基本原理是所有的数值计算可以分解为一些基本操作，包含 ,,$+- \\times, /$ 和一些初等函数 $\\exp , \\log , \\sin , \\cos$ 等，然后利用链式法则来自动计算一个复合函数的梯度．\n\n为简单起见，这里以一个神经网络中常见的复合函数的例子来说明自动微分的过程．令复合函数 $f(x ; w, b)$ 为\n\n$$\n\\begin{equation*}\nf(x ; w, b)=\\frac{1}{\\exp (-(w x+b))+1} \\tag{4.74}\n\\end{equation*}\n$$\n\n其中 $x$ 为输入标量，$w$ 和 $b$ 分别为权重和偏置参数。\n首先，我们将复合函数 $f(x ; w, b)$ 分解为一系列的基本操作，并构成一个计算图（Computational Graph）。计算图是数学运算的图形化表示。计算图中的每个非叶子节点表示一个基本操作，每个叶子节点为一个输入变量或常量。图4．8给出了当 $x=1, w=0, b=0$ 时复合函数 $f(x ; w, b)$ 的计算图，其中连边上的红色数字表示前向计算时复合函数中每个变量的实际取值．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-110.jpg?height=240&width=1021&top_left_y=919&top_left_x=147)\n\n图 4.8 复合函数 $f(x ; w, b)$ 的计算图\n\n从计算图上可以看出，复合函数 $f(x ; w, b)$ 由 6 个基本函数 $h_{i}, 1 \\leq i \\leq 6$ 组成．如表4．1所示，每个基本函数的导数都十分简单，可以通过规则来实现．\n\n表 4.1 复合函数 $f(x ; w, b)$ 的 6 个基本函数及其导数\n\n| 函数 | 导数 |  |\n| :--- | :--- | :--- |\n| $h_{1}=x \\times w$ | $\\frac{\\partial h_{1}}{\\partial w}=x$ | $\\frac{\\partial h_{1}}{\\partial x}=w$ |\n| $h_{2}=h_{1}+b$ | $\\frac{\\partial h_{2}}{\\partial h_{1}}=1$ | $\\frac{\\partial h_{2}}{\\partial b}=1$ |\n| $h_{3}=h_{2} \\times-1$ | $\\frac{\\partial h_{3}}{\\partial h_{2}}=-1$ |  |\n| $h_{4}=\\exp \\left(h_{3}\\right)$ | $\\frac{\\partial h_{4}}{\\partial h_{3}}=\\exp \\left(h_{3}\\right)$ |  |\n| $h_{5}=h_{4}+1$ | $\\frac{\\partial h_{5}}{\\partial h_{4}}=1$ |  |\n| $h_{6}=1 / h_{5}$ | $\\frac{\\partial h_{6}}{\\partial h_{5}}=-\\frac{1}{h_{5}^{2}}$ |  |\n\n整个复合函数 $f(x ; w, b)$ 关于参数 $w$ 和 $b$ 的导数可以通过计算图上的节点 $f(x ; w, b)$ 与参数 $w$ 和 $b$ 之间路径上所有的导数连乘来得到，即\n\n$$\n\\begin{align*}\n& \\frac{\\partial f(x ; w, b)}{\\partial w}=\\frac{\\partial f(x ; w, b)}{\\partial h_{6}} \\frac{\\partial h_{6}}{\\partial h_{5}} \\frac{\\partial h_{5}}{\\partial h_{4}} \\frac{\\partial h_{4}}{\\partial h_{3}} \\frac{\\partial h_{3}}{\\partial h_{2}} \\frac{\\partial h_{2}}{\\partial h_{1}} \\frac{\\partial h_{1}}{\\partial w},  \\tag{4.75}\\\\\n& \\frac{\\partial f(x ; w, b)}{\\partial b}=\\frac{\\partial f(x ; w, b)}{\\partial h_{6}} \\frac{\\partial h_{6}}{\\partial h_{5}} \\frac{\\partial h_{5}}{\\partial h_{4}} \\frac{\\partial h_{4}}{\\partial h_{3}} \\frac{\\partial h_{3}}{\\partial h_{2}} \\frac{\\partial h_{2}}{\\partial b} . \\tag{4.76}\n\\end{align*}\n$$\n\n以 $\\frac{\\partial f(x ; w, b)}{\\partial w}$ 为例，当 $x=1, w=0, b=0$ 时，可以得到\n\n$$\n\\begin{align*}\n\\left.\\frac{\\partial f(x ; w, b)}{\\partial w}\\right|_{x=1, w=0, b=0} & =\\frac{\\partial f(x ; w, b)}{\\partial h_{6}} \\frac{\\partial h_{6}}{\\partial h_{5}} \\frac{\\partial h_{5}}{\\partial h_{4}} \\frac{\\partial h_{4}}{\\partial h_{3}} \\frac{\\partial h_{3}}{\\partial h_{2}} \\frac{\\partial h_{2}}{\\partial h_{1}} \\frac{\\partial h_{1}}{\\partial w}  \\tag{4.77}\\\\\n& =1 \\times-0.25 \\times 1 \\times 1 \\times-1 \\times 1 \\times 1  \\tag{4.78}\\\\\n& =0.25 \\tag{4.79}\n\\end{align*}\n$$\n\n如果函数和参数之间有多条路径，可以将这多条路径上的导数再进行相加，得到最终的梯度。\n\n按照计算导数的顺序，自动微分可以分为两种模式：前向模式和反向模式．\n前向模式 前向模式是按计算图中计算方向的相同方向来递归地计算梯度。以 $\\frac{\\partial f(x ; w, b)}{\\partial w}$ 为例，当 $x=1, w=0, b=0$ 时，前向模式的累积计算顺序如下：\n\n$$\n\\begin{gather*}\n\\frac{\\partial h_{1}}{\\partial w}=x=1,  \\tag{4.80}\\\\\n\\frac{\\partial h_{2}}{\\partial w}=\\frac{\\partial h_{2}}{\\partial h_{1}} \\frac{\\partial h_{1}}{\\partial w}=1 \\times 1=1,  \\tag{4.81}\\\\\n\\frac{\\partial h_{3}}{\\partial w}=\\frac{\\partial h_{3}}{\\partial h_{2}} \\frac{\\partial h_{2}}{\\partial w}=-1 \\times 1,  \\tag{4.82}\\\\\n\\vdots  \\tag{4.84}\\\\\n\\frac{\\partial h_{6}}{\\partial w}=\\frac{\\partial h_{6}}{\\partial h_{5}} \\frac{\\partial h_{5}}{\\partial w}=-0.25 \\times-1=0.25, \\\\\n\\frac{\\partial f(x ; w, b)}{\\partial w}=\\frac{\\partial f(x ; w, b)}{\\partial h_{6}} \\frac{\\partial h_{6}}{\\partial w}=1 \\times 0.25=0.25 .\n\\end{gather*}\n$$\n\n反向模式 反向模式是按计算图中计算方向的相反方向来递归地计算梯度。以 $\\frac{\\partial f(x ; w, b)}{\\partial w}$ 为例，当 $x=1, w=0, b=0$ 时，反向模式的累积计算顺序如下：\n\n$$\n\\begin{align*}\n& \\frac{\\partial f(x ; w, b)}{\\partial h_{6}}=1  \\tag{4.86}\\\\\n& \\frac{\\partial f(x ; w, b)}{\\partial h_{5}}=\\frac{\\partial f(x ; w, b)}{\\partial h_{6}} \\frac{\\partial h_{6}}{\\partial h_{5}}=1 \\times-0.25  \\tag{4.87}\\\\\n& \\frac{\\partial f(x ; w, b)}{\\partial h_{4}}=\\frac{\\partial f(x ; w, b)}{\\partial h_{5}} \\frac{\\partial h_{5}}{\\partial h_{4}}=-0.25 \\times 1=-0.25 \\tag{4.88}\n\\end{align*}\n$$\n\nhttps：／／nndl．github．io／\n\n$$\n\\begin{array}{cc}\n\\vdots & \\vdots  \\tag{4.89}\\\\\n\\frac{\\partial f(x ; w, b)}{\\partial w}= & \\frac{\\partial f(x ; w, b)}{\\partial h_{1}} \\frac{\\partial h_{1}}{\\partial w}=0.25 \\times 1=0.25\n\\end{array}\n$$\n\n前向模式和反向模式可以看作是应用链式法则的两种梯度累积方式．从反向模式的计算顺序可以看出，反向模式和反向传播的计算梯度的方式相同．\n\n对于一般的函数形式 $f: \\mathbb{R}^{N} \\rightarrow \\mathbb{R}^{M}$ ，前向模式需要对每一个输入变量都进行一遍遍历，共需要 $N$ 遍。而反向模式需要对每一个输出都进行一个遍历，共需要 $M$ 遍。当 $N>M$ 时，反向模式更高效。在前馈神经网络的参数学习中，风险函数为 $f: \\mathbb{R}^{N} \\rightarrow \\mathbb{R}$ ，输出为标量，因此采用反向模式为最有效的计算方式，只需要一遍计算。\n\n符号微分和自动微分 符号微分和自动微分都利用计算图和链式法则来自动求解导数。符号微分在编译阶段先构造一个复合函数的计算图，通过符号计算得到导数的表达式，还可以对导数表达式进行优化，在程序运行阶段才代入变量的具体数值来计算导数。而自动微分则无需事先编译，在程序运行阶段边计算边记录计算图，计算图上的局部梯度都直接代入数值进行计算，然后用前向或反向模式来计算最终的梯度。\n\n图4．9给出了符号微分与自动微分的对比．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-112.jpg?height=249&width=1045&top_left_y=1169&top_left_x=133)\n\n图 4.9 符号微分与自动微分对比\n\n静态计算图和动态计算图 计算图按构建方式可以分为静态计算图和动态计算图．静态计算图是在编译时构建计算图，计算图构建好之后在程序运行时不能改变，而动态计算图是在程序运行时动态构建。两种构建方式各有优缺点。静态计算图在构建时可以进行优化，并行能力强，但灵活性比较差。动态计算图则不容易优化，当不同输入的网络结构不一致时，难以并行计算，但是灵活性比较高。\n\n在目前深度学习框架里，Theano 和 Tensorflow 采用的是静态计算图，而 DyNet、Chainer 和 PyTorch 采用的是动态计算图。\n\nTensorflow 2.0 也支持了动态计算图．",
        "总结": "- 自动微分（Automatic Differentiation，AD）是一种对程序函数进行计算导数的方法，处理对象是函数或程序，而非数学表达式。\n- 自动微分的基本原理是将数值计算分解为基本操作（如加减乘除、初等函数），并利用链式法则自动计算复合函数的梯度。\n- 复合函数 $f(x ; w, b)$ 由6个基本函数组成，每个基本函数的导数可通过简单规则实现。\n- 计算图用于表示数学运算的图形化结构，每个节点代表一个基本操作或输入变量。\n- 通过计算图中节点之间的路径，可以计算复合函数关于参数 $w$ 和 $b$ 的导数，如公式（4.75）和（4.76）所示。\n- 前向模式按计算图方向递归计算梯度，反向模式按相反方向递归计算梯度，反向模式与反向传播方式相同。\n- 前向模式需要 $N$ 遍遍历输入变量，反向模式需要 $M$ 遍遍历输出变量。当 $N > M$ 时，反向模式更高效。\n- 符号微分在编译阶段构造计算图并求导数表达式，自动微分则在运行阶段边计算边记录计算图，并直接代入数值进行梯度计算。\n- 计算图分为静态和动态两种构建方式：静态计算图在编译时构建，动态计算图在运行时构建。Tensorflow 和 Theano 使用静态计算图，PyTorch 和 Chainer 使用动态计算图。"
      },
      {
        "段落": "## 4.6 优化问题\n\n神经网络的参数学习比线性模型要更加困难，主要原因有两点：（1）非凸优化问题和（2）梯度消失问题。",
        "总结": "- 概念：优化问题在神经网络参数学习中比线性模型更加困难。  \n- 原因一：非凸优化问题，即损失函数可能存在多个局部极小值点，使得寻找全局最优解变得复杂。  \n- 原因二：梯度消失问题，即在深层网络中，梯度可能在反向传播过程中逐渐变小，导致参数更新缓慢或停滞。"
      },
      {
        "段落": "## 4．6．1 非凸优化问题\n\n神经网络的优化问题是一个非凸优化问题．以一个最简单的 1－1－1 结构的两层神经网络为例，\n\n$$\n\\begin{equation*}\ny=\\sigma\\left(w_{2} \\sigma\\left(w_{1} x\\right)\\right) \\tag{4.91}\n\\end{equation*}\n$$\n\n其中 $w_{1}$ 和 $w_{2}$ 为网络参数，$\\sigma(\\cdot)$ 为 Logistic 函数。\n给定一个输入样本 $(1,1)$ ，分别使用两种损失函数，第一种损失函数为平方误差损失： $\\mathcal{L}\\left(w_{1}, w_{2}\\right)=(1-y)^{2}$ ，第二种损失函数为交叉熵损失 $\\mathcal{L}\\left(w_{1}, w_{2}\\right)=\\log y$ 。当 $x=1, y=1$ 时，其平方误差和交叉嫡损失函数分别为： $\\mathcal{L}\\left(w_{1}, w_{2}\\right)=(1-y)^{2}$ 和 $\\mathcal{L}\\left(w_{1}, w_{2}\\right)=\\log y$ 。损失函数与参数 $w_{1}$ 和 $w_{2}$ 的关系如图4．10所示，可以看出两种损失函数都是关于参数的非凸函数．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-113.jpg?height=482&width=1099&top_left_y=1092&top_left_x=86)\n\n图 4.10 神经网络 $y=\\sigma\\left(w_{2} \\sigma\\left(w_{1} x\\right)\\right)$ 的损失函数",
        "总结": "- 非凸优化问题：神经网络的优化问题属于非凸优化问题，因为损失函数在参数空间中可能存在多个局部极小值点。  \n- 1－1－1结构的神经网络：以一个最简单的两层神经网络为例，其输出表达式为 $y=\\sigma(w_{2} \\sigma(w_{1} x))$，其中 $w_1$ 和 $w_2$ 是网络参数，$\\sigma(\\cdot)$ 是Logistic函数。  \n- 平方误差损失函数：定义为 $\\mathcal{L}(w_1, w_2) = (1 - y)^2$，用于衡量预测输出 $y$ 与目标值 1 的差异。  \n- 交叉熵损失函数：定义为 $\\mathcal{L}(w_1, w_2) = \\log y$，用于衡量预测概率与真实标签之间的差异。  \n- 损失函数的非凸性：当输入样本为 $(1, 1)$ 时，两种损失函数（平方误差和交叉熵）均关于参数 $w_1$ 和 $w_2$ 非凸，如图4.10所示。"
      },
      {
        "段落": "## 4．6．2 梯度消失问题\n\n在神经网络中误差反向传播的迭代公式为\n\n$$\n\\begin{equation*}\n\\delta^{(l)}=f_{l}^{\\prime}\\left(\\boldsymbol{z}^{(l)}\\right) \\odot\\left(\\boldsymbol{W}^{(l+1)}\\right)^{\\top} \\delta^{(l+1)} \\tag{4.92}\n\\end{equation*}\n$$\n\n误差从输出层反向传播时，在每一层都要乘以该层的激活函数的导数．当我们使用 Sigmoid 型函数：Logistic 函数 $\\sigma(x)$ 或 Tanh 函数时，其导数为\n\n$$\n\\begin{equation*}\n\\sigma^{\\prime}(x)=\\sigma(x)(1-\\sigma(x)) \\in[0,0.25] \\tag{4.93}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n$$\n\\begin{equation*}\n\\tanh ^{\\prime}(x)=1-(\\tanh (x))^{2} \\in[0,1] \\tag{4.94}\n\\end{equation*}\n$$\n\nSigmoid 型函数的导数的值域都小于或等于 1 ，如图4．11所示．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-114.jpg?height=391&width=841&top_left_y=324&top_left_x=233)\n\n图 4．11 Sigmoid型函数的导数\n\n由于 Sigmoid 型函数的饱和性，饱和区的导数更是接近于 0 。这样，误差经过每一层传递都会不断衰减．当网络层数很深时，梯度就会不停衰减，甚至消失，使得整个网络很难训练。这就是所谓的梯度消失问题（Vanishing Gradient Problem），也称为梯度弥散问题．\n\n在深度神经网络中，减轻梯度消失问题的方法有很多种．一种简单有效的方式是使用导数比较大的激活函数，比如 ReLU 等。",
        "总结": "- 梯度消失问题是指在深度神经网络中，误差反向传播时梯度不断衰减，最终导致网络难以训练的现象。  \n- 误差反向传播的迭代公式为 $\\delta^{(l)} = f_{l}'(\\boldsymbol{z}^{(l)}) \\odot (\\boldsymbol{W}^{(l+1)})^{\\top} \\delta^{(l+1)}$，每一层误差需乘以该层激活函数的导数。  \n- Sigmoid 型函数（如 Logistic 函数 $\\sigma(x)$ 和 Tanh 函数）的导数值域均小于或等于 1，且在饱和区接近于 0。  \n- Sigmoid 型函数的导数在饱和区接近于 0，导致误差传递时不断衰减，尤其在网络层数较深时，梯度可能完全消失。  \n- 解决梯度消失问题的方法之一是使用导数较大的激活函数，例如 ReLU。"
      },
      {
        "段落": "## 4.7 总结和深入阅读\n\n神经网络是一种典型的分布式并行处理模型，通过大量神经元之间的交互来处理信息，每一个神经元都发送兴奋和抑制的信息到其他神经元［McClel－ land et al．，1986］．和感知器不同，神经网络中的激活函数一般为连续可导函数．表4．2给出了常见激活函数及其导数．在一个神经网络中选择合适的激活函数十分重要。［Ramachandran et al．，2017］设计了不同形式的函数组合方式，并通过强化学习来搜索合适的激活函数，在多个任务上发现 Swish 函数具有更好的性能。\n\n本章介绍的前馈神经网络是一种类型最简单的网络，相邻两层的神经元之间为全连接关系，也称为全连接神经网络（Fully Connected Neural Network， FCNN）或多层感知器。前馈神经网络作为一种机器学习方法在很多模式识别和机器学习的教材中都有介绍，比如《Pattern Recognition and Machine Learning》 ［Bishop，2007］，《Pattern Classification》［Duda et al．，2001］等．\n\n前馈神经网络作为一种能力很强的非线性模型，其能力可以由通用近似定理来保证．关于通用近似定理的详细介绍可以参考［Haykin，2009］．\n\n梯度消失问题在过去的二三十年里一直没有有效地解决，是阻碍神经网络发展的重要原因之一．\n\n更多的优化方法参见第7．1节。\n\n表 4.2 常见激活函数及其导数\n\n| 激活函数 | 函数 | 导数 |\n| :--- | :--- | :--- |\n| Logistic 函数 | $f(x)=\\frac{1}{1+\\exp (-x)}$ | $f^{\\prime}(x)=f(x)(1-f(x))$ |\n| Tanh 函数 | $f(x)=\\frac{\\exp (x)-\\exp (-x)}{\\exp (x)+\\exp (-x)}$ | $f^{\\prime}(x)=1-f(x)^{2}$ |\n| ReLU 函数 | $f(x)=\\max (0, x)$ | $f^{\\prime}(x)=I(x>0)$ |\n| ELU函数 | $\\begin{aligned} & f(x)=\\quad \\max (0, x)+ \\\\ & \\min (0, \\gamma(\\exp (x)-1)) \\end{aligned}$ | $f^{\\prime}(x)=I(x>0)+I(x \\leq 0) \\cdot \\gamma \\exp (x)$ |\n| SoftPlus 函数 | $f(x)=\\log (1+\\exp (x))$ | $f^{\\prime}(x)=\\frac{1}{1+\\exp (-x)}$ |\n\n前馈神经网络在 20 世纪 80 年代后期就已被广泛使用，但是大部分都采用两层网络结构（即一个隐藏层和一个输出层），神经元的激活函数基本上都是 Sigmoid 型函数，并且使用的损失函数也大多数是平方损失。虽然当时前馈神经网络的参数学习依然有很多难点，但其作为一种连接主义的典型模型，标志人工智能从高度符号化的知识期向低符号化的学习期开始转变。\n\nTensorFlow 游乐场 ${ }^{1}$ 提供了一个非常好的神经网络训练过程可视化系统．",
        "总结": "- 神经网络是一种分布式并行处理模型，通过大量神经元之间的交互处理信息，激活函数一般为连续可导函数。  \n- 表4.2列出了常见激活函数及其导数，如Logistic、Tanh、ReLU、ELU和SoftPlus函数。  \n- 选择合适的激活函数对神经网络性能至关重要，Swish函数在多个任务上表现优于其他函数。  \n- 前馈神经网络是最简单的神经网络类型，相邻层神经元全连接，也称为全连接神经网络或多层感知器。  \n- 前馈神经网络作为非线性模型，其能力由通用近似定理保证，该定理确保其能近似任何连续函数。  \n- 梯度消失问题是阻碍神经网络发展的关键问题之一，长期未得到有效解决。  \n- 更多优化方法可参考第7.1节。  \n- 前馈神经网络在20世纪80年代后期广泛使用，多采用两层结构，激活函数多为Sigmoid型，损失函数多为平方损失。  \n- TensorFlow游乐场提供了一个可视化神经网络训练过程的系统。"
      },
      {
        "段落": "## 习题\n\n习题 4－1 对于一个神经元 $\\sigma\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}+b\\right)$ ，并使用梯度下降优化参数 $\\boldsymbol{w}$ 时，如果输入 $\\boldsymbol{x}$ 恒大于 0 ，其收玫速度会比零均值化的输入更慢。\n\n习题 4－2 试设计一个前馈神经网络来解决 XOR 问题，要求该前馈神经网络具有两个隐藏神经元和一个输出神经元，并使用 ReLU 作为激活函数。\n\n习题 4－3 试举例说明＂死亡 ReLU 问题＂，并提出解决方法．\n习题 4－4 计算 Swish 函数和 GELU 函数的导数．\n参见第 4．1．3 节。\n习题 4－5 如果限制一个神经网络的总神经元数量（不考虑输入层）为 $N+1$ ，输入层大小为 $m(0)$ ，输出层大小为 1 ，隐藏层的层数为 $L$ ，每个隐藏层的神经元数量为 $\\frac{N}{L}$ ，试分析参数数量和隐藏层层数 $L$ 的关系。\n\n习题 4－6 证明通用近似定理对于具有线性输出层和至少一个使用 ReLU 激活函数的隐藏层组成的前馈神经网络，也都是适用的。\n\n参见定理 4．1．\n\n[^6]习题 4－7 为什么在神经网络模型的结构化风险函数中不对偏置 $\\boldsymbol{b}$ 进行正则化？",
        "总结": "- 概念：神经元的激活函数、梯度下降优化、输入分布对收敛速度的影响、前馈神经网络、ReLU激活函数、死亡ReLU问题、Swish和GELU函数、通用近似定理、结构化风险函数与正则化。  \n- 算法：梯度下降优化方法、前馈神经网络设计（含ReLU激活函数）、Swish和GELU函数的导数计算。  \n- 定理/命题：通用近似定理适用于具有ReLU激活函数的前馈神经网络。  \n- 数学推导：涉及梯度下降的收敛速度分析、Swish和GELU函数的导数计算。  \n- 其他内容：死亡ReLU问题的示例及解决方法、神经网络参数数量与隐藏层层数的关系分析、结构化风险函数中偏置不进行正则化的原因。"
      },
      {
        "段落": "## 习题 4－8 为什么在用反向传播算法进行参数学习时要采用随机参数初始化\n\n的方式而不是直接令 $\\boldsymbol{W}=0, \\boldsymbol{b}=0$ ？\n习题 4－9 梯度消失问题是否可以通过增加学习率来缓解？",
        "总结": "- 概念：反向传播算法用于神经网络的参数学习，通过计算损失函数相对于参数的梯度来更新参数。  \n- 概念：随机参数初始化是为了打破对称性，确保不同神经元的参数在训练过程中能够独立更新。  \n- 概念：若所有参数初始化为零，则神经元之间会保持对称，导致无法有效学习。  \n- 算法：反向传播算法通过链式法则计算梯度，并利用梯度下降法更新参数。  \n- 问题：梯度消失问题是指在反向传播过程中，梯度逐渐趋近于零，导致参数更新缓慢或停滞。  \n- 问题：增加学习率可能暂时缓解梯度消失问题，但可能导致训练不稳定或发散。"
      },
      {
        "段落": "## 参考文献\n\nBishop C M．Pattern recognition and machine learning［M］．5th edition．Springer， 2007.\nClevert D A，Unterthiner T，Hochreiter S．Fast and accurate deep network learning by exponential linear units（elus）［J］．arXiv preprint arXiv：1511．07289， 2015.\nCybenko G．Approximations by superpositions of a sigmoidal function［J］．Mathematics of Control， Signals and Systems，1989，2：183－192．\nDuda R O，Hart P E，Stork D G．Pattern classification［M］．2nd edition．Wiley， 2001.\nDugas C，Bengio Y，Bélisle F，et al．Incorporating second－order functional knowledge for better option pricing［J］．Advances in Neural Information Processing Systems，2001：472－478．\nFunahashi K i，Nakamura Y．Approximation of dynamical systems by continuous time recurrent neural networks［J］．Neural networks，1993，6（6）：801－806．\nGilmer J，Schoenholz S S，Riley P F，et al．Neural message passing for quantum chemistry［J］．arXiv preprint arXiv：1704．01212， 2017.\nGlorot X，Bordes A，Bengio Y．Deep sparse rectifier neural networks［C］／／Proceedings of Interna－ tional Conference on Artificial Intelligence and Statistics．2011：315－323．\nGoodfellow I J，Warde－Farley D，Mirza M，et al．Maxout networks［C］／／Proceedings of the Interna－ tional Conference on Machine Learning．2013：1319－1327．\nGraves A，Wayne G，Danihelka I．Neural turing machines［J］．arXiv preprint arXiv：1410．5401， 2014.\nHaykin S．Neural networks：A comprehensive foundation：Macmillan college publishing company ［M］．New York， 1994.\nHaykin S．Neural networks and learning machines［M］．3rd edition．Pearson， 2009.\nHe K，Zhang X，Ren S，et al．Delving deep into rectifiers：Surpassing human－level performance on imagenet classification［C］／／Proceedings of the IEEE International Conference on Computer Vision．2015：1026－1034．\nHendrycks D，Gimpel K．Gaussian error linear units（GELUs）［J］．arXiv preprint arXiv：1606．08415， 2016.\n\nHornik K，Stinchcombe M，White H．Multilayer feedforward networks are universal approximators ［J］．Neural networks，1989，2（5）：359－366．\nKipf T N，Welling M．Semi－supervised classification with graph convolutional networks［J］．arXiv preprint arXiv：1609．02907， 2016.\nMaas A L，Hannun A Y，Ng A Y．Rectifier nonlinearities improve neural network acoustic models ［C］／／Proceedings of the International Conference on Machine Learning． 2013.\nMcClelland J L，Rumelhart D E，Group P R．Parallel distributed processing：Explorations in the mi－ crostructure of cognition．volume i：foundations \\＆volume ii：Psychological and biological models ［M］．MIT Press， 1986.\nMcCulloch W S，Pitts W．A logical calculus of the ideas immanent in nervous activity［J］．The bulletin of mathematical biophysics，1943，5（4）：115－133．\nNair V，Hinton G E．Rectified linear units improve restricted boltzmann machines［C］／／Proceedings of the International Conference on Machine Learning．2010：807－814．\nhttps：／／nndl．github．io／\n\nRamachandran P，Zoph B，Le Q V．Searching for activation functions［J］．arXiv preprint arXiv：1710．05941， 2017.\nSukhbaatar S，Weston J，Fergus R，et al．End－to－end memory networks［C］／／Advances in Neural Information Processing Systems．2015：2431－2439．\nVeličković P，Cucurull G，Casanova A，et al．Graph attention networks［J］．arXiv preprint arXiv：1710．10903， 2017.",
        "总结": "- 参考文献列出了多个与神经网络、模式识别和机器学习相关的学术文献，涵盖经典理论、深度学习模型、激活函数研究以及图神经网络等方向。"
      }
    ]
  },
    {
    "标题": "第5章 卷积神经网络",
    "内容": [
      {
        "段落": "一切都应该尽可能地简单，但不能过于简单．\n- 艾伯特•爱因斯坦（Albert Einstein）\n\n卷积神经网络（Convolutional Neural Network，CNN 或 ConvNet）是一种具有局部连接、权重共享等特性的深层前馈神经网络。\n\n卷积神经网络最早主要是用来处理图像信息．在用全连接前馈网络来处理图像时，会存在以下两个问题：\n（1）参数太多：如果输入图像大小为 $100 \\times 100 \\times 3$（即图像高度为 100 ，宽度为 100 以及 RGB 3 个颜色通道），在全连接前馈网络中，第一个隐藏层的每个神经元到输入层都有 $100 \\times 100 \\times 3=30000$ 个互相独立的连接，每个连接都对应一个权重参数。随着隐藏层神经元数量的增多，参数的规模也会急剧增加。这会导致整个神经网络的训练效率非常低，也很容易出现过拟合。\n（2）局部不变性特征：自然图像中的物体都具有局部不变性特征，比如尺度缩放、平移、旋转等操作不影响其语义信息。而全连接前馈网络很难提取这些局部不变性特征，一般需要进行数据增强来提高性能。\n\n卷积神经网络是受生物学上感受野机制的启发而提出的。感受野（Recep－ tive Field）机制主要是指听觉、视觉等神经系统中一些神经元的特性，即神经元只接受其所支配的刺激区域内的信号。在视觉神经系统中，视觉皮层中的神经细胞的输出依赖于视网膜上的光感受器。视网膜上的光感受器受刺激兴奋时，将神经冲动信号传到视觉皮层，但不是所有视觉皮层中的神经元都会接受这些信号。一个神经元的感受野是指视网膜上的特定区域，只有这个区域内的刺激才能够激活该神经元．\n\n目前的卷积神经网络一般是由卷积层、汇聚层和全连接层交叉堆叠而成的前馈神经网络，使用反向传播算法进行训练。\n\n全连接层一般在卷积网络的最顶层。\n\n卷积神经网络有三个结构上的特性：局部连接、权重共享以及汇聚。这些特性使得卷积神经网络具有一定程度上的平移、缩放和旋转不变性。和前馈神经网络相比，卷积神经网络的参数更少。\n\n卷积神经网络主要使用在图像和视频分析的各种任务（比如图像分类、人脸识别、物体识别、图像分割等）上，其准确率一般也远远超出了其他的神经网络模型．近年来卷积神经网络也广泛地应用到自然语言处理、推荐系统等领域．",
        "总结": "- 卷积神经网络（CNN 或 ConvNet）是一种具有局部连接、权重共享等特性的深层前馈神经网络  \n- 卷积神经网络最初用于处理图像信息，解决了全连接网络参数过多和难以提取局部不变性特征的问题  \n- 卷积神经网络受生物学感受野机制启发，模拟视觉系统中神经元只响应特定区域的特性  \n- 卷积神经网络通常由卷积层、汇聚层和全连接层交叉堆叠构成，使用反向传播算法进行训练  \n- 全连接层一般位于卷积网络的最顶层  \n- 卷积神经网络具有局部连接、权重共享和汇聚三个结构特性，使其具备一定程度的平移、缩放和旋转不变性  \n- 与全连接网络相比，卷积神经网络参数更少，适合处理图像、视频等数据  \n- 卷积神经网络广泛应用于图像分类、人脸识别、物体识别、图像分割等任务，并在自然语言处理、推荐系统等领域得到应用"
      },
      {
        "段落": "## 5.1 卷积\n\n卷积（Convolution），也叫褶积，是分析数学中一种重要的运算。在信号处理或图像处理中，经常使用一维或二维卷积。\n\n一维卷积 一维卷积经常用在信号处理中，用于计算信号的延迟累积。假设一个信号发生器每个时刻 $t$ 产生一个信号 $x_{t}$ ，其信息的衰减率为 $w_{k}$ ，即在 $k-1$ 个时间步长后，信息为原来的 $w_{k}$ 倍。假设 $w_{1}=1, w_{2}=1 / 2, w_{3}=1 / 4$ ，那么在时刻 $t$ 收到的信号 $y_{t}$ 为当前时刻产生的信息和以前时刻延迟信息的叠加，\n\n$$\n\\begin{align*}\ny_{t} & =1 \\times x_{t}+1 / 2 \\times x_{t-1}+1 / 4 \\times x_{t-2}  \\tag{5.1}\\\\\n& =w_{1} \\times x_{t}+w_{2} \\times x_{t-1}+w_{3} \\times x_{t-2}  \\tag{5.2}\\\\\n& =\\sum_{k=1}^{3} w_{k} x_{t-k+1} \\tag{5.3}\n\\end{align*}\n$$\n\n我们把 $w_{1}, w_{2}, \\cdots$ 称为滤波器（Filter）或卷积核（Convolution Kernel）。假设滤波器长度为 $K$ ，它和一个信号序列 $x_{1}, x_{2}, \\cdots$ 的卷积为\n\n$$\n\\begin{equation*}\ny_{t}=\\sum_{k=1}^{K} w_{k} x_{t-k+1} \\tag{5.4}\n\\end{equation*}\n$$\n\n信号序列 $\\boldsymbol{x}$ 和滤波器 $\\boldsymbol{w}$ 的卷积定义为\n\n$$\n\\begin{equation*}\ny=w * x \\tag{5.5}\n\\end{equation*}\n$$\n\n其中＊表示卷积运算。\n一般情况下滤波器的长度 $K$ 远小于信号序列长度 $N$ 。图5．1给出了一维卷积示例．滤波器为 $[-1,0,1]$ ，连接边上的数字为滤波器中的权重．\n\n当滤波器 $w_{k}=1 / K, 1 \\leq k \\leq K$ 时，卷积相当于信号序列的简单移动平均 （窗口大小为 $K$ ）。\n\n这里我们只考虑离散序列的情况。\n\n移动平均（Moving Av－ erage，MA）是在分析时间序列数据时的一种简单平滑技术，能有效地消除数据中的随机波动．移动平均可以看作是一种卷积．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-120.jpg?height=275&width=696&top_left_y=117&top_left_x=301)\n\n图 5.1 一维卷积示例（滤波器为 $[-1,0,1]$ ）\n\n二维卷积 卷积也经常用在图像处理中。因为图像为一个二维结构，所以需要将一维卷积进行扩展。给定一个图像 $\\boldsymbol{X} \\in \\mathbb{R}^{M \\times N}$ 和滤波器 $\\boldsymbol{W} \\in \\mathbb{R}^{U \\times V}$ ，一般 $U \\ll M, V \\ll N$ ，其卷积为\n\n$$\n\\begin{equation*}\ny_{i j}=\\sum_{u=1}^{U} \\sum_{v=1}^{V} w_{u v} x_{i-u+1, j-v+1} \\tag{5.6}\n\\end{equation*}\n$$\n\n一个输入信息 $\\boldsymbol{X}$ 和滤波器 $\\boldsymbol{W}$ 的二维卷积定义为\n\n$$\n\\begin{equation*}\nY=\\boldsymbol{W} * \\boldsymbol{X} \\tag{5.7}\n\\end{equation*}\n$$\n\n其中＊表示二维卷积运算。\n图 5.2 给出了二维卷积示例．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-120.jpg?height=359&width=937&top_left_y=1193&top_left_x=185)\n\n图 5.2 二维卷积示例\n\n在图像处理中常用的均值滤波（Mean Filter）就是一种二维卷积，将当前位置的像素值设为滤波器窗口中所有像素的平均值，即 $w_{u v}=\\frac{1}{U V}$ ．\n\n在图像处理中，卷积经常作为特征提取的有效方法．一幅图像在经过卷积操作后得到结果称为特征映射（Feature Map）。图5．3给出在图像处理中几种常用的滤波器，以及其对应的特征映射。图中最上面的滤波器是常用的高斯滤波器，可以用来对图像进行平滑去噪；中间和最下面的滤波器可以用来提取边缘特征．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-121.jpg?height=920&width=1014&top_left_y=110&top_left_x=151)\n\n图 5.3 图像处理中几种常用的滤波器示例",
        "总结": "- 卷积是一种重要的数学运算，广泛应用于信号处理和图像处理中，分为一维和二维卷积。\n- 一维卷积用于计算信号的延迟累积，通过滤波器（或卷积核）对信号进行加权求和，其形式为 $ y_t = \\sum_{k=1}^{K} w_k x_{t-k+1} $。\n- 滤波器的权重 $ w_1, w_2, \\cdots $ 决定了信号的加权方式，常用于平滑或提取特征。\n- 当滤波器权重为均匀分布时，卷积等价于移动平均（MA），用于消除数据中的随机波动。\n- 二维卷积是将一维卷积扩展到图像处理中，用于提取图像特征，形式为 $ y_{ij} = \\sum_{u=1}^{U} \\sum_{v=1}^{V} w_{uv} x_{i-u+1, j-v+1} $。\n- 常见的二维卷积应用包括均值滤波和高斯滤波，分别用于图像平滑和边缘检测。\n- 卷积操作后得到的结果称为特征映射（Feature Map），是图像处理中提取特征的重要手段。"
      },
      {
        "段落": "## 5．1．1 互相关\n\n在机器学习和图像处理领域，卷积的主要功能是在一个图像（或某种特征）上滑动一个卷积核（即滤波器），通过卷积操作得到一组新的特征。在计算卷积的过程中，需要进行卷积核翻转。在具体实现上，一般会以互相关操作来代替卷积，从而会减少一些不必要的操作或开销。互相关（Cross－Correlation）是一个衡量两个序列相关性的函数，通常是用滑动窗口的点积计算来实现。给定一个图像\n\n翻转就是从两个维度 （从上到下、从左到右）颠倒次序，即旋转 180度． $\\boldsymbol{X} \\in \\mathbb{R}^{M \\times N}$ 和卷积核 $\\boldsymbol{W} \\in \\mathbb{R}^{U \\times V}$ ，它们的互相关为\n\n$$\n\\begin{equation*}\ny_{i j}=\\sum_{u=1}^{U} \\sum_{v=1}^{V} w_{u v} x_{i+u-1, j+v-1} \\tag{5.8}\n\\end{equation*}\n$$\n\n和公式（5．6）对比可知，互相关和卷积的区别仅仅在于卷积核是否进行翻转。因此互相关也可以称为不翻转卷积．\n\n公式（5．8）可以表述为\n\n$$\n\\begin{align*}\nY & =\\boldsymbol{W} \\otimes \\boldsymbol{X}  \\tag{5.9}\\\\\n& =\\operatorname{rot} 180(\\boldsymbol{W}) * \\boldsymbol{X}, \\tag{5.10}\n\\end{align*}\n$$\n\n其中 $\\otimes$ 表示互相关运算， $\\operatorname{rot180(\\cdot )}$ 表示旋转 180 度，$Y \\in \\mathbb{R}^{M-U+1, N-V+1}$ 为输出 https：／／nndl．github．io／\n\n互相关和卷积的区别也可以理解为图像是否进行翻转。\n\n矩阵。\n在神经网络中使用卷积是为了进行特征抽取，卷积核是否进行翻转和其特征抽取的能力无关．特别是当卷积核是可学习的参数时，卷积和互相关在能力上是等价的。因此，为了实现上（或描述上）的方便起见，我们用互相关来代替卷积。事实上，很多深度学习工具中卷积操作其实都是互相关操作。",
        "总结": "- 互相关（Cross-Correlation）是一种衡量两个序列相关性的函数，通常通过滑动窗口的点积计算实现  \n- 互相关与卷积的主要区别在于卷积核是否进行翻转，互相关可视为不翻转卷积  \n- 互相关的数学表达式为 $ y_{ij} = \\sum_{u=1}^{U} \\sum_{v=1}^{V} w_{uv} x_{i+u-1, j+v-1} $  \n- 互相关运算符用 $ \\otimes $ 表示，而卷积运算符用 $ * $ 表示，两者在能力上是等价的  \n- 在神经网络中，卷积核是否翻转不影响特征抽取能力，尤其当卷积核是可学习参数时  \n- 为了实现或描述上的方便，通常用互相关代替卷积，许多深度学习工具中的卷积操作实际上就是互相关操作"
      },
      {
        "段落": "## 5．1．2 卷积的变种\n\n在卷积的标准定义基础上，还可以引入滤波器的滑动步长和零填充来增加卷积的多样性，可以更灵活地进行特征抽取。\n\n滤波器的步长（Stride）是指滤波器在滑动时的时间间隔．图5．4a给出了步长为 2 的卷积示例．\n\n零填充（Zero Padding）是在输入向量两端进行补零．图5．4b给出了输入的两端各补一个零后的卷积示例。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-122.jpg?height=597&width=599&top_left_y=903&top_left_x=354)\n\n图 5.4 卷积的步长和零填充\n\n假设卷积层的输入神经元个数为 $M$ ，卷积大小为 $K$ ，步长为 $S$ ，在输入两端各填补 $P$ 个 0 （zero padding），那么该卷积层的神经元数量为 $(M-K+2 P) / S+1$ 。\n\n一般常用的卷积有以下三类：\n（1）窄卷积（Narrow Convolution）：步长 $S=1$ ，两端不补零 $P=0$ ，卷积后输出长度为 $M-K+1$ ．\n（2）宽卷积（Wide Convolution）：步长 $S=1$ ，两端补零 $P=M-1$ ，卷积后输出长度 $M+K-1$ ．\n（3）等宽卷积（Equal－Width Convolution）：步长 $S=1$ ，两端补零 $P=(K-$ $1) / 2$ ，卷积后输出长度 $M$ ．图 5.4 b 就是一个等宽卷积示例．\nhttps：／／nndl．github．io／\n\n在本书之后描述中，除非特别声明，卷积一般指＂互相关＂．卷积符号用 $\\otimes$ 来表示，即不翻转卷积．真正的卷积用＊来表示。\n\n步长也可以小于 1 ，即微步卷积，参见第 5．5．1节。\n\n通常可以通过选择合适的卷积大小以及步长来使得 $(M-K+$ $2 P) / S+1$ 为整数．",
        "总结": "- 概念：卷积的变种，包括滑动步长和零填充，用于增强特征抽取的灵活性。  \n- 算法：卷积操作中引入步长（Stride）和零填充（Zero Padding）来调整输出长度。  \n- 公式：卷积层输出神经元数量为 $(M-K+2P)/S+1$，其中 $M$ 为输入神经元数，$K$ 为卷积大小，$S$ 为步长，$P$ 为零填充数量。  \n- 定理/命题：窄卷积、宽卷积、等宽卷积三种类型分别对应不同的步长和零填充设置，输出长度分别为 $M-K+1$、$M+K-1$ 和 $M$。  \n- 数学推导：通过调整步长和零填充参数，可使输出长度为整数，满足实际应用需求。  \n- 其他说明：文中提到卷积一般指“互相关”，使用符号 $\\otimes$ 表示，而真正的卷积使用符号 $*$。微步卷积（步长小于 1）在后续章节中进一步讨论。"
      },
      {
        "段落": "## 5．1．3 卷积的数学性质\n\n卷积有很多很好的数学性质。在本节中，我们介绍一些二维卷积的数学性质，这些数学性质同样可以适用到一维卷积的情况。",
        "总结": "- 卷积具有交换性，即两个函数的卷积顺序可以交换，结果不变。  \n- 卷积具有结合性，即多个函数的卷积可以按任意顺序结合进行。  \n- 卷积具有分配性，即卷积运算对加法运算具有分配律。  \n- 卷积与微分运算之间存在关系，卷积可以表示为微分运算的线性组合。  \n- 卷积与积分运算之间存在关系，卷积可以表示为积分运算的线性组合。  \n- 卷积在变换域（如傅里叶变换域）中具有简便的性质，例如卷积定理指出卷积在时域中的运算对应于频域中的乘法运算。"
      },
      {
        "段落": "### 5．1．3．1 交换性\n\n如果不限制两个卷积信号的长度，真正的翻转卷积是具有交换性的，即 $\\boldsymbol{x} *$ $\\boldsymbol{y}=\\boldsymbol{y} * \\boldsymbol{x}$ ．对于互相关的＂卷积＂，也同样具有一定的＂交换性＂．\n\n我们先介绍宽卷积（Wide Convolution）的定义。 给定一个二维图像 $\\boldsymbol{X} \\in$ $\\mathbb{R}^{M \\times N}$ 和一个二维卷积核 $\\boldsymbol{W} \\in \\mathbb{R}^{U \\times V}$ ，对图像 $\\boldsymbol{X}$ 进行零填充，两端各补 $U-1$ 和 $V-1$ 个零，得到全填充（Full Padding）的图像 $\\tilde{\\boldsymbol{X}} \\in \\mathbb{R}^{(M+2 U-2) \\times(N+2 V-2)}$ 。图像 $\\boldsymbol{X}$ 和卷积核 $\\boldsymbol{W}$ 的宽卷积定义为\n\n$$\n\\begin{equation*}\n\\boldsymbol{W} \\tilde{\\otimes} \\boldsymbol{X} \\triangleq \\boldsymbol{W} \\otimes \\tilde{\\boldsymbol{X}}, \\tag{5.11}\n\\end{equation*}\n$$\n\n其中 $\\tilde{\\otimes}$ 表示宽卷积运算。\n当输入信息和卷积核有固定长度时，它们的宽卷积依然具有交换性，即\n参见习题 5－1．\n\n$$\n\\begin{equation*}\n\\operatorname{rot180}(\\boldsymbol{W}) \\tilde{\\otimes} \\boldsymbol{X}=\\operatorname{rot180}(\\boldsymbol{X}) \\tilde{\\otimes} \\boldsymbol{W} \\tag{5.12}\n\\end{equation*}\n$$\n\n其中 rot180（•）表示旋转 180 度。",
        "总结": "- 交换性：真正的翻转卷积在不限制信号长度时具有交换性，即 $\\boldsymbol{x} * \\boldsymbol{y} = \\boldsymbol{y} * \\boldsymbol{x}$。\n- 宽卷积定义：宽卷积是对图像进行零填充后，使用标准卷积运算实现的卷积操作，记为 $\\tilde{\\otimes}$。\n- 宽卷积的交换性：当输入信息和卷积核有固定长度时，宽卷积也具有交换性，但需对卷积核和图像进行180度旋转，即 $\\operatorname{rot180}(\\boldsymbol{W}) \\tilde{\\otimes} \\boldsymbol{X} = \\operatorname{rot180}(\\boldsymbol{X}) \\tilde{\\otimes} \\boldsymbol{W}$。"
      },
      {
        "段落": "### 5．1．3．2 导数\n\n假设 $Y=\\boldsymbol{W} \\otimes \\boldsymbol{X}$ ，其中 $\\boldsymbol{X} \\in \\mathbb{R}^{M \\times N}, \\boldsymbol{W} \\in \\mathbb{R}^{U \\times V}, Y \\in \\mathbb{R}^{(M-U+1) \\times(N-V+1)}$ ，函数 $f(Y) \\in \\mathbb{R}$ 为一个标量函数，则\n\n$$\n\\begin{align*}\n\\frac{\\partial f(Y)}{\\partial w_{u v}} & =\\sum_{i=1}^{M-U+1} \\sum_{j=1}^{N-V+1} \\frac{\\partial y_{i j}}{\\partial w_{u v}} \\frac{\\partial f(Y)}{\\partial y_{i j}}  \\tag{5.13}\\\\\n& =\\sum_{i=1}^{M-U+1} \\sum_{j=1}^{N-V+1} x_{i+u-1, j+v-1} \\frac{\\partial f(Y)}{\\partial y_{i j}}  \\tag{5.14}\\\\\n& =\\sum_{i=1}^{M-U+1} \\sum_{j=1}^{N-V+1} \\frac{\\partial f(Y)}{\\partial y_{i j}} x_{u+i-1, v+j-1} \\tag{5.15}\n\\end{align*}\n$$\n\n从公式（5．15）可以看出，$f(Y)$ 关于 $\\boldsymbol{W}$ 的偏导数为 $\\boldsymbol{X}$ 和 $\\frac{\\partial f(Y)}{\\partial Y}$ 的卷积\n\n$$\n\\begin{equation*}\n\\frac{\\partial f(Y)}{\\partial \\boldsymbol{W}}=\\frac{\\partial f(Y)}{\\partial Y} \\otimes \\boldsymbol{X} \\tag{5.16}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n同理得到，\n\n$$\n\\begin{align*}\n\\frac{\\partial f(Y)}{\\partial x_{S t}} & =\\sum_{i=1}^{M-U+1} \\sum_{j=1}^{N-V+1} \\frac{\\partial y_{i j}}{\\partial x_{S t}} \\frac{\\partial f(Y)}{\\partial y_{i j}}  \\tag{5.17}\\\\\n& =\\sum_{i=1}^{M-U+1} \\sum_{j=1}^{N-V+1} w_{S-i+1, t-j+1} \\frac{\\partial f(Y)}{\\partial y_{i j}} \\tag{5.18}\n\\end{align*}\n$$\n\n其中当 $(s-i+1)<1$ ，或 $(s-i+1)>U$ ，或 $(t-j+1)<1$ ，或 $(t-j+1)>V$ 时， $w_{S-i+1, t-j+1}=0$ ．即相当于对 $\\boldsymbol{W}$ 进行了 $P=(M-U, N-V)$ 的零填充．\n\n从公式（5．18）可以看出，$f(Y)$ 关于 $\\boldsymbol{X}$ 的偏导数为 $\\boldsymbol{W}$ 和 $\\frac{\\partial f(Y)}{\\partial Y}$ 的宽卷积。公式 （5．18）中的卷积是真正的卷积而不是互相关，为了一致性，我们用互相关的＂卷积＂，即\n\n$$\n\\begin{align*}\n\\frac{\\partial f(Y)}{\\partial \\boldsymbol{X}} & =\\operatorname{rot} 180\\left(\\frac{\\partial f(Y)}{\\partial Y}\\right) \\tilde{\\otimes} \\boldsymbol{W}  \\tag{5.19}\\\\\n& =\\operatorname{rot} 180(\\boldsymbol{W}) \\tilde{\\otimes} \\frac{\\partial f(Y)}{\\partial Y} \\tag{5.20}\n\\end{align*}\n$$\n\n其中 $\\operatorname{rot180(\\cdot )}$ 表示旋转 180 度。",
        "总结": "- 概念：导数在张量运算中的应用，特别是涉及卷积操作时的偏导数计算。  \n- 算法：推导了标量函数 $f(Y)$ 关于卷积核 $\\boldsymbol{W}$ 和输入 $\\boldsymbol{X}$ 的偏导数，分别通过卷积和宽卷积的形式表达。  \n- 定理/命题：$f(Y)$ 关于 $\\boldsymbol{W}$ 的偏导数为 $\\boldsymbol{X}$ 和 $\\frac{\\partial f(Y)}{\\partial Y}$ 的卷积，即 $\\frac{\\partial f(Y)}{\\partial \\boldsymbol{W}} = \\frac{\\partial f(Y)}{\\partial Y} \\otimes \\boldsymbol{X}$。  \n- 数学推导：通过链式法则展开偏导数，利用卷积的性质将结果表示为卷积或宽卷积形式，并引入旋转操作以保持与互相关的兼容性。"
      },
      {
        "段落": "## 5.2 卷积神经网络\n\n卷积神经网络一般由卷积层、汇聚层和全连接层构成。",
        "总结": "- 卷积神经网络的基本结构包括卷积层、汇聚层和全连接层。  \n- 卷积层通过卷积操作提取输入数据的局部特征。  \n- 汇聚层用于降低数据的空间维度，减少参数数量，同时保留重要信息。  \n- 全连接层将前面提取的特征进行整合，用于最终的分类或回归任务。"
      },
      {
        "段落": "## 5．2．1 用卷积来代替全连接\n\n在全连接前馈神经网络中，如果第 $l$ 层有 $M_{l}$ 个神经元，第 $l-1$ 层有 $M_{l-1}$ 个神经元，连接边有 $M_{l} \\times M_{l-1}$ 个，也就是权重矩阵有 $M_{l} \\times M_{l-1}$ 个参数。当 $M_{l}$ 和 $M_{l-1}$ 都很大时，权重矩阵的参数非常多，训练的效率会非常低。\n\n如果采用卷积来代替全连接，第 $l$ 层的净输入 $\\boldsymbol{z}^{(l)}$ 为第 $l-1$ 层活性值 $\\boldsymbol{a}^{(l-1)}$和滤波器 $\\boldsymbol{w}^{(l)} \\in \\mathbb{R}^{K}$ 的卷积，即\n\n$$\n\\begin{equation*}\n\\boldsymbol{z}^{(l)}=\\boldsymbol{w}^{(l)} \\otimes \\boldsymbol{a}^{(l-1)}+b^{(l)} \\tag{5.21}\n\\end{equation*}\n$$\n\n其中滤波器 $\\boldsymbol{w}^{(l)} \\in \\mathbb{R}^{K}$ 为可学习的权重向量，$b^{(l)} \\in \\mathbb{R}$ 为可学习的偏置．\n根据卷积的定义，卷积层有两个很重要的性质：\n局部连接 在卷积层（假设是第 $l$ 层）中的每一个神经元都只和下一层（第 $l-1$层）中某个局部窗口内的神经元相连，构成一个局部连接网络。如图5．5b所示，卷积层和下一层之间的连接数大大减少，由原来的 $M_{l} \\times M_{l-1}$ 个连接变为 $M_{l} \\times K$ 个连接，$K$ 为滤波器大小。\nhttps：／／nndl．github．io／\n\n权重共享 从公式（5．21）可以看出，作为参数的滤波器 $\\boldsymbol{w}^{(l)}$ 对于第 $l$ 层的所有的神经元都是相同的。如图5．5b中，所有的同颜色连接上的权重是相同的。权重共享可以理解为一个滤波器只捕捉输入数据中的一种特定的局部特征。因此，如果要提取多种特征就需要使用多个不同的滤波器．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-125.jpg?height=576&width=584&top_left_y=352&top_left_x=372)\n\n图 5.5 全连接层和卷积层对比\n\n由于局部连接和权重共享，卷积层的参数只有一个 $K$ 维的权重 $\\boldsymbol{w}^{(l)}$ 和 1 维的偏置 $b^{(l)}$ ，共 $K+1$ 个参数．参数个数和神经元的数量无关．此外，第 $l$ 层的神经元个数不是任意选择的，而是满足 $M_{l}=M_{l-1}-K+1$ ．",
        "总结": "- 概念：卷积层通过局部连接和权重共享替代全连接层，以减少参数数量和提高训练效率。\n- 算法：卷积操作定义为第 $l$ 层的净输入 $\\boldsymbol{z}^{(l)}$ 是第 $l-1$ 层活性值 $\\boldsymbol{a}^{(l-1)}$ 与滤波器 $\\boldsymbol{w}^{(l)}$ 的卷积，加上偏置 $b^{(l)}$。\n- 定理/命题：卷积层的参数数量仅取决于滤波器大小 $K$ 和偏置 $b^{(l)}$，共 $K+1$ 个参数，与神经元数量无关。\n- 数学推导：卷积层的参数个数由 $K+1$ 决定，且第 $l$ 层神经元个数满足 $M_{l}=M_{l-1}-K+1$。"
      },
      {
        "段落": "## 5．2．2 卷积层\n\n卷积层的作用是提取一个局部区域的特征，不同的卷积核相当于不同的特征提取器。上一节中描述的卷积层的神经元和全连接网络一样都是一维结构。由于卷积网络主要应用在图像处理上，而图像为二维结构，因此为了更充分地利用图像的局部信息，通常将神经元组织为三维结构的神经层，其大小为高度 $M \\times$ 宽度 $N \\times$ 深度 $D$ ，由 $D$ 个 $M \\times N$ 大小的特征映射构成．\n\n特征映射（Feature Map）为一幅图像（或其他特征映射）在经过卷积提取到的特征，每个特征映射可以作为一类抽取的图像特征。为了提高卷积网络的表示能力，可以在每一层使用多个不同的特征映射，以更好地表示图像的特征。\n\n在输入层，特征映射就是图像本身。如果是灰度图像，就是有一个特征映射，输入层的深度 $D=1$ ；如果是彩色图像，分别有 RGB 三个颜色通道的特征映射，输入层的深度 $D=3$ ．\n\n不失一般性，假设一个卷积层的结构如下：\n（1）输入特征映射组：$X \\in \\mathbb{R}^{M \\times N \\times D}$ 为三维张量（Tensor），其中每个切片 https：／／nndl．github．io／\n（Slice）矩阵 $\\boldsymbol{X}^{d} \\in \\mathbb{R}^{M \\times N}$ 为一个输入特征映射， $1 \\leq d \\leq D$ ；\n（2）输出特征映射组：$Y \\in \\mathbb{R}^{M^{\\prime} \\times N^{\\prime} \\times P}$ 为三维张量，其中每个切片矩阵 $Y^{p} \\in$ $\\mathbb{R}^{M^{\\prime} \\times N^{\\prime}}$ 为一个输出特征映射， $1 \\leq p \\leq P$ ；\n（3）卷积核：$W \\in \\mathbb{R}^{U \\times V \\times D \\times P}$ 为四维张量，其中每个切片矩阵 $\\boldsymbol{W}^{p, d} \\in \\mathbb{R}^{U \\times V}$ 为一个二维卷积核， $1 \\leq d \\leq D, 1 \\leq p \\leq P$ 。\n\n图 5.6 给出卷积层的三维结构表示．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-126.jpg?height=452&width=1144&top_left_y=526&top_left_x=90)\n\n图 5.6 卷积层的三维结构表示\n\n为了计算输出特征映射 $Y^{p}$ ，用卷积核 $\\boldsymbol{W}^{p, 1}, \\boldsymbol{W}^{p, 2}, \\cdots, \\boldsymbol{W}^{p, D}$ 分别对输入特征映射 $\\boldsymbol{X}^{1}, \\boldsymbol{X}^{2}, \\cdots, \\boldsymbol{X}^{D}$ 进行卷积，然后将卷积结果相加，并加上一个标量偏置 $b$ 得到卷积层的净输入 $Z^{p}$ ，再经过非线性激活函数后得到输出特征映射 $Y^{p}$ 。\n\n$$\n\\begin{align*}\n\\boldsymbol{Z}^{p} & =\\boldsymbol{W}^{p} \\otimes \\boldsymbol{X}+b^{p}=\\sum_{d=1}^{D} \\boldsymbol{W}^{p, d} \\otimes \\boldsymbol{X}^{d}+b^{p},  \\tag{5.22}\\\\\n\\boldsymbol{Y}^{p} & =f\\left(\\boldsymbol{Z}^{p}\\right) . \\tag{5.23}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{W}^{p} \\in \\mathbb{R}^{U \\times V \\times D}$ 为三维卷积核，$f(\\cdot)$ 为非线性激活函数，一般用 ReLU 函数．\n整个计算过程如图5．7所示。如果希望卷积层输出 $P$ 个特征映射，可以将上述计算过程重复 $P$ 次，得到 $P$ 个输出特征映射 $\\boldsymbol{Y}^{1}, \\boldsymbol{Y}^{2}, \\cdots, \\boldsymbol{Y}^{P}$ 。\n\n在输入为 $X \\in \\mathbb{R}^{M \\times N \\times D}$ ，输出为 $Y \\in \\mathbb{R}^{M^{\\prime} \\times N^{\\prime} \\times P}$ 的卷积层中，每一个输出特征映射都需要 $D$ 个滤波器以及一个偏置．假设每个滤波器的大小为 $U \\times V$ ，那么共需要 $P \\times D \\times(U \\times V)+P$ 个参数．",
        "总结": "- 卷积层的作用是提取局部区域的特征，不同的卷积核对应不同的特征提取器  \n- 卷积层的神经元结构由一维扩展为三维，用于更好地利用图像的局部信息  \n- 特征映射是图像或特征映射经过卷积提取后的特征，每个特征映射代表一类图像特征  \n- 输入层的特征映射对应图像本身，灰度图像深度为1，彩色图像深度为3  \n- 卷积层结构包括输入特征映射组、输出特征映射组和卷积核，分别对应三维张量  \n- 卷积核为四维张量，每个切片为二维卷积核，用于对输入特征映射进行卷积操作  \n- 输出特征映射通过卷积核与输入特征映射的卷积、求和及偏置相加得到净输入，再经非线性激活函数得到  \n- 非线性激活函数通常使用ReLU函数  \n- 卷积层的参数数量由滤波器数量、大小及偏置决定，计算公式为 $P \\times D \\times (U \\times V) + P$"
      },
      {
        "段落": "## 5．2．3 汇聚层\n\n汇聚层（Pooling Layer）也叫子采样层（Subsampling Layer），其作用是进行特征选择，降低特征数量，从而减少参数数量．\n\n这里净输入是指没有经过非线性激活函数的净活性值（Net Acti－ vation）．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-127.jpg?height=518&width=921&top_left_y=116&top_left_x=195)\n\n图 5.7 卷积层中从输入特征映射组 $\\boldsymbol{X}$ 到输出特征映射 $Y^{p}$ 的计算示例\n\n卷积层虽然可以显著减少网络中连接的数量，但特征映射组中的神经元个数并没有显著减少。如果后面接一个分类器，分类器的输入维数依然很高，很容易出现过拟合。为了解决这个问题，可以在卷积层之后加上一个汇聚层，从而降低特征维数，避免过拟合。\n\n假设汇聚层的输入特征映射组为 $X \\in \\mathbb{R}^{M \\times N \\times D}$ ，对于其中每一个特征映射\n\n减少特征维数也可以通过增加卷积步长来实现． $\\boldsymbol{X}^{d} \\in \\mathbb{R}^{M \\times N}, 1 \\leq d \\leq D$ ，将其划分为很多区域 $R_{m, n}^{d}, 1 \\leq m \\leq M^{\\prime}, 1 \\leq n \\leq N^{\\prime}$ ，这些区域可以重叠，也可以不重叠。汇聚（Pooling）是指对每个区域进行下采样 （Down Sampling）得到一个值，作为这个区域的概括。\n\n常用的汇聚函数有两种：\n1．最大汇聚（Maximum Pooling 或 Max Pooling）：对于一个区域 $R_{m, n}^{d}$ ，选择这个区域内所有神经元的最大活性值作为这个区域的表示．\n\n$$\n\\begin{equation*}\ny_{m, n}^{d}=\\max _{i \\in R_{m, n}^{d}} x_{i} \\tag{5.24}\n\\end{equation*}\n$$\n\n其中 $x_{i}$ 为区域 $R_{k}^{d}$ 内每个神经元的活性值．\n2．平均汇聚（Mean Pooling）：一般是取区域内所有神经元活性值的平均值．\n\n$$\n\\begin{equation*}\ny_{m, n}^{d}=\\frac{1}{\\left|R_{m, n}^{d}\\right|} \\sum_{i \\in R_{m, n}^{d}} x_{i} . \\tag{5.25}\n\\end{equation*}\n$$\n\n对每一个输入特征映射 $\\boldsymbol{X}^{d}$ 的 $M^{\\prime} \\times N^{\\prime}$ 个区域进行子采样，得到汇聚层的输出特征映射 $\\boldsymbol{Y}^{d}=\\left\\{y_{m, n}^{d}\\right\\}, 1 \\leq m \\leq M^{\\prime}, 1 \\leq n \\leq N^{\\prime}$ 。\n\n图 5.8 给出了采样最大汇聚进行子采样操作的示例．可以看出，汇聚层不但可以有效地减少神经元的数量，还可以使得网络对一些小的局部形态改变保持不变性，并拥有更大的感受野。\nhttps：／／nndl．github．io／\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-128.jpg?height=521&width=945&top_left_y=112&top_left_x=183)\n\n图 5.8 汇聚层中最大汇聚过程示例\n\n目前主流的卷积网络中，汇聚层仅包含下采样操作。但在早期的一些卷积网络（比如 LeNet－5）中，有时也会在汇聚层使用非线性激活函数，比如\n\n$$\n\\begin{equation*}\n\\boldsymbol{Y}^{\\prime d}=f\\left(w^{d} \\boldsymbol{Y}^{d}+b^{d}\\right) \\tag{5.26}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{Y}^{\\prime} d$ 为汇聚层的输出，$f(\\cdot)$ 为非线性激活函数，$w^{d}$ 和 $b^{d}$ 为可学习的标量权重和偏置。\n\n典型的汇聚层是将每个特征映射划分为 $2 \\times 2$ 大小的不重叠区域，然后使用最大汇聚的方式进行下采样。汇聚层也可以看作是一个特殊的卷积层，卷积核大小为 $K \\times K$ ，步长为 $S \\times S$ ，卷积核为 max 函数或 mean 函数。过大的采样区域会急剧减少神经元的数量，也会造成过多的信息损失。",
        "总结": "- 汇聚层（Pooling Layer）也称为子采样层（Subsampling Layer），其作用是进行特征选择，降低特征数量，从而减少参数数量。  \n- 汇聚层通过将输入特征映射划分为多个区域，并对每个区域进行下采样操作，以减少神经元数量。  \n- 常见的汇聚方法包括最大汇聚（Max Pooling）和平均汇聚（Mean Pooling）。最大汇聚选择区域内最大值作为输出，平均汇聚则取区域内值的平均。  \n- 汇聚层可以提高网络对局部形态变化的鲁棒性，并扩大感受野。  \n- 汇聚层通常仅包含下采样操作，但在某些早期网络中也可能结合非线性激活函数。  \n- 典型的汇聚层将每个特征映射划分为 $2 \\times 2$ 不重叠区域，并使用最大汇聚进行下采样。  \n- 汇聚层可视为一种特殊的卷积层，其卷积核为 max 或 mean 函数，步长与核大小相关。  \n- 过大的采样区域会导致神经元数量急剧减少，并可能造成信息损失。"
      },
      {
        "段落": "## 5．2．4 典型的卷积网络结构\n\n一个典型的卷积网络是由卷积层、汇聚层、全连接层交叉堆叠而成。目前常用的卷积网络结构如图5．9所示。一个卷积块为连续 $M$ 个卷积层和 $b$ 个汇聚层 （ $M$ 通常设置为 $2 \\sim 5, b$ 为 0 或 1 ）。一个卷积网络中可以堆叠 $N$ 个连续的卷积块，然后在后面接着 $K$ 个全连接层（ $N$ 的取值区间比较大，比如 $1 \\sim 100$ 或者更大；$K$一般为 $0 \\sim 2$ ）。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-128.jpg?height=271&width=1124&top_left_y=1763&top_left_x=96)\n\n图 5.9 典型的卷积网络结构\n\n目前，整个网络结构趋向于使用更小的卷积核（比如 $1 \\times 1$ 和 $3 \\times 3$ ）以及更深的结构（比如层数大于50）。此外，由于卷积的操作性越来越灵活（比如不同的步长），汇聚层的作用也变得越来越小，因此目前比较流行的卷积网络中，汇聚层的比例正在逐渐降低，趋向于全卷积网络。",
        "总结": "- 典型的卷积网络结构由卷积层、汇聚层和全连接层交叉堆叠组成  \n- 卷积块包含连续 $M$ 个卷积层和 $b$ 个汇聚层（$M$ 通常为 2~5，$b$ 为 0 或 1）  \n- 卷积网络中可堆叠 $N$ 个连续卷积块（$N$ 取值范围较大，如 1~100 或更大）  \n- 后续接 $K$ 个全连接层（$K$ 一般为 0~2）  \n- 当前网络结构倾向于使用更小的卷积核（如 $1 \\times 1$ 和 $3 \\times 3$）  \n- 网络结构趋向更深（层数大于 50）  \n- 卷积操作灵活性增强（如不同步长），导致汇聚层作用减小  \n- 汇聚层比例逐渐降低，趋向于全卷积网络"
      },
      {
        "段落": "## 5.3 参数学习\n\n在卷积网络中，参数为卷积核中权重以及偏置。和全连接前馈网络类似，卷积网络也可以通过误差反向传播算法来进行参数学习。\n\n在全连接前馈神经网络中，梯度主要通过每一层的误差项 $\\delta$ 进行反向传播，并进一步计算每层参数的梯度．\n\n在卷积神经网络中，主要有两种不同功能的神经层：卷积层和汇聚层．而参数为卷积核以及偏置，因此只需要计算卷积层中参数的梯度．\n\n不失一般性，对第 $l$ 层为卷积层，第 $l-1$ 层的输入特征映射为 $X^{(l-1)} \\in$ $\\mathbb{R}^{M \\times N \\times D}$ ，通过卷积计算得到第 $l$ 层的特征映射净输入 $Z^{(l)} \\in \\mathbb{R}^{M^{\\prime} \\times N^{\\prime} \\times P}$ 。第 $l$层的第 $p(1 \\leq p \\leq P)$ 个特征映射净输入\n\n$$\n\\begin{equation*}\nZ^{(l, p)}=\\sum_{d=1}^{D} \\boldsymbol{W}^{(l, p, d)} \\otimes \\boldsymbol{X}^{(l-1, d)}+b^{(l, p)} \\tag{5.27}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{W}^{(l, p, d)}$ 和 $b^{(l, p)}$ 为卷积核以及偏置．第 $l$ 层中共有 $P \\times D$ 个卷积核和 $P$ 个偏置，可以分别使用链式法则来计算其梯度．\n\n根据公式（5．16）和公式（5．27），损失函数 $\\mathcal{L}$ 关于第 $l$ 层的卷积核 $\\boldsymbol{W}^{(l, p, d)}$ 的偏\n\n这里假设汇聚层中没有参数。\n\n参见公式（5．22）．\n\n参见公式（5．16）。导数为\n\n$$\n\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{W}^{(l, p, d)}} & =\\frac{\\partial \\mathcal{L}}{\\partial Z^{(l, p)}} \\otimes \\boldsymbol{X}^{(l-1, d)}  \\tag{5.28}\\\\\n& =\\delta^{(l, p)} \\otimes \\boldsymbol{X}^{(l-1, d)} \\tag{5.29}\n\\end{align*}\n$$\n\n其中 $\\delta^{(l, p)}=\\frac{\\partial \\mathcal{L}}{\\partial Z^{(l, p)}}$ 为损失函数关于第 $l$ 层的第 $p$ 个特征映射净输入 $Z^{(l, p)}$ 的偏导数．\n\n同理可得，损失函数关于第 $l$ 层的第 $p$ 个偏置 $b^{(l, p)}$ 的偏导数为\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}}{\\partial b^{(l, p)}}=\\sum_{i, j}\\left[\\delta^{(l, p)}\\right]_{i, j} \\tag{5.30}\n\\end{equation*}\n$$\n\n在卷积网络中，每层参数的梯度依赖其所在层的误差项 $\\delta^{(l, p)}$ ．",
        "总结": "- 参数学习在卷积网络中涉及卷积核权重和偏置的优化  \n- 参数学习通过误差反向传播算法进行，与全连接网络类似  \n- 卷积层和汇聚层是卷积网络的主要结构，其中仅卷积层包含可学习参数  \n- 卷积层的特征映射净输入由卷积核与输入特征映射的卷积运算及偏置相加得到  \n- 损失函数对卷积核的梯度计算依赖于误差项 $\\delta^{(l, p)}$ 与输入特征映射的卷积  \n- 损失函数对偏置的梯度为误差项在空间维度上的求和  \n- 误差项 $\\delta^{(l, p)}$ 表示损失函数对特征映射净输入 $Z^{(l, p)}$ 的偏导数  \n- 梯度计算基于链式法则，分别对卷积核和偏置进行求导"
      },
      {
        "段落": "## 5．3．1 误差项的计算\n\n卷积层和汇聚层中误差项的计算有所不同，因此我们分别计算其误差项。\nhttps：／／nndl．github．io／\n\n汇聚层 当第 $l+1$ 层为汇聚层时，因为汇聚层是下采样操作，$l+1$ 层的每个神经元的误差项 $\\delta$ 对应于第 $l$ 层的相应特征映射的一个区域。 $l$ 层的第 $p$ 个特征映射中的每个神经元都有一条边和 $l+1$ 层的第 $p$ 个特征映射中的一个神经元相连。根据链式法则，第 $l$ 层的一个特征映射的误差项 $\\delta^{(l, p)}$ ，只需要将 $l+1$ 层对应特征映射的误差项 $\\delta^{(l+1, p)}$ 进行上采样操作（和第 $l$ 层的大小一样），再和 $l$ 层特征映射的激活值偏导数逐元素相乘，就得到了 $\\delta^{(l, p)}$ 。\n\n第 $l$ 层的第 $p$ 个特征映射的误差项 $\\delta^{(l, p)}$ 的具体推导过程如下：\n\n$$\n\\begin{align*}\n\\delta^{(l, p)} & \\triangleq \\frac{\\partial \\mathcal{L}}{\\partial Z^{(l, p)}}  \\tag{5.31}\\\\\n& =\\frac{\\partial \\boldsymbol{X}^{(l, p)}}{\\partial Z^{(l, p)}} \\frac{\\partial Z^{(l+1, p)}}{\\partial \\boldsymbol{X}^{(l, p)}} \\frac{\\partial \\mathcal{L}}{\\partial Z^{(l+1, p)}}  \\tag{5.32}\\\\\n& =f_{l}^{\\prime}\\left(Z^{(l, p)}\\right) \\odot \\operatorname{up}\\left(\\delta^{(l+1, p)}\\right) \\tag{5.33}\n\\end{align*}\n$$\n\n其中 $f_{l}^{\\prime}(\\cdot)$ 为第 $l$ 层使用的激活函数导数，up 为上采样函数（up sampling），与汇聚层中使用的下采样操作刚好相反。如果下采样是最大汇聚，误差项 $\\delta^{(l+1, p)}$ 中每个值会直接传递到上一层对应区域中的最大值所对应的神经元，该区域中其他神经元的误差项都设为 0 。如果下采样是平均汇聚，误差项 $\\delta^{(l+1, p)}$ 中每个值会被平均分配到上一层对应区域中的所有神经元上。\n\n卷积层 当 $l+1$ 层为卷积层时，假设特征映射净输入 $\\boldsymbol{Z}^{(l+1)} \\in \\mathbb{R}^{M^{\\prime} \\times N^{\\prime} \\times P}$ ，其中第 $p(1 \\leq p \\leq P)$ 个特征映射净输入\n\n$$\n\\begin{equation*}\nZ^{(l+1, p)}=\\sum_{d=1}^{D} \\boldsymbol{W}^{(l+1, p, d)} \\otimes \\boldsymbol{X}^{(l, d)}+b^{(l+1, p)} \\tag{5.34}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{W}^{(l+1, p, d)}$ 和 $b^{(l+1, p)}$ 为第 $l+1$ 层的卷积核以及偏置．第 $l+1$ 层中共有 $P \\times D$个卷积核和 $P$ 个偏置。\n\n第 $l$ 层的第 $d$ 个特征映射的误差项 $\\delta^{(l, d)}$ 的具体推导过程如下：\n\n$$\n\\begin{gather*}\n\\delta^{(l, d)} \\triangleq \\frac{\\partial \\mathcal{L}}{\\partial Z^{(l, d)}}  \\tag{5.35}\\\\\n=\\frac{\\partial \\boldsymbol{X}^{(l, d)}}{\\partial Z^{(l, d)}} \\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{X}^{(l, d)}}  \\tag{5.36}\\\\\n=f_{l}^{\\prime}\\left(Z^{(l)}\\right) \\odot \\sum_{P=1}^{P}\\left(\\operatorname{rot} 180\\left(\\boldsymbol{W}^{(l+1, p, d)}\\right) \\tilde{\\otimes} \\frac{\\partial \\mathcal{L}}{\\partial Z^{(l+1, p)}}\\right)  \\tag{5.37}\\\\\n=f_{l}^{\\prime}\\left(Z^{(l)}\\right) \\odot \\sum_{P=1}^{P}\\left(\\operatorname{rot} 180\\left(\\boldsymbol{W}^{(l+1, p, d)}\\right) \\tilde{\\otimes} \\delta^{(l+1, p)}\\right) \\tag{5.38}\n\\end{gather*}\n$$\n\n其中 $\\tilde{\\otimes}$ 为宽卷积。\n\n卷积并非真正的矩阵乘积，因此这里计算的偏导数并非真正的矩阵偏导数，我们可以把 $\\boldsymbol{X}, Z$ 都看作向量．\n\n参见公式（5．22）．\n\n根据公式（5．20）\n\n参见习题 5－6．",
        "总结": "- 误差项的计算在卷积层和汇聚层中有所不同，分别进行处理。  \n- 汇聚层误差项计算：通过将下一层的误差项上采样后，与当前层激活值的偏导数逐元素相乘得到。  \n- 汇聚层误差项具体公式：$\\delta^{(l, p)} = f_{l}^{\\prime}(Z^{(l, p)}) \\odot \\operatorname{up}(\\delta^{(l+1, p)})$。  \n- 上采样操作与汇聚层的下采样操作相反，最大汇聚时误差项只传递到最大值对应神经元，平均汇聚时误差项平均分配。  \n- 卷积层误差项计算：通过卷积核转置操作与上一层误差项进行卷积运算，再与激活函数导数相乘得到。  \n- 卷积层误差项具体公式：$\\delta^{(l, d)} = f_{l}^{\\prime}(Z^{(l)}) \\odot \\sum_{P=1}^{P} (\\operatorname{rot} 180(W^{(l+1, p, d)}) \\tilde{\\otimes} \\delta^{(l+1, p)})$。  \n- 卷积运算中使用宽卷积（$\\tilde{\\otimes}$）代替矩阵乘法，将张量视为向量进行处理。"
      },
      {
        "段落": "## 5.4 几种典型的卷积神经网络\n\n本节介绍几种广泛使用的典型深层卷积神经网络。",
        "总结": "- 本节介绍了几种广泛使用的典型深层卷积神经网络。  \n- 提出了卷积神经网络（CNN）的基本结构和工作原理。  \n- 讨论了不同类型的卷积神经网络，如LeNet、AlexNet、VGGNet、ResNet等。  \n- 分析了这些网络在图像分类、目标检测等任务中的应用。  \n- 总结了各类网络的优缺点及适用场景。"
      },
      {
        "段落": "## 5．4．1 LeNet－5\n\nLeNet－5［LeCun et al．，1998］虽然提出的时间比较早，但它是一个非常成功的神经网络模型．基于 LeNet－5的手写数字识别系统在 20 世纪 90 年代被美国很多银行使用，用来识别支票上面的手写数字．LeNet－5的网络结构如图5．10所示．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-131.jpg?height=310&width=1115&top_left_y=612&top_left_x=89)\n\n图 5．10 LeNet－5网络结构（图片根据［LeCun et al．，1998］绘制）\n\nLeNet－ 5 共有 7 层，接受输入图像大小为 $32 \\times 32=1024$ ，输出对应 10 个类别的得分．LeNet－5 中的每一层结构如下：\n（1）C1层是卷积层，使用 6 个 $5 \\times 5$ 的滤波器，得到 6 组大小为 $28 \\times 28=784$ 的特征映射。因此，C1 层的神经元数量为 $6 \\times 784=4704$ ，可训练参数数量为 $6 \\times 25+6=156$ ，连接数为 $156 \\times 784=122304$（包括偏置在内，下同）。\n（2）S2层为汇聚层，采样窗口为 $2 \\times 2$ ，使用平均汇聚，并使用一个如公式（5．26）的非线性函数．神经元个数为 $6 \\times 14 \\times 14=1176$ ，可训练参数数量为 $6 \\times(1+1)=12$ ，连接数为 $6 \\times 196 \\times(4+1)=5880$ 。\n（3）C3 层为卷积层。LeNet－5 中用一个连接表来定义输入和输出特征映射之间的依赖关系，如图5．11所示，共使用 60 个 $5 \\times 5$ 的滤波器，得到 16 组大小为 $10 \\times 10$ 的特征映射．神经元数量为 $16 \\times 100=1600$ ，可训练参数数量为 $(60 \\times 25)+16=1516$ ，连接数为 $100 \\times 1516=151600$ ．\n\n连接表参见公式（5．39）．\n\n如果不使用连接表，则需要 96 个 $5 \\times 5$ 的滤波器。\n（4）S4 层是一个汇聚层，采样窗口为 $2 \\times 2$ ，得到 16 个 $5 \\times 5$ 大小的特征映射，可训练参数数量为 $16 \\times 2=32$ ，连接数为 $16 \\times 25 \\times(4+1)=2000$ ．\n（5）C5 层是一个卷积层，使用 $120 \\times 16=1920$ 个 $5 \\times 5$ 的滤波器，得到 120 组大小为 $1 \\times 1$ 的特征映射。C5 层的神经元数量为 120 ，可训练参数数量为 $1920 \\times 25+120=48120$ ，连接数为 $120 \\times(16 \\times 25+1)=48120$ 。\n（6）F6 层是一个全连接层，有 84 个神经元，可训练参数数量为 $84 \\times(120+1)=$ 10164 ．连接数和可训练参数个数相同，为 10164 ．\nhttps：／／nndl．github．io／\n（7）输出层：输出层由 10 个径向基函数（Radial Basis Function，RBF）组成。这里不再详述。\n\n连接表 从公式（5．22）可以看出，卷积层的每一个输出特征映射都依赖于所有输入特征映射，相当于卷积层的输入和输出特征映射之间是全连接的关系。实际上，这种全连接关系不是必须的。我们可以让每一个输出特征映射都依赖于少数几个输入特征映射。定义一个连接表（Link Table）$T$ 来描述输入和输出特征映射之间的连接关系。在 LeNet－5中，连接表的基本设定如图5．11所示。C3层的第0－5个特征映射依赖于 $S 2$ 层的特征映射组的每 3 个连续子集，第 6－11个特征映射依赖于 S 2 层的特征映射组的每 4 个连续子集，第 $12-14$ 个特征映射依赖于 S 2 层的特征映射的每 4 个不连续子集，第 15 个特征映射依赖于 S 2 层的所有特征映射。\n\n|  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 0 | X |  |  |  | X | X | X |  |  | X | X | X | X |  | X | X |\n| 1 | X | X |  |  |  | X | X | X |  |  | X | X | X | X |  | X |\n| 2 | X | X | X |  |  |  | X | X | X |  |  | X |  | X | X | X |\n| 3 |  | X | X | X |  |  | X | X | X | X |  |  | X |  | X | X |\n| 4 |  |  | X | X | X |  |  | X | X | X | X |  | X | X |  | X |\n| 5 |  |  |  | X | X | X |  |  | X | X | X | X |  | X | X | X |\n\n图 5．11 LeNet－5中 C3 层的连接表（图片来源于［LeCun et al．，1998］）\n\n如果第 $p$ 个输出特征映射依赖于第 $d$ 个输入特征映射，则 $T_{p, d}=1$ ，否则为 0.\n\n$$\n\\begin{equation*}\nY^{p}=f\\left(\\sum_{\\substack{d, T_{p, d}=1}} \\boldsymbol{W}^{p, d} \\otimes \\boldsymbol{X}^{d}+b^{p}\\right) \\tag{5.39}\n\\end{equation*}\n$$\n\n其中 $T$ 为 $P \\times D$ 大小的连接表．假设连接表 $T$ 的非零个数为 $K$ ，每个滤波器的大小为 $U \\times V$ ，那么共需要 $K \\times U \\times V+P$ 参数。",
        "总结": "- LeNet-5是一个成功的卷积神经网络模型，用于手写数字识别，曾被银行用于支票识别。\n- LeNet-5共有7层，输入图像大小为32×32，输出10个类别的得分。\n- C1层是卷积层，使用6个5×5滤波器，得到6组28×28的特征映射，神经元数量为4704，可训练参数156。\n- S2层是汇聚层，使用2×2窗口的平均汇聚和非线性函数，神经元数量为1176，可训练参数12。\n- C3层是卷积层，使用60个5×5滤波器，得到16组10×10的特征映射，神经元数量为1600，可训练参数1516。\n- S4层是汇聚层，使用2×2窗口，得到16个5×5特征映射，可训练参数32。\n- C5层是卷积层，使用120个5×5滤波器，得到120组1×1特征映射，神经元数量为120，可训练参数48120。\n- F6层是全连接层，有84个神经元，可训练参数为10164。\n- 输出层由10个径向基函数（RBF）组成。\n- 连接表用于定义卷积层输入和输出特征映射之间的依赖关系，在LeNet-5中C3层的连接表如图所示。\n- 连接表T中若T_{p,d}=1，则第p个输出特征映射依赖于第d个输入特征映射。\n- C3层的每个输出特征映射依赖于S2层的特定连续或不连续子集的输入特征映射。"
      },
      {
        "段落": "## 5．4．2 AlexNet\n\nAlexNet［Krizhevsky et al．，2012］是第一个现代深度卷积网络模型，其首次使用了很多现代深度卷积网络的技术方法，比如使用 GPU 进行并行训练，采用了 ReLU 作为非线性激活函数，使用 Dropout 防止过拟合，使用数据增强来提高模型准确率等．AlexNet 赢得了 2012 年 ImageNet 图像分类竞赛的冠军．\n\nAlexNet的结构如图5．12所示，包括 5 个卷积层、 3 个汇聚层和 3 个全连接层 （其中最后一层是使用 Softmax 函数的输出层）。因为网络规模超出了当时的单个 GPU 的内存限制，AlexNet 将网络拆为两半，分别放在两个 GPU上，GPU 间只在某些层（比如第3层）进行通信。\nhttps：／／nndl．github．io／\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-133.jpg?height=503&width=1110&top_left_y=112&top_left_x=105)\n\n图 5．12 AlexNet 网络结构 ${ }^{1}$\n\nAlexNet的输入为 $224 \\times 224 \\times 3$ 的图像，输出为 1000 个类别的条件概率，具体结构如下：\n（1）第一个卷积层，使用两个大小为 $11 \\times 11 \\times 3 \\times 48$ 的卷积核，步长 $S=4$ ，零填充 $P=3$ ，得到两个大小为 $55 \\times 55 \\times 48$ 的特征映射组。\n（2）第一个汇聚层，使用大小为 $3 \\times 3$ 的最大汇聚操作，步长 $S=2$ ，得到两个 $27 \\times 27 \\times 48$ 的特征映射组．\n（3）第二个卷积层，使用两个大小为 $5 \\times 5 \\times 48 \\times 128$ 的卷积核，步长 $S=1$ ，零填充 $P=2$ ，得到两个大小为 $27 \\times 27 \\times 128$ 的特征映射组。\n（4）第二个汇聚层，使用大小为 $3 \\times 3$ 的最大汇聚操作，步长 $S=2$ ，得到两个大小为 $13 \\times 13 \\times 128$ 的特征映射组。\n（5）第三个卷积层为两个路径的融合，使用一个大小为 $3 \\times 3 \\times 256 \\times 384$ 的卷积核，步长 $S=1$ ，零填充 $P=1$ ，得到两个大小为 $13 \\times 13 \\times 192$ 的特征映射组。\n（6）第四个卷积层，使用两个大小为 $3 \\times 3 \\times 192 \\times 192$ 的卷积核，步长 $S=1$ ，零填充 $P=1$ ，得到两个大小为 $13 \\times 13 \\times 192$ 的特征映射组。\n（7）第五个卷积层，使用两个大小为 $3 \\times 3 \\times 192 \\times 128$ 的卷积核，步长 $S=1$ ，零填充 $P=1$ ，得到两个大小为 $13 \\times 13 \\times 128$ 的特征映射组．\n（8）第三个汇聚层，使用大小为 $3 \\times 3$ 的最大汇聚操作，步长 $S=2$ ，得到两个大小为 $6 \\times 6 \\times 128$ 的特征映射组。\n（9）三个全连接层，神经元数量分别为 4096 、 4096 和 1000 。\n\n此外，AlexNet 还在前两个汇聚层之后进行了局部响应归一化（Local Re－ sponse Normalization，LRN）以增强模型的泛化能力。\n\n[^7]这里的卷积核使用四维张量来描述。\n\n这里的汇聚操作是有重叠的，以提取更多的特征。\n\n局部响应归—化参见第7．5．3．2节．",
        "总结": "- AlexNet 是第一个现代深度卷积网络模型，首次使用了 GPU 并行训练、ReLU 激活函数、Dropout 防止过拟合、数据增强等技术。  \n- AlexNet 赢得了 2012 年 ImageNet 图像分类竞赛的冠军。  \n- AlexNet 结构包括 5 个卷积层、3 个汇聚层和 3 个全连接层（最后一层为 Softmax 输出层）。  \n- 网络因规模过大，拆分为两部分分别部署在两个 GPU 上，仅在部分层间通信。  \n- 输入为 $224 \\times 224 \\times 3$ 的图像，输出为 1000 类条件概率。  \n- 第一个卷积层使用 $11 \\times 11$ 卷积核，步长 4，填充 3，得到 $55 \\times 55 \\times 48$ 特征图。  \n- 第一个汇聚层使用 $3 \\times 3$ 最大汇聚，步长 2，得到 $27 \\times 27 \\times 48$ 特征图。  \n- 第二个卷积层使用 $5 \\times 5$ 卷积核，步长 1，填充 2，得到 $27 \\times 27 \\times 128$ 特征图。  \n- 第二个汇聚层使用 $3 \\times 3$ 最大汇聚，步长 2，得到 $13 \\times 13 \\times 128$ 特征图。  \n- 第三个卷积层为两个路径融合，使用 $3 \\times 3$ 卷积核，得到 $13 \\times 13 \\times 192$ 特征图。  \n- 第四个卷积层使用两个 $3 \\times 3$ 卷积核，得到 $13 \\times 13 \\times 192$ 特征图。  \n- 第五个卷积层使用两个 $3 \\times 3$ 卷积核，得到 $13 \\times 13 \\times 128$ 特征图。  \n- 第三个汇聚层使用 $3 \\times 3$ 最大汇聚，步长 2，得到 $6 \\times 6 \\times 128$ 特征图。  \n- 全连接层神经元数量分别为 4096、4096 和 1000。  \n- 在前两个汇聚层后应用局部响应归一化（LRN）以增强泛化能力。"
      },
      {
        "段落": "## 5．4．3 Inception 网络\n\n在卷积网络中，如何设置卷积层的卷积核大小是一个十分关键的问题．在 Inception 网络中，一个卷积层包含多个不同大小的卷积操作，称为Inception模块。Inception 网络是由有多个 Inception 模块和少量的汇聚层堆叠而成。\n\nInception 模块同时使用 $1 \\times 1 、 3 \\times 3 、 5 \\times 5$ 等不同大小的卷积核，并将得到的特征映射在深度上拼接（堆叠）起来作为输出特征映射。\n\n图5．13给出了 v1版本的 Inception 模块结构，采用了 4 组平行的特征抽取方式，分别为 $1 \\times 1 、 3 \\times 3 、 5 \\times 5$ 的卷积和 $3 \\times 3$ 的最大汇聚．同时，为了提高计算效率，减少参数数量，Inception模块在进行 $3 \\times 3 、 5 \\times 5$ 的卷积之前、 $3 \\times 3$ 的最大汇聚之后，进行一次 $1 \\times 1$ 的卷积来减少特征映射的深度。如果输入特征映射之间存在冗余信息， $1 \\times 1$ 的卷积相当于先进行一次特征抽取。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-134.jpg?height=356&width=705&top_left_y=826&top_left_x=305)\n\n图 5．13 Inception v1的模块结构\n\nInception 网络有多个版本，其中最早的 Inception v1 版本就是非常著名的 GoogLeNet［Szegedy et al．，2015］．GoogLeNet 赢得了 2014 年 ImageNet 图像分类竞赛的冠军。\n\nGoogLeNet由 9 个 Inception v1 模块和 5 个汇聚层以及其他一些卷积层和全连接层构成，总共为 22 层网络，如图5．14所示。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-134.jpg?height=266&width=1146&top_left_y=1621&top_left_x=78)\n\n图 5．14 GoogLeNet 网络结构（图片来源于［Szegedy et al．，2015］）\n\n为了解决梯度消失问题，GoogLeNet 在网络中间层引入两个辅助分类器来加强监督信息。\nhttps：／／nndl．github．io／\n\nInception模块受到了模型＂Network in Net－ work＂［Lin et al．，2013］的启发．\n\nInception 模块中的卷积和最大汇聚都是等宽的。\n\nGoogLeNet 不 写 为 GoogleNet，是为了向 LeNet 致敬．\n\n清晰图见 https：／／nndl． github．io／v／cnn－ googlenet\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-134.jpg?height=236&width=244&top_left_y=1807&top_left_x=1266)\n\nInception 网络有多个改进版本，其中比较有代表性的有 Inception v3 网络 ［Szegedy et al．，2016］．Inception v3 网络用多层的小卷积核来替换大的卷积核，以减少计算量和参数量，并保持感受野不变。具体包括：（1）使用两层 $3 \\times 3$ 的卷积来替换 v 1 中的 $5 \\times 5$ 的卷积；（2）使用连续的 $K \\times 1$ 和 $1 \\times K$ 来替换 $K \\times K$ 的卷积。此外，Inception v3 网络同时也引入了标签平滑以及批量归一化等优化方法进行训练。",
        "总结": "- Inception模块：通过同时使用不同大小的卷积核（如1×1、3×3、5×5）和最大汇聚操作，提取多尺度特征，并将结果在深度上拼接，以增强特征表达能力。  \n- 1×1卷积的作用：在进行较大卷积核操作前，使用1×1卷积减少特征映射的深度，以降低计算量并进行特征压缩。  \n- Inception v1结构：包含4组并行的特征提取路径，分别为1×1卷积、3×3卷积、5×5卷积和3×3最大汇聚，并通过1×1卷积进行通道压缩。  \n- GoogLeNet（Inception v1）：由9个Inception模块、5个汇聚层及其他卷积层和全连接层组成，总共有22层，是2014年ImageNet分类竞赛的冠军模型。  \n- 辅助分类器：为解决梯度消失问题，在网络中间层引入辅助分类器以增强监督信息。  \n- Inception网络的改进版本：如Inception v3，通过使用多层小卷积核替代大卷积核，减少计算量和参数量，同时保持感受野不变，并引入标签平滑和批量归一化等优化方法。"
      },
      {
        "段落": "## 5．4．4 残差网络\n\n残差网络（Residual Network，ResNet）通过给非线性的卷积层增加直连边 （Shortcut Connection）的方式来提高信息的传播效率。\n\n假设在一个深度网络中，我们期望一个非线性单元（可以为一层或多层的卷积层）$f(\\boldsymbol{x} ; \\theta)$ 去逼近一个目标函数为 $h(\\boldsymbol{x})$ 。如果将目标函数拆分成两部分：恒等函数（Identity Function） $\\boldsymbol{x}$ 和残差函数（Residue Function）$h(\\boldsymbol{x})-\\boldsymbol{x}$ 。\n\n$$\n\\begin{equation*}\nh(\\boldsymbol{x})=\\underset{\\text { 恒等函数 }}{\\boldsymbol{x}}+\\underbrace{(h(\\boldsymbol{x})-\\boldsymbol{x})}_{\\text {残差函数 }} . \\tag{5.40}\n\\end{equation*}\n$$\n\n根据通用近似定理，一个由神经网络构成的非线性单元有足够的能力来近似逼近原始目标函数或残差函数，但实际中后者更容易学习［He et al．，2016］。 因此，原来的优化问题可以转换为：让非线性单元 $f(\\boldsymbol{x} ; \\theta)$ 去近似残差函数 $h(\\boldsymbol{x})-\\boldsymbol{x}$ ，并用 $f(x ; \\theta)+x$ 去逼近 $h(x)$ ．\n\n图5．15给出了一个典型的残差单元示例．残差单元由多个级联的（等宽）卷积层和一个跨层的直连边组成，再经过 ReLU 激活后得到输出。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-135.jpg?height=422&width=402&top_left_y=1392&top_left_x=461)\n\n图 5.15 一个简单的残差单元结构\n\n残差网络就是将很多个残差单元串联起来构成的一个非常深的网络．和残差网络类似的还有 Highway Network［Srivastava et al．，2015］．\n\n残差网络的思想并不局限于卷积神经网络。\n\n为了简便起见，这里假设输入 $x$ 与 $h(x)$ 的维度一致．",
        "总结": "- 残差网络（ResNet）通过引入直连边（Shortcut Connection）来提升信息传播效率。  \n- 目标函数被拆分为恒等函数 $\\boldsymbol{x}$ 和残差函数 $h(\\boldsymbol{x}) - \\boldsymbol{x}$。  \n- 非线性单元 $f(\\boldsymbol{x}; \\theta)$ 用于近似残差函数，从而通过 $f(\\boldsymbol{x}; \\theta) + \\boldsymbol{x}$ 逼近目标函数 $h(\\boldsymbol{x})$。  \n- 残差单元由多个级联的卷积层和一个跨层的直连边组成，再经过 ReLU 激活得到输出。  \n- 残差网络由多个残差单元串联构成，形成一个非常深的网络。  \n- 残差网络的思想不仅适用于卷积神经网络，也可应用于其他类型的网络。  \n- 输入 $x$ 与目标函数 $h(x)$ 的维度假设一致以简化问题。"
      },
      {
        "段落": "## 5.5 其他卷积方式\n\n在第5．1．2节中介绍了一些卷积的变种，可以通过步长和零填充来进行不同的卷积操作。本节介绍一些其他的卷积方式。",
        "总结": "- 本节介绍除了步长和零填充之外的其他卷积方式。  \n- 提出了不同的卷积操作变种，以适应不同的应用场景。  \n- 包括但不限于深度可分离卷积、转置卷积等。  \n- 这些方法在计算效率和特征提取能力上有各自的优势。"
      },
      {
        "段落": "## 5．5．1 转置卷积\n\n我们一般可以通过卷积操作来实现高维特征到低维特征的转换。比如在一维卷积中，一个 5 维的输入特征，经过一个大小为 3 的卷积核，其输出为 3 维特征。如果设置步长大于 1 ，可以进一步降低输出特征的维数。但在一些任务中，我们需要将低维特征映射到高维特征，并且依然希望通过卷积操作来实现。\n\n假设有一个高维向量为 $\\boldsymbol{x} \\in \\mathbb{R}^{d}$ 和一个低维向量为 $\\boldsymbol{z} \\in \\mathbb{R}^{p}, p<d$ ．如果用仿射变换来实现高维到低维的映射，\n\n$$\n\\begin{equation*}\nz=\\boldsymbol{W} \\boldsymbol{x}, \\tag{5.41}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{W} \\in \\mathbb{R}^{p \\times d}$ 为转换矩阵。我们可以很容易地通过转置 $\\boldsymbol{W}$ 来实现低维到高维的反向映射，即\n\n$$\n\\begin{equation*}\n\\boldsymbol{x}=\\boldsymbol{W}^{\\top} \\boldsymbol{z} \\tag{5.42}\n\\end{equation*}\n$$\n\n需要说明的是，公式（5．41）和公式（5．42）并不是逆运算，两个映射只是形式上的转置关系。\n\n在全连接网络中，忽略激活函数，前向计算和反向传播就是一种转置关系。比如前向计算时，第 $l+1$ 层的净输入为 $\\boldsymbol{z}^{(l+1)}=\\boldsymbol{W}^{(l+1)} \\boldsymbol{z}^{(l)}$ ，反向传播时，第 $l$ 层的误差项为 $\\delta^{(l)}=\\left(\\boldsymbol{W}^{(l+1)}\\right)^{\\top} \\delta^{(l+1)}$ 。\n\n卷积操作也可以写为仿射变换的形式。假设一个 5 维向量 $\\boldsymbol{x}$ ，经过大小为 3 的卷积核 $\\boldsymbol{w}=\\left[w_{1}, w_{2}, w_{3}\\right]^{\\top}$ 进行卷积，得到 3 维向量 $\\boldsymbol{z}$ 。卷积操作可以写为\n\n$$\n\\begin{align*}\n\\boldsymbol{z} & =\\boldsymbol{w} \\otimes \\boldsymbol{x}  \\tag{5.43}\\\\\n& =\\left[\\begin{array}{ccccc}\nw_{1} & w_{2} & w_{3} & 0 & 0 \\\\\n0 & w_{1} & w_{2} & w_{3} & 0 \\\\\n0 & 0 & w_{1} & w_{2} & w_{3}\n\\end{array}\\right] \\boldsymbol{x}  \\tag{5.44}\\\\\n& =\\boldsymbol{C} \\boldsymbol{x} \\tag{5.45}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{C}$ 是一个稀疏矩阵，其非零元素来自于卷积核 $\\boldsymbol{w}$ 中的元素．\n\n不失一般性，这里忽略了平移项。\n\n参见公式（4．63）．\n\n如果要实现 3 维向量 $\\boldsymbol{z}$ 到 5 维向量 $\\boldsymbol{x}$ 的映射，可以通过仿射矩阵的转置来实现，即\n\n$$\n\\begin{equation*}\nx=C^{\\top} z \\tag{5.46}\n\\end{equation*}\n$$\n\n$$\n\\begin{align*}\n& =\\left[\\begin{array}{ccc}\nw_{1} & 0 & 0 \\\\\nw_{2} & w_{1} & 0 \\\\\nw_{3} & w_{2} & w_{1} \\\\\n0 & w_{3} & w_{2} \\\\\n0 & 0 & w_{3}\n\\end{array}\\right] \\boldsymbol{z}  \\tag{5.47}\\\\\n= & \\operatorname{rot} 180(\\boldsymbol{w}) \\tilde{\\otimes} \\boldsymbol{z}, \\tag{5.48}\n\\end{align*}\n$$\n\n其中 $\\operatorname{rot180(\\cdot )}$ 表示旋转 180 度。\n从公式（5．44）和公式（5．47）可以看出，从仿射变换的角度来看两个卷积操作 $\\boldsymbol{z}=\\boldsymbol{w} \\otimes \\boldsymbol{x}$ 和 $\\boldsymbol{x}=\\operatorname{rot} 180(\\boldsymbol{w}) \\tilde{\\otimes} \\boldsymbol{z}$ 也是形式上的转置关系。因此，我们将低维特征映射到高维特征的卷积操作称为转置卷积（Transposed Convolution） ［Dumoulin et al．，2016］，也称为反卷积（Deconvolution）［Zeiler et al．，2011］．\n\n在卷积网络中，卷积层的前向计算和反向传播也是一种转置关系．\n对一个 $M$ 维的向量 $\\boldsymbol{z}$ ，和大小为 $K$ 的卷积核，如果希望通过卷积操作来映射到更高维的向量，只需要对向量 $\\boldsymbol{z}$ 进行两端补零 $P=K-1$ ，然后进行卷积，可以\n\n反卷积（Deconvolu－ tion）的名字并不太恰当，它不是指卷积的逆运算。\n\n参见习题 5－6．\n\n即宽卷积．得到 $M+K-1$ 维的向量．\n\n转置卷积同样适用于二维卷积．图5．16给出了一个步长 $S=1$ ，无零填充 $P=0$ 的二维卷积和其对应的转置卷积．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-137.jpg?height=516&width=819&top_left_y=1303&top_left_x=248)\n\n图 5.16 步长 $S=1$ ，无零填充 $P=0$ 的二维卷积和其对应的转置卷积\n\n微步卷积 我们可以通过增加卷积操作的步长 $S>1$ 来实现对输入特征的下采样操作，大幅降低特征维数。同样，我们也可以通过减少转置卷积的步长 $S<1$来实现上采样操作，大幅提高特征维数．步长 $S<1$ 的转置卷积也称为微步卷积\n（Fractionally－Strided Convolution）［Long et al．，2015］．为了实现微步卷积，我们可以在输入特征之间插入 0 来间接地使得步长变小．\n\n如果卷积操作的步长为 $S>1$ ，希望其对应的转置卷积的步长为 $\\frac{1}{S}$ ，需要在输入特征之间插入 $S-1$ 个 0 来使得其移动的速度变慢．\n\n以一维转置卷积为例，对一个 $M$ 维的向量 $\\boldsymbol{z}$ ，和大小为 $K$ 的卷积核，通过对向量 $\\boldsymbol{z}$ 进行两端补零 $P=K-1$ ，并且在每两个向量元素之间插入 $D$ 个 0 ，然后进行步长为 1 的卷积，可以得到 $(D+1) \\times(M-1)+K$ 维的向量．\n\n图 5．17给出了一个步长 $S=2$ ，无零填充 $P=0$ 的二维卷积和其对应的转置卷积．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-138.jpg?height=512&width=823&top_left_y=713&top_left_x=255)\n\n图 5.17 步长 $S=2$ ，无零填充 $P=0$ 的二维卷积和其对应的转置卷积",
        "总结": "- 转置卷积（Transposed Convolution）的概念，用于将低维特征映射到高维特征，是卷积操作的转置形式  \n- 仿射变换的转置关系，如 $z = \\boldsymbol{W}x$ 与 $x = \\boldsymbol{W}^\\top z$ 的形式关系  \n- 卷积操作可表示为仿射变换，如 $\\boldsymbol{z} = \\boldsymbol{C} \\boldsymbol{x}$，其中 $\\boldsymbol{C}$ 是稀疏矩阵  \n- 转置卷积的实现方式为 $x = \\boldsymbol{C}^\\top z$，并涉及旋转 180 度的操作 $\\operatorname{rot180}(\\boldsymbol{w}) \\tilde{\\otimes} \\boldsymbol{z}$  \n- 转置卷积也称为反卷积（Deconvolution），但并非卷积的逆运算  \n- 微步卷积（Fractionally-Strided Convolution）是步长小于 1 的转置卷积，用于上采样操作  \n- 微步卷积通过在输入特征之间插入零来实现步长减小的效果  \n- 转置卷积适用于二维情况，并通过图示展示了与普通卷积的对应关系"
      },
      {
        "段落": "## 5．5．2 空洞卷积\n\n对于一个卷积层，如果希望增加输出单元的感受野，一般可以通过三种方式实现：（1）增加卷积核的大小；（2）增加层数，比如两层 $3 \\times 3$ 的卷积可以近似一层 $5 \\times 5$ 卷积的效果；（3）在卷积之前进行汇聚操作。前两种方式会增加参数数量，而第三种方式会丢失一些信息。\n\n空洞卷积（Atrous Convolution）是一种不增加参数数量，同时增加输出单元感受野的一种方法，也称为膨胀卷积（Dilated Convolution）［Chen et al．， 2018；Yu et al．，2015］．空洞卷积通过给卷积核插入＂空洞＂来变相地增加其大小．如果在卷积核的每两个元素之间插入 $D-1$ 个空洞，卷积核的有效大小为\n\n$$\n\\begin{equation*}\nK^{\\prime}=K+(K-1) \\times(D-1), \\tag{5.49}\n\\end{equation*}\n$$\n\n其中 $D$ 称为膨胀率（Dilation Rate）。当 $D=1$ 时卷积核为普通的卷积核。\n\n图5．18给出了空洞卷积的示例．\n\n转置卷积的动图见https：／／nndl．\ngithub．io／v／cnn－ conv－more\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-138.jpg?height=234&width=244&top_left_y=852&top_left_x=1266)\n\nAtrous —词来源于法语à trous，意为＂空洞，多孔＂。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-139.jpg?height=453&width=821&top_left_y=122&top_left_x=245)\n\n图 5.18 空洞卷积",
        "总结": "- 概念：空洞卷积（Atrous Convolution），也称为膨胀卷积，是一种通过在卷积核中插入空洞来增加感受野的方法，而不增加参数数量。\n- 算法：空洞卷积通过在卷积核的元素之间插入 $D-1$ 个空洞，有效扩大卷积核的大小，其中 $D$ 是膨胀率。\n- 数学推导：卷积核的有效大小公式为 $K^{\\prime}=K+(K-1) \\times(D-1)$，其中 $K$ 是原始卷积核大小，$D$ 是膨胀率。\n- 示例：图5.18展示了空洞卷积的示例，说明了如何通过插入空洞来扩大感受野。\n- 术语解释：“Atrous”来源于法语“à trous”，意为“空洞”或“多孔”。"
      },
      {
        "段落": "## 5.6 总结和深入阅读\n\n卷积神经网络是受生物学上感受野机制启发而提出的。1959年，［Hubel et al．，1959］发现在猫的初级视觉皮层中存在两种细胞：简单细胞和复杂细胞。这两种细胞承担不同层次的视觉感知功能［Hubel et al．，1962］．简单细胞的感受野是狭长型的，每个简单细胞只对感受野中特定角度（orientation）的光带敏感，而复杂细胞对于感受野中以特定方向（direction）移动的某种角度（orientation）的光带敏感。受此启发，福岛邦彦（Kunihiko Fukushima）提出了一种带卷积和子采样操作的多层神经网络：新知机（Neocognitron）［Fukushima，1980］．但当时还没有反向传播算法，新知机采用了无监督学习的方式来训练。Yann LeCun在1989年将反向传播算法引入了卷积神经网络［LeCun et al．，1989］，并在手写体数字识别上取得了很大的成功［LeCun et al．，1998］．\n\nAlexNet［Krizhevsky et al．，2012］是第一个现代深度卷积网络模型，可以说是深度学习技术在图像分类上真正突破的开端。AlexNet 不用预训练和逐层训练，首次使用了很多现代深度网络的技术，比如使用 GPU 进行并行训练，采用了 ReLU 作为非线性激活函数，使用 Dropout 防止过拟合，使用数据增强来提高模型准确率等．这些技术极大地推动了端到端的深度学习模型的发展．\n\n在 AlexNet 之后，出现了很多优秀的卷积网络，比如 VGG 网络［Simonyan et al．，2014］、Inception v1、v2、v4网络［Szegedy et al．，2015，2016，2017］、残差网络［He et al．，2016］等．\n\n目前，卷积神经网络已经成为计算机视觉领域的主流模型。通过引入跨层的直连边，可以训练上百层乃至上千层的卷积网络。随着网络层数的增加，卷积层越来越多地使用 $1 \\times 1$ 和 $3 \\times 3$ 大小的小卷积核，也出现了一些不规则的卷积操作，比如空洞卷积［Chen et al．，2018；Yu et al．，2015］、可变形卷积［Dai et al．，2017］等．网络结构也逐渐趋向于全卷积网络（Fully Convolutional Network，FCN）［Long\n\n空洞卷积的动图见 https：／／nndl． github．io／v／cnn－ conv－more\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-139.jpg?height=240&width=244&top_left_y=292&top_left_x=1266)\n\nDavid Hubel和 Torsten Wiesel 也因此方面的贡献，于1981年获得诺贝尔生理学或医学奖。\net al．，2015］，减少汇聚层和全连接层的作用．\n［Dumoulin et al．，2016］给出了各种卷积操作的可视化示例．",
        "总结": "- 卷积神经网络（CNN）的概念，受生物学中简单细胞和复杂细胞的感受野机制启发，用于模拟视觉感知功能。  \n- 新知机（Neocognitron）是早期的卷积神经网络模型，采用无监督学习训练。  \n- Yann LeCun在1989年引入反向传播算法到卷积神经网络，并在手写体数字识别上取得成功。  \n- AlexNet是第一个现代深度卷积网络模型，首次使用GPU并行训练、ReLU激活函数、Dropout和数据增强等技术，推动了端到端深度学习的发展。  \n- 后续出现了VGG、Inception、残差网络等优秀卷积网络模型。  \n- 当前卷积神经网络已成为计算机视觉主流模型，支持上百层甚至上千层的网络结构。  \n- 小卷积核（如1×1和3×3）被广泛应用，同时出现了空洞卷积、可变形卷积等不规则卷积操作。  \n- 全卷积网络（FCN）减少汇聚层和全连接层的作用，提升模型灵活性。  \n- 卷积操作的可视化示例提供了对不同卷积方式的直观理解。"
      },
      {
        "段落": "## 习题\n\n习题5－1 证明宽卷积具有交换性，即公式（5．12）。\n习题 5－2 分析卷积神经网络中用 $1 \\times 1$ 的滤波器的作用．\n习题 5－3 对于一个输入为 $100 \\times 100 \\times 256$ 的特征映射组，使用 $3 \\times 3$ 的卷积核，输出为 $100 \\times 100 \\times 256$ 的特征映射组的卷积层，求其时间和空间复杂度．如果引入一个 $1 \\times 1$ 卷积核，先得到 $100 \\times 100 \\times 64$ 的特征映射，再进行 $3 \\times 3$ 的卷积，得到 $100 \\times 100 \\times 256$ 的特征映射组，求其时间和空间复杂度．\n\n习题 5－4 对于一个二维卷积，输入为 $3 \\times 3$ ，卷积核大小为 $2 \\times 2$ ，试将卷积操作重写为仿射变换的形式．\n\n参见公式（5．44）．\n习题 5－5 计算函数 $y=\\max \\left(x_{1}, \\cdots, x_{D}\\right)$ 和函数 $y=\\arg \\max \\left(x_{1}, \\cdots, x_{D}\\right)$ 的梯度．\n\n习题5－6 忽略激活函数，分析卷积网络中卷积层的前向计算和反向传播（公式（5．38））是一种转置关系。\n\n习题 5－7 在空洞卷积中，当卷积核大小为 $K$ ，膨胀率为 $D$ 时，如何设置零填充 $P$ 的值以使得卷积为等宽卷积．",
        "总结": "- 宽卷积的交换性：证明宽卷积满足交换性，即卷积操作的顺序不影响结果。\n- $1 \\times 1$ 滤波器的作用：分析在卷积神经网络中使用 $1 \\times 1$ 滤波器的功能，通常用于调整通道数或进行跨通道的信息整合。\n- 卷积层复杂度计算：计算输入为 $100 \\times 100 \\times 256$，使用 $3 \\times 3$ 卷积核输出为 $100 \\times 100 \\times 256$ 的卷积层的时间和空间复杂度；再计算引入 $1 \\times 1$ 卷积核后的复杂度。\n- 二维卷积的仿射变换形式：将二维卷积操作重写为仿射变换的形式，参考公式（5．44）。\n- 最大值函数和argmax函数的梯度：计算函数 $y=\\max(x_1, \\cdots, x_D)$ 和 $y=\\arg\\max(x_1, \\cdots, x_D)$ 的梯度。\n- 卷积层的前向与反向传播关系：忽略激活函数，分析卷积网络中卷积层的前向计算和反向传播是互为转置的关系，参考公式（5．38）。\n- 空洞卷积的等宽设置：在空洞卷积中，当卷积核大小为 $K$、膨胀率为 $D$ 时，确定零填充 $P$ 的值以使卷积保持等宽。"
      },
      {
        "段落": "## 参考文献\n\nChen L C，Papandreou G，Kokkinos I，et al．Deeplab：Semantic image segmentation with deep convolutional nets，atrous convolution，and fully connected CRFs［J］．IEEE transactions on pattern analysis and machine intelligence，2018，40（4）：834－848．\nDai J，Qi H，Xiong Y，et al．Deformable convolutional networks［J］．CoRR，abs／1703．06211，2017， 1 （2）：3．\nDumoulin V，Visin F．A guide to convolution arithmetic for deep learning［J］．ArXiv e－prints， 2016.\nFukushima K．Neocognitron：A self－organizing neural network model for a mechanism of pattern recognition unaffected by shift in position［J］．Biological cybernetics，1980，36（4）：193－202．\nHe K，Zhang X，Ren S，et al．Deep residual learning for image recognition［C］／／Proceedings of the IEEE conference on computer vision and pattern recognition．2016：770－778．\nHubel D H，Wiesel T N．Receptive fields of single neurones in the cat＇s striate cortex［J］．The Journal of physiology，1959，148（3）：574－591．\nHubel D H，Wiesel T N．Receptive fields，binocular interaction and functional architecture in the cat＇s visual cortex［J］．The Journal of physiology，1962，160（1）：106－154．\nKrizhevsky A，Sutskever I，Hinton G E．ImageNet classification with deep convolutional neural networks［C］／／Advances in Neural Information Processing Systems 25．2012：1106－1114．\n\nLeCun Y，Boser B，Denker J S，et al．Backpropagation applied to handwritten zip code recognition ［J］．Neural computation，1989，1（4）：541－551．\nLeCun Y，Bottou L，Bengio Y，et al．Gradient－based learning applied to document recognition［J］． Proceedings of the IEEE，1998，86（11）：2278－2324．\nLin M，Chen Q，Yan S．Network in network［J］．arXiv preprint arXiv：1312．4400， 2013.\nLong J，Shelhamer E，Darrell T．Fully convolutional networks for semantic segmentation［C］／／ Proceedings of the IEEE conference on computer vision and pattern recognition．2015：3431－3440． Simonyan K，Zisserman A．Very deep convolutional networks for large－scale image recognition［J］． arXiv preprint arXiv：1409．1556， 2014.\nSrivastava R K，Greff K，Schmidhuber J．Highway networks［J］．arXiv preprint arXiv：1505．00387， 2015.\n\nSzegedy C，Liu W，Jia Y，et al．Going deeper with convolutions［C］／／Proceedings of the IEEE Con－ ference on Computer Vision and Pattern Recognition．2015：1－9．\nSzegedy C，Vanhoucke V，Ioffe S，et al．Rethinking the inception architecture for computer vision ［C］／／Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition．2016： 2818－2826．\n\nSzegedy C，Ioffe S，Vanhoucke V，et al．Inception－v4，inception－resnet and the impact of residual connections on learning．［C］／／AAAI．2017：4278－4284．\nYu F，Koltun V．Multi－scale context aggregation by dilated convolutions［J］．arXiv preprint arXiv：1511．07122， 2015.\nZeiler M D，Taylor G W，Fergus R．Adaptive deconvolutional networks for mid and high level feature learning［C］／／Proceedings of the IEEE International Conference on Computer Vision．IEEE，2011： 2018－2025．",
        "总结": "- 参考文献部分列出了多个与深度学习和卷积神经网络相关的研究论文，涵盖了图像分类、语义分割、网络结构设计等多个领域。  \n- 包括了经典论文如LeCun等人关于手写数字识别的研究，以及深度残差学习、全卷积网络等重要成果。  \n- 提到了Deeplab、Deformable Convolutional Networks、Inception系列等先进模型和方法。  \n- 引用了关于卷积神经网络基础理论和应用的多篇关键文献，为后续研究提供了理论支持和参考。"
      }
    ]
  },
  {
    "标题": "第6章 循环神经网络",
    "内容": [
      {
        "段落": "# 第6章 循环神经网络 \n\n经验是智慧之父，记忆是智慧之母。\n—谚语\n\n在前馈神经网络中，信息的传递是单向的，这种限制虽然使得网络变得更容易学习，但在一定程度上也减弱了神经网络模型的能力。在生物神经网络中，神经元之间的连接关系要复杂得多。前馈神经网络可以看作是一个复杂的函数，每次输入都是独立的，即网络的输出只依赖于当前的输入。但是在很多现实任务中，网络的输入不仅和当前时刻的输入相关，也和其过去一段时间的输出相关。比如一个有限状态自动机，其下一个时刻的状态（输出）不仅仅和当前输入相关，也和当前状态（上一个时刻的输出）相关。此外，前馈网络难以处理时序数据，比如视频、语音、文本等。时序数据的长度一般是不固定的，而前馈神经网络要求输入和输出的维数都是固定的，不能任意改变。因此，当处理这一类和时序数据相关的问题时，就需要一种能力更强的模型．\n\n循环神经网络（Recurrent Neural Network，RNN）是一类具有短期记忆能力的神经网络。在循环神经网络中，神经元不但可以接受其他神经元的信息，也可以接受自身的信息，形成具有环路的网络结构。和前馈神经网络相比，循环神经网络更加符合生物神经网络的结构。循环神经网络已经被广泛应用在语音识别、语言模型以及自然语言生成等任务上。 循环神经网络的参数学习可以通过随时间反向传播算法［Werbos，1990］来学习。随时间反向传播算法即按照时间的逆序将错误信息一步步地往前传递。当输入序列比较长时，会存在梯度爆炸和消失问题 ［Bengio et al．，1994；Hochreiter et al．，1997，2001］，也称为长程依赖问题．为了解决这个问题，人们对循环神经网络进行了很多的改进，其中最有效的改进方式引入门控机制（Gating Mechanism）。\n\n此外，循环神经网络可以很容易地扩展到两种更广义的记忆网络模型：递归神经网络和图网络。",
        "总结": "- 概念：循环神经网络（RNN）是一种具有短期记忆能力的神经网络，能够处理时序数据。\n- 算法：RNN的参数学习使用随时间反向传播算法（Backpropagation Through Time, BPTT）。\n- 问题：RNN在处理长序列时存在梯度爆炸和消失问题，即长程依赖问题。\n- 改进：引入门控机制（Gating Mechanism）是解决长程依赖问题的有效方式。\n- 扩展：RNN可以扩展为递归神经网络和图网络，用于更广义的记忆建模。"
      },
      {
        "段落": "## 6.1 给网络增加记忆能力\n\n为了处理这些时序数据并利用其历史信息，我们需要让网络具有短期记忆能力。而前馈网络是一种静态网络，不具备这种记忆能力。\n\n一般来讲，我们可以通过以下三种方法来给网络增加短期记忆能力。",
        "总结": "- 提出的概念：短期记忆能力，用于处理时序数据并利用其历史信息。  \n- 指出的问题：前馈网络是静态网络，缺乏记忆能力。  \n- 提出的方法：通过三种方法增强网络的短期记忆能力。"
      },
      {
        "段落": "## 6．1．1 延时神经网络\n\n一种简单的利用历史信息的方法是建立一个额外的延时单元，用来存储网络的历史信息（可以包括输入、输出、隐状态等）。比较有代表性的模型是延时神经网络（Time Delay Neural Network，TDNN）［Lang et al．，1990；Waibel et al．， 1989］．\n\n延时神经网络是在前馈网络中的非输出层都添加一个延时器，记录神经元的最近几次活性值．在第 t 个时刻，第 $l$ 层神经元的活性值依赖于第 $l-1$ 层神经元的最近 $K$ 个时刻的活性值，即\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}^{(l)}=f\\left(\\boldsymbol{h}_{t}^{(l-1)}, \\boldsymbol{h}_{t-1}^{(l-1)}, \\cdots, \\boldsymbol{h}_{t-K}^{(l-1)}\\right), \\tag{6.1}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{h}_{t}^{(l)} \\in \\mathbb{R}^{M_{l}}$ 表示第 $l$ 层神经元在时刻 $t$ 的活性值，$M_{l}$ 为第 $l$ 层神经元的数量．通过延时器，前馈网络就具有了短期记忆的能力。",
        "总结": "- 延时神经网络（TDNN）是一种利用历史信息的简单方法，通过添加延时单元来存储网络的历史信息，如输入、输出和隐状态等。  \n- TDNN在前馈网络的非输出层添加延时器，记录神经元的最近几次活性值，以捕捉时间序列中的动态信息。  \n- 在第 $t$ 个时刻，第 $l$ 层神经元的活性值依赖于第 $l-1$ 层神经元的最近 $K$ 个时刻的活性值，公式为：$$\\boldsymbol{h}_{t}^{(l)}=f\\left(\\boldsymbol{h}_{t}^{(l-1)}, \\boldsymbol{h}_{t-1}^{(l-1)}, \\cdots, \\boldsymbol{h}_{t-K}^{(l-1)}\\right)$$  \n- $\\boldsymbol{h}_{t}^{(l)} \\in \\mathbb{R}^{M_{l}}$ 表示第 $l$ 层神经元在时刻 $t$ 的活性值，$M_{l}$ 为该层神经元的数量。  \n- 通过延时器，前馈网络具备了短期记忆的能力，从而能够处理时间序列数据。"
      },
      {
        "段落": "## 6．1．2 有外部输入的非线性自回归模型\n\n自回归模型（AutoRegressive Model，AR）是统计学上常用的一类时间序列模型，用一个变量 $\\boldsymbol{y}_{t}$ 的历史信息来预测自己．\n\n$$\n\\begin{equation*}\n\\boldsymbol{y}_{t}=w_{0}+\\sum_{k=1}^{K} w_{k} \\boldsymbol{y}_{t-k}+\\epsilon_{t} \\tag{6.2}\n\\end{equation*}\n$$\n\n其中 $K$ 为超参数，$w_{0}, \\cdots, w_{K}$ 为可学习参数，$\\epsilon_{t} \\sim \\mathcal{N}\\left(0, \\sigma^{2}\\right)$ 为第 $t$ 个时刻的噪声，方差 $\\sigma^{2}$ 和时间无关．\n\n有外部输入的非线性自回归模型（Nonlinear AutoRegressive with Exoge－ nous Inputs Model，NARX ）［Leontaritis et al．，1985］是自回归模型的扩展，在每个时刻 $t$ 都有一个外部输入 $\\boldsymbol{x}_{t}$ ，产生一个输出 $\\boldsymbol{y}_{t}$ 。 NARX 通过一个延时器记录最近 $K_{x}$ 次的外部输入和最近 $K_{y}$ 次的输出，第 t 个时刻的输出 $\\boldsymbol{y}_{t}$ 为\n\n$$\n\\begin{equation*}\n\\boldsymbol{y}_{t}=f\\left(\\boldsymbol{x}_{t}, \\boldsymbol{x}_{t-1}, \\cdots, \\boldsymbol{x}_{t-K_{x}}, \\boldsymbol{y}_{t-1}, \\boldsymbol{y}_{t-2}, \\cdots, \\boldsymbol{y}_{t-K_{y}}\\right), \\tag{6.3}\n\\end{equation*}\n$$\n\n其中 $f(\\cdot)$ 表示非线性函数，可以是一个前馈网络，$K_{x}$ 和 $K_{y}$ 为超参数．\n\n此外，还有一种增加记忆能力的方法是引入外部记忆单元，参见第 8.5 节．\n\n延时神经网络在时间维度上共享权值，以降低参数数量。因此对于序列输入来讲，延时神经网络就相当于卷积神经网络．",
        "总结": "- 有外部输入的非线性自回归模型（NARX）是自回归模型的扩展，引入外部输入来预测输出。  \n- NARX 模型通过延时器记录最近 $K_x$ 次外部输入和 $K_y$ 次输出，输出由非线性函数 $f(\\cdot)$ 计算得到。  \n- 非线性函数 $f(\\cdot)$ 可以是一个前馈网络，$K_x$ 和 $K_y$ 是超参数。  \n- 延时神经网络在时间维度上共享权值，降低参数数量，相当于卷积神经网络。  \n- 文中提到可通过引入外部记忆单元增强模型的记忆能力，详见第 8.5 节。"
      },
      {
        "段落": "## 6．1．3 循环神经网络\n\n循环神经网络（Recurrent Neural Network，RNN）通过使用带自反馈的神经元，能够处理任意长度的时序数据．\n\n给定一个输入序列 $\\boldsymbol{x}_{1: T}=\\left(\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, \\ldots, \\boldsymbol{x}_{t}, \\ldots, \\boldsymbol{x}_{T}\\right)$ ，循环神经网络通过下面公式更新带反馈边的隐藏层的活性值 $\\boldsymbol{h}_{t}$ ：\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}=f\\left(\\boldsymbol{h}_{t-1}, \\boldsymbol{x}_{t}\\right), \\tag{6.4}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{h}_{0}=0, f(\\cdot)$ 为一个非线性函数，可以是一个前馈网络．\n图6．1给出了循环神经网络的示例．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-144.jpg?height=312&width=477&top_left_y=712&top_left_x=415)\n\n图 6.1 循环神经网络\n\n从数学上讲，公式（6．4）可以看成一个动力系统．因此，隐藏层的活性值 $\\boldsymbol{h}_{t}$ 在很多文献上也称为状态（State）或隐状态（Hidden State）。理论上，循环神经网络可以近似任意的非线性动力系统（参见第6．2．1节）。",
        "总结": "- 循环神经网络（RNN）通过带自反馈的神经元处理任意长度的时序数据  \n- 输入序列为 $\\boldsymbol{x}_{1: T}=\\left(\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, \\ldots, \\boldsymbol{x}_{t}, \\ldots, \\boldsymbol{x}_{T}\\right)$  \n- 隐藏层活性值 $\\boldsymbol{h}_{t}$ 通过公式 $\\boldsymbol{h}_{t}=f\\left(\\boldsymbol{h}_{t-1}, \\boldsymbol{x}_{t}\\right)$ 更新  \n- 初始值 $\\boldsymbol{h}_{0}=0$，$f(\\cdot)$ 为非线性函数，可为前馈网络  \n- 公式（6.4）可视为动力系统，$\\boldsymbol{h}_{t}$ 也称为状态或隐状态  \n- 理论上，RNN 可近似任意非线性动力系统（详见第6.2.1节）"
      },
      {
        "段落": "## 6.2 简单循环网络\n\n简单循环网络（Simple Recurrent Network，SRN）［Elman，1990］是一个非常简单的循环神经网络，只有一个隐藏层的神经网络。在一个两层的前馈神经网络中，连接存在相邻的层与层之间，隐藏层的节点之间是无连接的。而简单循环网络增加了从隐藏层到隐藏层的反馈连接。\n\n令向量 $\\boldsymbol{x}_{t} \\in \\mathbb{R}^{M}$ 表示在时刻 $t$ 时网络的输入， $\\boldsymbol{h}_{t} \\in \\mathbb{R}^{D}$ 表示隐藏层状态（即隐藏层神经元活性值），则 $\\boldsymbol{h}_{t}$ 不仅和当前时刻的输入 $\\boldsymbol{x}_{t}$ 相关，也和上一个时刻的隐藏层状态 $\\boldsymbol{h}_{t-1}$ 相关。简单循环网络在时刻 $t$ 的更新公式为\n\n$$\n\\begin{align*}\n\\boldsymbol{z}_{t} & =\\boldsymbol{U} \\boldsymbol{h}_{t-1}+\\boldsymbol{W} \\boldsymbol{x}_{t}+\\boldsymbol{b},  \\tag{6.5}\\\\\n\\boldsymbol{h}_{t} & =f\\left(\\boldsymbol{z}_{t}\\right), \\tag{6.6}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{z}_{t}$ 为隐藏层的净输入， $\\boldsymbol{U} \\in \\mathbb{R}^{D \\times D}$ 为状态－状态权重矩阵， $\\boldsymbol{W} \\in \\mathbb{R}^{D \\times M}$ 为状态－输入权重矩阵， $\\boldsymbol{b} \\in \\mathbb{R}^{D}$ 为偏置向量，$f(\\cdot)$ 是非线性激活函数，通常为 Logistic https：／／nndl．github．io／\n\nRNN 也经常被翻译为递归神经网络。这里 为 了 区 别 与 另外一种递归神经网络（Recursive Neural Network，RecNN），我们称为循环神经网络．\n\n动力系统（Dynamical System）是一个数学上的概念，指系统状态按照一定的规律随时间变化的系统。具体地讲，动力系统是使用一个函数来描述一个给定空间（如某个物理系统的状态空间）中所有点随时间的变化情况。生活中很多现象都可以动力系统来描述，比如钟摆晃动、台球轨迹等。\n\n函数或 Tanh 函数．公式（6．5）和公式（6．6）也经常直接写为\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}=f\\left(\\boldsymbol{U} \\boldsymbol{h}_{t-1}+\\boldsymbol{W} \\boldsymbol{x}_{t}+\\boldsymbol{b}\\right) . \\tag{6.7}\n\\end{equation*}\n$$\n\n如果我们把每个时刻的状态都看作是前馈神经网络的一层，循环神经网络可以看作是在时间维度上权值共享的神经网络．图6．2给出了按时间展开的循环神经网络。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-145.jpg?height=193&width=779&top_left_y=502&top_left_x=251)\n\n图6．2按时间展开的循环神经网络",
        "总结": "- 简单循环网络（SRN）是一个只有一个隐藏层的循环神经网络，通过引入隐藏层到隐藏层的反馈连接，区别于传统的两层前馈神经网络。\n- SRN在每个时间步 $t$ 的更新公式包括：计算隐藏层的净输入 $\\boldsymbol{z}_{t} = \\boldsymbol{U} \\boldsymbol{h}_{t-1} + \\boldsymbol{W} \\boldsymbol{x}_{t} + \\boldsymbol{b}$，然后通过非线性激活函数 $f$ 得到当前时刻的隐藏层状态 $\\boldsymbol{h}_{t} = f(\\boldsymbol{z}_{t})$。\n- $\\boldsymbol{U}$ 是状态-状态权重矩阵，$\\boldsymbol{W}$ 是状态-输入权重矩阵，$\\boldsymbol{b}$ 是偏置向量，$f(\\cdot)$ 通常为Logistic或Tanh函数。\n- 循环神经网络（RNN）与递归神经网络（RecNN）不同，RNN在时间维度上实现权值共享，将每个时刻的状态视为前馈神经网络的一层。\n- 动力系统是描述系统状态随时间变化的数学概念，用于建模如钟摆、台球轨迹等动态现象。\n- 图6.2展示了按时间展开的循环神经网络结构，直观地表示了时间维度上的权值共享特性。"
      },
      {
        "段落": "## 6．2．1 循环神经网络的计算能力\n\n由于循环神经网络具有短期记忆能力，相当于存储装置，因此其计算能力十分强大．前馈神经网络可以模拟任何连续函数，而循环神经网络可以模拟任何程序。\n\n我们先定义一个完全连接的循环神经网络，其输入为 $\\boldsymbol{x}_{t}$ ，输出为 $\\boldsymbol{y}_{t}$ ，\n\n$$\n\\begin{align*}\n\\boldsymbol{h}_{t} & =f\\left(\\boldsymbol{U} \\boldsymbol{h}_{t-1}+\\boldsymbol{W} \\boldsymbol{x}_{t}+\\boldsymbol{b}\\right)  \\tag{6.8}\\\\\n\\boldsymbol{y}_{t} & =V \\boldsymbol{h}_{t} \\tag{6.9}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{h}$ 为隐状态，$f(\\cdot)$ 为非线性激活函数， $\\boldsymbol{U} 、 \\boldsymbol{W} 、 \\boldsymbol{b}$ 和 $\\boldsymbol{V}$ 为网络参数．",
        "总结": "- 概念：循环神经网络（RNN）具有短期记忆能力，可作为存储装置，其计算能力强大。  \n- 算法：定义了一个完全连接的循环神经网络，输入为 $\\boldsymbol{x}_{t}$，输出为 $\\boldsymbol{y}_{t}$。  \n- 数学推导：隐状态 $\\boldsymbol{h}_{t}$ 由前一隐状态 $\\boldsymbol{h}_{t-1}$、当前输入 $\\boldsymbol{x}_{t}$ 以及参数 $\\boldsymbol{U}, \\boldsymbol{W}, \\boldsymbol{b}$ 通过非线性激活函数 $f(\\cdot)$ 计算得到；输出 $\\boldsymbol{y}_{t}$ 由隐状态 $\\boldsymbol{h}_{t}$ 和参数 $\\boldsymbol{V}$ 计算得到。"
      },
      {
        "段落": "### 6．2．1．1 循环神经网络的通用近似定理\n\n循环神经网络的拟合能力也十分强大．一个完全连接的循环网络是任何非线性动力系统的近似器。\n\n定理 6．1－循环神经网络的通用近似定理［Haykin，2009］：如果一个完全连接的循环神经网络有足够数量的 sigmoid 型隐藏神经元，它可以以任意的准确率去近似任何一个非线性动力系统\n\n$$\n\\begin{align*}\n\\boldsymbol{s}_{t} & =g\\left(\\boldsymbol{s}_{t-1}, \\boldsymbol{x}_{t}\\right)  \\tag{6.10}\\\\\n\\boldsymbol{y}_{t} & =o\\left(\\boldsymbol{s}_{t}\\right) \\tag{6.11}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{s}_{t}$ 为每个时刻的隐状态， $\\boldsymbol{x}_{t}$ 是外部输入，$g(\\cdot)$ 是可测的状态转换函数， $o(\\cdot)$ 是连续输出函数，并且对状态空间的紧致性没有限制。\n\n证明．（1）根据通用近似定理，两层的前馈神经网络可以近似任意有界闭集上的任意连续函数。因此，动力系统的两个函数可以用两层的全连接前馈网络近似。\n\n首先，非线性动力系统的状态转换函数 $\\boldsymbol{s}_{t}=g\\left(\\boldsymbol{s}_{t-1}, \\boldsymbol{x}_{t}\\right)$ 可以由一个两层的神经网络 $\\boldsymbol{s}_{t}=C f\\left(A \\boldsymbol{s}_{t-1}+B \\boldsymbol{x}_{t}+\\boldsymbol{b}\\right)$ 来近似，可以分解为\n\n$$\n\\begin{align*}\n\\boldsymbol{s}_{t}^{\\prime} & =f\\left(A \\boldsymbol{s}_{t-1}+B \\boldsymbol{x}_{t}+\\boldsymbol{b}\\right)  \\tag{6.12}\\\\\n& =f\\left(A C \\boldsymbol{s}_{t-1}^{\\prime}+B \\boldsymbol{x}_{t}+\\boldsymbol{b}\\right)  \\tag{6.13}\\\\\n\\boldsymbol{s}_{t} & =C \\boldsymbol{s}_{t}^{\\prime} \\tag{6.14}\n\\end{align*}\n$$\n\n其中 $A, B, C$ 为权重矩阵， $\\boldsymbol{b}$ 为偏置向量．\n同理，非线性动力系统的输出函数 $\\boldsymbol{y}_{t}=o\\left(\\boldsymbol{s}_{t}\\right)=o\\left(g\\left(\\boldsymbol{s}_{t-1}, \\boldsymbol{x}_{t}\\right)\\right)$ 也可以用一个两层的前馈神经网络近似。\n\n$$\n\\begin{align*}\n\\boldsymbol{y}_{t}^{\\prime} & =f\\left(A^{\\prime} \\boldsymbol{s}_{t-1}+B^{\\prime} \\boldsymbol{x}_{t}+\\boldsymbol{b}^{\\prime}\\right)  \\tag{6.15}\\\\\n& =f\\left(A^{\\prime} C \\boldsymbol{s}_{t-1}^{\\prime}+B^{\\prime} \\boldsymbol{x}_{t}+\\boldsymbol{b}^{\\prime}\\right)  \\tag{6.16}\\\\\n\\boldsymbol{y}_{t} & =D \\boldsymbol{y}_{t}^{\\prime} \\tag{6.17}\n\\end{align*}\n$$\n\n其中 $A^{\\prime}, B^{\\prime}, D$ 为权重矩阵， $\\boldsymbol{b}^{\\prime}$ 为偏置向量．\n（2）公式（6．13）和公式（6．16）可以合并为\n\n$$\n\\left[\\begin{array}{l}\n\\boldsymbol{s}_{t}^{\\prime}  \\tag{6.18}\\\\\n\\boldsymbol{y}_{t}^{\\prime}\n\\end{array}\\right]=f\\left(\\left[\\begin{array}{cc}\nA C & 0 \\\\\nA^{\\prime} C & 0\n\\end{array}\\right]\\left[\\begin{array}{l}\n\\boldsymbol{s}_{t-1}^{\\prime} \\\\\n\\boldsymbol{y}_{t-1}^{\\prime}\n\\end{array}\\right]+\\left[\\begin{array}{c}\nB \\\\\nB^{\\prime}\n\\end{array}\\right] \\boldsymbol{x}_{t}+\\left[\\begin{array}{c}\n\\boldsymbol{b} \\\\\n\\boldsymbol{b}^{\\prime}\n\\end{array}\\right]\\right) .\n$$\n\n公式（6．17）可以改写为\n\n$$\n\\boldsymbol{y}_{t}=\\left[\\begin{array}{ll}\n0 & D\n\\end{array}\\right]\\left[\\begin{array}{c}\n\\boldsymbol{s}_{t}^{\\prime}  \\tag{6.19}\\\\\n\\boldsymbol{y}_{t}^{\\prime}\n\\end{array}\\right]\n$$\n\n令 $\\boldsymbol{h}_{t}=\\left[\\boldsymbol{s}_{t}^{\\prime} ; \\boldsymbol{y}_{t}^{\\prime}\\right]$ ，则非线性动力系统可以由下面的全连接循环神经网络来近似。\n\n$$\n\\begin{align*}\n& \\boldsymbol{h}_{t}=f\\left(\\boldsymbol{U} \\boldsymbol{h}_{t-1}+\\boldsymbol{W} \\boldsymbol{x}_{t}+\\boldsymbol{b}\\right)  \\tag{6.20}\\\\\n& \\boldsymbol{y}_{t}=\\boldsymbol{V} \\boldsymbol{h}_{t} \\tag{6.21}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{U}=\\left[\\begin{array}{cc}A C & 0 \\\\ A^{\\prime} C & 0\\end{array}\\right], \\boldsymbol{W}=\\left[\\begin{array}{c}B \\\\ B^{\\prime}\\end{array}\\right], \\boldsymbol{b}=\\left[\\begin{array}{c}\\boldsymbol{b} \\\\ \\boldsymbol{b}^{\\prime}\\end{array}\\right], \\boldsymbol{V}=\\left[\\begin{array}{ll}0 & D\\end{array}\\right]$ ．\n\n通用近似定理参见第 4．3．1节。\n\n本 证 明 参 考 文 献 ［Schäfer et al．，2006］．",
        "总结": "- 循环神经网络的通用近似定理指出，完全连接的循环网络可以以任意准确率近似任何非线性动力系统。  \n- 定理6.1表明，只要隐藏层有足够多的sigmoid型神经元，循环神经网络能够近似任意非线性动力系统。  \n- 非线性动力系统的状态转换函数和输出函数均可由两层前馈神经网络近似。  \n- 通过合并状态和输出的近似表达式，构造了一个全连接循环神经网络来近似非线性动力系统。  \n- 该循环神经网络由隐状态和输出组成，其结构包含权重矩阵、偏置向量和激活函数。  \n- 证明参考了文献[Schäfer et al., 2006]，并基于前馈神经网络的通用近似定理进行推导。"
      },
      {
        "段落": "### 6．2．1．2 图灵完备\n\n图灵完备（Turing Completeness）是指一种数据操作规则，比如一种计算机编程语言，可以实现图灵机（Turing Machine）的所有功能，解决所有的可计算问题．目前主流的编程语言（比如 C＋＋、Java、Python等）都是图灵完备的．\n\n定理 6．2－图灵完备［Siegelmann et al．，1991］：所有的图灵机都可以被一个由使用 Sigmoid 型激活函数的神经元构成的全连接循环网络来进行模拟。\n\n因此，一个完全连接的循环神经网络可以近似解决所有的可计算问题．",
        "总结": "- 图灵完备是指一种数据操作规则或编程语言能够实现图灵机的所有功能，解决所有可计算问题。  \n- 主流编程语言如C++、Java、Python等均为图灵完备。  \n- 定理6．2－图灵完备指出，所有图灵机均可被由Sigmoid型激活函数构成的全连接循环网络模拟。  \n- 全连接循环神经网络可近似解决所有可计算问题。"
      },
      {
        "段落": "## 6.3 应用到机器学习\n\n循环神经网络可以应用到很多不同类型的机器学习任务．根据这些任务的特点可以分为以下几种模式：序列到类别模式、同步的序列到序列模式、异步的序列到序列模式。\n\n下面我们分别来看下这几种应用模式．",
        "总结": "- 提出了循环神经网络（RNN）在不同机器学习任务中的应用模式。  \n- 列举了三种应用模式：序列到类别模式、同步的序列到序列模式、异步的序列到序列模式。  \n- 每种模式根据任务特点进行分类，为后续具体分析奠定基础。"
      },
      {
        "段落": "## 6．3．1 序列到类别模式\n\n序列到类别模式主要用于序列数据的分类问题：输入为序列，输出为类别．比如在文本分类中，输入数据为单词的序列，输出为该文本的类别。\n\n假设一个样本 $\\boldsymbol{x}_{1: T}=\\left(\\boldsymbol{x}_{1}, \\cdots, \\boldsymbol{x}_{T}\\right)$ 为一个长度为 $T$ 的序列，输出为一个类别 $y \\in\\{1, \\cdots, C\\}$ 。我们可以将样本 $\\boldsymbol{x}$ 按不同时刻输入到循环神经网络中，并得到不同时刻的隐藏状态 $\\boldsymbol{h}_{1}, \\cdots, \\boldsymbol{h}_{T}$ 。我们可以将 $\\boldsymbol{h}_{T}$ 看作整个序列的最终表示（或特征），并输入给分类器 $g(\\cdot)$ 进行分类（如图6．3a所示）。\n\n$$\n\\begin{equation*}\n\\hat{y}=g\\left(\\boldsymbol{h}_{T}\\right), \\tag{6.22}\n\\end{equation*}\n$$\n\n其中 $g(\\cdot)$ 可以是简单的线性分类器（比如 Logistic 回归）或复杂的分类器（比如多层前馈神经网络）。\n\n除了将最后时刻的状态作为整个序列的表示之外，我们还可以对整个序列的所有状态进行平均，并用这个平均状态来作为整个序列的表示（如图6．3b所示）。\n\n$$\n\\begin{equation*}\n\\hat{y}=g\\left(\\frac{1}{T} \\sum_{t=1}^{T} \\boldsymbol{h}_{t}\\right) \\tag{6.23}\n\\end{equation*}\n$$\n\n图灵机是一种抽象的信息处理装置，可以用来解决所有的可计算问题，参见第8．5．2节。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-148.jpg?height=269&width=1043&top_left_y=157&top_left_x=123)\n\n图 6.3 序列到类别模式",
        "总结": "- 序列到类别模式用于处理序列数据的分类问题，输入为序列，输出为类别。  \n- 样本表示为长度为 $T$ 的序列 $\\boldsymbol{x}_{1:T}$，输出为类别 $y \\in \\{1, \\cdots, C\\}$。  \n- 通过循环神经网络处理序列，得到不同时刻的隐藏状态 $\\boldsymbol{h}_{1}, \\cdots, \\boldsymbol{h}_{T}$。  \n- 最终表示可以是最后一个时刻的隐藏状态 $\\boldsymbol{h}_T$，并输入分类器进行分类。  \n- 分类器 $g(\\cdot)$ 可以是线性分类器或多层前馈神经网络。  \n- 另一种方法是对所有时刻的隐藏状态进行平均，作为整个序列的表示。  \n- 平均表示形式为 $\\frac{1}{T} \\sum_{t=1}^{T} \\boldsymbol{h}_t$，并输入分类器进行分类。  \n- 图6.3展示了两种不同的序列到类别模式结构。"
      },
      {
        "段落": "## 6．3．2 同步的序列到序列模式\n\n同步的序列到序列模式主要用于序列标注（Sequence Labeling）任务，即每一时刻都有输入和输出，输入序列和输出序列的长度相同。比如在词性标注 （Part－of－Speech Tagging）中，每一个单词都需要标注其对应的词性标签。\n\n在同步的序列到序列模式（如图6．4所示）中，输入为一个长度为 $T$ 的序列 $\\boldsymbol{x}_{1: T}=\\left(\\boldsymbol{x}_{1}, \\cdots, \\boldsymbol{x}_{T}\\right)$ ，输出为序列 $y_{1: T}=\\left(y_{1}, \\cdots, y_{T}\\right)$ 。样本 $\\boldsymbol{x}$ 按不同时刻输入到循环神经网络中，并得到不同时刻的隐状态 $\\boldsymbol{h}_{1}, \\cdots, \\boldsymbol{h}_{T}$ 。每个时刻的隐状态 $\\boldsymbol{h}_{t}$ 代表了当前时刻和历史的信息，并输入给分类器 $g(\\cdot)$ 得到当前时刻的标签 $\\hat{y}_{t}$ 。\n\n$$\n\\begin{equation*}\n\\hat{y}_{t}=g\\left(\\boldsymbol{h}_{t}\\right), \\quad \\forall t \\in[1, T] . \\tag{6.24}\n\\end{equation*}\n$$\n\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-148.jpg?height=207&width=534&top_left_y=1227&top_left_x=373)\n\n图 6.4 同步的序列到序列模式",
        "总结": "- 同步的序列到序列模式用于序列标注任务，输入和输出序列长度相同。  \n- 每个时刻的输入被输入到循环神经网络，生成对应的隐状态。  \n- 隐状态通过分类器得到当前时刻的标签。  \n- 标签生成公式为：$\\hat{y}_{t}=g\\left(\\boldsymbol{h}_{t}\\right)$。  \n- 该模式如图6.4所示，用于处理如词性标注等任务。"
      },
      {
        "段落": "## 6．3．3 异步的序列到序列模式\n\n异步的序列到序列模式也称为编码器－解码器（Encoder－Decoder）模型，即输入序列和输出序列不需要有严格的对应关系，也不需要保持相同的长度。比如在机器翻译中，输入为源语言的单词序列，输出为目标语言的单词序列。\n\n参见第15．6节。\n在异步的序列到序列模式中，输入为长度为 $T$ 的序列 $\\boldsymbol{x}_{1: T}=\\left(\\boldsymbol{x}_{1}, \\cdots, \\boldsymbol{x}_{T}\\right)$ ，输出为长度为 $M$ 的序列 $y_{1: M}=\\left(y_{1}, \\cdots, y_{M}\\right)$ 。异步的序列到序列模式一般通过先编码后解码的方式来实现。先将样本 $\\boldsymbol{x}$ 按不同时刻输入到一个循环神经网络（编码器）中，并得到其编码 $\\boldsymbol{h}_{T}$ 。然后再使用另一个循环神经网络（解码器），得到输出序列 $\\hat{y}_{1: M}$ 。为了建立输出序列之间的依赖关系，在解码器中通常使用非线性的\n\n自回归模型．\n\n$$\n\\begin{align*}\n\\boldsymbol{h}_{t} & =f_{1}\\left(\\boldsymbol{h}_{t-1}, \\boldsymbol{x}_{t}\\right)  \\tag{6.25}\\\\\n\\boldsymbol{h}_{T+t} & =f_{2}\\left(\\boldsymbol{h}_{T+t-1}, \\hat{\\boldsymbol{y}}_{t-1}\\right)  \\tag{6.26}\\\\\n\\hat{y}_{t} & =g\\left(\\boldsymbol{h}_{T+t}\\right) \\tag{6.27}\n\\end{align*}\n$$\n\n$$\n\\begin{aligned}\n& \\forall t \\in[1, T] \\\\\n& \\forall t \\in[1, M] \\\\\n& \\forall t \\in[1, M]\n\\end{aligned}\n$$\n\n其中 $f_{1}(\\cdot)$ 和 $f_{2}(\\cdot)$ 分别为用作编码器和解码器的循环神经网络，$g(\\cdot)$ 为分类器，$\\hat{\\boldsymbol{y}}_{t}$为预测输出 $\\hat{y}_{t}$ 的向量表示。\n\n图6．5给出了异步的序列到序列模式示例，其中 $\\langle E O S\\rangle$ 表示输入序列的结束，虚线表示将上一个时刻的输出作为下一个时刻的输入。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-149.jpg?height=244&width=1064&top_left_y=656&top_left_x=106)\n\n图 6.5 异步的序列到序列模式",
        "总结": "- 异步的序列到序列模式，也称为编码器-解码器模型，输入序列和输出序列无需严格对应或长度相同。  \n- 输入为长度为 $T$ 的序列 $\\boldsymbol{x}_{1:T}$，输出为长度为 $M$ 的序列 $y_{1:M}$。  \n- 通过编码器将输入序列编码为隐状态 $\\boldsymbol{h}_T$，再通过解码器生成输出序列 $\\hat{y}_{1:M}$。  \n- 解码器使用自回归模型建立输出序列之间的依赖关系。  \n- 编码过程通过循环神经网络 $f_1$ 实现，解码过程通过循环神经网络 $f_2$ 实现，最终通过分类器 $g$ 生成输出。  \n- 公式描述了编码与解码过程：$\\boldsymbol{h}_t = f_1(\\boldsymbol{h}_{t-1}, \\boldsymbol{x}_t)$，$\\boldsymbol{h}_{T+t} = f_2(\\boldsymbol{h}_{T+t-1}, \\hat{\\boldsymbol{y}}_{t-1})$，$\\hat{y}_t = g(\\boldsymbol{h}_{T+t})$。  \n- 图6.5展示了异步的序列到序列模式示例，包含输入结束标记 $\\langle E O S\\rangle$ 和解码过程的反馈机制。"
      },
      {
        "段落": "## 6.4 参数学习\n\n循环神经网络的参数可以通过梯度下降方法来进行学习．\n以随机梯度下降为例，给定一个训练样本 $(\\boldsymbol{x}, \\boldsymbol{y})$ ，其中 $\\boldsymbol{x}_{1: T}=\\left(\\boldsymbol{x}_{1}, \\cdots, \\boldsymbol{x}_{T}\\right)$ 为长度是 $T$ 的输入序列，$y_{1: T}=\\left(y_{1}, \\cdots, y_{T}\\right)$ 是长度为 $T$ 的标签序列。即在每个时刻 $t$ ，都有一个监督信息 $y_{t}$ ，我们定义时刻 $t$ 的损失函数为\n\n$$\n\\begin{equation*}\n\\mathcal{L}_{t}=\\mathcal{L}\\left(y_{t}, g\\left(\\boldsymbol{h}_{t}\\right)\\right), \\tag{6.28}\n\\end{equation*}\n$$\n\n其中 $g\\left(\\boldsymbol{h}_{t}\\right)$ 为第 $t$ 时刻的输出， $\\mathcal{L}$ 为可微分的损失函数，比如交叉熵．那么整个序列的损失函数为\n\n$$\n\\begin{equation*}\n\\mathcal{L}=\\sum_{t=1}^{T} \\mathcal{L}_{t} . \\tag{6.29}\n\\end{equation*}\n$$\n\n整个序列的损失函数 $\\mathcal{L}$ 关于参数 $\\boldsymbol{U}$ 的梯度为\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{U}}=\\sum_{t=1}^{T} \\frac{\\partial \\mathcal{L}_{t}}{\\partial \\boldsymbol{U}} \\tag{6.30}\n\\end{equation*}\n$$\n\n即每个时刻损失 $\\mathcal{L}_{t}$ 对参数 $\\boldsymbol{U}$ 的偏导数之和。\n循环神经网络中存在一个递归调用的函数 $f(\\cdot)$ ，因此其计算参数梯度的方式和前馈神经网络不太相同。在循环神经网络中主要有两种计算梯度的方式：随时间反向传播（BPTT）算法和实时循环学习（RTRL）算法．\nhttps：／／nndl．github．io／\n\n自回归模型参见第 6．1．2节。\n\n异步的序列到序列模式可以进一步参见第 15．6．1节．\n\n不失一般性，这里我们以同步的序列到序列模式为例来介绍循环神经网络的参数学习。",
        "总结": "- 参数学习方法：使用梯度下降法，以随机梯度下降为例。  \n- 损失函数定义：每个时刻 $t$ 的损失函数为 $\\mathcal{L}_t = \\mathcal{L}(y_t, g(\\boldsymbol{h}_t))$，其中 $\\mathcal{L}$ 为可微分的损失函数（如交叉熵）。  \n- 整体损失函数：序列总损失为 $\\mathcal{L} = \\sum_{t=1}^{T} \\mathcal{L}_t$。  \n- 参数梯度计算：整个序列的损失函数对参数 $\\boldsymbol{U}$ 的梯度为各时刻损失对参数偏导数之和。  \n- 梯度计算方式：循环神经网络因存在递归调用的函数 $f(\\cdot)$，其梯度计算不同于前馈网络，主要采用随时间反向传播（BPTT）和实时循环学习（RTRL）两种方法。  \n- 同步序列到序列模式：作为示例介绍参数学习过程。"
      },
      {
        "段落": "## 6．4．1 随时间反向传播算法\n\n随时间反向传播（BackPropagation Through Time，BPTT）算法的主要思想是通过类似前馈神经网络的错误反向传播算法［Werbos，1990］来计算梯度．\n\nBPTT 算法将循环神经网络看作是一个展开的多层前馈网络，其中＂每一层＂对应循环网络中的＂每个时刻＂（见图6．2）。这样，循环神经网络就可以按照前馈网络中的反向传播算法计算参数梯度．在＂展开＂的前馈网络中，所有层的参数是共享的，因此参数的真实梯度是所有＂展开层＂的参数梯度之和。\n\n计算偏导数 $\\frac{\\partial \\mathcal{L}_{t}}{\\partial U}$ 先来计算公式（6．30）中第 $t$ 时刻损失对参数 $\\boldsymbol{U}$ 的偏导数 $\\frac{\\partial \\mathcal{L}_{t}}{\\partial U}$ 。\n因为参数 $\\boldsymbol{U}$ 和隐藏层在每个时刻 $k(1 \\leq k \\leq t)$ 的净输入 $\\boldsymbol{z}_{k}=\\boldsymbol{U} \\boldsymbol{h}_{k-1}+$ $\\boldsymbol{W} \\boldsymbol{x}_{k}+\\boldsymbol{b}$ 有关，因此第 $t$ 时刻的损失函数 $\\mathcal{L}_{t}$ 关于参数 $u_{i j}$ 的梯度为：\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}_{t}}{\\partial u_{i j}}=\\sum_{k=1}^{t} \\frac{\\partial^{+} z_{k}}{\\partial u_{i j}} \\frac{\\partial \\mathcal{L}_{t}}{\\partial z_{k}} \\tag{6.31}\n\\end{equation*}\n$$\n\n其中 $\\frac{\\partial^{+} \\boldsymbol{z}_{k}}{\\partial u_{i j}}$ 表示＂直接＂偏导数，即公式 $\\boldsymbol{z}_{k}=\\boldsymbol{U} \\boldsymbol{h}_{k-1}+\\boldsymbol{W} \\boldsymbol{x}_{k}+\\boldsymbol{b}$ 中保持 $\\boldsymbol{h}_{k-1}$ 不变，对 $u_{i j}$ 进行求偏导数，得到\n\n$$\n\\begin{align*}\n\\frac{\\partial^{+} \\boldsymbol{z}_{k}}{\\partial u_{i j}} & =\\left[0, \\cdots,\\left[\\boldsymbol{h}_{k-1}\\right]_{j}, \\cdots, 0\\right]  \\tag{6.32}\\\\\n& \\triangleq \\mathbb{l}_{i}\\left(\\left[\\boldsymbol{h}_{k-1}\\right]_{j}\\right) \\tag{6.33}\n\\end{align*}\n$$\n\n其中 $\\left[\\boldsymbol{h}_{k-1}\\right]_{j}$ 为第 $k-1$ 时刻隐状态的第 $j$ 维； $\\mathbb{D}_{i}(x)$ 除了第 $i$ 行值为 $x$ 外，其余都为 0 的行向量．\n\n定义误差项 $\\delta_{t, k}=\\frac{\\partial \\mathcal{L}_{t}}{\\partial z_{k}}$ 为第 $t$ 时刻的损失对第 $k$ 时刻隐藏神经层的净输入 $\\boldsymbol{z}_{k}$的导数，则当 $1 \\leq k<t$ 时\n\n$$\n\\begin{align*}\n\\delta_{t, k} & =\\frac{\\partial \\mathcal{L}_{t}}{\\partial \\boldsymbol{z}_{k}}  \\tag{6.34}\\\\\n& =\\frac{\\partial \\boldsymbol{h}_{k}}{\\partial \\boldsymbol{z}_{k}} \\frac{\\partial \\boldsymbol{z}_{k+1}}{\\partial \\boldsymbol{h}_{k}} \\frac{\\partial \\mathcal{L}_{t}}{\\partial \\boldsymbol{z}_{k+1}}  \\tag{6.35}\\\\\n& =\\operatorname{diag}\\left(f^{\\prime}\\left(\\boldsymbol{z}_{k}\\right)\\right) \\boldsymbol{U}^{\\top} \\delta_{t, k+1} \\tag{6.36}\n\\end{align*}\n$$\n\n将公式（6．36）和公式（6．33）代入公式（6．31）得到\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}_{t}}{\\partial u_{i j}}=\\sum_{k=1}^{t}\\left[\\delta_{t, k}\\right]_{i}\\left[\\boldsymbol{h}_{k-1}\\right]_{j} . \\tag{6.37}\n\\end{equation*}\n$$\n\n将上式写成矩阵形式为\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}_{t}}{\\partial \\boldsymbol{U}}=\\sum_{k=1}^{t} \\delta_{t, k} \\boldsymbol{h}_{k-1}^{\\top} \\tag{6.38}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n链式法则参见公式（B．18）。\n\n图6．6给出了误差项随时间进行反向传播算法的示例．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-151.jpg?height=337&width=933&top_left_y=204&top_left_x=187)\n\n图 6.6 误差项随时间反向传播算法示例\n\n参数梯度 将公式（6．38）代入到公式（6．30），得到整个序列的损失函数 $\\mathcal{L}$ 关于参数 $\\boldsymbol{U}$ 的梯度\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{U}}=\\sum_{t=1}^{T} \\sum_{k=1}^{t} \\delta_{t, k} \\boldsymbol{h}_{k-1}^{\\top} \\tag{6.39}\n\\end{equation*}\n$$\n\n同理可得， $\\mathcal{L}$ 关于权重 $\\boldsymbol{W}$ 和偏置 $\\boldsymbol{b}$ 的梯度为\n\n$$\n\\begin{align*}\n\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{W}} & =\\sum_{t=1}^{T} \\sum_{k=1}^{t} \\delta_{t, k} \\boldsymbol{x}_{k}^{\\top}  \\tag{6.40}\\\\\n\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{b}} & =\\sum_{t=1}^{T} \\sum_{k=1}^{t} \\delta_{t, k} \\tag{6.41}\n\\end{align*}\n$$\n\n计算复杂度 在 BPTT 算法中，参数的梯度需要在一个完整的＂前向＂计算和＂反向＂计算后才能得到并进行参数更新．",
        "总结": "- 随时间反向传播算法（BPTT）将循环神经网络视为展开的前馈网络，通过反向传播计算参数梯度  \n- BPTT 中，所有展开层的参数共享，参数的真实梯度是各展开层梯度之和  \n- 计算 $\\frac{\\partial \\mathcal{L}_t}{\\partial u_{ij}}$ 时，需考虑每个时刻 $k$ 的净输入 $\\boldsymbol{z}_k$ 对参数 $u_{ij}$ 的偏导数  \n- 直接偏导数 $\\frac{\\partial^+ \\boldsymbol{z}_k}{\\partial u_{ij}}$ 表示对 $u_{ij}$ 求偏导，保持 $\\boldsymbol{h}_{k-1}$ 不变  \n- 定义误差项 $\\delta_{t,k} = \\frac{\\partial \\mathcal{L}_t}{\\partial z_k}$，用于反向传播计算  \n- 当 $1 \\leq k < t$ 时，误差项 $\\delta_{t,k}$ 通过链式法则计算为 $\\operatorname{diag}(f'(\\boldsymbol{z}_k)) \\boldsymbol{U}^\\top \\delta_{t,k+1}$  \n- 将公式（6.36）和（6.33）代入（6.31）得到 $\\frac{\\partial \\mathcal{L}_t}{\\partial u_{ij}} = \\sum_{k=1}^{t} [\\delta_{t,k}]_i [\\boldsymbol{h}_{k-1}]_j$  \n- 矩阵形式表示为 $\\frac{\\partial \\mathcal{L}_t}{\\partial \\boldsymbol{U}} = \\sum_{k=1}^{t} \\delta_{t,k} \\boldsymbol{h}_{k-1}^\\top$  \n- 整个序列的损失函数 $\\mathcal{L}$ 关于参数 $\\boldsymbol{U}$ 的梯度为 $\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{U}} = \\sum_{t=1}^{T} \\sum_{k=1}^{t} \\delta_{t,k} \\boldsymbol{h}_{k-1}^\\top$  \n- 同理可得关于权重 $\\boldsymbol{W}$ 和偏置 $\\boldsymbol{b}$ 的梯度分别为 $\\sum_{t=1}^{T} \\sum_{k=1}^{t} \\delta_{t,k} \\boldsymbol{x}_{k}^\\top$ 和 $\\sum_{t=1}^{T} \\sum_{k=1}^{t} \\delta_{t,k}$  \n- BPTT 算法中，参数梯度需通过完整的前向和反向计算得到，并用于更新参数  \n- 图6.6展示了误差项随时间反向传播的示例"
      },
      {
        "段落": "## 6．4．2 实时循环学习算法\n\n与反向传播的 BPTT 算法不同的是，实时循环学习（Real－Time Recurrent Learning，RTRL）是通过前向传播的方式来计算梯度［Williams et al．，1995］．\n\n假设循环神经网络中第 $t+1$ 时刻的状态 $\\boldsymbol{h}_{t+1}$ 为\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t+1}=f\\left(\\boldsymbol{z}_{t+1}\\right)=f\\left(\\boldsymbol{U} \\boldsymbol{h}_{t}+\\boldsymbol{W} \\boldsymbol{x}_{t+1}+\\boldsymbol{b}\\right) \\tag{6.42}\n\\end{equation*}\n$$\n\n其关于参数 $u_{i j}$ 的偏导数为\n\n$$\n\\begin{align*}\n\\frac{\\partial \\boldsymbol{h}_{t+1}}{\\partial u_{i j}} & =\\left(\\frac{\\partial^{+} \\boldsymbol{z}_{t+1}}{\\partial u_{i j}}+\\frac{\\partial \\boldsymbol{h}_{t}}{\\partial u_{i j}} \\boldsymbol{U}^{\\top}\\right) \\frac{\\partial \\boldsymbol{h}_{t+1}}{\\partial \\boldsymbol{z}_{t+1}}  \\tag{6.43}\\\\\n& =\\left(\\rrbracket_{i}\\left(\\left[\\boldsymbol{h}_{t}\\right]_{j}\\right)+\\frac{\\partial \\boldsymbol{h}_{t}}{\\partial u_{i j}} \\boldsymbol{U}^{\\top}\\right) \\operatorname{diag}\\left(f^{\\prime}\\left(\\boldsymbol{z}_{t+1}\\right)\\right) \\tag{6.44}\n\\end{align*}\n$$\n\nhttps：／／nndl．github．io／\n\n$$\n\\begin{equation*}\n=\\left(\\unrhd_{i}\\left(\\left[\\boldsymbol{h}_{t}\\right]_{j}\\right)+\\frac{\\partial \\boldsymbol{h}_{t}}{\\partial u_{i j}} \\boldsymbol{U}^{\\top}\\right) \\odot\\left(f^{\\prime}\\left(\\boldsymbol{z}_{t+1}\\right)\\right)^{\\top}, \\tag{6.45}\n\\end{equation*}\n$$\n\n其中 $d_{i}(x)$ 是除了第 $i$ 行值为 $x$ 外，其余都为 0 的行向量。\nRTRL算法从第1个时刻开始，除了计算循环神经网络的隐状态之外，还利用公式（6．45）依次前向计算偏导数 $\\frac{\\partial \\boldsymbol{h}_{1}}{\\partial u_{i j}}, \\frac{\\partial \\boldsymbol{h}_{2}}{\\partial u_{i j}}, \\frac{\\partial \\boldsymbol{h}_{3}}{\\partial u_{i j}}, \\cdots$ 。\n\n这样，假设第 $t$ 个时刻存在一个监督信息，其损失函数为 $\\mathcal{L}_{t}$ ，就可以同时计算损失函数对 $u_{i j}$ 的偏导数\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}_{t}}{\\partial u_{i j}}=\\frac{\\partial \\boldsymbol{h}_{t}}{\\partial u_{i j}} \\frac{\\partial \\mathcal{L}_{t}}{\\partial \\boldsymbol{h}_{t}} . \\tag{6.46}\n\\end{equation*}\n$$\n\n这样在第 $t$ 时刻，可以实时地计算损失 $\\mathcal{L}_{t}$ 关于参数 $\\boldsymbol{U}$ 的梯度，并更新参数．参数 $\\boldsymbol{W}$ 和 $\\boldsymbol{b}$ 的梯度也可以同样按上述方法实时计算．\n\n两种算法比较 RTRL算法和 BPTT 算法都是基于梯度下降的算法，分别通过前向模式和反向模式应用链式法则来计算梯度。在循环神经网络中，一般网络输出维度远低于输入维度，因此 BPTT 算法的计算量会更小，但是 BPTT 算法需要保存所有时刻的中间梯度，空间复杂度较高。RTRL算法不需要梯度回传，因此非常适合用于需要在线学习或无限序列的任务中．",
        "总结": "- 实时循环学习（RTRL）算法是一种通过前向传播计算梯度的方法，与反向传播的时间序列算法（BPTT）不同。  \n- RTRL算法通过计算隐状态对参数的偏导数，逐时刻前向传播以实时更新参数。  \n- 在每一步中，利用公式计算隐状态对参数 $u_{ij}$ 的偏导数，并结合损失函数对隐状态的梯度，得到损失函数对参数的梯度。  \n- RTRL算法不需要梯度回传，适合在线学习或处理无限序列的任务。  \n- 与BPTT相比，RTRL的空间复杂度较低，但计算量可能更大。  \n- BPTT需要保存所有时刻的中间梯度，空间复杂度较高，而RTRL则通过前向传播实时计算梯度。"
      },
      {
        "段落": "## 6.5 长程依赖问题\n\n循环神经网络在学习过程中的主要问题是由于梯度消失或爆炸问题，很难建模长时间间隔（Long Range）的状态之间的依赖关系。\n\n在 BPTT 算法中，将公式（6．36）展开得到\n\n$$\n\\begin{equation*}\n\\delta_{t, k}=\\prod_{\\tau=k}^{t-1}\\left(\\operatorname{diag}\\left(f^{\\prime}\\left(\\boldsymbol{z}_{\\tau}\\right)\\right) \\boldsymbol{U}^{\\top}\\right) \\delta_{t, t} \\tag{6.47}\n\\end{equation*}\n$$\n\n如果定义 $\\gamma \\cong\\left\\|\\operatorname{diag}\\left(f^{\\prime}\\left(\\boldsymbol{z}_{\\tau}\\right)\\right) \\boldsymbol{U}^{\\top}\\right\\|$ ，则\n\n$$\n\\begin{equation*}\n\\delta_{t, k} \\cong \\gamma^{t-k} \\delta_{t, t} \\tag{6.48}\n\\end{equation*}\n$$\n\n若 $\\gamma>1$ ，当 $t-k \\rightarrow \\infty$ 时，$\\gamma^{t-k} \\rightarrow \\infty$ 。当间隔 $t-k$ 比较大时，梯度也变得很大，会造成系统不稳定，称为梯度爆炸问题（Gradient Exploding Problem）。\n\n相反，若 $\\gamma<1$ ，当 $t-k \\rightarrow \\infty$ 时，$\\gamma^{t-k} \\rightarrow 0$ ．当间隔 $t-k$ 比较大时，梯度也变得非常小，会出现和深层前馈神经网络类似的梯度消失问题（Vanishing Gradient Problem）．\n\n要注意的是，在循环神经网络中的梯度消失不是说 $\\frac{\\partial \\mathcal{L}_{t}}{\\partial U}$ 的梯度消失了，而是 $\\frac{\\partial \\mathcal{L}_{t}}{\\partial \\boldsymbol{h}_{k}}$ 的梯度消失了（当间隔 $t-k$ 比较大时）。也就是说，参数 $\\boldsymbol{U}$ 的更新主要靠当前时刻 $t$ 的几个相邻状态 $\\boldsymbol{h}_{k}$ 来更新，长距离的状态对参数 $\\boldsymbol{U}$没有影响。\n\n由于循环神经网络经常使用非线性激活函数为 Logistic 函数或 Tanh 函数作为非线性激活函数，其导数值都小于 1 ，并且权重矩阵 $\\|\\boldsymbol{U}\\|$ 也不会太大，因此如果时间间隔 $t-k$ 过大，$\\delta_{t, k}$ 会趋向于 0 ，因而经常会出现梯度消失问题．\n\n虽然简单循环网络理论上可以建立长时间间隔的状态之间的依赖关系，但是由于梯度爆炸或消失问题，实际上只能学习到短期的依赖关系。这样，如果时刻 $t$ 的输出 $y_{t}$ 依赖于时刻 $k$ 的输入 $\\boldsymbol{x}_{k}$ ，当间隔 $t-k$ 比较大时，简单神经网络很难建模这种长距离的依赖关系，称为长程依赖问题（Long－Term Dependencies Problem）．",
        "总结": "- 长程依赖问题是指循环神经网络难以建模长时间间隔的状态之间的依赖关系。  \n- BPTT算法展开后，误差项 $\\delta_{t, k}$ 可表示为 $\\gamma^{t-k} \\delta_{t, t}$，其中 $\\gamma$ 是与激活函数导数和权重矩阵相关的范数。  \n- 若 $\\gamma > 1$，误差项随时间间隔增大而指数增长，导致梯度爆炸问题。  \n- 若 $\\gamma < 1$，误差项随时间间隔增大而指数衰减，导致梯度消失问题。  \n- 梯度消失指的是 $\\frac{\\partial \\mathcal{L}_{t}}{\\partial \\boldsymbol{h}_{k}}$ 的梯度消失，而非参数 $\\boldsymbol{U}$ 的梯度消失。  \n- 使用Logistic或Tanh等激活函数时，其导数值小于1，容易导致梯度消失。  \n- 简单循环网络理论上可建模长程依赖，但实际因梯度问题只能学习短期依赖。  \n- 长程依赖问题指当输出 $y_t$ 依赖于较早的输入 $\\boldsymbol{x}_k$ 时，网络难以建模这种长距离的依赖关系。"
      },
      {
        "段落": "## 6．5．1 改进方案\n\n为了避免梯度爆炸或消失问题，一种最直接的方式就是选取合适的参数，同时使用非饱和的激活函数，尽量使得 $\\operatorname{diag}\\left(f^{\\prime}(\\boldsymbol{z})\\right) \\boldsymbol{U}^{\\top} \\approx 1$ ，这种方式需要足够的人工调参经验，限制了模型的广泛应用。比较有效的方式是通过改进模型或优化方法来缓解循环网络的梯度爆炸和梯度消失问题。\n\n梯度爆炸 一般而言，循环网络的梯度爆炸问题比较容易解决，一般通过权重衰减或梯度截断来避免．\n\n权重衰减是通过给参数增加 $\\ell_{1}$ 或 $\\ell_{2}$ 范数的正则化项来限制参数的取值范围，从而使得 $\\gamma \\leq 1$ ．梯度截断是另一种有效的启发式方法，当梯度的模大于一定阈值时，就将它截断成为一个较小的数。\n\n梯度消失 梯度消失是循环网络的主要问题．除了使用一些优化技巧外，更有效的方式就是改变模型，比如让 $\\boldsymbol{U}=\\boldsymbol{I}$ ，同时令 $\\frac{\\partial \\boldsymbol{h}_{t}}{\\partial \\boldsymbol{h}_{t-1}}=\\boldsymbol{I}$ 为单位矩阵，即\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}=\\boldsymbol{h}_{t-1}+g\\left(\\boldsymbol{x}_{t} ; \\theta\\right), \\tag{6.49}\n\\end{equation*}\n$$\n\n其中 $g(\\cdot)$ 是一个非线性函数，$\\theta$ 为参数．\n公式（6．49）中， $\\boldsymbol{h}_{t}$ 和 $\\boldsymbol{h}_{t-1}$ 之间为线性依赖关系，且权重系数为 1 ，这样就不存在梯度爆炸或消失问题。但是，这种改变也丢失了神经元在反馈边上的非线性激活的性质，因此也降低了模型的表示能力。\n\n为了避免这个缺点，我们可以采用一种更加有效的改进策略：\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}=\\boldsymbol{h}_{t-1}+g\\left(\\boldsymbol{x}_{t}, \\boldsymbol{h}_{t-1} ; \\theta\\right), \\tag{6.50}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n长程依赖问题也称为长期依赖问题或长距离依赖问题．\n\n梯度截断是一种启发式的解决梯度爆炸问题的有效方法，参见第 7．2．4．4节．\n\n这样 $\\boldsymbol{h}_{t}$ 和 $\\boldsymbol{h}_{t-1}$ 之间为既有线性关系，也有非线性关系，并且可以缓解梯度消失问题．但这种改进依然存在两个问题：\n（1）梯度爆炸问题：令 $\\boldsymbol{z}_{k}=\\boldsymbol{U} \\boldsymbol{h}_{k-1}+\\boldsymbol{W} \\boldsymbol{x}_{k}+\\boldsymbol{b}$ 为在第 $k$ 时刻函数 $g(\\cdot)$ 的输入，在计算公式（6．34）中的误差项 $\\delta_{t, k}=\\frac{\\partial \\mathcal{L}_{t}}{\\partial z_{k}}$ 时，梯度可能会过大，从而导致梯度爆炸问题．\n（2）记忆容量（Memory Capacity）问题：随着 $\\boldsymbol{h}_{t}$ 不断累积存储新的输入信息，会发生饱和现象。假设 $g(\\cdot)$ 为 Logistic 函数，则随着时间 $t$ 的增长， $\\boldsymbol{h}_{t}$ 会变得越来越大，从而导致 $\\boldsymbol{h}$ 变得饱和。也就是说，隐状态 $\\boldsymbol{h}_{t}$ 可以存储的信息是有限的，随着记忆单元存储的内容越来越多，其丢失的信息也越来越多。\n\n为了解决这两个问题，可以通过引入门控机制来进一步改进模型．",
        "总结": "- 改进方案旨在解决循环网络中的梯度爆炸和梯度消失问题，通过选择合适的参数和非饱和激活函数，使得 $\\operatorname{diag}\\left(f^{\\prime}(\\boldsymbol{z})\\right) \\boldsymbol{U}^{\\top} \\approx 1$，但需要大量人工调参经验。  \n- 梯度爆炸问题可通过权重衰减或梯度截断解决，其中权重衰减通过 $\\ell_1$ 或 $\\ell_2$ 正则化限制参数范围，梯度截断则在梯度过大时将其截断。  \n- 梯度消失是循环网络的主要问题，可通过改变模型结构，如令 $\\boldsymbol{U} = \\boldsymbol{I}$ 并使 $\\frac{\\partial \\boldsymbol{h}_t}{\\partial \\boldsymbol{h}_{t-1}} = \\boldsymbol{I}$ 来缓解。  \n- 公式（6.49）中 $\\boldsymbol{h}_t$ 与 $\\boldsymbol{h}_{t-1}$ 为线性依赖关系，权重系数为 1，避免了梯度问题，但丢失了非线性激活的性质。  \n- 改进策略（公式 6.50）引入非线性关系，缓解梯度消失问题，但可能仍存在梯度爆炸和记忆容量问题。  \n- 梯度爆炸问题可能因误差项 $\\delta_{t,k}$ 过大而出现。  \n- 记忆容量问题指隐状态 $\\boldsymbol{h}_t$ 随时间累积信息可能导致饱和，从而限制其存储能力。  \n- 引入门控机制可进一步解决上述两个问题。"
      },
      {
        "段落": "## 6.6 基于门控的循环神经网络\n\n为了改善循环神经网络的长程依赖问题，一种非常好的解决方案是在公式（6．50）的基础上引入门控机制来控制信息的累积速度，包括有选择地加入新的信息，并有选择地遗忘之前累积的信息。这一类网络可以称为基于门控的循环神经网络（Gated RNN）。本节中，主要介绍两种基于门控的循环神经网络：长短期记忆网络和门控循环单元网络．",
        "总结": "- 提出概念：基于门控的循环神经网络（Gated RNN），用于改善循环神经网络的长程依赖问题。  \n- 引入机制：通过门控机制控制信息的累积速度，实现有选择地加入新信息和遗忘旧信息。  \n- 主要内容：介绍两种基于门控的循环神经网络，即长短期记忆网络（LSTM）和门控循环单元网络（GRU）。"
      },
      {
        "段落": "## 6．6．1 长短期记忆网络\n\n长短期记忆网络（Long Short－Term Memory Network，LSTM）［Gers et al．， 2000；Hochreiter et al．，1997］是循环神经网络的一个变体，可以有效地解决简单循环神经网络的梯度爆炸或消失问题。\n\n在公式（6．50）的基础上，LSTM网络主要改进在以下两个方面：\n新的内部状态 LSTM 网络引入一个新的内部状态（internal state） $\\boldsymbol{c}_{t} \\in \\mathbb{R}^{D}$ 专门进行线性的循环信息传递，同时（非线性地）输出信息给隐藏层的外部状态 $\\boldsymbol{h}_{t} \\in \\mathbb{R}^{D}$ ．内部状态 $\\boldsymbol{c}_{t}$ 通过下面公式计算：\n\n$$\n\\begin{align*}\n\\boldsymbol{c}_{t} & =\\boldsymbol{f}_{t} \\odot \\boldsymbol{c}_{t-1}+\\boldsymbol{i}_{t} \\odot \\tilde{\\boldsymbol{c}}_{t}  \\tag{6.51}\\\\\n\\boldsymbol{h}_{t} & =\\boldsymbol{o}_{t} \\odot \\tanh \\left(\\boldsymbol{c}_{t}\\right) \\tag{6.52}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{f}_{t} \\in[0,1]^{D} 、 \\boldsymbol{i}_{t} \\in[0,1]^{D}$ 和 $\\boldsymbol{o}_{t} \\in[0,1]^{D}$ 为三个门（gate）来控制信息传递的路径；$\\odot$ 为向量元素乘积； $\\boldsymbol{c}_{t-1}$ 为上一时刻的记忆单元；$\\tilde{\\boldsymbol{c}}_{t} \\in \\mathbb{R}^{D}$ 是通过非线性函数得到的候选状态：\n\n$$\n\\begin{equation*}\n\\tilde{\\boldsymbol{c}}_{t}=\\tanh \\left(\\boldsymbol{W}_{c} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{c} \\boldsymbol{h}_{t-1}+\\boldsymbol{b}_{c}\\right) . \\tag{6.53}\n\\end{equation*}\n$$\n\n在每个时刻 $t$ ，LSTM 网络的内部状态 $\\boldsymbol{c}_{t}$ 记录了到当前时刻为止的历史信息． https：／／nndl．github．io／\n\n这种改进和残差网络十分类似，参见第 5．4．4节。\n\n参见习题 6－3．\n\n还有一种增加记忆容量的方法是增加一些额外的存储单元：外部记忆，参见第 8.5 节。\n\n公式（6．53）～公式（6．56）中的 $\\boldsymbol{W}_{*}, \\boldsymbol{U}_{*}, \\boldsymbol{b}_{*}$ 为可学习的网络参数，其中 $* \\in\\{i, f, o, c\\}$ ．\n\n门控机制 在数字电路中，门（gate）为一个二值变量 $\\{0,1\\}, 0$ 代表关闭状态，不许任何信息通过； 1 代表开放状态，允许所有信息通过。\n\nLSTM 网络引入门控机制（Gating Mechanism）来控制信息传递的路径。公式（6．51）和公式（6．52）中三个＂门＂分别为输入门 $\\boldsymbol{i}_{t}$ 、遗忘门 $\\boldsymbol{f}_{t}$ 和输出门 $\\boldsymbol{o}_{t}$ 。这三个门的作用为\n（1）遗忘门 $\\boldsymbol{f}_{t}$ 控制上一个时刻的内部状态 $\\boldsymbol{c}_{t-1}$ 需要遗忘多少信息．\n（2）输入门 $\\boldsymbol{i}_{t}$ 控制当前时刻的候选状态 $\\tilde{\\boldsymbol{c}}_{t}$ 有多少信息需要保存。\n（3）输出门 $\\boldsymbol{o}_{t}$ 控制当前时刻的内部状态 $\\boldsymbol{c}_{t}$ 有多少信息需要输出给外部状态 $\\boldsymbol{h}_{t}$ 。\n\n当 $\\boldsymbol{f}_{t}=0, \\boldsymbol{i}_{t}=1$ 时，记忆单元将历史信息清空，并将候选状态向量 $\\boldsymbol{c}_{t}$ 写入．但此时记忆单元 $c_{t}$ 依然和上一时刻的历史信息相关。当 $\\boldsymbol{f}_{t}=1, \\boldsymbol{i}_{t}=0$ 时，记忆单元将复制上一时刻的内容，不写入新的信息。\n\nLSTM 网络中的＂门＂是一种＂软＂门，取值在 $(0,1)$ 之间，表示以一定的比例允许信息通过．三个门的计算方式为：\n\n$$\n\\begin{align*}\n\\boldsymbol{i}_{t} & =\\sigma\\left(\\boldsymbol{W}_{i} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{i} \\boldsymbol{h}_{t-1}+\\boldsymbol{b}_{i}\\right)  \\tag{6.54}\\\\\n\\boldsymbol{f}_{t} & =\\sigma\\left(\\boldsymbol{W}_{f} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{f} \\boldsymbol{h}_{t-1}+\\boldsymbol{b}_{f}\\right)  \\tag{6.55}\\\\\n\\boldsymbol{o}_{t} & =\\sigma\\left(\\boldsymbol{W}_{o} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{o} \\boldsymbol{h}_{t-1}+\\boldsymbol{b}_{o}\\right) \\tag{6.56}\n\\end{align*}\n$$\n\n其中 $\\sigma(\\cdot)$ 为 Logistic 函数，其输出区间为 $(0,1), \\boldsymbol{x}_{t}$ 为当前时刻的输入， $\\boldsymbol{h}_{t-1}$ 为上一时刻的外部状态。\n\n图6．7给出了 LSTM 网络的循环单元结构，其计算过程为：（1）首先利用上一时刻的外部状态 $\\boldsymbol{h}_{t-1}$ 和当前时刻的输入 $\\boldsymbol{x}_{t}$ ，计算出三个门，以及候选状态 $\\tilde{\\boldsymbol{c}}_{t}$ ；（2）结合遗忘门 $\\boldsymbol{f}_{t}$ 和输入门 $\\boldsymbol{i}_{t}$ 来更新记忆单元 $\\boldsymbol{c}_{t}$ ；（3）结合输出门 $\\boldsymbol{o}_{t}$ ，将内部状态的信息传递给外部状态 $\\boldsymbol{h}_{t}$ 。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-155.jpg?height=427&width=948&top_left_y=1569&top_left_x=179)\n\n图 6．7 LSTM 网络的循环单元结构\n\n通过 LSTM 循环单元，整个网络可以建立较长距离的时序依赖关系．公式 （6．51）～公式（6．56）可以简洁地描述为\n\n$$\n\\begin{align*}\n{\\left[\\begin{array}{c}\n\\tilde{\\boldsymbol{c}}_{t} \\\\\n\\boldsymbol{o}_{t} \\\\\n\\boldsymbol{i}_{t} \\\\\n\\boldsymbol{f}_{t}\n\\end{array}\\right] } & =\\left[\\begin{array}{c}\n\\tanh \\\\\n\\sigma \\\\\n\\sigma \\\\\n\\sigma\n\\end{array}\\right]\\left(\\boldsymbol{W}\\left[\\begin{array}{c}\n\\boldsymbol{x}_{t} \\\\\n\\boldsymbol{h}_{t-1}\n\\end{array}\\right]+\\boldsymbol{b}\\right)  \\tag{6.57}\\\\\n\\boldsymbol{c}_{t} & =\\boldsymbol{f}_{t} \\odot \\boldsymbol{c}_{t-1}+\\boldsymbol{i}_{t} \\odot \\tilde{\\boldsymbol{c}}_{t}  \\tag{6.58}\\\\\n\\boldsymbol{h}_{t} & =\\boldsymbol{o}_{t} \\odot \\tanh \\left(\\boldsymbol{c}_{t}\\right) \\tag{6.59}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{x}_{t} \\in \\mathbb{R}^{M}$ 为当前时刻的输入， $\\boldsymbol{W} \\in \\mathbb{R}^{4 D \\times(D+M)}$ 和 $\\boldsymbol{b} \\in \\mathbb{R}^{4 D}$ 为网络参数．\n记忆 循环神经网络中的隐状态 $\\boldsymbol{h}$ 存储了历史信息，可以看作是一种记忆（Mem－ ory）。在简单循环网络中，隐状态每个时刻都会被重写，因此可以看作是一种短期记忆（Short－Term Memory）。在神经网络中，长期记忆（Long－Term Mem－ ory）可以看作是网络参数，隐含了从训练数据中学到的经验，其更新周期要远远慢于短期记忆。而在 LSTM 网络中，记忆单元 $\\boldsymbol{c}$ 可以在某个时刻捕捉到某个关键信息，并有能力将此关键信息保存一定的时间间隔。记忆单元 $\\boldsymbol{c}$ 中保存信息的生命周期要长于短期记忆 $\\boldsymbol{h}$ ，但又远远短于长期记忆，因此称为长短期记忆（Long Short－Term Memory ）．\n\n长短期记忆是指长的 ＂短期记忆＂。\n\n一般在深度网络参数学习时，参数初始化的值一般都比较小．但是在训练 LSTM 网络时，过小的值会使得遗忘门的值比较小。这意味着前一时刻的信息大部分都丢失了，这样网络很难捕捉到长距离的依赖信息。并且相邻时间间隔的梯度会非常小，这会导致梯度弥散问题。因此遗忘的参数初始值一般都设得比较大，其偏置向量 $\\boldsymbol{b}_{f}$ 设为 1 或 2 。",
        "总结": "- 长短期记忆网络（LSTM）是循环神经网络的变体，用于解决梯度消失或爆炸问题  \n- LSTM引入内部状态$\\boldsymbol{c}_t$进行线性循环信息传递，并通过非线性输出到外部状态$\\boldsymbol{h}_t$  \n- 内部状态$\\boldsymbol{c}_t$由遗忘门$\\boldsymbol{f}_t$、输入门$\\boldsymbol{i}_t$和候选状态$\\tilde{\\boldsymbol{c}}_t$计算得到  \n- 三个门（遗忘门、输入门、输出门）控制信息传递路径，分别对应信息遗忘、保存和输出  \n- 门控机制通过Logistic函数计算，取值范围在$(0,1)$之间，实现“软”控制  \n- 记忆单元$\\boldsymbol{c}_t$保存历史信息，生命周期长于短期记忆$\\boldsymbol{h}_t$，但短于长期记忆  \n- LSTM通过门控机制有效捕捉长距离时序依赖关系，避免梯度弥散问题  \n- 参数初始化时遗忘门偏置$\\boldsymbol{b}_f$通常设为1或2，以保留更多历史信息"
      },
      {
        "段落": "## 6．6．2 LSTM 网络的各种变体\n\n目前主流的 LSTM 网络用三个门来动态地控制内部状态应该遗忘多少历史信息，输入多少新信息，以及输出多少信息。我们可以对门控机制进行改进并获得 LSTM 网络的不同变体．\n\n无遗忘门的 LSTM 网络［Hochreiter et al．，1997］最早提出的 LSTM 网络是没有遗忘门的，其内部状态的更新为\n\n$$\n\\begin{equation*}\nc_{t}=c_{t-1}+i_{t} \\odot \\tilde{c}_{t} . \\tag{6.60}\n\\end{equation*}\n$$\n\n如之前的分析，记忆单元 $\\boldsymbol{c}$ 会不断增大．当输入序列的长度非常大时，记忆单元的容量会饱和，从而大大降低 LSTM 模型的性能。\nhttps：／／nndl．github．io／\npeephole 连接 另外一种变体是三个门不但依赖于输入 $\\boldsymbol{x}_{t}$ 和上一时刻的隐状态 $\\boldsymbol{h}_{t-1}$ ，也依赖于上一个时刻的记忆单元 $\\boldsymbol{c}_{t-1}$ 。\n\n$$\n\\begin{align*}\n\\boldsymbol{i}_{t} & =\\sigma\\left(\\boldsymbol{W}_{i} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{i} \\boldsymbol{h}_{t-1}+\\boldsymbol{V}_{i} \\boldsymbol{c}_{t-1}+\\boldsymbol{b}_{i}\\right)  \\tag{6.61}\\\\\n\\boldsymbol{f}_{t} & =\\sigma\\left(\\boldsymbol{W}_{f} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{f} \\boldsymbol{h}_{t-1}+\\boldsymbol{V}_{f} \\boldsymbol{c}_{t-1}+\\boldsymbol{b}_{f}\\right)  \\tag{6.62}\\\\\n\\boldsymbol{o}_{t} & =\\sigma\\left(\\boldsymbol{W}_{o} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{o} \\boldsymbol{h}_{t-1}+\\boldsymbol{V}_{o} \\boldsymbol{c}_{t}+\\boldsymbol{b}_{o}\\right) \\tag{6.63}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{V}_{i}, \\boldsymbol{V}_{f}$ 和 $\\boldsymbol{V}_{o}$ 为对角矩阵。\n耦合输入门和遗忘门 LSTM 网络中的输入门和遗忘门有些互补关系，因此同时用两个门比较冗余。为了减少 LSTM 网络的计算复杂度，将这两门合并为一个门。\n令 $\\boldsymbol{f}_{t}=\\mathbf{1}-\\boldsymbol{i}_{t}$ ，内部状态的更新方式为\n\n$$\n\\begin{equation*}\nc_{t}=\\left(1-i_{t}\\right) \\odot c_{t-1}+i_{t} \\odot \\tilde{c}_{t} \\tag{6.64}\n\\end{equation*}\n$$",
        "总结": "- LSTM网络的变体通过改进门控机制实现  \n- 无遗忘门的LSTM网络最早提出，其内部状态更新公式为 $c_t = c_{t-1} + i_t \\odot \\tilde{c}_t$  \n- 记忆单元 $c$ 随时间不断增大，可能导致容量饱和，影响模型性能  \n- Peephole连接变体中，三个门不仅依赖于输入 $x_t$ 和隐状态 $h_{t-1}$，还依赖于记忆单元 $c_{t-1}$  \n- 输入门和遗忘门的耦合变体通过合并两个门以减少计算复杂度，公式为 $f_t = 1 - i_t$，并更新为 $c_t = (1 - i_t) \\odot c_{t-1} + i_t \\odot \\tilde{c}_t$"
      },
      {
        "段落": "## 6．6．3 门控循环单元网络\n\n门控循环单元（Gated Recurrent Unit，GRU）网络［Cho et al．，2014；Chung et al．，2014］是一种比 LSTM 网络更加简单的循环神经网络．\n\nGRU网络引入门控机制来控制信息更新的方式。和 LSTM 不同，GRU 不引入额外的记忆单元，GRU 网络也是在公式（6．50）的基础上引入一个更新门（Update Gate）来控制当前状态需要从历史状态中保留多少信息（不经过非线性变换），以及需要从候选状态中接受多少新信息。\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}=\\boldsymbol{z}_{t} \\odot \\boldsymbol{h}_{t-1}+\\left(1-\\boldsymbol{z}_{t}\\right) \\odot g\\left(\\boldsymbol{x}_{t}, \\boldsymbol{h}_{t-1} ; \\theta\\right) \\tag{6.65}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{z}_{t} \\in[0,1]^{D}$ 为更新门，\n\n$$\n\\begin{equation*}\n\\boldsymbol{z}_{t}=\\sigma\\left(\\boldsymbol{W}_{z} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{z} \\boldsymbol{h}_{t-1}+\\boldsymbol{b}_{z}\\right) \\tag{6.66}\n\\end{equation*}\n$$\n\n在 LSTM 网络中，输入门和遗忘门是互补关系，具有一定的冗余性。GRU网络直接使用一个门来控制输入和遗忘之间的平衡。当 $\\boldsymbol{z}_{t}=\\mathbf{0}$ 时，当前状态 $\\boldsymbol{h}_{t}$ 和前一时刻的状态 $\\boldsymbol{h}_{t-1}$ 之间为非线性函数关系；当 $\\boldsymbol{z}_{t}=\\mathbf{1}$ 时， $\\boldsymbol{h}_{t}$ 和 $\\boldsymbol{h}_{t-1}$ 之间为线性函数关系。\n\n在 GRU 网络中，函数 $g\\left(\\boldsymbol{x}_{t}, \\boldsymbol{h}_{t-1} ; \\theta\\right)$ 的定义为\n\n$$\n\\begin{equation*}\n\\tilde{\\boldsymbol{h}}_{t}=\\tanh \\left(\\boldsymbol{W}_{h} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{h}\\left(\\boldsymbol{r}_{t} \\odot \\boldsymbol{h}_{t-1}\\right)+\\boldsymbol{b}_{h}\\right) \\tag{6.67}\n\\end{equation*}\n$$\n\n其中 $\\tilde{\\boldsymbol{h}}_{t}$ 表示当前时刻的候选状态， $\\boldsymbol{r}_{t} \\in[0,1]^{D}$ 为重置门（Reset Gate）\n\n$$\n\\begin{equation*}\n\\boldsymbol{r}_{t}=\\sigma\\left(\\boldsymbol{W}_{r} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{r} \\boldsymbol{h}_{t-1}+\\boldsymbol{b}_{r}\\right) \\tag{6.68}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n公式（6．66）～公式（6．68）中的 $\\boldsymbol{W}_{*}, \\boldsymbol{U}_{*}, \\boldsymbol{b}_{*}$ 为可学习的网络参数，其中 $* \\in\\{b, r, z\\}$ ．\n\n这里使用 tanh 激 活 函数是由于其导数有比较大的值域，能够缓解梯度消失问题．\n\n用来控制候选状态 $\\tilde{\\boldsymbol{h}}_{t}$ 的计算是否依赖上一时刻的状态 $\\boldsymbol{h}_{t-1}$ ．\n当 $\\boldsymbol{r}_{t}=\\mathbf{0}$ 时，候选状态 $\\tilde{\\boldsymbol{h}}_{t}=\\tanh \\left(\\boldsymbol{W}_{c} \\boldsymbol{x}_{t}+\\boldsymbol{b}\\right)$ 只和当前输入 $\\boldsymbol{x}_{t}$ 相关，和历史状态无关。当 $\\boldsymbol{r}_{t}=\\mathbf{1}$ 时，候选状态 $\\tilde{\\boldsymbol{h}}_{t}=\\tanh \\left(\\boldsymbol{W}_{h} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{h} \\boldsymbol{h}_{t-1}+\\boldsymbol{b}_{h}\\right)$ 和当前输入 $\\boldsymbol{x}_{t}$以及历史状态 $\\boldsymbol{h}_{t-1}$ 相关，和简单循环网络一致．\n\n综上，GRU 网络的状态更新方式为\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}=\\boldsymbol{z}_{t} \\odot \\boldsymbol{h}_{t-1}+\\left(1-\\boldsymbol{z}_{t}\\right) \\odot \\tilde{\\boldsymbol{h}}_{t} \\tag{6.69}\n\\end{equation*}\n$$\n\n可以看出，当 $\\boldsymbol{z}_{t}=0, \\boldsymbol{r}=1$ 时，GRU网络退化为简单循环网络；若 $\\boldsymbol{z}_{t}=0, \\boldsymbol{r}=0$时，当前状态 $\\boldsymbol{h}_{t}$ 只和当前输入 $\\boldsymbol{x}_{t}$ 相关，和历史状态 $\\boldsymbol{h}_{t-1}$ 无关。当 $\\boldsymbol{z}_{t}=1$ 时，当前状态 $\\boldsymbol{h}_{t}=\\boldsymbol{h}_{t-1}$ 等于上一时刻状态 $\\boldsymbol{h}_{t-1}$ ，和当前输入 $\\boldsymbol{x}_{t}$ 无关。\n\n图6．8给出了 GRU 网络的循环单元结构．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-158.jpg?height=468&width=937&top_left_y=796&top_left_x=183)\n\n图 6．8 GRU 网络的循环单元结构",
        "总结": "- 门控循环单元（GRU）是一种比LSTM更简单的循环神经网络  \n- GRU通过引入更新门控制当前状态从历史状态保留的信息量和从候选状态接受的新信息量  \n- GRU的更新门公式为 $\\boldsymbol{z}_{t}=\\sigma\\left(\\boldsymbol{W}_{z} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{z} \\boldsymbol{h}_{t-1}+\\boldsymbol{b}_{z}\\right)$  \n- GRU的候选状态计算引入重置门 $\\boldsymbol{r}_{t}=\\sigma\\left(\\boldsymbol{W}_{r} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{r} \\boldsymbol{h}_{t-1}+\\boldsymbol{b}_{r}\\right)$ 来控制是否依赖上一时刻状态  \n- 候选状态公式为 $\\tilde{\\boldsymbol{h}}_{t}=\\tanh \\left(\\boldsymbol{W}_{h} \\boldsymbol{x}_{t}+\\boldsymbol{U}_{h}\\left(\\boldsymbol{r}_{t} \\odot \\boldsymbol{h}_{t-1}\\right)+\\boldsymbol{b}_{h}\\right)$  \n- GRU的状态更新公式为 $\\boldsymbol{h}_{t}=\\boldsymbol{z}_{t} \\odot \\boldsymbol{h}_{t-1}+\\left(1-\\boldsymbol{z}_{t}\\right) \\odot \\tilde{\\boldsymbol{h}}_{t}$  \n- 当 $\\boldsymbol{z}_{t}=0$ 且 $\\boldsymbol{r}=1$ 时，GRU退化为简单循环网络  \n- 当 $\\boldsymbol{z}_{t}=0$ 且 $\\boldsymbol{r}=0$ 时，当前状态仅依赖当前输入，与历史状态无关  \n- 当 $\\boldsymbol{z}_{t}=1$ 时，当前状态等于上一时刻状态，与当前输入无关  \n- GRU通过更新门和重置门实现对信息流的控制，简化了LSTM的记忆单元结构"
      },
      {
        "段落": "## 6.7 深层循环神经网络\n\n如果将深度定义为网络中信息传递路径长度的话，循环神经网络可以看作是既＂深＂又＂浅＂的网络。一方面来说，如果我们把循环网络按时间展开，长时间间隔的状态之间的路径很长，循环网络可以看作是一个非常深的网络。从另一方面来说，如果同一时刻网络输入到输出之间的路径 $\\boldsymbol{x}_{t} \\rightarrow \\boldsymbol{y}_{t}$ ，这个网络是非常浅的。\n\n因此，我们可以增加循环神经网络的深度从而增强循环神经网络的能力。增加循环神经网络的深度主要是增加同一时刻网络输入到输出之间的路径 $\\boldsymbol{x}_{t} \\rightarrow$ $y_{t}$ ，比如增加隐状态到输出 $\\boldsymbol{h}_{t} \\rightarrow \\boldsymbol{y}_{t}$ ，以及输入到隐状态 $\\boldsymbol{x}_{t} \\rightarrow \\boldsymbol{h}_{t}$ 之间的路径的深度．",
        "总结": "- 概念：深层循环神经网络，通过增加网络深度来增强模型能力。  \n- 算法：通过增加同一时刻输入到输出之间的路径深度，如隐状态到输出和输入到隐状态的路径。  \n- 数学推导：提到时间展开后，长时间间隔状态之间的路径较长，使循环网络可视为深网络；同一时刻输入到输出的路径较短，使网络较浅。  \n- 命题：增加循环神经网络的深度可以提升其表达能力。"
      },
      {
        "段落": "## 6．7．1 堆叠循环神经网络\n\n一种常见的增加循环神经网络深度的做法是将多个循环网络堆叠起来，称为堆叠循环神经网络（Stacked Recurrent Neural Network，SRNN）。一个堆叠的简单循环网络（Stacked SRN）也称为循环多层感知器（Recurrent Multi－ Layer Perceptron，RMLP ）［Parlos et al．，1991］．\n\n图6．9给出了按时间展开的堆叠循环神经网络．第 $l$ 层网络的输入是第 $l-1$层网络的输出。我们定义 $\\boldsymbol{h}_{t}^{(l)}$ 为在时刻 $t$ 时第 $l$ 层的隐状态\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}^{(l)}=f\\left(\\boldsymbol{U}^{(l)} \\boldsymbol{h}_{t-1}^{(l)}+\\boldsymbol{W}^{(l)} \\boldsymbol{h}_{t}^{(l-1)}+\\boldsymbol{b}^{(l)}\\right) \\tag{6.70}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{U}^{(l)} 、 \\boldsymbol{W}^{(l)}$ 和 $\\boldsymbol{b}^{(l)}$ 为权重矩阵和偏置向量， $\\boldsymbol{h}_{t}^{(0)}=\\boldsymbol{x}_{t}$ 。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-159.jpg?height=370&width=887&top_left_y=738&top_left_x=197)\n\n图 6.9 按时间展开的堆叠循环神经网络",
        "总结": "- 堆叠循环神经网络（Stacked Recurrent Neural Network，SRNN）是一种通过堆叠多个循环网络来增加循环神经网络深度的方法。  \n- 堆叠的简单循环网络也被称为循环多层感知器（Recurrent Multi-Layer Perceptron，RMLP）。  \n- 图6.9展示了按时间展开的堆叠循环神经网络结构。  \n- 第 $l$ 层网络的输入是第 $l-1$ 层网络的输出。  \n- 在时刻 $t$，第 $l$ 层的隐状态 $\\boldsymbol{h}_{t}^{(l)}$ 由以下公式定义：  \n  $$\n  \\boldsymbol{h}_{t}^{(l)}=f\\left(\\boldsymbol{U}^{(l)} \\boldsymbol{h}_{t-1}^{(l)}+\\boldsymbol{W}^{(l)} \\boldsymbol{h}_{t}^{(l-1)}+\\boldsymbol{b}^{(l)}\\right)\n  $$  \n- 其中 $\\boldsymbol{U}^{(l)}$、$\\boldsymbol{W}^{(l)}$ 和 $\\boldsymbol{b}^{(l)}$ 分别为权重矩阵和偏置向量。  \n- 初始隐状态 $\\boldsymbol{h}_{t}^{(0)}$ 等于输入 $\\boldsymbol{x}_{t}$。"
      },
      {
        "段落": "## 6．7．2 双向循环神经网络\n\n在有些任务中，一个时刻的输出不但和过去时刻的信息有关，也和后续时刻的信息有关。比如给定一个句子，其中一个词的词性由它的上下文决定，即包含左右两边的信息。因此，在这些任务中，我们可以增加一个按照时间的逆序来传递信息的网络层，来增强网络的能力。\n\n双向循环神经网络（Bidirectional Recurrent Neural Network，Bi－RNN）由两层循环神经网络组成，它们的输入相同，只是信息传递的方向不同．\n\n假设第 1 层按时间顺序，第 2 层按时间逆序，在时刻 $t$ 时的隐状态定义为 $\\boldsymbol{h}_{t}^{(1)}$和 $\\boldsymbol{h}_{t}^{(2)}$ ，则\n\n$$\n\\begin{align*}\n\\boldsymbol{h}_{t}^{(1)} & =f\\left(\\boldsymbol{U}^{(1)} \\boldsymbol{h}_{t-1}^{(1)}+\\boldsymbol{W}^{(1)} \\boldsymbol{x}_{t}+\\boldsymbol{b}^{(1)}\\right)  \\tag{6.71}\\\\\n\\boldsymbol{h}_{t}^{(2)} & =f\\left(\\boldsymbol{U}^{(2)} \\boldsymbol{h}_{t+1}^{(2)}+\\boldsymbol{W}^{(2)} \\boldsymbol{x}_{t}+\\boldsymbol{b}^{(2)}\\right)  \\tag{6.72}\\\\\n\\boldsymbol{h}_{t} & =\\boldsymbol{h}_{t}^{(1)} \\oplus \\boldsymbol{h}_{t}^{(2)} \\tag{6.73}\n\\end{align*}\n$$\n\n其中 $\\oplus$ 为向量拼接操作．\n图6．10给出了按时间展开的双向循环神经网络．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-160.jpg?height=376&width=889&top_left_y=128&top_left_x=196)\n\n图 6.10 按时间展开的双向循环神经网络",
        "总结": "- 概念：双向循环神经网络（Bi-RNN）由两个按不同方向传递信息的循环神经网络层组成，用于处理需要同时考虑过去和未来信息的任务。\n- 算法：Bi-RNN通过两个方向的隐状态（正向和反向）进行信息传递，并将两个方向的隐状态拼接起来作为最终输出。\n- 数学推导：正向隐状态 $\\boldsymbol{h}_{t}^{(1)}$ 由当前输入和前一时刻的隐状态计算得到，反向隐状态 $\\boldsymbol{h}_{t}^{(2)}$ 由当前输入和下一时刻的隐状态计算得到，最终隐状态为两者的拼接 $\\boldsymbol{h}_{t} = \\boldsymbol{h}_{t}^{(1)} \\oplus \\boldsymbol{h}_{t}^{(2)}$。"
      },
      {
        "段落": "## 6.8 扩展到图结构\n\n如果将循环神经网络按时间展开，每个时刻的隐状态 $\\boldsymbol{h}_{t}$ 看作一个节点，那么这些节点构成一个链式结构，每个节点 $t$ 都收到其父节点的消息（Message），更新自己的状态，并传递给其子节点。而链式结构是一种特殊的图结构，我们可以比较容易地将这种消息传递（Message Passing）的思想扩展到任意的图结构上。",
        "总结": "- 概念：消息传递（Message Passing）机制，用于在图结构中传播信息。  \n- 算法：基于循环神经网络（RNN）的时间展开形式，将每个时刻的隐状态视为图中的节点，并通过消息传递更新节点状态。  \n- 图结构扩展：链式结构作为图结构的特例，消息传递机制可推广至任意图结构。"
      },
      {
        "段落": "## 6．8．1 递归神经网络\n\n递归神经网络（Recursive Neural Network，RecNN）是循环神经网络在有向无循环图上的扩展［Pollack，1990］．递归神经网络的一般结构为树状的层次结构，如图6．11a所示．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-160.jpg?height=378&width=1112&top_left_y=1302&top_left_x=93)\n\n图 6.11 递归神经网络\n\n以图6．11a中的结构为例，有三个隐藏层 $\\boldsymbol{h}_{1} 、 \\boldsymbol{h}_{2}$ 和 $\\boldsymbol{h}_{3}$ ，其中 $\\boldsymbol{h}_{1}$ 由两个输入层 $\\boldsymbol{x}_{1}$ 和 $\\boldsymbol{x}_{2}$ 计算得到， $\\boldsymbol{h}_{2}$ 由另外两个输入层 $\\boldsymbol{x}_{3}$ 和 $\\boldsymbol{x}_{4}$ 计算得到， $\\boldsymbol{h}_{3}$ 由两个隐藏层 $\\boldsymbol{h}_{1}$和 $\\boldsymbol{h}_{2}$ 计算得到。\n\n对于一个节点 $\\boldsymbol{h}_{i}$ ，它可以接受来自父节点集合 $\\pi_{i}$ 中所有节点的消息，并更新自己的状态。\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{i}=f\\left(\\boldsymbol{h}_{\\pi_{i}}\\right), \\tag{6.74}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{h}_{\\pi_{i}}$ 表示集合 $\\pi_{i}$ 中所有节点状态的拼接，$f(\\cdot)$ 是一个和节点位置无关的非线性函数，可以为一个单层的前馈神经网络．比如图6．11a所示的递归神经网络具体可以写为\n\n$$\n\\begin{align*}\n& \\boldsymbol{h}_{1}=\\sigma\\left(\\boldsymbol{W}\\left[\\begin{array}{l}\n\\boldsymbol{x}_{1} \\\\\n\\boldsymbol{x}_{2}\n\\end{array}\\right]+\\boldsymbol{b}\\right)  \\tag{6.75}\\\\\n& \\boldsymbol{h}_{2}=\\sigma\\left(\\boldsymbol{W}\\left[\\begin{array}{l}\n\\boldsymbol{x}_{3} \\\\\n\\boldsymbol{x}_{4}\n\\end{array}\\right]+\\boldsymbol{b}\\right)  \\tag{6.76}\\\\\n& \\boldsymbol{h}_{3}=\\sigma\\left(\\boldsymbol{W}\\left[\\begin{array}{l}\n\\boldsymbol{h}_{1} \\\\\n\\boldsymbol{h}_{2}\n\\end{array}\\right]+\\boldsymbol{b}\\right) \\tag{6.77}\n\\end{align*}\n$$\n\n其中 $\\sigma(\\cdot)$ 表示非线性激活函数， $\\boldsymbol{W}$ 和 $\\boldsymbol{b}$ 是可学习的参数．同样，输出层 $y$ 可以为一个分类器，比如\n\n$$\n\\begin{equation*}\ny=g\\left(\\boldsymbol{W}^{\\prime} \\boldsymbol{h}_{3}+\\boldsymbol{b}^{\\prime}\\right) \\tag{6.78}\n\\end{equation*}\n$$\n\n其中 $g(\\cdot)$ 为分类器， $\\boldsymbol{W}^{\\prime}$ 和 $\\boldsymbol{b}^{\\prime}$ 为分类器的参数．\n当递归神经网络的结构退化为线性序列结构（见图6．11b）时，递归神经网络就等价于简单循环网络．\n\n参见习题 6－6．\n递归神经网络主要用来建模自然语言句子的语义［Socher et al．，2011，2013］．给定一个句子的语法结构（一般为树状结构），可以使用递归神经网络来按照句法的组合关系来合成一个句子的语义。句子中每个短语成分又可以分成一些子成分，即每个短语的语义都可以由它的子成分语义组合而来，并进而合成整句的语义．\n\n同样，我们也可以用门控机制来改进递归神经网络中的长距离依赖问题，比如树结构的长短期记忆模型（Tree－Structured LSTM）［Tai et al．，2015；Zhu et al．， 2015］就是将 LSTM 模型的思想应用到树结构的网络中，来实现更灵活的组合函数．",
        "总结": "- 递归神经网络（RecNN）是循环神经网络在有向无环图上的扩展，结构为树状层次结构。  \n- 每个节点通过接收父节点消息并更新自身状态来计算其隐藏状态。  \n- 隐藏状态的计算公式为 $\\boldsymbol{h}_{i} = f(\\boldsymbol{h}_{\\pi_{i}})$，其中 $f(\\cdot)$ 是非线性函数，如单层前馈神经网络。  \n- 具体实例中，隐藏层通过拼接输入或子节点状态并应用激活函数计算，如 $\\boldsymbol{h}_{3} = \\sigma(\\boldsymbol{W}[\\boldsymbol{h}_{1}, \\boldsymbol{h}_{2}] + \\boldsymbol{b})$。  \n- 输出层可为分类器，如 $y = g(\\boldsymbol{W}'\\boldsymbol{h}_{3} + \\boldsymbol{b}')$。  \n- 当结构退化为线性序列时，RecNN等价于简单循环网络。  \n- RecNN主要用于建模自然语言句子的语义，基于语法树结构合成句子语义。  \n- 句子中每个短语的语义由其子成分语义组合而来，最终合成整句语义。  \n- 可通过门控机制（如Tree-Structured LSTM）改进长距离依赖问题，实现更灵活的组合函数。"
      },
      {
        "段落": "## 6．8．2 图神经网络\n\n在实际应用中，很多数据是图结构的，比如知识图谱、社交网络、分子网络等。而前馈网络和反馈网络很难处理图结构的数据。\n\n图神经网络（Graph Neural Network，GNN）是将消息传递的思想扩展到图结构数据上的神经网络．\n\n对于一个任意的图结构 $G(\\mathcal{V}, \\mathcal{E})$ ，其中 $\\mathcal{V}$ 表示节点集合， $\\mathcal{E}$ 表示边集合。每条边表示两个节点之间的依赖关系．节点之间的连接可以是有向的，也可以是无向 https：／／nndl．github．io／\n\n的．图中每个节点 $v$ 都用一组神经元来表示其状态 $\\boldsymbol{h}^{(v)}$ ，初始状态可以为节点 $v$的输入特征 $\\boldsymbol{x}^{(v)}$ 。每个节点可以收到来自相邻节点的消息，并更新自己的状态。\n\n$$\n\\begin{align*}\n\\boldsymbol{m}_{t}^{(v)} & =\\sum_{u \\in \\mathcal{N}(v)} f\\left(\\boldsymbol{h}_{t-1}^{(v)}, \\boldsymbol{h}_{t-1}^{(u)}, \\boldsymbol{e}^{(u, v)}\\right)  \\tag{6.79}\\\\\n\\boldsymbol{h}_{t}^{(v)} & =g\\left(\\boldsymbol{h}_{t-1}^{(v)}, \\boldsymbol{m}_{t}^{(v)}\\right) \\tag{6.80}\n\\end{align*}\n$$\n\n其中 $\\mathcal{N}(v)$ 表示节点 $v$ 的邻居， $\\boldsymbol{m}_{t}^{(v)}$ 表示在第 $t$ 时刻节点 $v$ 收到的信息， $\\boldsymbol{e}^{(u, v)}$ 为边 $e^{(u, v)}$ 上的特征。\n\n公式（6．79）和公式（6．80）是一种同步的更新方式，所有的结构同时接受信息并更新自己的状态。而对于有向图来说，使用异步的更新方式会更有效率，比如循环神经网络或递归神经网络。在整个图更新 $T$ 次后，可以通过一个读出函数 （Readout Function）$g(\\cdot)$ 来得到整个网络的表示：\n\n$$\n\\begin{equation*}\n\\boldsymbol{o}_{t}=g\\left(\\left\\{\\boldsymbol{h}_{T}^{(v)} \\mid v \\in \\mathcal{V}\\right\\}\\right) . \\tag{6.81}\n\\end{equation*}\n$$",
        "总结": "- 图神经网络（GNN）是一种扩展消息传递思想到图结构数据上的神经网络  \n- 图结构数据包括知识图谱、社交网络、分子网络等，传统前馈网络和反馈网络难以处理  \n- 图 $G(\\mathcal{V}, \\mathcal{E})$ 由节点集合 $\\mathcal{V}$ 和边集合 $\\mathcal{E}$ 组成，边表示节点间的依赖关系  \n- 每个节点 $v$ 用状态 $\\boldsymbol{h}^{(v)}$ 表示，初始状态为节点输入特征 $\\boldsymbol{x}^{(v)}$  \n- 节点通过接收相邻节点消息更新自身状态，消息计算公式为 $\\boldsymbol{m}_{t}^{(v)} = \\sum_{u \\in \\mathcal{N}(v)} f\\left(\\boldsymbol{h}_{t-1}^{(v)}, \\boldsymbol{h}_{t-1}^{(u)}, \\boldsymbol{e}^{(u, v)}\\right)$  \n- 状态更新公式为 $\\boldsymbol{h}_{t}^{(v)} = g\\left(\\boldsymbol{h}_{t-1}^{(v)}, \\boldsymbol{m}_{t}^{(v)}\\right)$  \n- 消息传递和状态更新是同步进行的，适用于无向图；有向图可采用异步更新方式，如循环神经网络或递归神经网络  \n- 图更新 $T$ 次后，通过读出函数 $g(\\cdot)$ 得到整个网络的表示 $\\boldsymbol{o}_{t} = g\\left(\\left\\{\\boldsymbol{h}_{T}^{(v)} \\mid v \\in \\mathcal{V}\\right\\}\\right)$"
      },
      {
        "段落": "## 6.9 总结和深入阅读\n\n循环神经网络可以建模时间序列数据之间的相关性．和延时神经网络［Lang et al．，1990；Waibel et al．，1989］以及有外部输入的非线性自回归模型［Leontaritis et al．，1985］相比，循环神经网络可以更方便地建模长时间间隔的相关性．\n\n常用的循环神经网络的参数学习算法是 BPTT 算法［Werbos，1990］，其计算时间和空间要求会随时间线性增长。为了提高效率，当输入序列的长度比较大时，可以使用带截断（truncated）的 BPTT 算法［Williams et al．，1990］，只计算固定时间间隔内的梯度回传．\n\n一个完全连接的循环神经网络有着强大的计算和表示能力，可以近似任何非线性动力系统以及图灵机，解决所有的可计算问题．然而由于梯度爆炸和梯度消失问题，简单循环网络存在长期依赖问题［Bengio et al．，1994；Hochreiter et al．， 2001］．为了解决这个问题，人们对循环神经网络进行了很多的改进，其中最有效的改进方式为引入门控机制，比如LSTM网络［Gers et al．，2000；Hochreiter et al．， 1997］和GRU网络［Chung et al．，2014］．当然还有一些其他方法，比如时钟循环神经网络（Clockwork RNN）［Koutnik et al．，2014］、乘法 RNN［Sutskever et al．， 2011；Wu et al．，2016］以及引入注意力机制等．\n\nLSTM 网络是目前为止最成功的循环神经网络模型，成功应用在很多领域，比如语音识别、机器翻译［Sutskever et al．，2014］、语音模型以及文本生成．LSTM网络通过引入线性连接来缓解长距离依赖问题．虽然 LSTM 网络取得了很大的成功，其结构的合理性一直受到广泛关注．人们不断尝试对其进行改进来寻找最\n\n注意力机制参见第 8.2节。\n\n优结构，比如减少门的数量、提高并行能力等．关于 LSTM 网络的分析可以参考文献［Greff et al．，2017；Jozefowicz et al．，2015；Karpathy et al．，2015］．\n\nLSTM 网络的线性连接以及门控机制是一种十分有效的避免梯度消失问题的方法．这种机制也可以用在深层的前馈网络中，比如残差网络［He et al．，2016］和高速网络［Srivastava et al．，2015］都通过引入线性连接来训练非常深的卷积网络。对于循环神经网格，这种机制也可以用在非时间维度上，比如 Gird LSTM 网络［Kalchbrenner et al．，2015］、Depth Gated RNN［Chung et al．，2015］等．\n\n此外，循环神经网络可以很容易地扩展到更广义的图结构数据上，称为图网络［Scarselli et al．，2009］．递归神经网络是一种在有向无环图上的简单的图网络．图网络是目前新兴的研究方向，还没有比较成熟的网络模型。在不同的网络结构以及任务上，都有很多不同的具体实现方式。其中比较有名的图网络模型包括图卷积网络（Graph Convolutional Network，GCN）［Kipf et al．，2016］、图注意力网络（Graph Attention Network，GAT）［Veličković et al．，2017］、消息传递神经网络（Message Passing Neural Network，MPNN）［Gilmer et al．，2017］等．关于图网络的综述可以参考文献［Battaglia et al．，2018］．",
        "总结": "- 循环神经网络（RNN）可以建模时间序列数据之间的相关性，相比延时神经网络和非线性自回归模型，更方便建模长时间间隔的相关性。  \n- BPTT（误差反向传播通过时间）是常用的RNN参数学习算法，但计算时间和空间随时间线性增长；使用截断BPTT可提高效率。  \n- 完全连接的RNN具有强大的计算和表示能力，可近似任何非线性动力系统和图灵机，但存在梯度爆炸和梯度消失问题，导致长期依赖问题。  \n- 引入门控机制（如LSTM和GRU）是解决长期依赖问题的有效方法，其他方法包括时钟RNN、乘法RNN和注意力机制。  \n- LSTM网络是当前最成功的RNN模型，广泛应用于语音识别、机器翻译等领域，通过线性连接缓解长距离依赖问题。  \n- LSTM的结构合理性受到关注，改进方向包括减少门的数量、提高并行能力等。  \n- LSTM的线性连接和门控机制也可用于深层前馈网络（如残差网络、高速网络）以及循环网络的非时间维度（如Gird LSTM、Depth Gated RNN）。  \n- 循环神经网络可扩展到图结构数据上，形成图网络，如图卷积网络（GCN）、图注意力网络（GAT）、消息传递神经网络（MPNN）等。  \n- 图网络是新兴研究方向，尚未有成熟模型，不同任务有不同的实现方式。"
      },
      {
        "段落": "## 习题\n\n习题6－1 分析延时神经网络、卷积神经网络和循环神经网络的异同点．\n习题6－2 计算公式（6．40）和公式（6．41）中的梯度。\n习题 6－3 当使用公式（6．50）作为循环神经网络的状态更新公式时，分析其可能存在梯度爆炸的原因并给出解决方法．\n\n习题 6－4 计算 LSTM 网络中参数的梯度，并分析其避免梯度消失的效果．\n习题 6－5 计算 GRU 网络中参数的梯度，并分析其避免梯度消失的效果．\n习题 6－6 证明当递归神经网络的结构退化为线性序列结构时，递归神经网络就等价于简单循环神经网络。",
        "总结": "- 延时神经网络、卷积神经网络和循环神经网络的异同点分析  \n- 公式（6．40）和公式（6．41）中的梯度计算  \n- 使用公式（6．50）作为循环神经网络状态更新公式时梯度爆炸的原因及解决方法  \n- LSTM 网络中参数的梯度计算及其避免梯度消失的效果分析  \n- GRU 网络中参数的梯度计算及其避免梯度消失的效果分析  \n- 递归神经网络退化为线性序列结构时等价于简单循环神经网络的证明"
      },
      {
        "段落": "## 参考文献\n\nBattaglia P W，Hamrick J B，Bapst V，et al．Relational inductive biases，deep learning，and graph networks［J］．arXiv preprint arXiv：1806．01261， 2018.\nBengio Y，Simard P，Frasconi P．Learning long－term dependencies with gradient descent is difficult ［J］．Neural Networks，IEEE Transactions on，1994，5（2）：157－166．\nCho K，Van Merriënboer B，Gulcehre C，et al．Learning phrase representations using RNN encoder－ decoder for statistical machine translation［J］．arXiv preprint arXiv：1406．1078， 2014.\nChung J，Gulcehre C，Cho K，et al．Empirical evaluation of gated recurrent neural networks on sequence modeling［J］．arXiv preprint arXiv：1412．3555， 2014.\n\nChung J，Gulcehre C，Cho K，et al．Gated feedback recurrent neural networks［C］／／International Conference on Machine Learning．2015：2067－2075．\nElman J L．Finding structure in time［J］．Cognitive science，1990，14（2）：179－211．\nGers F A，Schmidhuber J，Cummins F．Learning to forget：Continual prediction with lstm［J］． Neural Computation， 2000.\nGilmer J，Schoenholz S S，Riley P F，et al．Neural message passing for quantum chemistry［J］．arXiv preprint arXiv：1704．01212， 2017.\nGreff K，Srivastava R K，Koutník J，et al．Lstm：A search space odyssey［J］．IEEE transactions on neural networks and learning systems， 2017.\nHaykin S．Neural networks and learning machines［M］．3rd edition．Pearson， 2009.\nHe K，Zhang X，Ren S，et al．Deep residual learning for image recognition［C］／／Proceedings of the IEEE conference on computer vision and pattern recognition．2016：770－778．\nHochreiter S，Schmidhuber J．Long short－term memory［J］．Neural computation，1997，9（8）：1735－ 1780.\n\nHochreiter S，Bengio Y，Frasconi P，et al．Gradient flow in recurrent nets：The difficulty of learning longterm dependencies［M／OL］／／Kolen J F，Kremer S C．A Field Guide to Dynamical Recurrent Networks．IEEE，2001：237－243．https：／／ieeexplore．ieee．org／document／5264952．\nJozefowicz R，Zaremba W，Sutskever I．An empirical exploration of recurrent network architectures ［C］／／Proceedings of the 32nd International Conference on Machine Learning．2015：2342－2350．\nKalchbrenner N，Danihelka I，Graves A．Grid long short－term memory［J］．arXiv preprint arXiv：1507．01526， 2015.\nKarpathy A，Johnson J，Fei－Fei L．Visualizing and understanding recurrent networks［J］．arXiv preprint arXiv：1506．02078， 2015.\nKipf T N，Welling M．Semi－supervised classification with graph convolutional networks［J］．arXiv preprint arXiv：1609．02907， 2016.\nKoutnik J，Greff K，Gomez F，et al．A clockwork rnn［C］／／Proceedings of The 31st International Conference on Machine Learning．2014：1863－1871．\nLang K J，Waibel A H，Hinton G E．A time－delay neural network architecture for isolated word recognition［J］．Neural networks，1990，3（1）：23－43．\nLeontaritis I，Billings S A．Input－output parametric models for non－linear systems part i：deter－ ministic non－linear systems［J］．International journal of control，1985，41（2）：303－328．\nParlos A，Atiya A，Chong K，et al．Recurrent multilayer perceptron for nonlinear system identifi－ cation［C］／／International Joint Conference on Neural Networks：volume 2．IEEE，1991：537－540．\nPollack J B．Recursive distributed representations［J］．Artificial Intelligence，1990，46（1）：77－105．\nScarselli F，Gori M，Tsoi A C，et al．The graph neural network model［J］．IEEE Transactions on Neural Networks，2009，20（1）：61－80．\nSchäfer A M，Zimmermann H G．Recurrent neural networks are universal approximators［C］／／ International Conference on Artificial Neural Networks．Springer，2006：632－640．\nSiegelmann H T，Sontag E D．Turing computability with neural nets［J］．Applied Mathematics Letters，1991，4（6）：77－80．\nSocher R，Lin C C，Manning C，et al．Parsing natural scenes and natural language with recursive neural networks［C］／／Proceedings of the International Conference on Machine Learning． 2011.\nSocher R，Perelygin A，Wu J Y，et al．Recursive deep models for semantic compositionality over a sentiment treebank［C］／／Proceedings of EMNLP． 2013.\nSrivastava R K，Greff K，Schmidhuber J．Highway networks［J］．arXiv preprint arXiv：1505．00387， 2015.\n\nSutskever I，Martens J，Hinton G E．Generating text with recurrent neural networks［C］／／ Proceedings of the 28th International Conference on Machine Learning．2011：1017－1024．\n\nSutskever I，Vinyals O，Le Q V．Sequence to sequence learning with neural networks［C］／／Advances in Neural Information Processing Systems．2014：3104－3112．\nTai K S，Socher R，Manning C D．Improved semantic representations from tree－structured long short－term memory networks［C］／／Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics． 2015.\nVeličković P，Cucurull G，Casanova A，et al．Graph attention networks［J］．arXiv preprint arXiv：1710．10903， 2017.\n\nWaibel A，Hanazawa T，Hinton G，et al．Phoneme recognition using time－delay neural networks ［J］．IEEE transactions on acoustics，speech，and signal processing，1989，37（3）：328－339．\nWerbos P J．Backpropagation through time：what it does and how to do it［J］．Proceedings of the IEEE，1990，78（10）：1550－1560．\nWilliams R J，Peng J．An efficient gradient－based algorithm for on－line training of recurrent network trajectories［J］．Neural computation，1990，2（4）：490－501．\nWilliams R J，Zipser D．Gradient－based learning algorithms for recurrent networks and their com－ putational complexity［J］．Backpropagation：Theory，architectures，and applications，1995，1：433－ 486.\n\nWu Y，Zhang S，Zhang Y，et al．On multiplicative integration with recurrent neural networks［C］／／ Advances in neural information processing systems．2016：2856－2864．\nZhu X，Sobihani P，Guo H．Long short－term memory over recursive structures［C］／／Proceedings of LCML．2015：1604－1612．",
        "总结": "- 关系归纳偏置（Relational Inductive Biases）  \n- 图神经网络（Graph Networks）  \n- 长短期记忆网络（LSTM）及其变种  \n- 门控循环神经网络（Gated Recurrent Neural Networks, GRUs）  \n- 递归神经网络（Recursive Neural Networks）  \n- 神经消息传递（Neural Message Passing）  \n- 深度残差学习（Deep Residual Learning）  \n- 图卷积网络（Graph Convolutional Networks）  \n- 时序数据建模与长时依赖学习  \n- 神经网络的通用近似能力  \n- 递归分布式表示（Recursive Distributed Representations）  \n- 基于时间延迟的神经网络（Time-Delay Neural Networks）  \n- 高速网络（Highway Networks）  \n- 图注意力网络（Graph Attention Networks）  \n- 序列到序列学习（Sequence-to-Sequence Learning）  \n- 基于递归结构的长短期记忆网络  \n- 递归深度模型用于语义组合性分析"
      }
    ]
  },
  {
    "标题": "第7章 网络优化与正则化",
    "内容": [
      {
        "段落": "# 第7章 网络优化与正则化 \n\n任何数学技巧都不能弥补信息的缺失。\n一科尼利厄斯•兰佐斯（Cornelius Lanczos）\n匈牙利数学家、物理学家\n\n虽然神经网络具有非常强的表达能力，但是当应用神经网络模型到机器学习时依然存在一些难点问题．主要分为两大类：\n（1）优化问题：神经网络模型是一个非凸函数，再加上在深度网络中的梯度消失问题，很难进行优化；另外，深度神经网络模型一般参数比较多，训练数据也比较大，会导致训练的效率比较低。\n（2）泛化问题：因为神经网络的拟合能力强，反而容易在训练集上产生过拟合。因此在训练深度神经网络时，同时也需要通过一定的正则化方法来改进网络的泛化能力。\n\n目前，研究者从大量的实践中总结了一些经验技巧，从优化和正则化两个方面来提高学习效率并得到一个好的网络模型。",
        "总结": "- 概念：网络优化与正则化是提升神经网络性能的两个关键方面。  \n- 算法：未提及具体算法，但涉及优化方法和正则化技术。  \n- 定理或命题：未提及具体定理或命题。  \n- 数学推导：未涉及具体的数学推导内容。  \n- 优化问题：神经网络模型为非凸函数，存在梯度消失问题，且参数多、训练数据大导致训练效率低。  \n- 泛化问题：神经网络拟合能力强，易在训练集上过拟合，需通过正则化方法提升泛化能力。  \n- 研究经验：研究者总结了优化和正则化方面的经验技巧以提高学习效率和模型性能。"
      },
      {
        "段落": "## 7.1 网络优化\n\n深度神经网络是一个高度非线性的模型，其风险函数是一个非凸函数，因此风险最小化是一个非凸优化问题，会存在很多局部最优点。",
        "总结": "- 概念：深度神经网络具有高度非线性特性，其风险函数为非凸函数。  \n- 问题类型：风险最小化属于非凸优化问题。  \n- 特点：该问题存在多个局部最优点。"
      },
      {
        "段落": "## 7．1．1 网络优化的难点\n\n有效地学习深度神经网络的参数是一个具有挑战性的问题，其主要原因有以下几个方面。",
        "总结": "- 网络优化的难点在于有效学习深度神经网络的参数。  \n- 主要原因包括参数空间的高维性、非凸优化问题、局部极小值的存在以及梯度消失或爆炸等问题。"
      },
      {
        "段落": "### 7．1．1．1 网络结构多样性\n\n神经网络的种类非常多，比如卷积网络、循环网络、图网络等，其结构也非常不同。有些比较深，有些比较宽。不同参数在网络中的作用也有很大的差异，比如连接权重和偏置的不同，以及循环网络中循环连接上的权重和其它权重的不同。\n\n由于网络结构的多样性，我们很难找到一种通用的优化方法．不同的优化方法在不同网络结构上的差异也都比较大。\n\n此外，网络的超参数一般也比较多，这也给优化带来很大的挑战。",
        "总结": "- 网络结构多样性指的是神经网络存在多种类型，如卷积网络、循环网络、图网络等，它们的结构差异较大，有的较深，有的较宽。  \n- 不同网络结构中，参数的作用存在显著差异，例如连接权重、偏置以及循环网络中循环连接的权重与其他权重的不同。  \n- 由于网络结构的多样性，难以找到一种适用于所有网络的通用优化方法，不同优化方法在不同结构上的表现差异较大。  \n- 网络通常具有较多的超参数，这进一步增加了优化的难度和挑战。"
      },
      {
        "段落": "### 7．1．1．2 高维变量的非凸优化\n\n低维空间的非凸优化问题主要是存在一些局部最优点。基于梯度下降的优化方法会陷入局部最优点，因此在低维空间中非凸优化的主要难点是如何选择初始化参数和逃离局部最优点。深度神经网络的参数非常多，其参数学习是在非常高维空间中的非凸优化问题，其挑战和在低维空间的非凸优化问题有所不同。\n\n鞍点 在高维空间中，非凸优化的难点并不在于如何逃离局部最优点，而是如何逃离鞍点（Saddle Point）［Dauphin et al．，2014］．鞍点的梯度是 0 ，但是在一些维度上是最高点，在另一些维度上是最低点，如图7．1所示．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-167.jpg?height=406&width=575&top_left_y=1130&top_left_x=368)\n\n图7．1鞍点示例\n\n在高维空间中，局部最优点要求在每一维度上都是最低点，这种概率非常低．假设网络有 10,000 维参数，在某一维上梯度为 0 的点是局部最低点的概率为 $p$ ，那么在整个参数空间中，梯度为 0 的点是局部最优点的概率为 $p^{10,000}$ ，这种可能性非常小．也就是说高维空间中，大部分梯度为 0 的点都是鞍点。基于梯度下降的优化方法会在鞍点附近接近于停滞，很难从这些鞍点中逃离。因此，随机梯度下降对于高维空间中的非凸优化问题十分重要，通过在梯度方向上引入随机性，从而可以有效地逃离鞍点。\n\n鞍点的叫法是因为其形状像马鞍．\n\n在一般的非凸问题中， $p \\approx 0.5$ ．\n\n鞍点的特征是一阶梯度为零但是二阶梯度的 Hessian 矩阵不是半正定矩阵，参见定理 C．2．\n\n平坦最小值 深度神经网络的参数非常多，并且有一定的冗余性，这使得每单个参数对最终损失的影响都比较小，这导致了损失函数在局部最小解附近通常是一个平坦的区域，称为平坦最小值（Flat Minima）［Hochreiter et al．，1997；Li et al．， 2017a］．图7．2给出了平坦最小值和尖锐最小值（Sharp Minima）的示例．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-168.jpg?height=460&width=1091&top_left_y=386&top_left_x=108)\n\n图 7.2 平坦最小值和陡峭最小值的示例（图片来源：［Hochreiter et al．，1997］）\n\n在一个平坦最小值的邻域内，所有点对应的训练损失都比较接近，表明我们在训练神经网络时，不需要精确地找到一个局部最小解，只要在一个局部最小解的邻域内就足够了。平坦最小值通常被认为和模型泛化能力有一定的关系。一般而言，当一个模型收敛一个平坦的局部最小值时，其鲁棒性会更好，即微小的参数变动不会剧烈影响模型能力；而当模型收敛到一个尖锐的局部最小值时，其鲁棒性也会比较差。具备良好泛化能力的模型通常应该是鲁棒的，因此理想的局部最小值应该是平坦的．\n\n局部最小解的等价性 在非常大的神经网络中，大部分的局部最小解是等价的，它们在测试集上性能都比较相似。此外，局部最小解对应的训练损失都可能非常接近于全局最小解对应的训练损失［Choromanska et al．，2015］．虽然神经网络有一定概率收玫于比较差的局部最小值，但随着网络规模增加，网络陷入比较差的局部最小值的概率大大降低．在训练神经网络时，我们通常没有必要找全局最小值，这反而可能导致过拟合．\n\n目前，深度神经网络的参数学习主要是通过梯度下降法来寻找一组可以最小化结构风险的参数。在具体实现中，梯度下降法可以分为：批量梯度下降、随机梯度下降以及小批量梯度下降三种形式。根据不同的数据量和参数量，可以选择一种具体的实现形式。除了在收敛效果和效率上的差异，这三种方法都存在一些共同的问题，比如（1）如何改进优化算法；（2）如何初始化参数；（3）如何预处理数据等。\n\n这里的很多描述都是经验性的，并没有很好的理论证明．",
        "总结": "- 高维变量的非凸优化问题主要挑战在于逃离鞍点而非局部最优点  \n- 鞍点是指梯度为0但Hessian矩阵不是半正定的点，其在高维空间中更为常见  \n- 鞍点导致基于梯度下降的优化方法在高维空间中容易停滞  \n- 随机梯度下降通过引入随机性有助于逃离鞍点  \n- 平坦最小值指损失函数在局部最小解附近呈现平坦区域，与模型泛化能力相关  \n- 平坦最小值对应的模型鲁棒性更好，而尖锐最小值则鲁棒性较差  \n- 在大规模神经网络中，大部分局部最小解性能相近且接近全局最小解  \n- 神经网络收敛到较差局部最小值的概率随网络规模增加而降低  \n- 参数学习主要通过梯度下降法实现，包括批量、随机和小批量梯度下降  \n- 三种梯度下降方法存在收敛效果和效率差异，但都面临优化、初始化和数据预处理等问题  \n- 当前许多描述缺乏严格的理论证明，更多依赖经验性结论"
      },
      {
        "段落": "## 7.2 优化算法\n\n本节介绍一些在训练神经网络时常用的优化算法．",
        "总结": "- 本节介绍了训练神经网络时常用的优化算法。  \n- 优化算法的目标是通过调整模型参数来最小化损失函数。  \n- 常见的优化算法包括梯度下降、随机梯度下降（SGD）、动量法（Momentum）、Adam 等。  \n- 这些算法在训练过程中通过计算梯度并更新参数来提高模型性能。  \n- 本节可能还讨论了不同优化算法的优缺点及适用场景。"
      },
      {
        "段落": "## 7．2．1 小批量梯度下降\n\n在训练深度神经网络时，训练数据的规模通常都比较大。如果在梯度下降时，每次迭代都要计算整个训练数据上的梯度，这就需要比较多的计算资源。另外大规模训练集中的数据通常会非常冗余，也没有必要在整个训练集上计算梯度。因此，在训练深度神经网络时，经常使用小批量梯度下降法（Mini－Batch Gradient Descent）。\n\n令 $f(\\boldsymbol{x} ; \\theta)$ 表示一个深度神经网络，$\\theta$ 为网络参数，在使用小批量梯度下降进行优化时，每次选取 $K$ 个训练样本 $\\mathcal{S}_{t}=\\left\\{\\left(\\boldsymbol{x}^{(k)}, \\boldsymbol{y}^{(k)}\\right)\\right\\}_{k=1}^{K}$ 。第 $t$ 次迭代（Iteration）时损失函数关于参数 $\\theta$ 的偏导数为\n\n$$\n\\begin{equation*}\ng_{t}(\\theta)=\\frac{1}{K} \\sum_{(\\boldsymbol{x}, \\boldsymbol{y}) \\in \\mathcal{S}_{t}} \\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, f(\\boldsymbol{x} ; \\theta))}{\\partial \\theta} \\tag{7.1}\n\\end{equation*}\n$$\n\n其中 $\\mathcal{L}(\\cdot)$ 为可微分的损失函数，$K$ 称为批量大小（Batch Size）。\n第 $t$ 次更新的梯度 $\\mathrm{g}_{t}$ 定义为\n\n$$\n\\begin{equation*}\n\\mathrm{g}_{t} \\triangleq \\mathfrak{g}_{t}\\left(\\theta_{t-1}\\right) \\tag{7.2}\n\\end{equation*}\n$$\n\n使用梯度下降来更新参数，\n\n$$\n\\begin{equation*}\n\\theta_{t} \\leftarrow \\theta_{t-1}-\\alpha \\mathrm{g}_{t}, \\tag{7.3}\n\\end{equation*}\n$$\n\n其中 $\\alpha>0$ 为学习率。\n每次迭代时参数更新的差值 $\\Delta \\theta_{t}$ 定义为\n\n$$\n\\begin{equation*}\n\\Delta \\theta_{t} \\triangleq \\theta_{t}-\\theta_{t-1} \\tag{7.4}\n\\end{equation*}\n$$\n\n$\\Delta \\theta_{t}$ 和梯度 $g_{t}$ 并不需要完全一致．$\\Delta \\theta_{t}$ 为每次迭代时参数的实际更新方向，即 $\\theta_{t}=\\theta_{t-1}+\\Delta \\theta_{t}$ ．在标准的小批量梯度下降中，$\\Delta \\theta_{t}=-\\alpha \\mathbf{g}_{t}$ ．\n\n从上面公式可以看出，影响小批量梯度下降法的主要因素有：（1）批量大小 $K$ 、（2）学习率 $\\alpha$ 以及（3）梯度估计。为了更有效地训练深度神经网络，在标准的小批量梯度下降法的基础上，也经常使用一些改进方法以加快优化速度，比如如何选择批量大小、如何调整学习率以及如何修正梯度估计。我们分别从这三个方面来介绍在神经网络优化中常用的算法。这些改进的优化算法也同样可以应用在批量或随机梯度下降法上。\nhttps：／／nndl．github．io／",
        "总结": "- 小批量梯度下降法（Mini-Batch Gradient Descent）用于训练深度神经网络，通过每次使用一个小批量的数据来计算梯度，减少计算资源需求并避免大规模数据的冗余。\n- 每次迭代中，使用 $K$ 个训练样本计算损失函数关于参数 $\\theta$ 的平均梯度 $g_t(\\theta)$，公式为 $g_t(\\theta) = \\frac{1}{K} \\sum_{(\\boldsymbol{x}, \\boldsymbol{y}) \\in \\mathcal{S}_t} \\frac{\\partial \\mathcal{L}(\\boldsymbol{y}, f(\\boldsymbol{x}; \\theta))}{\\partial \\theta}$。\n- 参数更新公式为 $\\theta_t \\leftarrow \\theta_{t-1} - \\alpha g_t$，其中 $\\alpha$ 为学习率，表示更新步长。\n- 每次迭代的参数更新差值 $\\Delta \\theta_t = \\theta_t - \\theta_{t-1}$，在标准小批量梯度下降中，$\\Delta \\theta_t = -\\alpha g_t$。\n- 小批量梯度下降的主要影响因素包括批量大小 $K$、学习率 $\\alpha$ 和梯度估计。\n- 改进的小批量梯度下降方法包括选择合适的批量大小、调整学习率和修正梯度估计，以加快优化速度。这些方法也可应用于批量或随机梯度下降。"
      },
      {
        "段落": "## 7．2．2 批量大小选择\n\n在小批量梯度下降法中，批量大小（Batch Size）对网络优化的影响也非常大．一般而言，批量大小不影响随机梯度的期望，但是会影响随机梯度的方差．批量大小越大，随机梯度的方差越小，引入的噪声也越小，训练也越稳定，因此可以设置较大的学习率。而批量大小较小时，需要设置较小的学习率，否则模型会不收玫．学习率通常要随着批量大小的增大而相应地增大．一个简单有效的方法是线性缩放规则（Linear Scaling Rule）［Goyal et al．，2017］：当批量大小增加 $m$ 倍时，学习率也增加 $m$ 倍。线性缩放规则往往在批量大小比较小时适用，当批量大小非常大时，线性缩放会使得训练不稳定。\n\n图7．3给出了从 Epoch（回合）和 Iteration（单次更新）的角度，批量大小对损失下降的影响。每一次小批量更新为一次 Iteration，所有训练集的样本更新一遍为一次 Epoch，两者的关系为 1 个 Epoch 等于（ $\\frac{\\text { 训练样本的数量 } N}{\\text { 批量大小 } K}$ ）次 Iterations．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-170.jpg?height=1185&width=718&top_left_y=879&top_left_x=290)\n\n图 7.3 在 MNIST 数据集上批量大小对损失下降的影响\n\n参见习题 7－1．\n参见第 7．2．3．2 节。\n\n值得注意的是，图7．3中的三种批量大小对应的学习率设置不同，因\n\n从图7．3a可以看出，批量大小越大，下降效果越明显，并且下降曲线越平滑．但从图7．3b可以看出，如果按整个数据集上的回合（Epoch）数来看，则是批量样本数越小，适当小的批量大小会导致更快的收敛。\n\n此外，批量大小和模型的泛化能力的也有一定的关系．Keskar et al．［2016］通过实验发现：批量大小越大，越有可能收敛到陡峭最小值；批量大小越小，越有可能收玫到平坦最小值。",
        "总结": "- 概念：批量大小（Batch Size）是小批量梯度下降法中的一个重要参数，影响优化过程的稳定性与收敛速度。\n- 算法：线性缩放规则（Linear Scaling Rule）用于调整学习率，当批量大小增加 $m$ 倍时，学习率也增加 $m$ 倍。\n- 定理/命题：批量大小增大时，随机梯度的方差减小，训练更稳定，可设置较大的学习率；反之则需较小的学习率。\n- 数学推导：1 个 Epoch 等于 $\\frac{N}{K}$ 次 Iterations，其中 $N$ 是训练样本数量，$K$ 是批量大小。\n- 图表说明：图7.3展示了不同批量大小对损失下降的影响，包括从 Epoch 和 Iteration 角度的分析。\n- 实验发现：批量大小与模型泛化能力相关，较大批量可能收敛到陡峭最小值，较小批量可能收敛到平坦最小值。"
      },
      {
        "段落": "## 7．2．3 学习率调整\n\n学习率是神经网络优化时的重要超参数。在梯度下降法中，学习率 $\\alpha$ 的取值非常关键，如果过大就不会收玫，如果过小则收玫速度太慢。常用的学习率调整方法包括学习率衰减、学习率预热、周期性学习率调整以及一些自适应调整学习率的方法，比如 AdaGrad、RMSprop、AdaDelta 等。自适应学习率方法可以针对每个参数设置不同的学习率．",
        "总结": "- 学习率是神经网络优化中的重要超参数，影响模型收敛性。  \n- 学习率过大可能导致不收敛，过小则收敛速度慢。  \n- 常用的学习率调整方法包括学习率衰减、预热、周期性调整等。  \n- 自适应调整方法如 AdaGrad、RMSprop、AdaDelta 可为每个参数设置不同学习率。"
      },
      {
        "段落": "### 7．2．3．1 学习率衰减\n\n从经验上看，学习率在一开始要保持大些来保证收玫速度，在收玫到最优点附近时要小些以避免来回振荡。 比较简单的学习率调整可以通过学习率衰减（Learning Rate Decay）的方式来实现，也称为学习率退火（Learning Rate Annealing）．\n\n不失一般性，这里的衰减方式设置为按迭代次数进行衰减。假设初始化学习率为 $\\alpha_{0}$ ，在第 $t$ 次迭代时的学习率 $\\alpha_{t}$ 。常见的衰减方法有以下几种：\n\n分段常数衰减（Piecewise Constant Decay）：即每经过 $T_{1}, T_{2}, \\cdots, T_{m}$ 次迭代将学习率衰减为原来的 $\\beta_{1}, \\beta_{2}, \\cdots, \\beta_{m}$ 倍，其中 $T_{m}$ 和 $\\beta_{m}<1$ 为根据经验设置的超参数。分段常数衰减也称为阶梯衰减（Step Decay）。\n\n逆时衰减（Inverse Time Decay）：\n\n$$\n\\begin{equation*}\n\\alpha_{t}=\\alpha_{0} \\frac{1}{1+\\beta \\times t}, \\tag{7.5}\n\\end{equation*}\n$$\n\n其中 $\\beta$ 为衰减率。\n指数衰减（Exponential Decay）：\n\n$$\n\\begin{equation*}\n\\alpha_{t}=\\alpha_{0} \\beta^{t} \\tag{7.6}\n\\end{equation*}\n$$\n\n其中 $\\beta<1$ 为衰减率．\n自然指数衰减（Natural Exponential Decay）：\n\n$$\n\\begin{equation*}\n\\alpha_{t}=\\alpha_{0} \\exp (-\\beta \\times t), \\tag{7.7}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n学习率衰减是按每次迭代（Iteration）进行，也可以按每 $m$ 次迭代或每个回合（Epoch）进行．衰减率通常和总迭代次数相关。\n\n其中 $\\beta$ 为衰减率。\n余弦衰减（Cosine Decay）：\n\n$$\n\\begin{equation*}\n\\alpha_{t}=\\frac{1}{2} \\alpha_{0}\\left(1+\\cos \\left(\\frac{t \\pi}{T}\\right)\\right) \\tag{7.8}\n\\end{equation*}\n$$\n\n其中 $T$ 为总的迭代次数．\n图7．4给出了不同衰减方法的示例（假设初始学习率为 1 ）．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-172.jpg?height=477&width=589&top_left_y=511&top_left_x=363)\n\n图 7.4 不同学习率衰减方法的比较",
        "总结": "- 概念：学习率衰减（Learning Rate Decay）是一种调整学习率的方法，用于在训练过程中动态改变学习率以提高收敛效率和稳定性。\n- 算法：提出多种学习率衰减方法，包括分段常数衰减（Step Decay）、逆时衰减、指数衰减、自然指数衰减和余弦衰减。\n- 数学推导：给出每种衰减方法的具体数学表达式，如逆时衰减公式为 $\\alpha_t = \\alpha_0 \\frac{1}{1+\\beta \\times t}$，指数衰减公式为 $\\alpha_t = \\alpha_0 \\beta^t$，自然指数衰减公式为 $\\alpha_t = \\alpha_0 \\exp(-\\beta \\times t)$，余弦衰减公式为 $\\alpha_t = \\frac{1}{2} \\alpha_0 (1 + \\cos(\\frac{t\\pi}{T}))$。"
      },
      {
        "段落": "### 7．2．3．2 学习率预热\n\n在小批量梯度下降法中，当批量大小的设置比较大时，通常需要比较大的学习率。但在刚开始训练时，由于参数是随机初始化的，梯度往往也比较大，再加上比较大的初始学习率，会使得训练不稳定。\n\n为了提高训练稳定性，我们可以在最初几轮迭代时，采用比较小的学习率，等梯度下降到一定程度后再恢复到初始的学习率，这种方法称为学习率预热（Learning Rate Warmup）。\n\n一个常用的学习率预热方法是逐渐预热（Gradual Warmup）［Goyal et al．， 2017］．假设预热的迭代次数为 $T^{\\prime}$ ，初始学习率为 $\\alpha_{0}$ ，在预热过程中，每次更新的学习率为\n\n$$\n\\begin{equation*}\n\\alpha_{t}^{\\prime}=\\frac{t}{T^{\\prime}} \\alpha_{0}, \\quad 1 \\leq t \\leq T^{\\prime} \\tag{7.9}\n\\end{equation*}\n$$\n\n当预热过程结束，再选择一种学习率衰减方法来逐渐降低学习率。",
        "总结": "- 学习率预热是一种在训练初期使用较小学习率，待模型训练稳定后再恢复到初始学习率的方法，以提高训练稳定性。  \n- 逐渐预热（Gradual Warmup）是常用的学习率预热方法，通过线性增长的方式逐步提升学习率。  \n- 在预热阶段，学习率随迭代次数线性增加，公式为 $\\alpha_{t}^{\\prime}=\\frac{t}{T^{\\prime}} \\alpha_{0}$，其中 $t$ 为当前迭代次数，$T^{\\prime}$ 为预热总迭代次数，$\\alpha_{0}$ 为初始学习率。  \n- 预热结束后，通常采用学习率衰减方法进一步调整学习率。"
      },
      {
        "段落": "### 7．2．3．3 周期性学习率调整\n\n为了使得梯度下降法能够逃离鞍点或尖锐最小值，一种经验性的方式是在训练过程中周期性地增大学习率。当参数处于尖锐最小值附近时，增大学习率有助 https：／／nndl．github．io／\n\n于逃离尖锐最小值；当参数处于平坦最小值附近时，增大学习率依然有可能在该平坦最小值的吸引域（Basin of Attraction）内。因此，周期性地增大学习率虽然可能短期内损害优化过程，使得网络收玫的稳定性变差，但从长期来看有助于找到更好的局部最优解．\n\n本节介绍两种常用的周期性调整学习率的方法：循环学习率和带热重启的随机梯度下降。\n\n循环学习率 一种简单的方法是使用循环学习率（Cyclic Learning Rate）［Goyal et al．，2017］，即让学习率在一个区间内周期性地增大和缩小．通常可以使用线性缩放来调整学习率，称为三角循环学习率（Triangular Cyclic Learning Rate）。假设每个循环周期的长度相等都为 $2 \\Delta T$ ，其中前 $\\Delta T$ 步为学习率线性增大阶段，后 $\\Delta T$ 步为学习率线性缩小阶段．在第 $t$ 次迭代时，其所在的循环周期数 $m$ 为\n\n$$\n\\begin{equation*}\nm=\\left\\lfloor 1+\\frac{t}{2 \\Delta T}\\right\\rfloor \\tag{7.10}\n\\end{equation*}\n$$\n\n其中 $\\rfloor\\rfloor$ 表示＂向下取整＂函数．第 $t$ 次迭代的学习率为\n\n$$\n\\begin{equation*}\n\\alpha_{t}=\\alpha_{\\min }^{m}+\\left(\\alpha_{\\max }^{m}-\\alpha_{\\min }^{m}\\right)(\\max (0,1-b)), \\tag{7.11}\n\\end{equation*}\n$$\n\n其中 $\\alpha_{\\text {max }}^{m}$ 和 $\\alpha_{\\text {min }}^{m}$ 分别为第 $m$ 个周期中学习率的上界和下界，可以随着 $m$ 的增大而逐渐降低；$b \\in[0,1]$ 的计算为\n\n$$\n\\begin{equation*}\nb=\\left|\\frac{t}{\\Delta T}-2 m+1\\right| \\tag{7.12}\n\\end{equation*}\n$$\n\n带热重启的随机梯度下降 带热重启的随机梯度下降（Stochastic Gradient De－ scent with Warm Restarts，SGDR ）［Loshchilov et al．，2017a］是用热重启方式来替代学习率衰减的方法．学习率每间隔一定周期后重新初始化为某个预先设定值，然后逐渐衰减。每次重启后模型参数不是从头开始优化，而是从重启前的参数基础上继续优化。\n\n假设在梯度下降过程中重启 $M$ 次，第 $m$ 次重启在上次重启开始第 $T_{m}$ 个回合后进行，$T_{m}$ 称为重启周期．在第 $m$ 次重启之前，采用余弦衰减来降低学习率．第 $t$次迭代的学习率为\n\n$$\n\\begin{equation*}\n\\alpha_{t}=\\alpha_{\\min }^{m}+\\frac{1}{2}\\left(\\alpha_{\\max }^{m}-\\alpha_{\\min }^{m}\\right)\\left(1+\\cos \\left(\\frac{T_{c u r}}{T_{m}} \\pi\\right)\\right), \\tag{7.13}\n\\end{equation*}\n$$\n\n其中 $\\alpha_{\\text {max }}^{m}$ 和 $\\alpha_{\\text {min }}^{m}$ 分别为第 $m$ 个周期中学习率的上界和下界，可以随着 $m$ 的增大而逐渐降低；$T_{\\text {cur }}$ 为从上次重启之后的回合（Epoch）数。 $T_{\\text {cur }}$ 可以取小数，比如 $0.1 、 0.2$ 等，这样可以在一个回合内部进行学习率衰减．重启周期 $T_{m}$ 可以随着重启次数逐渐增加，比如 $T_{m}=T_{m-1} \\times \\kappa$ ，其中 $\\kappa \\geq 1$ 为放大因子．\n\n图7．5给出了两种周期性学习率调整的示例（假设初始学习率为 1 ），每个周期中学习率的上界也逐步衰减。\nhttps：／／nndl．github．io／\n\n当 $\\alpha_{\\text {max }}^{m}=\\alpha_{0}, \\alpha_{\\text {min }}^{m}=$ 0 ，并不进行重启时，公式（7．13）退化为公式（7．8）。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-174.jpg?height=459&width=959&top_left_y=143&top_left_x=178)\n\n图 7.5 周期性学习率调整",
        "总结": "- 周期性学习率调整用于帮助梯度下降法逃离鞍点或尖锐最小值，通过在训练过程中周期性地增大学习率，有助于找到更好的局部最优解。\n- 循环学习率是一种方法，学习率在一个区间内周期性地增大和缩小，通常采用线性缩放，称为三角循环学习率。\n- 学习率的计算公式基于当前迭代次数和周期数，通过线性变化来调整学习率的上下界。\n- 带热重启的随机梯度下降（SGDR）通过在一定周期后重新初始化学习率为预设值，并逐渐衰减，重启后继续优化参数。\n- 学习率的衰减采用余弦函数形式，允许在重启周期内进行连续的学习率调整。\n- 重启周期可以随着重启次数增加而扩展，通过放大因子控制。\n- 当不进行重启且学习率上下界固定时，SGDR 的公式退化为标准的学习率衰减公式。"
      },
      {
        "段落": "### 7．2．3．4 AdaGrad 算法\n\n在标准的梯度下降法中，每个参数在每次迭代时都使用相同的学习率．由于每个参数的维度上收玫速度都不相同，因此根据不同参数的收玫情况分别设置学习率．\n\nAdaGrad（Adaptive Gradient）算法［Duchi et al．，2011］是借鉴 $\\ell_{2}$ 正则化的思想，每次迭代时自适应地调整每个参数的学习率。在第 $t$ 次迭代时，先计算每个参数梯度平方的累计值\n\n$$\n\\begin{equation*}\nG_{t}=\\sum_{\\tau=1}^{t} \\boldsymbol{g}_{\\tau} \\odot \\boldsymbol{g}_{\\tau} \\tag{7.14}\n\\end{equation*}\n$$\n\n其中 $\\odot$ 为按元素乘积，$g_{\\tau} \\in \\mathbb{R}^{|\\theta|}$ 是第 $\\tau$ 次迭代时的梯度。\nAdaGrad 算法的参数更新差值为\n\n$$\n\\begin{equation*}\n\\Delta \\theta_{t}=-\\frac{\\alpha}{\\sqrt{G_{t}+\\epsilon}} \\odot g_{t} \\tag{7.15}\n\\end{equation*}\n$$\n\n其中 $\\alpha$ 是初始的学习率，$\\epsilon$ 是为了保持数值稳定性而设置的非常小的常数，一般取值 $e^{-7}$ 到 $e^{-10}$ 。此外，这里的开平方、除、加运算都是按元素进行的操作。\n\n在 AdaGrad 算法中，如果某个参数的偏导数累积比较大，其学习率相对较小；相反，如果其偏导数累积较小，其学习率相对较大。但整体是随着迭代次数的增加，学习率逐渐缩小。\n\nAdaGrad 算法的缺点是在经过一定次数的迭代依然没有找到最优点时，由于这时的学习率已经非常小，很难再继续找到最优点。",
        "总结": "- 概念：AdaGrad 算法是一种自适应梯度下降方法，根据参数的梯度历史动态调整学习率。  \n- 算法：在每次迭代中，计算梯度平方的累计值 $ G_t = \\sum_{\\tau=1}^{t} g_\\tau \\odot g_\\tau $，并用该值调整每个参数的学习率。  \n- 数学推导：参数更新公式为 $ \\Delta \\theta_t = -\\frac{\\alpha}{\\sqrt{G_t + \\epsilon}} \\odot g_t $，其中 $ \\alpha $ 是初始学习率，$ \\epsilon $ 是用于数值稳定的小常数。  \n- 特点：学习率随迭代次数增加而逐渐减小，对梯度较大的参数学习率较小，对梯度较小的参数学习率较大。  \n- 缺点：在迭代次数较多时，学习率可能过小，导致难以找到最优解。"
      },
      {
        "段落": "### 7．2．3．5 RMSprop算法\n\nRMSprop算法是 Geoff Hinton 提出的一种自适应学习率的方法［Tieleman et al．，2012］，可以在有些情况下避免 AdaGrad 算法中学习率不断单调下降以至于过早衰减的缺点．\n\nRMSprop 算法首先计算每次迭代梯度 $\\boldsymbol{g}_{t}$ 平方的指数衰减移动平均，\n\n$$\n\\begin{align*}\nG_{t} & =\\beta G_{t-1}+(1-\\beta) \\boldsymbol{g}_{t} \\odot \\boldsymbol{g}_{t}  \\tag{7.16}\\\\\n& =(1-\\beta) \\sum_{\\tau=1}^{t} \\beta^{t-\\tau} \\boldsymbol{g}_{\\tau} \\odot \\boldsymbol{g}_{\\tau} \\tag{7.17}\n\\end{align*}\n$$\n\n其中 $\\beta$ 为衰减率，一般取值为 0.9 ．\nRMSprop 算法的参数更新差值为\n\n$$\n\\begin{equation*}\n\\Delta \\theta_{t}=-\\frac{\\alpha}{\\sqrt{G_{t}+\\epsilon}} \\odot \\boldsymbol{g}_{t} \\tag{7.18}\n\\end{equation*}\n$$\n\n其中 $\\alpha$ 是初始的学习率，比如 0．001．\n从上式可以看出，RMSProp 算法和 AdaGrad 算法的区别在于 $G_{t}$ 的计算由累积方式变成了指数衰减移动平均。在迭代过程中，每个参数的学习率并不是呈衰减趋势，既可以变小也可以变大。",
        "总结": "- RMSprop算法是一种自适应学习率方法，由Geoff Hinton提出，用于解决AdaGrad学习率单调下降的问题。  \n- 算法通过计算梯度平方的指数衰减移动平均来更新参数，公式为 $ G_{t} = \\beta G_{t-1} + (1-\\beta) \\boldsymbol{g}_{t} \\odot \\boldsymbol{g}_{t} $。  \n- $ G_{t} $ 的计算采用指数衰减移动平均，而非AdaGrad的累积方式，使得学习率在迭代过程中可以动态变化。  \n- 参数更新公式为 $ \\Delta \\theta_{t} = -\\frac{\\alpha}{\\sqrt{G_{t}+\\epsilon}} \\odot \\boldsymbol{g}_{t} $，其中 $\\alpha$ 是初始学习率，$\\epsilon$ 是防止除零的小常数。"
      },
      {
        "段落": "### 7．2．3．6 AdaDelta算法\n\nAdaDelta（算）法［Zeiler，2012］也是 AdaGrad 算法的一个改进．和 RM－ Sprop 算法类似，AdaDelta 算法通过梯度平方的指数衰减移动平均来调整学习率。此外，AdaDelta 算法还引入了每次参数更新差值 $\\Delta \\theta$ 的平方的指数衰减权移动平均。\n\n第 $t$ 次迭代时，参数更新差值 $\\Delta \\theta$ 的平方的指数衰减权移动平均为\n\n$$\n\\begin{equation*}\n\\Delta X_{t-1}^{2}=\\beta_{1} \\Delta X_{t-2}^{2}+\\left(1-\\beta_{1}\\right) \\Delta \\theta_{t-1} \\odot \\Delta \\theta_{t-1} \\tag{7.19}\n\\end{equation*}\n$$\n\n其中 $\\beta_{1}$ 为衰减率．此时 $\\Delta \\theta_{t}$ 还未知，因此只能计算到 $\\Delta X_{t-1}$ ．\nAdaDelta 算法的参数更新差值为\n\n$$\n\\begin{equation*}\n\\Delta \\theta_{t}=-\\frac{\\sqrt{\\Delta X_{t-1}^{2}+\\epsilon}}{\\sqrt{G_{t}+\\epsilon}} \\mathrm{g}_{t} \\tag{7.20}\n\\end{equation*}\n$$\n\n其中 $G_{t}$ 的计算方式和 RMSprop 算法一样（公式（7．16）），$\\Delta X_{t-1}^{2}$ 为参数更新差值 $\\Delta \\theta$ 的指数衰减权移动平均。\n\n从上式可以看出，AdaDelta 算法将 RMSprop 算法中的初始学习率 $\\alpha$ 改为动态计算的 $\\sqrt{\\Delta X_{t-1}^{2}}$ ，在一定程度上平抑了学习率的波动。\nhttps：／／nndl．github．io／",
        "总结": "- AdaDelta算法是AdaGrad算法的改进，通过梯度平方的指数衰减移动平均调整学习率，并引入参数更新差值的平方的指数衰减权移动平均。  \n- 第$t$次迭代时，参数更新差值$\\Delta \\theta$的平方的指数衰减权移动平均计算公式为$\\Delta X_{t-1}^{2}=\\beta_{1} \\Delta X_{t-2}^{2}+(1-\\beta_{1}) \\Delta \\theta_{t-1} \\odot \\Delta \\theta_{t-1}$。  \n- 参数更新差值$\\Delta \\theta_{t}$的计算公式为$-\\frac{\\sqrt{\\Delta X_{t-1}^{2}+\\epsilon}}{\\sqrt{G_{t}+\\epsilon}} \\mathrm{g}_{t}$，其中$G_{t}$的计算方式与RMSprop相同。  \n- AdaDelta将RMSprop中的初始学习率$\\alpha$改为动态计算的$\\sqrt{\\Delta X_{t-1}^{2}}$，以平抑学习率波动。"
      },
      {
        "段落": "## 7．2．4 梯度估计修正\n\n除了调整学习率之外，还可以进行梯度估计（Gradient Estimation）的修正。从图7．3看出，在随机（小批量）梯度下降法中，如果每次选取样本数量比较小，损失会呈现振荡的方式下降。也就是说，随机梯度下降方法中每次迭代的梯度估计和整个训练集上的最优梯度并不一致，具有一定的随机性。一种有效地缓解梯度估计随机性的方式是通过使用最近一段时间内的平均梯度来代替当前时刻的随机梯度来作为参数更新的方向，从而提高优化速度．",
        "总结": "- 梯度估计修正的概念：通过使用最近一段时间内的平均梯度代替当前时刻的随机梯度，以缓解随机梯度下降中的梯度估计随机性。  \n- 随机梯度下降的局限性：当样本数量较小时，损失函数呈现振荡下降，导致梯度估计与整体训练集最优梯度不一致。  \n- 修正方法的核心思想：利用平均梯度替代当前随机梯度，以提高优化过程的稳定性与速度。"
      },
      {
        "段落": "### 7．2．4．1 动量法\n\n动量（Momentum）是模拟物理中的概念。一般而言，一个物体的动量指的是这个物体在它运动方向上保持运动的趋势，是物体的质量和速度的乘积。动量法（Momentum Method）是用之前积累动量来替代真正的梯度［Rumelhart et al．，1988］．每次迭代的梯度可以看作是加速度．\n\n在第 $t$ 次迭代时，计算负梯度的＂加权移动平均＂作为参数的更新方向，\n\n$$\n\\begin{equation*}\n\\Delta \\theta_{t}=\\rho \\Delta \\theta_{t-1}-\\alpha \\mathbf{g}_{t}=-\\alpha \\sum_{\\tau=1}^{t} \\rho^{t-\\tau} \\mathbf{g}_{\\tau}, \\tag{7.21}\n\\end{equation*}\n$$\n\n其中 $\\rho$ 为动量因子，通常设为 $0.9, \\alpha$ 为学习率．\n这样，每个参数的实际更新差值取决于最近一段时间内梯度的加权平均值．当某个参数在最近一段时间内的梯度方向不一致时，其真实的参数更新幅度变小；相反，当在最近一段时间内的梯度方向都一致时，其真实的参数更新幅度变大，起到加速作用。一般而言，在迭代初期，梯度方向都比较一致，动量法会起到加速作用，可以更快地到达最优点。在迭代后期，梯度方向会不一致，在收敛值附近振荡，动量法会起到减速作用，增加稳定性。从某种角度来说，当前梯度叠加上部分的上次梯度，一定程度上可以近似看作二阶梯度。",
        "总结": "- 动量法（Momentum Method）是模拟物理中动量概念的优化算法，通过使用之前梯度的加权移动平均来更新参数，以加速收敛。  \n- 动量法的更新公式为：$\\Delta \\theta_{t} = \\rho \\Delta \\theta_{t-1} - \\alpha \\mathbf{g}_{t}$，其中 $\\rho$ 为动量因子，$\\alpha$ 为学习率。  \n- 参数更新方向由最近一段时间内梯度的加权平均决定，当梯度方向一致时加速，方向不一致时减速，增加稳定性。  \n- 动量法在迭代初期加速收敛，在后期减少振荡，提升收敛稳定性。  \n- 当前梯度与上次梯度的叠加可近似看作二阶梯度信息。"
      },
      {
        "段落": "### 7．2．4．2 Nesterov 加速梯度\n\nNesterov 加速梯度（Nesterov Accelerated Gradient，NAG），也叫Nesterov动量法（Nesterov Momentum）是一种对动量法的改进［Nesterov，2013；Sutskever et al．，2013］．\n\n在动量法中，实际的参数更新方向 $\\Delta \\theta_{t}$ 为上一步的参数更新方向 $\\Delta \\theta_{t-1}$ 和当前梯度的反方向 $-g_{t}$ 的叠加。这样，$\\Delta \\theta_{t}$ 可以被拆分为两步进行，先根据 $\\Delta \\theta_{t-1}$ 更新一次得到参数 $\\hat{\\theta}$ ，再用 $-g_{t}$ 进行更新．\n\n$$\n\\begin{align*}\n\\hat{\\theta} & =\\theta_{t-1}+\\rho \\Delta \\theta_{t-1},  \\tag{7.22}\\\\\n\\theta_{t} & =\\hat{\\theta}-\\alpha \\mathbf{g}_{t}, \\tag{7.23}\n\\end{align*}\n$$\n\nhttps：／／nndl．github．io／\n\n增加批量大小也是缓解随机性的一种方式。\n\n其中梯度 $\\boldsymbol{g}_{t}$ 为点 $\\theta_{t-1}$ 上的梯度，因此在第二步更新中有些不太合理．更合理的更新方向应该为 $\\hat{\\theta}$ 上的梯度．\n\n这样，合并后的更新方向为\n\n$$\n\\begin{equation*}\n\\Delta \\theta_{t}=\\rho \\Delta \\theta_{t-1}-\\alpha \\mathfrak{g}_{t}\\left(\\theta_{t-1}+\\rho \\Delta \\theta_{t-1}\\right) \\tag{7.24}\n\\end{equation*}\n$$\n\n其中 $\\mathfrak{g}_{t}\\left(\\theta_{t-1}+\\rho \\Delta \\theta_{t-1}\\right)$ 表示损失函数在点 $\\hat{\\theta}=\\theta_{t-1}+\\rho \\Delta \\theta_{t-1}$ 上的偏导数．\n图7．6给出了动量法和 Nesterov 加速梯度在参数更新时的比较．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-177.jpg?height=481&width=832&top_left_y=553&top_left_x=235)\n\n图 7.6 动量法和 Nesterov 加速梯度的比较",
        "总结": "- Nesterov 加速梯度（NAG）是对动量法的改进，通过在更新方向上使用预测点的梯度来提升优化效果。  \n- 动量法中，参数更新方向 $\\Delta \\theta_{t}$ 是上一步更新方向 $\\Delta \\theta_{t-1}$ 和当前梯度 $-g_{t}$ 的叠加。  \n- 在动量法中，先根据 $\\Delta \\theta_{t-1}$ 更新得到参数 $\\hat{\\theta}$，再用 $-g_{t}$ 进行更新。  \n- 更合理的更新方向应使用预测点 $\\hat{\\theta}$ 上的梯度，而非原始点 $\\theta_{t-1}$ 上的梯度。  \n- NAG 的更新公式为 $\\Delta \\theta_{t} = \\rho \\Delta \\theta_{t-1} - \\alpha \\mathfrak{g}_{t}(\\hat{\\theta})$，其中 $\\mathfrak{g}_{t}(\\hat{\\theta})$ 是预测点上的梯度。  \n- 图7.6对比了动量法和Nesterov加速梯度在参数更新过程中的差异。"
      },
      {
        "段落": "### 7．2．4．3 Adam 算法\n\n自适应动量估计（Adaptive Moment Estimation，Adam）算法［Kingma et al．，2015］可以看作是动量法和 RMSprop 算法的结合，不但使用动量作为参数更新方向，而且可以自适应调整学习率．\n\nAdam 算法一方面计算梯度平方 $g_{t}^{2}$ 的指数加权平均（和 RMSprop 算法类似），另一方面计算梯度 $\\mathrm{g}_{t}$ 的指数加权平均（和动量法类似）。\n\n$$\n\\begin{gather*}\nM_{t}=\\beta_{1} M_{t-1}+\\left(1-\\beta_{1}\\right) g_{t}  \\tag{7.25}\\\\\nG_{t}=\\beta_{2} G_{t-1}+\\left(1-\\beta_{2}\\right) g_{t} \\odot g_{t} \\tag{7.26}\n\\end{gather*}\n$$\n\n其中 $\\beta_{1}$ 和 $\\beta_{2}$ 分别为两个移动平均的衰减率，通常取值为 $\\beta_{1}=0.9, \\beta_{2}=0.99$ ．\n$M_{t}$ 可以看作是梯度的均值（一阶矩），$G_{t}$ 可以看作是梯度的未减去均值的方差（二阶矩）。\n\n假设 $M_{0}=0, G_{0}=0$ ，那么在迭代初期 $M_{t}$ 和 $G_{t}$ 的值会比真实的均值和方差要小．特别是当 $\\beta_{1}$ 和 $\\beta_{2}$ 都接近于 1 时，偏差会很大．因此，需要对偏差进行修正．\n$\\mathfrak{g}_{t}$ 的 定 义 参 见 公式（7．1）。\n\n$$\n\\begin{equation*}\n\\hat{M}_{t}=\\frac{M_{t}}{1-\\beta_{1}^{t}}, \\tag{7.27}\n\\end{equation*}\n$$\n\n$$\n\\begin{equation*}\n\\hat{G}_{t}=\\frac{G_{t}}{1-\\beta_{2}^{t}} \\tag{7.28}\n\\end{equation*}\n$$\n\nAdam 算法的参数更新差值为\n\n$$\n\\begin{equation*}\n\\Delta \\theta_{t}=-\\frac{\\alpha}{\\sqrt{\\hat{G}_{t}+\\epsilon}} \\hat{M}_{t} \\tag{7.29}\n\\end{equation*}\n$$\n\n其中学习率 $\\alpha$ 通常设为 0.001 ，并且也可以进行衰减，比如 $\\alpha_{t}=\\alpha_{0} / \\sqrt{t}$ 。\nAdam 算法是 RMSProp 算法与动量法的结合，因此一种自然的 Adam 算法的改进方法是引入 Nesterov 加速梯度，称为Nadam算法［Dozat，2016］．",
        "总结": "- Adam算法是动量法和RMSprop的结合，同时使用动量调整参数更新方向并自适应调整学习率  \n- 计算梯度均值（一阶矩）$M_t$ 和梯度平方的均值（二阶矩）$G_t$，分别通过指数加权平均实现  \n- $M_t = \\beta_1 M_{t-1} + (1-\\beta_1)g_t$，$G_t = \\beta_2 G_{t-1} + (1-\\beta_2)g_t \\odot g_t$  \n- $\\beta_1$ 和 $\\beta_2$ 分别为一阶和二阶矩的衰减率，通常取 $\\beta_1=0.9, \\beta_2=0.99$  \n- 初始 $M_0 = 0, G_0 = 0$，导致初期估计值偏小，需通过偏差修正  \n- 偏差修正公式为 $\\hat{M}_t = \\frac{M_t}{1-\\beta_1^t}$，$\\hat{G}_t = \\frac{G_t}{1-\\beta_2^t}$  \n- 参数更新公式为 $\\Delta \\theta_t = -\\frac{\\alpha}{\\sqrt{\\hat{G}_t + \\epsilon}} \\hat{M}_t$，其中 $\\alpha$ 通常设为 0.001  \n- 学习率 $\\alpha$ 可以随时间衰减，如 $\\alpha_t = \\alpha_0 / \\sqrt{t}$  \n- Adam算法可结合Nesterov加速梯度改进，形成Nadam算法"
      },
      {
        "段落": "### 7．2．4．4 梯度截断\n\n在深度神经网络或循环神经网络中，除了梯度消失之外，梯度爆炸也是影响学习效率的主要因素。在基于梯度下降的优化过程中，如果梯度突然增大，用大的梯度更新参数反而会导致其远离最优点。为了避免这种情况，当梯度的模大于一定阈值时，就对梯度进行截断，称为梯度截断（Gradient Clipping）［Pascanu et al．，2013］．\n\n图7．7给出了一个循环神经网络的损失函数关于参数的曲面．图中的曲面为只有一个隐藏神经元的循环神经网络 $h_{t}=\\sigma\\left(w h_{t-1}+b\\right)$ 的损失函数，其中 $w$ 和 $b$为参数。假如 $h_{0}$ 初始值为 0.3 ，损失函数为 $\\mathcal{L}=\\left(h_{100}-0.65\\right)^{2}$ 。从图7．7中可以看出，损失函数关于参数 $w, b$ 的梯度在某个区域会突然变大．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-178.jpg?height=499&width=587&top_left_y=1307&top_left_x=360)\n\n图7．7梯度爆炸问题示例\n\n梯度截断是一种比较简单的启发式方法，把梯度的模限定在一个区间，当梯度的模小于或大于这个区间时就进行截断．一般截断的方式有以下几种：\n\n按值截断 在第 $t$ 次迭代时，梯度为 $\\boldsymbol{g}_{t}$ ，给定一个区间 $[a, b]$ ，如果一个参数的梯度小于 $a$ 时，就将其设为 $a$ ；如果大于 $b$ 时，就将其设为 $b$ 。\n\n$$\n\\begin{equation*}\n\\boldsymbol{g}_{t}=\\max \\left(\\min \\left(\\boldsymbol{g}_{t}, b\\right), a\\right) . \\tag{7.30}\n\\end{equation*}\n$$\n\n按模截断 按模截断是将梯度的模截断到一个给定的截断阈值 $b$ 。\n如果 $\\left\\|\\boldsymbol{g}_{t}\\right\\|^{2} \\leq b$ ，保持 $\\boldsymbol{g}_{t}$ 不变。如果 $\\left\\|\\boldsymbol{g}_{t}\\right\\|^{2}>b$ ，令\n\n$$\n\\begin{equation*}\ng_{t}=\\frac{b}{\\left\\|g_{t}\\right\\|} g_{t} \\tag{7.31}\n\\end{equation*}\n$$\n\n截断阈值 $b$ 是一个超参数，也可以根据一段时间内的平均梯度来自动调整．实验中发现，训练过程对阈值 $b$ 并不十分敏感，通常一个小的阈值就可以得到很好的结果［Pascanu et al．，2013］．",
        "总结": "- 概念：梯度截断是一种用于防止梯度爆炸的启发式方法，通过限制梯度的模值来避免参数更新过大。\n- 算法：按值截断将梯度限制在区间 [a, b] 内，按模截断将梯度的模限制在一个阈值 b 内。\n- 数学推导：按值截断公式为 $\\boldsymbol{g}_{t} = \\max(\\min(\\boldsymbol{g}_{t}, b), a)$；按模截断公式为 $g_{t} = \\frac{b}{\\left\\|g_{t}\\right\\|} g_{t}$，当 $\\left\\|\\boldsymbol{g}_{t}\\right\\|^{2} > b$ 时使用。\n- 命题：截断阈值 $b$ 是一个超参数，通常对训练过程不十分敏感，较小的阈值即可获得良好效果。"
      },
      {
        "段落": "## 7．2．5 优化算法小结\n\n本节介绍的几种优化方法大体上可以分为两类：一是调整学习率，使得优化更稳定；二是梯度估计修正，优化训练速度。表7．1汇总了本节介绍的几种神经网络常用优化算法．",
        "总结": "- 本节将优化算法分为两类：调整学习率以提高稳定性，以及梯度估计修正以加快训练速度  \n- 表7．1汇总了本节介绍的几种常用的神经网络优化算法"
      },
      {
        "段落": "## 表 7.1 神经网络常用优化方法的汇总\n\n|  | 类别 | 优化算法 |\n| :--- | :--- | :--- |\n| ![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-179.jpg?height=185&width=57&top_left_y=1248&top_left_x=135) | 固定衰减学习率周期性学习率自适应学习率 | 分段常数衰减、逆时衰减、（自然）指数衰减、余弦衰减循环学习率、SGDR AdaGrad、RMSprop、AdaDelta |\n|  | 梯度估计修正 | 动量法、Nesterov 加速梯度、梯度截断 |\n|  | 综合方法 | Adam $\\approx$ 动量法＋RMSprop |\n\n这些优化算法可以使用下面公式来统一描述概括：\n\n$$\n\\begin{align*}\n\\Delta \\theta_{t} & =-\\frac{\\alpha_{t}}{\\sqrt{G_{t}+\\epsilon}} M_{t}  \\tag{7.32}\\\\\nG_{t} & =\\psi\\left(g_{1}, \\cdots, g_{t}\\right)  \\tag{7.33}\\\\\nM_{t} & =\\phi\\left(g_{1}, \\cdots, g_{t}\\right) \\tag{7.34}\n\\end{align*}\n$$\n\n其中 $g_{t}$ 是第 $t$ 步的梯度；$\\alpha_{t}$ 是第 $t$ 步的学习率，可以进行衰减，也可以不变；$\\psi(\\cdot)$ 是学习率缩放函数，可以取 1 或历史梯度的模的移动平均；$\\phi(\\cdot)$ 是优化后的参数更新方向，可以取当前的梯度 $g_{t}$ 或历史梯度的移动平均．\nhttps：／／nndl．github．io／\n\n在训练循环神经网络时，按模截断是避免梯度爆炸问题的有效方法．\n\n参见习题 7－3．\n\n图7．8给出了这几种优化方法在 MNIST 数据集上收玫性的比较（学习率为 0.001 ，批量大小为 128 ）。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-180.jpg?height=672&width=913&top_left_y=254&top_left_x=199)\n\n图7．8不同优化方法的比较",
        "总结": "- 概念：介绍了神经网络中常用的优化方法，包括固定衰减学习率、周期性学习率、自适应学习率等类别。\n- 概念：列举了多种优化算法，如分段常数衰减、逆时衰减、指数衰减、循环学习率、SGDR、AdaGrad、RMSprop、AdaDelta等。\n- 概念：提到了梯度估计修正方法，如动量法、Nesterov加速梯度和梯度截断。\n- 概念：介绍了综合方法，如Adam，其结合了动量法和RMSprop。\n- 公式：提供了一个统一的公式框架来描述优化算法，包括参数更新方向 $M_t$ 和学习率缩放函数 $G_t$。\n- 方法：指出在训练循环神经网络时，按模截断是避免梯度爆炸问题的有效方法。\n- 图表：图7.8展示了不同优化方法在MNIST数据集上的收敛性比较，学习率为0.001，批量大小为128。"
      },
      {
        "段落": "## 7.3 参数初始化\n\n神经网络的参数学习是一个非凸优化问题．当使用梯度下降法来进行优化网络参数时，参数初始值的选取十分关键，关系到网络的优化效率和泛化能力。参数初始化的方式通常有以下三种：\n（1）预训练初始化：不同的参数初始值会收敛到不同的局部最优解．虽然这些局部最优解在训练集上的损失比较接近，但是它们的泛化能力差异很大．一个好的初始值会使得网络收玫到一个泛化能力高的局部最优解。通常情况下，一个已经在大规模数据上训练过的模型可以提供一个好的参数初始值，这种初始化方法称为预训练初始化（Pretrained Initialization）。预训练任务可以为监督学习或无监督学习任务。由于无监督学习任务更容易获取大规模的训练数据，因此被广泛采用．预训练模型在目标任务上的学习过程也称为精调（Fine－tuning）。\n（2）随机初始化：在线性模型的训练（比如感知器和 Logistic 回归）中，我们一般将参数全部初始化为 0 。但是这在神经网络的训练中会存在一些问题。因为如果参数都为 0 ，在第一遍前向计算时，所有的隐层神经元的激活值都相同．在反向传播时，所有权重的更新也都相同．这样会导致隐层神经元没有区分性．这种现象也称为对称权重现象．为了打破这个平衡，比较好的方式\n\n预训练初始化通常会提升模型泛化能力的一种解释是预训练任务起到一定的正则化作用。\n\n是对每个参数都随机初始化（Random Initialization），这样使得不同神经元之间的区分性更好．\n（3）固定值初始化：对于一些特殊的参数，我们可以根据经验用一个特殊的固定值来进行初始化。比如偏置（Bias）通常用 0 来初始化，但是有时可以设置某些经验值以提高优化效率。在 LSTM 网络的遗忘门中，偏置通常初始化为 1 或 2 ，使得时序上的梯度变大。对于使用 ReLU 的神经元，有时也可以将偏置设为 0.01 ，使得 ReLU 神经元在训练初期更容易激活，从而获得一定的梯度来进行误差反向传播．\n\n虽然预训练初始化通常具有更好的收玫性和泛化性，但是灵活性不够，不能在目标任务上任意地调整网络结构。因此，好的随机初始化方法对训练神经网络模型来说依然十分重要。这里我们介绍三类常用的随机初始化方法：基于固定方差的参数初始化、基于基于方差缩放的初始化方法和正交初始化方法．",
        "总结": "- 参数初始化是神经网络训练中的关键步骤，影响优化效率和泛化能力  \n- 预训练初始化利用已训练好的模型参数作为初始值，提升泛化能力，常用于监督或无监督任务，无监督任务更常用  \n- 随机初始化通过为每个参数赋予随机值打破对称权重现象，提高神经元区分性  \n- 固定值初始化根据经验为特定参数设置固定初始值，如偏置初始化为0或特定值以优化训练过程  \n- 基于固定方差的初始化方法为参数赋予固定方差的随机值  \n- 基于方差缩放的初始化方法根据网络层的输入输出维度调整参数方差  \n- 正交初始化方法通过正交矩阵初始化参数，有助于保持梯度稳定  \n- 预训练初始化虽有优势，但灵活性不足，随机初始化仍是重要手段"
      },
      {
        "段落": "## 7．3．1 基于固定方差的参数初始化\n\n一种最简单的随机初始化方法是从一个固定均值（通常为 0 ）和方差 $\\sigma^{2}$ 的分布中采样来生成参数的初始值。基于固定方差的参数初始化方法主要有以下两种：\n（1）高斯分布初始化：使用一个高斯分布 $\\mathcal{N}\\left(0, \\sigma^{2}\\right)$ 对每个参数进行随机初始化．\n（2）均匀分布初始化：在一个给定的区间 $[-r, r]$ 内采用均匀分布来初始化参数．假设随机变量 $x$ 在区间 $[a, b]$ 内均匀分布，则其方差为\n\n$$\n\\begin{equation*}\n\\operatorname{var}(x)=\\frac{(b-a)^{2}}{12} \\tag{7.35}\n\\end{equation*}\n$$\n\n因此，若使用区间为 $[-r, r]$ 的均分分布来采样，并满足 $\\operatorname{var}(x)=\\sigma^{2}$ 时，则 $r$的取值为\n\n$$\n\\begin{equation*}\nr=\\sqrt{3 \\sigma^{2}} \\tag{7.36}\n\\end{equation*}\n$$\n\n在基于固定方差的随机初始化方法中，比较关键的是如何设置方差 $\\sigma^{2}$ 。如果参数范围取的太小，一是会导致神经元的输出过小，经过多层之后信号就慢慢消失了；二是还会使得 Sigmoid 型激活函数丢失非线性的能力。以 Sigmoid 型函数为例，在 0 附近基本上是近似线性的。这样多层神经网络的优势也就不存在了。如果参数范围取的太大，会导致输入状态过大。对于 Sigmoid 型激活函数来说，激活值变得饱和，梯度接近于 0 ，从而导致梯度消失问题．\n\n为了降低固定方差对网络性能以及优化效率的影响，基于固定方差的随机初始化方法一般需要配合逐层归一化来使用．\nhttps：／／nndl．github．io／\n\n遗忘门参见公式（6．55）．\n\n随机初始化通常只应用在神经网络的权重矩阵上。\n\n这里的＂固定＂的含义是方差 $\\sigma^{2}$ 为一个预设值，和神经元的输入、激活函数以及所在层数无关．",
        "总结": "- 概念：基于固定方差的参数初始化方法，即从一个固定均值（通常为0）和方差σ²的分布中采样生成参数的初始值。\n- 算法：高斯分布初始化，使用正态分布N(0, σ²)对每个参数进行随机初始化；均匀分布初始化，在区间[-r, r]内采用均匀分布初始化参数。\n- 数学推导：均匀分布的方差公式为var(x) = (b-a)²/12，当区间为[-r, r]且满足var(x)=σ²时，r = √(3σ²)。\n- 命题：固定方差σ²的设置对网络性能和优化效率有重要影响。参数范围过小会导致神经元输出过小或激活函数失去非线性能力；参数范围过大则可能导致激活值饱和，出现梯度消失问题。\n- 注意事项：固定方差的含义是σ²为预设值，与神经元输入、激活函数及所在层数无关。通常需配合逐层归一化使用以降低其影响。\n- 应用范围：随机初始化通常应用于神经网络的权重矩阵。"
      },
      {
        "段落": "## 7．3．2 基于方差缩放的参数初始化\n\n要高效地训练神经网络，给参数选取一个合适的随机初始化区间是非常重要的．一般而言，参数初始化的区间应该根据神经元的性质进行差异化的设置．如果一个神经元的输入连接很多，它的每个输入连接上的权重就应该小一些，以避免神经元的输出过大（当激活函数为 ReLU 时）或过饱和（当激活函数为 Sigmoid 函数时）。\n\n初始化一个深度网络时，为了缓解梯度消失或爆炸问题，我们尽可能保持每个神经元的输入和输出的方差一致，根据神经元的连接数量进行自适应的调整初始化分布的方差，这类方法称为方差缩放（Variance Scaling）。",
        "总结": "- 概念：方差缩放（Variance Scaling）是一种参数初始化方法，旨在通过调整初始化分布的方差来保持神经元输入和输出的方差一致，以缓解梯度消失或爆炸问题。  \n- 算法：方差缩放根据神经元的连接数量自适应调整初始化分布的方差，确保输入和输出的方差保持一致。  \n- 数学推导：通过分析神经元输入和输出的方差关系，推导出初始化参数的方差应与连接数量成比例，从而保证网络训练的稳定性。  \n- 激活函数影响：当使用ReLU激活函数时，需避免神经元输出过大；当使用Sigmoid函数时，需避免神经元过饱和。  \n- 初始化区间设置：参数初始化区间应根据神经元的输入连接数量进行差异化设置，输入连接多时权重应更小。"
      },
      {
        "段落": "### 7．3．2．1 Xavier 初始化\n\n假设在一个神经网络中，第 $l$ 层的一个神经元 $a^{(l)}$ ，其接收前一层的 $M_{l-1}$ 个神经元的输出 $a_{i}^{(l-1)}, 1 \\leq i \\leq M_{l-1}$ ，\n\n$$\n\\begin{equation*}\na^{(l)}=f\\left(\\sum_{i=1}^{M_{l-1}} w_{i}^{(l)} a_{i}^{(l-1)}\\right) \\tag{7.37}\n\\end{equation*}\n$$\n\n其中 $f(\\cdot)$ 为激活函数，$w_{i}^{(l)}$ 为参数，$M_{l-1}$ 是第 $l-1$ 层神经元个数．为简单起见，这里令激活函数 $f(\\cdot)$ 为恒等函数，即 $f(x)=x$ 。\n\n假设 $w_{i}^{(l)}$ 和 $a_{i}^{(l-1)}$ 的均值都为 0 ，并且互相独立，则 $a^{(l)}$ 的均值为\n\n$$\n\\begin{equation*}\n\\mathbb{E}\\left[a^{(l)}\\right]=\\mathbb{E}\\left[\\sum_{i=1}^{M_{l-1}} w_{i}^{(l)} a_{i}^{(l-1)}\\right]=\\sum_{i=1}^{M_{l-1}} \\mathbb{E}\\left[w_{i}^{(l)}\\right] \\mathbb{E}\\left[a_{i}^{(l-1)}\\right]=0 \\tag{7.38}\n\\end{equation*}\n$$\n\n$a^{(l)}$ 的方差为\n\n$$\n\\begin{align*}\n\\operatorname{var}\\left(a^{(l)}\\right) & =\\operatorname{var}\\left(\\sum_{i=1}^{M_{l-1}} w_{i}^{(l)} a_{i}^{(l-1)}\\right)  \\tag{7.39}\\\\\n& =\\sum_{i=1}^{M_{l-1}} \\operatorname{var}\\left(w_{i}^{(l)}\\right) \\operatorname{var}\\left(a_{i}^{(l-1)}\\right)  \\tag{7.40}\\\\\n& =M_{l-1} \\operatorname{var}\\left(w_{i}^{(l)}\\right) \\operatorname{var}\\left(a_{i}^{(l-1)}\\right) \\tag{7.41}\n\\end{align*}\n$$\n\n也就是说，输入信号的方差在经过该神经元后被放大或缩小了 $M_{l-1} \\operatorname{var}\\left(w_{i}^{(l)}\\right)$ 倍．为了使得在经过多层网络后，信号不被过分放大或过分减弱，我们尽可能保持每个神经元的输入和输出的方差一致。这样 $M_{l-1} \\operatorname{var}\\left(w_{i}^{(l)}\\right)$ 设为 1 比较合理，即\n\n$$\n\\begin{equation*}\n\\operatorname{var}\\left(w_{i}^{(l)}\\right)=\\frac{1}{M_{l-1}} \\tag{7.42}\n\\end{equation*}\n$$\n\n同理，为了使得在反向传播中，误差信号也不被放大或缩小，需要将 $w_{i}^{(l)}$ 的方差保持为\n\n$$\n\\begin{equation*}\n\\operatorname{var}\\left(w_{i}^{(l)}\\right)=\\frac{1}{M_{l}} \\tag{7.43}\n\\end{equation*}\n$$\n\n作为折中，同时考虑信号在前向和反向传播中都不被放大或缩小，可以设置\n\n$$\n\\begin{equation*}\n\\operatorname{var}\\left(w_{i}^{(l)}\\right)=\\frac{2}{M_{l-1}+M_{l}} \\tag{7.44}\n\\end{equation*}\n$$\n\n在计算出参数的理想方差后，可以通过高斯分布或均匀分布来随机初始化参数．当采用高斯分布来随机初始化参数时，连接权重 $w_{i}^{(l)}$ 可以按 $\\mathcal{N}\\left(0, \\frac{2}{M_{l-1}+M_{l}}\\right)$的高斯分布进行初始化．若采用区间为 $[-r, r]$ 的均分分布来初始化 $w_{i}^{(l)}$ 时，则 $r$的取值为 $\\sqrt{\\frac{6}{M_{l-1}+M_{l}}}$ 。这种根据每层的神经元数量来自动计算初始化参数方差的方法称为Xavier 初始化［Glorot et al．，2010］．\n\n虽然在 Xavier 初始化中，我们假设激活函数为恒等函数，但是 Xavier 初始化也适用于 Logistic 函数和 Tanh 函数。这是因为由于神经元的参数和输入的绝对值通常比较小，处于激活函数的线性区间．这时 Logistic 函数和 Tanh 函数可以近似为线性函数。由于 Logistic 函数在线性区间的斜率约为 0．25，因此其参数初始化的方差约为 $16 \\times \\frac{2}{M_{l-1}+M_{l}}$ ．",
        "总结": "- Xavier 初始化是一种根据每层神经元数量自动计算参数初始化方差的方法，旨在保持输入和输出的方差一致，防止信号在多层网络中被过分放大或减弱。\n- 假设激活函数为恒等函数，且输入和权重的均值为0且独立，神经元输出的方差由前一层神经元数量和权重方差决定。\n- 为保持前向传播中方差一致，权重方差应设为 $ \\frac{1}{M_{l-1}} $。\n- 为保持反向传播中误差信号方差一致，权重方差应设为 $ \\frac{1}{M_{l}} $。\n- 综合前向和反向传播需求，权重方差设为 $ \\frac{2}{M_{l-1}+M_{l}} $。\n- 权重可按高斯分布 $ \\mathcal{N}\\left(0, \\frac{2}{M_{l-1}+M_{l}}\\right) $ 或均匀分布 $ [-r, r] $ 初始化，其中 $ r = \\sqrt{\\frac{6}{M_{l-1}+M_{l}}} $。\n- Xavier 初始化不仅适用于恒等函数，也适用于 Logistic 和 Tanh 函数，因其在激活函数线性区间内可近似为线性函数。\n- Logistic 函数在线性区间的斜率约为 0.25，因此其参数初始化方差约为 $ 16 \\times \\frac{2}{M_{l-1}+M_{l}} $。"
      },
      {
        "段落": "### 7．3．2．2 He 初始化\n\n当第 $l$ 层神经元使用 ReLU 激活函数时，通常有一半的神经元输出为 0 ，因此其分布的方差也近似为使用恒等函数时的一半．这样，只考虑前向传播时，参数 $w_{i}^{(l)}$ 的理想方差为\n\n$$\n\\begin{equation*}\n\\operatorname{var}\\left(w_{i}^{(l)}\\right)=\\frac{2}{M_{l-1}} \\tag{7.45}\n\\end{equation*}\n$$\n\n其中 $M_{l-1}$ 是第 $l-1$ 层神经元个数．\n因此当使用 ReLU 激活函数时，若采用高斯分布来初始化参数 $w_{i}^{(l)}$ ，其方差为 $\\frac{2}{M_{l-1}}$ ；若采用区间为 $[-r, r]$ 的均分分布来初始化参数 $w_{i}^{(l)}$ ，则 $r=\\sqrt{\\frac{6}{M_{l-1}}}$ 。这种初始化方法称为 He 初始化［He et al．，2015］．\n\n表7．2给出了 Xavier 初始化和 He 初始化的具体设置情况．",
        "总结": "- He初始化是针对使用ReLU激活函数的神经网络层设计的参数初始化方法。\n- 当使用ReLU时，由于一半的神经元输出为0，参数的方差应为使用恒等函数时的一半。\n- He初始化中，若采用高斯分布，参数的方差为 $ \\frac{2}{M_{l-1}} $；若采用均分分布，则区间为 $[-r, r]$，其中 $ r = \\sqrt{\\frac{6}{M_{l-1}}} $。\n- He初始化由He等人在2015年提出。"
      },
      {
        "段落": "## 7．3．3 正交初始化\n\n上面介绍的两种基于方差的初始化方法都是对权重矩阵中的每个参数进行独立采样。由于采样的随机性，采样出来的权重矩阵依然可能存在梯度消失或梯度爆炸问题．\nhttps：／／nndl．github．io／\n\n参见习题 7－4．\n\n参见公式（7．36）．\n\nXavier 初始化方法中， Xavier 是发明者 Xavier Glorot的名字．Xavier初始化也称为 Glorot 初始化．\n\n在实际应用中，Logistic函数和 Tanh 函数都需要将方差 $\\frac{2}{M_{l-1}+M_{l}}$ 乘以一个缩放因子 $\\rho$ 。 $\\rho$根据经验设定。\n\n参见习题 7－5．\n\nHe 初始化在有些文献上也称为Kaiming初始化。\n\n表 7．2 Xavier 初始化和 He 初始化的具体设置情况\n\n| 初始化方法 | 激活函数 | 均匀分布 $[-r, r]$ | 高斯分布 $\\mathcal{N}\\left(0, \\sigma^{2}\\right)$ |\n| :---: | :---: | :--- | :--- |\n| Xavier初始化 | Logistic | $r=\\sqrt[4]{\\frac{6}{M_{l-1}+M_{l}}}$ | $\\sigma^{2}=16 \\times \\frac{2}{M_{l-1}+M_{l}}$ |\n| Xavier初始化 | Tanh | $r=\\sqrt{\\frac{6}{M_{l-1}+M_{l}}}$ | $\\sigma^{2}=\\frac{2}{M_{l-1}+M_{l}}$ |\n| He 初始化 | ReLU | $r=\\sqrt{\\frac{6}{M_{l-1}}}$ | $\\sigma^{2}=\\frac{2}{M_{l-1}}$ |\n\n假设一个 $L$ 层的等宽线性网络（激活函数为恒等函数）为\n\n$$\n\\begin{equation*}\n\\boldsymbol{y}=\\boldsymbol{W}^{(L)} \\boldsymbol{W}^{(L-1)} \\cdots \\boldsymbol{W}^{(1)} \\boldsymbol{x} \\tag{7.46}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{W}^{(l)} \\in \\mathbb{R}^{M \\times M}(1 \\leq l \\leq L)$ 为神经网络的第 $l$ 层权重矩阵。在反向传播中，误差项 $\\delta$ 的反向传播公式为 $\\delta^{(l-1)}=\\left(\\boldsymbol{W}^{(l)}\\right)^{\\top} \\delta^{(l)}$ 。为了避免梯度消失或梯度爆炸问题，我们希望误差项在反向传播中具有范数保持性（Norm－Preserving），即 $\\left\\|\\delta^{(l-1)}\\right\\|^{2}=\\left\\|\\delta^{(l)}\\right\\|^{2}=\\left\\|\\left(\\boldsymbol{W}^{(l)}\\right)^{\\top} \\delta^{(l)}\\right\\|^{2}$ 。如果我们以均值为 0 、方差为 $\\frac{1}{M}$ 的高斯分布来随机生成权重矩阵 $\\boldsymbol{W}^{(l)}$ 中每个元素的初始值，那么当 $M \\rightarrow \\infty$ 时，范数保持性成立。但是当 $M$ 不足够大时，这种对每个参数进行独立采样的初始化方式难以保证范数保持性。\n\n因此，一种更加直接的方式是将 $\\boldsymbol{W}^{(l)}$ 初始化为正交矩阵，即 $\\boldsymbol{W}^{(l)}\\left(\\boldsymbol{W}^{(l)}\\right)^{\\top}=$ $I$ ，这种方法称为正交初始化（Orthogonal Initialization）［Saxe et al．，2014］．正交初始化的具体实现过程可以分为两步：首先，用均值为 0 、方差为 1 的高斯分布初始化一个矩阵；其次，将这个矩阵用奇异值分解得到两个正交矩阵，并使用其中之一作为权重矩阵。\n\n根据正交矩阵的性质，这个线性网络在信息的前向传播过程和误差的反向传播过程中都具有范数保持性，从而可以避免在训练开始时就出现梯度消失或梯度爆炸现象。\n\n当在非线性神经网络中应用正交初始化时，通常需要将正交矩阵乘以一个缩放系数 $\\rho$ 。比如当激活函数为 ReLU 时，激活函数在 0 附近的平均梯度可以近似为\n\n这里假设每一层的偏置初始化为 0 ．\n\n误差项参见公式（4．63）．\n\n奇异值分解参 见第 A．2．5．2节．\n\n正交初始化通常用在循环神经网络中循环边上的权重矩阵上。 0.5 ．为了保持范数不变，缩放系数 $\\rho$ 可以设置为 $\\sqrt{2}$ ．",
        "总结": "- 正交初始化是一种通过将权重矩阵初始化为正交矩阵，以确保前向传播和反向传播过程中保持误差项范数的方法。  \n- 正交初始化的具体步骤包括：先用均值为0、方差为1的高斯分布初始化矩阵，再通过奇异值分解得到正交矩阵并使用其中之一作为权重矩阵。  \n- 正交初始化能够避免训练初期出现梯度消失或梯度爆炸问题，因为它保证了误差项在反向传播中的范数保持性。  \n- 在非线性神经网络中应用正交初始化时，通常需要将正交矩阵乘以一个缩放系数 $\\rho$，例如当激活函数为ReLU时，$\\rho$ 可设置为 $\\sqrt{2}$。  \n- Xavier 初始化和 He 初始化是基于方差的初始化方法，分别适用于 Logistic、Tanh 和 ReLU 激活函数，并通过调整方差来控制权重的初始分布。  \n- 表格对比了 Xavier 初始化和 He 初始化在不同激活函数下的均匀分布和高斯分布参数设置。  \n- 为了保持范数不变，正交初始化在非线性网络中通常需要引入缩放系数 $\\rho$。"
      },
      {
        "段落": "## 7.4 数据预处理\n\n一般而言，样本的原始特征中的每一维特征由于来源以及度量单位不同，其特征取值的分布范围往往差异很大．当我们计算不同样本之间的欧氏距离时，取值范围大的特征会起到主导作用．这样，对于基于相似度比较的机器学习方法 https：／／nndl．github．io／\n（比如最近邻分类器），必须先对样本进行预处理，将各个维度的特征归一化到同一个取值区间，并且消除不同特征之间的相关性，才能获得比较理想的结果。虽然神经网络可以通过参数的调整来适应不同特征的取值范围，但是会导致训练效率比较低。\n\n假设一个只有一层的网络 $y=\\tanh \\left(w_{1} x_{1}+w_{2} x_{2}+b\\right)$ ，其中 $x_{1} \\in[0,10]$ ， $x_{2} \\in[0,1]$ ．之前我们提到 $\\tanh$ 函数的导数在区间 $[-2,2]$ 上是敏感的，其余的导数接近于 0 ．因此，如果 $w_{1} x_{1}+w_{2} x_{2}+b$ 过大或过小，都会导致梯度过小，难以训练。为了提高训练效率，我们需要使 $w_{1} x_{1}+w_{2} x_{2}+b$ 在 $[-2,2]$ 区间，因此需要将 $w_{1}$ 设得小一点，比如在 $[-0.1,0.1]$ 之间．可以想象，如果数据维数很多时，我们很难这样精心去选择每一个参数。因此，如果每一个特征的取值范围都在相似的区间，比如 $[0,1]$ 或者 $[-1,1]$ ，我们就不太需要区别对待每一个参数，从而减少人工干预。\n\n除了参数初始化之外，不同输入特征的取值范围差异比较大时，梯度下降法的效率也会受到影响。图7．9给出了数据归一化对梯度的影响。其中，图7．9a为未归一化数据的等高线图．取值范围不同会造成在大多数位置上的梯度方向并不是最优的搜索方向。当使用梯度下降法寻求最优解时，会导致需要很多次迭代才能收敛。如果我们把数据归一化为取值范围相同，如图7．9b所示，大部分位置的梯度方向近似于最优搜索方向。这样，在梯度下降求解时，每一步梯度的方向都基本指向最小值，训练效率会大大提高。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-185.jpg?height=455&width=940&top_left_y=1235&top_left_x=194)\n\n图 7.9 数据归一化对梯度的影响\n\n归一化的方法有很多种，比如之前我们介绍的 sigmoid 型函数等都可以将不同取值范围的特征挤压到一个比较受限的区间。这里，我们介绍几种在神经网络中经常使用的归一化方法．\n\n缩放归一化 缩放归一化是一种非常简单的归一化方法，通过缩放将每一个特征的取值范围归一到 $[0,1]$ 或 $[-1,1]$ 之间．假设有 $N$ 个样本 $\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ ，对于每一维\n\n特征 $x$ ，\n\n$$\n\\begin{equation*}\n\\hat{x}^{(n)}=\\frac{x^{(n)}-\\min _{n}\\left(x^{(n)}\\right)}{\\max _{n}\\left(x^{(n)}\\right)-\\min _{n}\\left(x^{(n)}\\right)} \\tag{7.47}\n\\end{equation*}\n$$\n\n其中 $\\min (x)$ 和 $\\max (x)$ 分别是特征 $x$ 在所有样本上的最小值和最大值．\n标准归一化 标准归一化也叫 z －score 归一化，来源于统计上的标准分数。将每一个维特征都调整为均值为 0 ，方差为 1 ．假设有 $N$ 个样本 $\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ ，对于每一维特征 $x$ ，我们先计算它的均值和方差：\n\n$$\n\\begin{align*}\n\\mu & =\\frac{1}{N} \\sum_{n=1}^{N} x^{(n)}  \\tag{7.48}\\\\\n\\sigma^{2} & =\\frac{1}{N} \\sum_{n=1}^{N}\\left(x^{(n)}-\\mu\\right)^{2} \\tag{7.49}\n\\end{align*}\n$$\n\n然后，将特征 $x^{(n)}$ 减去均值，并除以标准差，得到新的特征值 $\\hat{x}^{(n)}$ 。\n\n$$\n\\begin{equation*}\n\\hat{x}^{(n)}=\\frac{x^{(n)}-\\mu}{\\sigma} \\tag{7.50}\n\\end{equation*}\n$$\n\n这里 $\\sigma$ 不能为 0 ．如果方差为 0 ，说明这一维特征没有任务区分性，可以直接删掉．\n白化 白化（Whitening）是一种重要的预处理方法，用来降低输入数据特征之间的冗余性。输入数据经过白化处理后，特征之间相关性较低，并且所有特征具有相同的方差．\n\n白化的一个主要实现方式是使用主成分分析（Principal Component Analy－ sis，PCA）方法去除掉各个成分之间的相关性。\n\n图7．10给出了标准归一化和 PCA 白化的比较．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-186.jpg?height=327&width=1063&top_left_y=1472&top_left_x=124)\n\n图7．10标准归一化和PCA白化",
        "总结": "- 数据预处理的概念：数据预处理是为了消除不同特征之间的相关性，并将各个维度的特征归一化到同一个取值区间，以提高机器学习方法的性能和神经网络的训练效率。  \n- 欧氏距离的问题：不同样本之间的欧氏距离计算中，取值范围大的特征会主导结果，影响基于相似度比较的机器学习方法的效果。  \n- 神经网络的参数调整问题：神经网络虽然可以适应不同特征的取值范围，但会导致训练效率低下。  \n- 梯度问题：特征取值范围差异大时，梯度下降法的效率受到影响，导致收敛速度慢。  \n- 归一化的作用：归一化可以使得梯度方向更接近最优搜索方向，从而提高训练效率。  \n- 缩放归一化方法：通过缩放将特征归一到 [0,1] 或 [-1,1] 区间，公式为 $\\hat{x}^{(n)} = \\frac{x^{(n)} - \\min(x)}{\\max(x) - \\min(x)}$。  \n- 标准归一化方法（Z-score）：调整每个特征为均值为 0、方差为 1，公式为 $\\hat{x}^{(n)} = \\frac{x^{(n)} - \\mu}{\\sigma}$。  \n- 白化（Whitening）：降低输入数据特征之间的冗余性，使特征之间相关性较低且方差相同，常用 PCA 方法实现。"
      },
      {
        "段落": "## 7.5 逐层归一化\n\n在深度神经网络中，中间某一层的输入是其之前的神经层的输出。因此，其之前的神经层的参数变化会导致其输入的分布发生较大的差异。在使用随机梯度 https：／／nndl．github．io／\n\n下降来训练网络时，每次参数更新都会导致网络中间每一层的输入的分布发生改变。越深的层，其输入的分布会改变得越明显。就像一栋高楼，低楼层发生一个较小的偏移，都会导致高楼层较大的偏移。\n\n从机器学习角度来看，如果某个神经层的输入分布发生了改变，那么其参数需要重新学习，这种现象叫做内部协变量偏移（Internal Covariate Shift）。",
        "总结": "- 逐层归一化是为了解决深度神经网络中内部协变量偏移的问题。  \n- 内部协变量偏移指的是神经网络中某一层的输入分布因前面层参数的变化而发生改变的现象。  \n- 这种现象会导致深层网络的训练变得困难，因为深层的输入分布变化更显著。  \n- 逐层归一化旨在通过规范化每一层的输入分布，减少这种偏移，从而提升训练效率和模型性能。"
      },
      {
        "段落": "## 机器学习小知识 1 协变量偏移\n\n在传统机器学习中，一个常见的问题是协变量偏移（Covariate Shift）．协变量是一个统计学概念，是可能影响预测结果的统计变量．在机器学习中，协变量可以看作是输入。一般的机器学习算法都要求输入在训练集和测试集上的分布是相似的。如果不满足这个假设，在训练集上学习到的模型在测试集上的表现会比较差。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-187.jpg?height=538&width=620&top_left_y=779&top_left_x=339)\n\n为了解决内部协变量偏移问题，就要使得每一个神经层的输入的分布在训练过程中保持一致。最简单直接的方法就是对每一个神经层都进行归一化操作，使其分布保存稳定。下面介绍几种比较常用的逐层归一化方法：批量归一化、层归一化和其他一些方法。",
        "总结": "- 协变量偏移是指训练集和测试集上的输入分布不一致，导致模型在测试集上表现不佳的问题。  \n- 协变量可以视为影响预测结果的输入变量，传统机器学习假设训练集和测试集的输入分布相似。  \n- 解决内部协变量偏移的方法是保持每个神经层输入分布的稳定。  \n- 常见的逐层归一化方法包括批量归一化、层归一化以及其他方法。"
      },
      {
        "段落": "## 7．5．1 批量归一化\n\n批量归一化（Batch Normalization，BN）方法［Ioffe et al．，2015］是一种有效的逐层归一化方法，可以对神经网络中任意的中间层进行归一化操作。\n\n对于一个深度神经网络，令第 $l$ 层的净输入为 $\\boldsymbol{z}^{(l)}$ ，神经元的输出为 $\\boldsymbol{a}^{(l)}$ ，即\n\n$$\n\\begin{equation*}\n\\boldsymbol{a}^{(l)}=f\\left(\\boldsymbol{z}^{(l)}\\right)=f\\left(\\boldsymbol{W} \\boldsymbol{a}^{(l-1)}+\\boldsymbol{b}\\right), \\tag{7.51}\n\\end{equation*}\n$$\n\n其中 $f(\\cdot)$ 是激活函数， $\\boldsymbol{W}$ 和 $\\boldsymbol{b}$ 是可学习的参数．\n\n这里的逐层归一化方法是指可以应用在深度神经网络中的任何一个中间层。实际上并不需要对所有层进行归一化。\n\n协变量偏移参见第 10．4．2节．\n\n为了减少内部协变量偏移问题，就要使得净输入 $\\boldsymbol{z}^{(l)}$ 的分布一致，比如都归一化到标准正态分布。虽然归一化操作可以应用在输入 $\\boldsymbol{a}^{(l-1)}$ 上，但其分布性质不如 $\\boldsymbol{z}^{(l)}$ 稳定。因此，在实践中归一化操作一般应用在仿射变换之后，激活函数之前。\n\n利用第7．4节中介绍的数据预处理方法对 $\\boldsymbol{z}^{(l)}$ 进行归一化，相当于每一层都进行一次数据预处理，从而加速收敛速度。但是逐层归一化需要在中间层进行操作，要求效率比较高，因此复杂度比较高的白化方法就不太合适。为了提高归一化效率，一般使用标准归一化，将净输入 $\\boldsymbol{z}^{(l)}$ 的每一维都归一到标准正态分布。\n\n$$\n\\begin{equation*}\n\\hat{\\boldsymbol{z}}^{(l)}=\\frac{\\boldsymbol{z}^{(l)}-\\mathbb{E}\\left[\\boldsymbol{z}^{(l)}\\right]}{\\sqrt{\\operatorname{var}\\left(\\boldsymbol{z}^{(l)}\\right)+\\epsilon}} \\tag{7.52}\n\\end{equation*}\n$$\n\n其中 $\\mathbb{E}\\left[\\boldsymbol{z}^{(l)}\\right]$ 和 $\\operatorname{var}\\left(\\boldsymbol{z}^{(l)}\\right)$ 是指当前参数下， $\\boldsymbol{z}^{(l)}$ 的每一维在整个训练集上的期望和方差。因为目前主要的训练方法是基于小批量的随机梯度下降法，所以准确地计算 $\\boldsymbol{z}^{(l)}$ 的期望和方差是不可行的。因此， $\\boldsymbol{z}^{(l)}$ 的期望和方差通常用当前小批量样本集的均值和方差近似估计。\n\n给定一个包含 $K$ 个样本的小批量样本集合，第 $l$ 层神经元的净输入 $\\boldsymbol{z}^{(1, l)}$ ， $\\cdots, \\boldsymbol{z}^{(K, l)}$ 的均值和方差为\n\n$$\n\\begin{align*}\n\\mu_{\\mathcal{B}} & =\\frac{1}{K} \\sum_{k=1}^{K} \\boldsymbol{z}^{(k, l)}  \\tag{7.53}\\\\\n\\sigma_{\\mathcal{B}}^{2} & =\\frac{1}{K} \\sum_{k=1}^{K}\\left(\\boldsymbol{z}^{(k, l)}-\\mu_{\\mathcal{B}}\\right) \\odot\\left(\\boldsymbol{z}^{(k, l)}-\\mu_{\\mathcal{B}}\\right) \\tag{7.54}\n\\end{align*}\n$$\n\n对净输入 $\\boldsymbol{z}^{(l)}$ 的标准归一化会使得其取值集中到 0 附近，如果使用 sigmoid型激活函数时，这个取值区间刚好是接近线性变换的区间，减弱了神经网络的非线性性质。因此，为了使得归一化不对网络的表示能力造成负面影响，可以通过一个附加的缩放和平移变换改变取值区间。\n\n$$\n\\begin{align*}\n\\hat{\\boldsymbol{z}}^{(l)} & =\\frac{\\boldsymbol{z}^{(l)}-\\boldsymbol{\\mu}_{\\mathcal{B}}}{\\sqrt{\\sigma_{\\mathcal{B}}^{2}+\\epsilon}} \\odot \\boldsymbol{\\gamma}+\\boldsymbol{\\beta}  \\tag{7.55}\\\\\n& \\triangleq \\mathrm{BN}_{\\boldsymbol{\\gamma}, \\boldsymbol{\\beta}}\\left(\\boldsymbol{z}^{(l)}\\right) \\tag{7.56}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{\\gamma}$ 和 $\\boldsymbol{\\beta}$ 分别代表缩放和平移的参数向量。从最保守的角度考虑，可以通过标准归一化的逆变换来使得归一化后的变量可以被还原为原来的值。当 $\\gamma=\\sqrt{\\sigma_{\\mathcal{B}}^{2}}$ ， $\\beta=\\mu_{\\mathcal{B}}$ 时，$\\hat{\\boldsymbol{z}}^{(l)}=\\boldsymbol{z}^{(l)}$ 。\n\n批量归一化操作可以看作是一个特殊的神经层，加在每一层非线性激活函数之前，即\n\n$$\n\\begin{equation*}\n\\boldsymbol{a}^{(l)}=f\\left(\\mathrm{BN}_{\\gamma, \\beta}\\left(\\boldsymbol{z}^{(l)}\\right)\\right)=f\\left(\\mathrm{BN}_{\\gamma, \\beta}\\left(\\boldsymbol{W} \\boldsymbol{a}^{(l-1)}\\right)\\right), \\tag{7.57}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n其中因为批量归一化本身具有平移变换，所以仿射变换 $\\boldsymbol{W} \\boldsymbol{a}^{(l-1)}$ 不再需要偏置参数．\n\n这里要注意的是，每次小批量样本的 $\\mu_{\\mathcal{B}}$ 和方差 $\\sigma_{\\mathcal{B}}^{2}$ 是净输入 $\\boldsymbol{z}^{(l)}$ 的函数，而不是常量。因此在计算参数梯度时需要考虑 $\\mu_{\\mathcal{B}}$ 和 $\\sigma_{\\mathcal{B}}^{2}$ 的影响。当训练完成时，用整个数据集上的均值 $\\mu$ 和方差 $\\sigma$ 来分别代替每次小批量样本的 $\\mu_{\\mathcal{B}}$ 和方差 $\\sigma_{\\mathcal{B}}^{2}$ 。在实践中，$\\mu_{\\mathcal{B}}$ 和 $\\sigma_{\\mathcal{B}}^{2}$ 也可以用移动平均来计算。",
        "总结": "- 批量归一化（Batch Normalization，BN）是一种逐层归一化方法，用于对神经网络的中间层进行归一化操作。\n- BN的目标是使净输入 $\\boldsymbol{z}^{(l)}$ 的分布一致，通常归一化到标准正态分布。\n- 归一化操作一般应用在仿射变换之后、激活函数之前，以提高效率。\n- 标准归一化公式为 $\\hat{\\boldsymbol{z}}^{(l)}=\\frac{\\boldsymbol{z}^{(l)}-\\mathbb{E}\\left[\\boldsymbol{z}^{(l)}\\right]}{\\sqrt{\\operatorname{var}\\left(\\boldsymbol{z}^{(l)}\\right)+\\epsilon}}$，其中期望和方差用当前小批量样本近似估计。\n- 小批量样本的均值和方差分别计算为 $\\mu_{\\mathcal{B}} = \\frac{1}{K} \\sum_{k=1}^{K} \\boldsymbol{z}^{(k, l)}$ 和 $\\sigma_{\\mathcal{B}}^{2} = \\frac{1}{K} \\sum_{k=1}^{K}\\left(\\boldsymbol{z}^{(k, l)}-\\mu_{\\mathcal{B}}\\right) \\odot\\left(\\boldsymbol{z}^{(k, l)}-\\mu_{\\mathcal{B}}\\right)$。\n- 为了保持网络的表示能力，BN引入了缩放和平移参数 $\\boldsymbol{\\gamma}$ 和 $\\boldsymbol{\\beta}$，公式为 $\\hat{\\boldsymbol{z}}^{(l)} = \\frac{\\boldsymbol{z}^{(l)}-\\boldsymbol{\\mu}_{\\mathcal{B}}}{\\sqrt{\\sigma_{\\mathcal{B}}^{2}+\\epsilon}} \\odot \\boldsymbol{\\gamma}+\\boldsymbol{\\beta}$。\n- 批量归一化操作作为特殊的神经层，加在非线性激活函数之前，即 $\\boldsymbol{a}^{(l)}=f\\left(\\mathrm{BN}_{\\gamma, \\beta}\\left(\\boldsymbol{z}^{(l)}\\right)\\right)$。\n- 在训练过程中，$\\mu_{\\mathcal{B}}$ 和 $\\sigma_{\\mathcal{B}}^{2}$ 是小批量样本的函数而非常量，在计算梯度时需考虑其影响。\n- 训练完成后，用整个数据集的均值和方差替代小批量样本的统计量，并可通过移动平均计算。"
      },
      {
        "段落": "## 7．5．2 层归一化\n\n批量归一化是对一个中间层的单个神经元进行归一化操作，因此要求小批量样本的数量不能太小，否则难以计算单个神经元的统计信息。此外，如果一个神经元的净输入的分布在神经网络中是动态变化的，比如循环神经网络，那么就无法应用批量归一化操作。\n\n层归一化（Layer Normalization）［Ba et al．，2016］是和批量归一化非常类似的方法．和批量归一化不同的是，层归一化是对一个中间层的所有神经元进行归一化。\n\n对于一个深度神经网络，令第 $l$ 层神经元的净输入为 $\\boldsymbol{z}^{(l)}$ ，其均值和方差为\n\n$$\n\\begin{align*}\n\\mu^{(l)} & =\\frac{1}{M_{l}} \\sum_{i=1}^{M_{l}} z_{i}^{(l)}  \\tag{7.58}\\\\\n\\sigma^{(l)^{2}} & =\\frac{1}{M_{l}} \\sum_{i=1}^{M_{l}}\\left(z_{i}^{(l)}-\\mu^{(l)}\\right)^{2} \\tag{7.59}\n\\end{align*}\n$$\n\n其中 $M_{l}$ 为第 $l$ 层神经元的数量．\n层归一化定义为\n\n$$\n\\begin{align*}\n\\hat{\\boldsymbol{z}}^{(l)} & =\\frac{\\boldsymbol{z}^{(l)}-\\mu^{(l)}}{\\sqrt{\\sigma^{(l)^{2}}+\\epsilon}} \\odot \\boldsymbol{\\gamma}+\\boldsymbol{\\beta}  \\tag{7.60}\\\\\n& \\triangleq \\operatorname{LN}_{\\boldsymbol{\\gamma}, \\boldsymbol{\\beta}}\\left(\\boldsymbol{z}^{(l)}\\right) \\tag{7.61}\n\\end{align*}\n$$\n\n其中 $\\gamma$ 和 $\\beta$ 分别代表缩放和平移的参数向量，和 $\\boldsymbol{z}^{(l)}$ 维数相同．\n循环神经网络中的层归一化 层归一化可以应用在循环神经网络中，对循环神经层进行归一化操作。假设在时刻 $t$ ，循环神经网络的隐藏层为 $\\boldsymbol{h}_{t}$ ，其层归一化的更新为\n\n参见习题 7－6．\n\n参见公式（6．6）．\n\n$$\n\\begin{align*}\n\\boldsymbol{z}_{t} & =\\boldsymbol{U} \\boldsymbol{h}_{t-1}+\\boldsymbol{W} \\boldsymbol{x}_{t}  \\tag{7.62}\\\\\n\\boldsymbol{h}_{t} & =f\\left(\\operatorname{LN}_{\\gamma, \\beta}\\left(\\boldsymbol{z}_{t}\\right)\\right) \\tag{7.63}\n\\end{align*}\n$$\n\n其中输入为 $\\boldsymbol{x}_{t}$ 为第 $t$ 时刻的输入，$U$ 和 $\\boldsymbol{W}$ 为网络参数．\nhttps：／／nndl．github．io／\n\n在标准循环神经网络中，循环神经层的净输入一般会随着时间慢慢变大或变小，从而导致梯度爆炸或消失。而层归一化的循环神经网络可以有效地缓解这种状况。\n\n层归一化和批量归一化整体上是十分类似的，差别在于归一化的方法不同。对于 $K$ 个样本的一个小批量集合 $\\boldsymbol{Z}^{(l)}=\\left[\\boldsymbol{z}^{(1, l)} ; \\cdots ; \\boldsymbol{z}^{(K, l)}\\right]$ ，层归一化是对矩阵 $\\boldsymbol{Z}^{(l)}$的每一列进行归一化，而批量归一化是对每一行进行归一化。一般而言，批量归一化是一种更好的选择．当小批量样本数量比较小时，可以选择层归一化．",
        "总结": "- 层归一化是一种与批量归一化类似的方法，但其对一个中间层的所有神经元进行归一化，而不是单个神经元。  \n- 层归一化的计算公式为：$\\hat{\\boldsymbol{z}}^{(l)} = \\frac{\\boldsymbol{z}^{(l)} - \\mu^{(l)}}{\\sqrt{\\sigma^{(l)^2} + \\epsilon}} \\odot \\boldsymbol{\\gamma} + \\boldsymbol{\\beta}$，其中 $\\mu^{(l)}$ 和 $\\sigma^{(l)^2}$ 分别为第 $l$ 层神经元的均值和方差，$\\gamma$ 和 $\\beta$ 为可学习的缩放和平移参数。  \n- 层归一化可以应用于循环神经网络（RNN），在每个时间步对隐藏层进行归一化处理。  \n- 在RNN中，层归一化有助于缓解梯度爆炸或消失的问题，因为其能够稳定隐藏层的激活分布。  \n- 层归一化与批量归一化的区别在于：层归一化对矩阵的每一列进行归一化，而批量归一化对每一行进行归一化。  \n- 当小批量样本数量较小时，层归一化通常是一个更好的选择。"
      },
      {
        "段落": "## 7．5．3 其他归一化方法\n\n除了上述两种归一化方法外，也有一些其他的归一化方法．",
        "总结": "- 提出了除了之前提到的两种归一化方法之外，还存在其他归一化方法。  \n- 这些方法可能包括不同的归一化技术，用于处理数据的不同需求和场景。  \n- 文中未具体说明这些其他归一化方法的名称或详细内容。"
      },
      {
        "段落": "### 7．5．3．1 权重归一化\n\n权重归一化（Weight Normalization）［Salimans et al．，2016］是对神经网络的连接权重进行归一化，通过再参数化（Reparameterization）方法，将连接权重分解为长度和方向两种参数。假设第 $l$ 层神经元 $\\boldsymbol{a}^{(l)}=f\\left(\\boldsymbol{W} \\boldsymbol{a}^{(l-1)}+\\boldsymbol{b}\\right)$ ，我们将 $\\boldsymbol{W}$再参数化为\n\n$$\n\\begin{equation*}\n\\boldsymbol{W}_{i,:}=\\frac{g_{i}}{\\left\\|\\boldsymbol{v}_{i}\\right\\|} \\boldsymbol{v}_{i}, \\quad 1 \\leq i \\leq M_{l} \\tag{7.64}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{W}_{i,:}$ 表示权重 $\\boldsymbol{W}$ 的第 $i$ 行，$M_{l}$ 为神经元数量。新引入的参数 $g_{i}$ 为标量， $\\boldsymbol{v}_{i}$ 和 $\\boldsymbol{a}^{(l-1)}$ 维数相同．\n\n由于在神经网络中权重经常是共享的，权重数量往往比神经元数量要少，因此权重归一化的开销会比较小。",
        "总结": "- 权重归一化是对神经网络的连接权重进行归一化，通过再参数化方法将权重分解为长度和方向两种参数。  \n- 权重 $ \\boldsymbol{W} $ 被再参数化为 $ \\boldsymbol{W}_{i,:} = \\frac{g_{i}}{\\|\\boldsymbol{v}_{i}\\|} \\boldsymbol{v}_{i} $，其中 $ g_{i} $ 是标量，$ \\boldsymbol{v}_{i} $ 与输入 $ \\boldsymbol{a}^{(l-1)} $ 维数相同。  \n- 权重归一化减少了权重数量，从而降低了计算开销，尤其适用于权重共享的神经网络。"
      },
      {
        "段落": "### 7．5．3．2 局部响应归一化\n\n局部响应归一化（Local Response Normalization，LRN）［Krizhevsky et al．， 2012］是一种受生物学启发的归一化方法，通常用在基于卷积的图像处理上．\n\n假设一个卷积层的输出特征映射 $\\mathbf{Y} \\in \\mathbb{R}^{M^{\\prime} \\times N^{\\prime} \\times P}$ 为三维张量，其中每个切片矩阵 $Y^{p} \\in \\mathbb{R}^{M^{\\prime} \\times N^{\\prime}}$ 为一个输出特征映射， $1 \\leq p \\leq P$ 。\n\n参见公式（5．23）。\n局部响应归一化是对邻近的特征映射进行局部归一化．\n\n$$\n\\begin{align*}\n\\hat{Y}^{p} & =Y^{p} /\\left(k+\\alpha \\sum_{j=\\max \\left(1, p-\\frac{n}{2}\\right)}^{\\min \\left(P, p+\\frac{n}{2}\\right)}\\left(Y^{j}\\right)^{2}\\right)^{\\beta}  \\tag{7.65}\\\\\n& \\triangleq \\operatorname{LRN}_{n, k, \\alpha, \\beta}\\left(Y^{p}\\right) \\tag{7.66}\n\\end{align*}\n$$\n\n其中除和幂运算都是按元素运算，$n, k, \\alpha, \\beta$ 为超参，$n$ 为局部归一化的特征窗口大小．在 AlexNet 中，这些超参的取值为 $n=5, k=2, \\alpha=10 \\mathrm{e}^{-4}, \\beta=0.75$ ．\nhttps：／／nndl．github．io／\n\n局部响应归一化和层归一化都是对同层的神经元进行归一化。不同的是，局部响应归一化应用在激活函数之后，只是对邻近的神经元进行局部归一化，并且不减去均值．\n\n局部响应归一化和生物神经元中的侧抑制（lateral inhibition）现象比较类似，即活跃神经元对相邻神经元具有抑制作用。当使用 ReLU作为激活函数时，神经元的活性值是没有限制的，局部响应归一化可以起到平衡和约束作用。如果一个神经元的活性值非常大，那么和它邻近的神经元就近似地归一化为 0 ，从而起到抑制作用，增强模型的泛化能力。最大汇聚也具有侧抑制作用。但最大汇聚是对同一个特征映射中的邻近位置中的神经元进行抑制，而局部响应归一化是对同一个位置的邻近特征映射中的神经元进行抑制。\n\n上述的归一化方法可以根据需要应用在神经网络的中间层，从而减少前面网络参数更新对后面网络输入带来的内部协变量偏移问题，提高深度神经网络的训练效率。同时，归一化方法也可以作为一种有效的正则化方法，从而提高网络的泛化能力，避免过拟合。",
        "总结": "- 局部响应归一化（LRN）是一种受生物学启发的归一化方法，用于卷积神经网络中，对邻近特征映射进行局部归一化。  \n- LRN的公式为：$\\hat{Y}^{p} = Y^{p} / \\left(k + \\alpha \\sum_{j=\\max(1, p-\\frac{n}{2})}^{\\min(P, p+\\frac{n}{2})}(Y^{j})^2\\right)^{\\beta}$，其中 $n, k, \\alpha, \\beta$ 是超参数。  \n- 在AlexNet中，超参数取值为 $n=5, k=2, \\alpha=10^{-4}, \\beta=0.75$。  \n- LRN与层归一化不同，它应用在激活函数之后，仅对邻近神经元进行局部归一化，并不减去均值。  \n- LRN类似于生物神经元中的侧抑制现象，活跃神经元会抑制邻近神经元的活性，增强模型泛化能力。  \n- 当使用ReLU作为激活函数时，LRN可以限制神经元的活性值，防止过大值导致的问题。  \n- LRN可用于中间层以减少内部协变量偏移，提高训练效率，并作为一种正则化方法以避免过拟合。"
      },
      {
        "段落": "## 7.6 超参数优化\n\n在神经网络中，除了可学习的参数之外，还存在很多超参数。这些超参数对网络性能的影响也很大．不同的机器学习任务往往需要不同的超参数．常见的超参数有以下三类：\n（1）网络结构，包括神经元之间的连接关系、层数、每层的神经元数量、激活函数的类型等。\n（2）优化参数，包括优化方法、学习率、小批量的样本数量等。\n（3）正则化系数．\n\n超参数优化（Hyperparameter Optimization）主要存在两方面的困难。（1）超参数优化是一个组合优化问题，无法像一般参数那样通过梯度下降方法来优化，也没有一种通用有效的优化方法。（2）评估一组超参数配置（Configura－ tion）的时间代价非常高，从而导致一些优化方法（比如演化算法（Evolution Algorithm））在超参数优化中难以应用。\n\n假设一个神经网络中总共有 $K$ 个超参数，每个超参数配置表示为一个向量 $x \\in X, X \\subset \\mathbb{R}^{K}$ 是超参数配置的取值空间．超参数优化的目标函数定义为 $f(\\boldsymbol{x}): \\mathcal{X} \\rightarrow \\mathbb{R}, f(\\boldsymbol{x})$ 是衡量一组超参数配置 $\\boldsymbol{x}$ 效果的函数，一般设置为开发集上的错误率。目标函数 $f(\\boldsymbol{x})$ 可以看作是一个黑盒（black－box）函数，不需要知道其具体形式。虽然在神经网络的超参数优化中，$f(\\boldsymbol{x})$ 的函数形式已知，但 $f(\\boldsymbol{x})$ 不是\n\n邻近的神经元指对应同样位置的邻近特征映射。\n\n关于 $\\boldsymbol{x}$ 的连续函数，并且 $\\boldsymbol{x}$ 不同，$f(\\boldsymbol{x})$ 的函数形式也不同，因此无法使用梯度下降等优化方法。\n\n对于超参数的配置，比较简单的方法有网格搜索、随机搜索、贝叶斯优化、动态资源分配和神经架构搜索。",
        "总结": "- 超参数优化是指调整神经网络中非可学习的超参数以提升模型性能的过程。  \n- 超参数分为三类：网络结构、优化参数和正则化系数。  \n- 超参数优化面临两大困难：组合优化问题无法用梯度下降解决，以及评估配置成本高。  \n- 目标函数 $f(\\boldsymbol{x})$ 是衡量超参数配置效果的函数，通常为开发集错误率。  \n- $f(\\boldsymbol{x})$ 被视为黑盒函数，其形式未知且非连续，难以用传统优化方法处理。  \n- 常见的超参数优化方法包括网格搜索、随机搜索、贝叶斯优化、动态资源分配和神经架构搜索。"
      },
      {
        "段落": "## 7．6．1 网格搜索\n\n网格搜索（Grid Search）是一种通过尝试所有超参数的组合来寻址合适一组超参数配置的方法。假设总共有 $K$ 个超参数，第 $k$ 个超参数的可以取 $m_{k}$ 个值。那么总共的配置组合数量为 $m_{1} \\times m_{2} \\times \\cdots \\times m_{K}$ 。如果超参数是连续的，可以将超参数离散化，选择几个＂经验＂值．比如学习率 $\\alpha$ ，我们可以设置\n\n$$\n\\alpha \\in\\{0.01,0.1,0.5,1.0\\}\n$$\n\n一般而言，对于连续的超参数，我们不能按等间隔的方式进行离散化，需要根据超参数自身的特点进行离散化．\n\n网格搜索根据这些超参数的不同组合分别训练一个模型，然后测试这些模型在开发集上的性能，选取一组性能最好的配置。",
        "总结": "- 网格搜索是一种通过尝试所有超参数组合来寻找最优超参数配置的方法  \n- 若有 $K$ 个超参数，第 $k$ 个超参数有 $m_k$ 个取值，则总共有 $m_1 \\times m_2 \\times \\cdots \\times m_K$ 种配置组合  \n- 对于连续超参数，需将其离散化，例如学习率 $\\alpha$ 可设置为 $\\{0.01, 0.1, 0.5, 1.0\\}$  \n- 离散化连续超参数时，应根据其自身特点而非等间隔方式选择值  \n- 网格搜索通过训练不同超参数组合的模型，并在开发集上测试性能，选择表现最好的配置"
      },
      {
        "段落": "## 7．6．2 随机搜索\n\n不同超参数对模型性能的影响有很大差异。有些超参数（比如正则化系数）对模型性能的影响有限，而另一些超参数（比如学习率）对模型性能影响比较大。在这种情况下，采用网格搜索会在不重要的超参数上进行不必要的尝试。一种在实践中比较有效的改进方法是对超参数进行随机组合，然后选取一个性能最好的配置，这就是随机搜索（Random Search）［Bergstra et al．，2012］．随机搜索在实践中更容易实现，一般会比网格搜索更加有效。\n\n网格搜索和随机搜索都没有利用不同超参数组合之间的相关性，即如果模型的超参数组合比较类似，其模型性能也是比较接近的。因此这两种搜索方式一般都比较低效。下面我们介绍两种自适应的超参数优化方法：贝叶斯优化和动态资源分配。",
        "总结": "- 随机搜索是一种通过随机组合超参数并选择性能最好的配置来优化模型的算法。  \n- 与网格搜索相比，随机搜索在实践中更容易实现，并且通常更有效。  \n- 随机搜索和网格搜索均未利用超参数组合之间的相关性，因此效率较低。  \n- 文中提出贝叶斯优化和动态资源分配作为两种自适应的超参数优化方法。"
      },
      {
        "段落": "## 7．6．3 贝叶斯优化\n\n贝叶斯优化（Bayesian optimization）［Bergstra et al．，2011；Snoek et al．， 2012］是一种自适应的超参数优化方法，根据当前已经试验的超参数组合，来预测下一个可能带来最大收益的组合。\n\n一种比较常用的贝叶斯优化方法为时序模型优化（Sequential Model－Based Optimization，SMBO ）［Hutter et al．，2011］．假设超参数优化的函数 $f(\\boldsymbol{x})$ 服从高 https：／／nndl．github．io／\n\n斯过程，则 $p(f(\\boldsymbol{x}) \\mid \\boldsymbol{x})$ 为一个正态分布．贝叶斯优化过程是根据已有的 $N$ 组试验结果 $\\mathcal{H}=\\left\\{\\boldsymbol{x}_{n}, y_{n}\\right\\}_{n=1}^{N}$（ $y_{n}$ 为 $f\\left(\\boldsymbol{x}_{n}\\right)$ 的观测值）来建模高斯过程，并计算 $f(\\boldsymbol{x})$ 的后验分布 $p_{\\mathcal{G P}}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$ 。\n\n为了使得 $p_{\\mathcal{G P}}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$ 接近其真实分布，就需要对样本空间进行足够多的采样。但是超参数优化中每一个样本的生成成本很高，需要用尽可能少的样本来使得 $p_{\\theta}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$ 接近于真实分布。因此，需要通过定义一个收益函数 （Acquisition Function）$a(x, \\mathcal{H})$ 来判断一个样本是否能够给建模 $p_{\\theta}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$提供更多的收益．收益越大，其修正的高斯过程会越接近目标函数的真实分布．\n\n收益函数的定义有很多种方式．一个常用的是期望改善（Expected Improve－ ment，EI）函数。假设 $y^{*}=\\min \\left\\{y_{n}, 1 \\leq n \\leq N\\right\\}$ 是当前已有样本中的最优值，期望改善函数为，\n\n$$\n\\begin{equation*}\n\\mathbf{E I}(\\boldsymbol{x}, \\mathcal{H})=\\int_{-\\infty}^{\\infty} \\max \\left(y^{*}-y, 0\\right) p_{\\mathcal{G P}}(y \\mid \\boldsymbol{x}, \\mathcal{H}) \\mathrm{d} y \\tag{7.67}\n\\end{equation*}\n$$\n\n期望改善是定义一个样本 $\\boldsymbol{x}$ 在当前模型 $p_{\\mathcal{G P}}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$ 下，$f(\\boldsymbol{x})$ 超过最好结果 $y^{*}$ 的期望．除了期望改善函数之外，收益函数还有其他定义形式，比如改善概率（Probability of Improvement）、高斯过程置信上界（GP Upper Confidence Bound，GP－UCB）等。\n\n时序模型优化方法如算法7．1所示．\n\n```\n算法 7.1: 时序模型优化 (SMBO) 方法\n        输入: 优化目标函数 $f(\\boldsymbol{x})$, 迭代次数 $T$, 收益函数 $a(x, \\mathcal{H})$\n    $\\mathcal{H} \\leftarrow \\varnothing$;\n    随机初始化高斯过程, 并计算 $p_{g \\mathcal{P}}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$;\n    for $t \\leftarrow 1$ to $T$ do\n        $\\boldsymbol{x}^{\\prime} \\leftarrow \\arg \\max _{x} a(x, \\mathcal{H}) ;$\n        评价 $y^{\\prime}=f\\left(\\boldsymbol{x}^{\\prime}\\right)$; // 代价高\n        $\\mathcal{H} \\leftarrow \\mathcal{H} \\cup\\left(\\boldsymbol{x}^{\\prime}, y^{\\prime}\\right)$;\n        根据 $\\mathcal{H}$ 重新建模高斯过程, 并计算 $p_{\\mathcal{G P}}(f(\\boldsymbol{x}) \\mid \\boldsymbol{x}, \\mathcal{H})$;\n    end\n    输出: $\\mathcal{H}$\n```\n\n贝叶斯优化的一个缺点是高斯过程建模需要计算协方差矩阵的逆，时间复杂度是 $O\\left(N^{3}\\right)$ ，因此不能很好地处理高维情况。深度神经网络的超参数一般比较多，为了使用贝叶斯优化来搜索神经网络的超参数，需要一些更高效的高斯过程建模．也有一些方法可以将时间复杂度从 $O\\left(N^{3}\\right)$ 降低到 $O(N)[S n o e k ~ e t ~ a l ., ~ 2015]$ ．\n\n高斯过程参见第 D．3．2节。",
        "总结": "- 贝叶斯优化是一种自适应的超参数优化方法，根据已试验的超参数组合预测下一个可能带来最大收益的组合。  \n- 时序模型优化（SMBO）是常用的贝叶斯优化方法，假设目标函数服从高斯过程，通过建模高斯过程并计算后验分布来优化。  \n- 收益函数（Acquisition Function）用于判断样本是否能为建模提供更多信息，期望改善（EI）是常用的收益函数定义方式。  \n- 期望改善函数计算样本在当前模型下超过当前最优值的期望收益。  \n- SMBO算法通过迭代选择收益最大的样本进行评估，并更新高斯过程模型。  \n- 贝叶斯优化的缺点是高斯过程建模时间复杂度为 $O(N^3)$，难以处理高维问题。  \n- 有方法可将时间复杂度降低到 $O(N)$，以提高效率。  \n- 高斯过程的详细内容可参考第 D．3．2 节。"
      },
      {
        "段落": "## 7．6．4 动态资源分配\n\n在超参数优化中，每组超参数配置的评估代价比较高。如果我们可以在较早的阶段就估计出一组配置的效果会比较差，那么我们就可以中止这组配置的评估，将更多的资源留给其他配置。这个问题可以归结为多臂赌博机问题的一个泛化问题：最优臂问题（Best－Arm Problem），即在给定有限的机会次数下，如何玩\n\n多臂赌博机问题参见第14．1．1节。这些赌博机并找到收益最大的臂。和多臂赌博机问题类似，最优臂问题也是在利用和探索之间找到最佳的平衡．\n\n由于目前神经网络的优化方法一般都采取随机梯度下降，因此我们可以通过一组超参数的学习曲线来预估这组超参数配置是否有希望得到比较好的结果。如果一组超参数配置的学习曲线不收玫或者收敛比较差，我们可以应用早期停止 （Early－Stopping）策略来中止当前的训练。\n\n动态资源分配的关键是将有限的资源分配给更有可能带来收益的超参数组合。一种有效方法是逐次减半（Successive Halving）方法［Jamieson et al．，2016］，将超参数优化看作是一种非随机的最优臂问题。假设要尝试 $N$ 组超参数配置，总共可利用的资源预算（摇臂的次数）为 $B$ ，我们可以通过 $T=\\left\\lceil\\log _{2}(N)\\right\\rceil-1$ 轮逐次减半的方法来选取最优的配置，具体过程如算法7．2所示．\n\n```\n算法 7.2: 一种逐次减半的动态资源分配方法\n    输入: 预算 $B, N$ 个超参数配置 $\\left\\{\\boldsymbol{x}_{n}\\right\\}_{n=1}^{N}$\n    $T \\leftarrow\\left\\lceil\\log _{2}(N)\\right\\rceil-1 ;$\n    随机初始化 $\\mathcal{S}_{0}=\\left\\{\\boldsymbol{x}_{n}\\right\\}_{n=1}^{N}$;\n    for $t \\leftarrow 1$ to $T$ do\n        $r_{t} \\leftarrow\\left\\lfloor\\frac{B}{\\left|\\mathcal{S}_{t}\\right| \\times T}\\right\\rfloor ;$\n        给 $S_{t}$ 中的每组配置分配 $r_{t}$ 的资源;\n        运行 $S_{t}$ 所有配置, 评估结果为 $\\boldsymbol{y}_{t}$;\n        根据评估结果, 选取 $\\left|S_{t}\\right| / 2$ 组最优的配置\n            $\\mathcal{S}_{t} \\leftarrow \\arg \\max \\left(\\mathcal{S}_{t}, \\boldsymbol{y}_{t},\\left|\\mathcal{S}_{t}\\right| / 2\\right) ; / / \\arg \\max (\\mathcal{S}, \\boldsymbol{y}, m)$ 为从集合 $\\mathcal{S}$ 中选取 $m$\n            个元素, 对应最优的 $m$ 个评估结果。\n    end\n    输出: 最优配置 $\\mathcal{S}_{K}$\n```\n\n在逐次减半方法中，尝试的超参数配置数量 $N$ 十分关键。如果 $N$ 越大，得到最佳配置的机会也越大，但每组配置分到的资源就越少，这样早期的评估结果可能不准确。反之，如果 $N$ 越小，每组超参数配置的评估会越准确，但有可能无法得到最优的配置。因此，如何设置 $N$ 是平衡＂利用－探索＂的一个关键因素。一种改进的方法是 HyperBand 方法［Li et al．，2017b］，通过尝试不同的 $N$ 来选取最优参数．",
        "总结": "- 概念：动态资源分配，旨在通过优化资源分配策略，在有限的计算资源下提高超参数优化的效率。\n- 算法：逐次减半（Successive Halving）方法，将超参数优化视为非随机的最优臂问题，通过多轮筛选逐步减少候选配置数量。\n- 定理或命题：动态资源分配的关键在于如何将有限资源分配给更可能带来收益的超参数组合。\n- 数学推导：算法中使用对数函数计算轮数 $T = \\left\\lceil \\log_2(N) \\right\\rceil - 1$，其中 $N$ 是超参数配置数量，以确定筛选轮次。每轮中资源分配为 $r_t = \\left\\lfloor \\frac{B}{|\\mathcal{S}_t| \\times T} \\right\\rfloor$，用于评估当前配置。"
      },
      {
        "段落": "## 7．6．5 神经架构搜索\n\n上面介绍的超参数优化方法都是在固定（或变化比较小）的超参数空间 $x$中进行最优配置搜索，而最重要的神经网络架构一般还是需要由有经验的专家来进行设计。从某种角度来讲，深度学习使得机器学习中的＂特征工程＂问题转变为 ＂网络架构工程＂问题．\n\n神经架构搜索（Neural Architecture Search，NAS）［Zoph et al．，2017］是一个新的比较有前景的研究方向，通过神经网络来自动实现网络架构的设计。一个神经网络的架构可以用一个变长的字符串来描述。利用元学习的思想，神经架构搜索利用一个控制器来生成另一个子网络的架构描述。控制器可以由一个循环神经网络来实现。控制器的训练可以通过强化学习来完成，其奖励信号为生成的子网络在开发集上的准确率。",
        "总结": "- 概念：神经架构搜索（Neural Architecture Search，NAS）是一种通过神经网络自动设计网络架构的方法。  \n- 算法：使用控制器生成子网络架构，控制器可由循环神经网络实现，通过强化学习进行训练。  \n- 定理/命题：NAS将传统特征工程问题转化为网络架构工程问题。  \n- 数学推导：未提及具体数学推导内容。"
      },
      {
        "段落": "## 7.7 网络正则化\n\n机器学习模型的关键是泛化问题，即在样本真实分布上的期望风险最小化．而训练数据集上的经验风险最小化和期望风险并不一致。由于神经网络的拟合能力非常强，其在训练数据上的错误率往往都可以降到非常低，甚至可以到 0 ，从而导致过拟合．因此，如何提高神经网络的泛化能力反而成为影响模型能力的最关键因素。\n\n正则化（Regularization）是一类通过限制模型复杂度，从而避免过拟合，提高泛化能力的方法，比如引入约束、增加先验、提前停止等。\n\n在传统的机器学习中，提高泛化能力的方法主要是限制模型复杂度，比如采用 $\\ell_{1}$ 和 $\\ell_{2}$ 正则化等方式．而在训练深度神经网络时，特别是在过度参数化 （Over－Parameterization）时，$\\ell_{1}$ 和 $\\ell_{2}$ 正则化的效果往往不如浅层机器学习模型中显著。因此训练深度学习模型时，往往还会使用其他的正则化方法，比如数据增强、提前停止、丢弃法、集成法等。",
        "总结": "- 网络正则化是通过限制模型复杂度来避免过拟合，提高泛化能力的方法  \n- 传统机器学习中常用 $\\ell_1$ 和 $\\ell_2$ 正则化来限制模型复杂度  \n- 在深度神经网络中，$\\ell_1$ 和 $\\ell_2$ 正则化效果不如浅层模型显著  \n- 深度学习中常使用数据增强、提前停止、丢弃法、集成法等其他正则化方法  \n- 过度参数化是深度学习中需要特别考虑的正则化问题"
      },
      {
        "段落": "## 7．7．1 $\\ell_{1}$ 和 $\\ell_{2}$ 正则化\n\n$\\ell_{1}$ 和 $\\ell_{2}$ 正则化是机器学习中最常用的正则化方法，通过约束参数的 $\\ell_{1}$ 和 $\\ell_{2}$范数来减小模型在训练数据集上的过拟合现象。\n\n强化学习参见第14．1节。\n\n参见第2．8．1节。\n\n过度参数化是指模型参数的数量远远大于训练数据的数量．\n\n范数参见第 A．1．3 节．\n通过加入 $\\ell_{1}$ 和 $\\ell_{2}$ 正则化，优化问题可以写为\n\n$$\n\\begin{equation*}\n\\theta^{*}=\\underset{\\theta}{\\arg \\min } \\frac{1}{N} \\sum_{n=1}^{N} \\mathcal{L}\\left(y^{(n)}, f\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)\\right)+\\lambda \\ell_{p}(\\theta) \\tag{7.68}\n\\end{equation*}\n$$\n\n其中 $\\mathcal{L}(\\cdot)$ 为损失函数，$N$ 为训练样本数量，$f(\\cdot)$ 为待学习的神经网络，$\\theta$ 为其参数， $\\ell_{p}$ 为范数函数，$p$ 的取值通常为 $\\{1,2\\}$ 代表 $\\ell_{1}$ 和 $\\ell_{2}$ 范数，$\\lambda$ 为正则化系数．\nhttps：／／nndl．github．io／\n\n带正则化的优化问题等价于下面带约束条件的优化问题，\n\n$$\n\\begin{align*}\n& \\theta^{*}=\\underset{\\theta}{\\arg \\min } \\frac{1}{N} \\sum_{n=1}^{N} \\mathcal{L}\\left(y^{(n)}, f\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)\\right),  \\tag{7.69}\\\\\n& \\text { s.t. } \\quad \\ell_{p}(\\theta) \\leq 1 . \\tag{7.70}\n\\end{align*}\n$$\n\n图7．11给出了不同范数约束条件下的最优化问题示例．红线表示函数 $\\ell_{p}=$ $1, \\mathcal{F}$ 为函数 $f(\\theta)$ 的等高线（为简单起见，这里用直线表示）。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-196.jpg?height=324&width=1161&top_left_y=579&top_left_x=73)\n\n图 7.11 不同范数约束条件下的最优化问题示例\n\n从图7．11可以看出，$\\ell_{1}$ 范数的约束通常会使得最优解位于坐标轴上，从而使得最终的参数为稀疏性向量。此外，$\\ell_{1}$ 范数在零点不可导，因此经常用下式来近似：\n\n$$\n\\begin{equation*}\n\\ell_{1}(\\theta)=\\sum_{d}^{D} \\sqrt{\\theta_{d}^{2}+\\epsilon} \\tag{7.71}\n\\end{equation*}\n$$\n\n其中 $D$ 为参数数量，$\\epsilon$ 为一个非常小的常数．\n一种折中的正则化方法是同时加入 $\\ell_{1}$ 和 $\\ell_{2}$ 正则化，称为弹性网络正则化 （Elastic Net Regularization）［Zou et al．，2005］，．\n\n$$\n\\begin{equation*}\n\\theta^{*}=\\underset{\\theta}{\\arg \\min } \\frac{1}{N} \\sum_{n=1}^{N} \\mathcal{L}\\left(y^{(n)}, f\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)\\right)+\\lambda_{1} \\ell_{1}(\\theta)+\\lambda_{2} \\ell_{2}(\\theta), \\tag{7.72}\n\\end{equation*}\n$$\n\n其中 $\\lambda_{1}$ 和 $\\lambda_{2}$ 分别为两个正则化项的系数．",
        "总结": "- $\\ell_1$ 和 $\\ell_2$ 正则化是机器学习中常用的正则化方法，通过约束参数的 $\\ell_1$ 和 $\\ell_2$ 范数来减少过拟合现象。  \n- 优化问题在加入正则化后可表示为：$\\theta^* = \\arg \\min_{\\theta} \\frac{1}{N} \\sum_{n=1}^{N} \\mathcal{L}(y^{(n)}, f(\\boldsymbol{x}^{(n)}; \\theta)) + \\lambda \\ell_p(\\theta)$，其中 $\\ell_p$ 为范数函数，$p$ 取值为 1 或 2。  \n- 带正则化的优化问题等价于带约束条件的优化问题：$\\theta^* = \\arg \\min_{\\theta} \\frac{1}{N} \\sum_{n=1}^{N} \\mathcal{L}(y^{(n)}, f(\\boldsymbol{x}^{(n)}; \\theta))$，约束条件为 $\\ell_p(\\theta) \\leq 1$。  \n- 图7.11展示了不同范数约束下的优化示例，$\\ell_1$ 范数约束通常使最优解位于坐标轴上，导致参数稀疏。  \n- $\\ell_1$ 范数在零点不可导，常用 $\\ell_1(\\theta) = \\sum_{d=1}^{D} \\sqrt{\\theta_d^2 + \\epsilon}$ 近似，其中 $\\epsilon$ 是一个很小的常数。  \n- 弹性网络正则化（Elastic Net Regularization）是同时使用 $\\ell_1$ 和 $\\ell_2$ 正则化的折中方法，其优化目标为：$\\theta^* = \\arg \\min_{\\theta} \\frac{1}{N} \\sum_{n=1}^{N} \\mathcal{L}(y^{(n)}, f(\\boldsymbol{x}^{(n)}; \\theta)) + \\lambda_1 \\ell_1(\\theta) + \\lambda_2 \\ell_2(\\theta)$。"
      },
      {
        "段落": "## 7．7．2 权重衰减\n\n权重衰减（Weight Decay）是一种有效的正则化方法［Hanson et al．，1989］，在每次参数更新时，引入一个衰减系数。\n\n$$\n\\begin{equation*}\n\\theta_{t} \\leftarrow(1-\\beta) \\theta_{t-1}-\\alpha \\mathbf{g}_{t}, \\tag{7.73}\n\\end{equation*}\n$$\n\n其中 $\\mathrm{g}_{t}$ 为第 $t$ 步更新时的梯度，$\\alpha$ 为学习率，$\\beta$ 为权重衰减系数，一般取值比较小，比如 0．0005．在标准的随机梯度下降中，权重衰减正则化和 $\\ell_{2}$ 正则化的效果相同。因此，权重衰减在一些深度学习框架中通过 $\\ell_{2}$ 正则化来实现。但是，在较为复杂的优化方法（比如 Adam）中，权重衰减和 $\\ell_{2}$ 正则化并不等价［Loshchilov et al．， 2017b］．",
        "总结": "- 权重衰减是一种有效的正则化方法，通过在参数更新时引入衰减系数来防止过拟合。  \n- 权重衰减的更新公式为：$\\theta_{t} \\leftarrow (1-\\beta) \\theta_{t-1} - \\alpha \\mathbf{g}_{t}$，其中 $\\beta$ 为衰减系数，$\\alpha$ 为学习率，$\\mathbf{g}_{t}$ 为第 $t$ 步的梯度。  \n- 在标准随机梯度下降中，权重衰减正则化与 $\\ell_2$ 正则化效果相同。  \n- 在复杂优化方法（如 Adam）中，权重衰减与 $\\ell_2$ 正则化并不等价。"
      },
      {
        "段落": "## 7．7．3 提前停止\n\n提前停止（Early Stop）对于深度神经网络来说是一种简单有效的正则化方法．由于深度神经网络的拟合能力非常强，因此比较容易在训练集上过拟合．在使用梯度下降法进行优化时，我们可以使用一个和训练集独立的样本集合，称为验证集（Validation Set），并用验证集上的错误来代替期望错误。当验证集上的错误率不再下降，就停止迭代。\n\n然而在实际操作中，验证集上的错误率变化曲线并不一定是图2．4中所示的平衡曲线，很可能是先升高再降低。因此，提前停止的具体停止标准需要根据实际任务进行优化［Prechelt，1998］．",
        "总结": "- 提出的概念：提前停止（Early Stop），作为深度神经网络的一种简单有效的正则化方法。  \n- 核心思想：通过监控验证集上的错误率来决定是否停止训练，以防止过拟合。  \n- 关键点：验证集用于代替期望错误，当验证集错误率不再下降时停止训练。  \n- 实际问题：验证集错误率变化曲线可能并非单调下降，可能先升高再降低。  \n- 建议：提前停止的具体标准需根据实际任务进行优化。"
      },
      {
        "段落": "## 7．7．4 丢弃法\n\n当训练一个深度神经网络时，我们可以随机丢弃一部分神经元（同时丢弃其对应的连接边）来避免过拟合，这种方法称为丢弃法（Dropout Method）［Sri－ vastava et al．，2014］．每次选择丢弃的神经元是随机的．最简单的方法是设置一个固定的概率 $p$ ．对每一个神经元都以概率 $p$ 来判定要不要保留。对于一个神经层 $\\boldsymbol{y}=f(\\boldsymbol{W} \\boldsymbol{x}+\\boldsymbol{b})$ ，我们可以引入一个掩蔽函数mask $(\\cdot)$ 使得 $\\boldsymbol{y}=f(\\boldsymbol{W} \\operatorname{mask}(\\boldsymbol{x})+\\boldsymbol{b})$ 。掩蔽函数 $\\operatorname{mask}(\\cdot)$ 的定义为\n\n$$\n\\operatorname{mask}(\\boldsymbol{x})= \\begin{cases}\\boldsymbol{m} \\odot \\boldsymbol{x} & \\text { 当训练阶段时 }  \\tag{7.74}\\\\ p \\boldsymbol{x} & \\text { 当测试阶段时 }\\end{cases}\n$$\n\n其中 $\\boldsymbol{m} \\in\\{0,1\\}^{D}$ 是丢弃掩码（Dropout Mask），通过以概率为 $p$ 的伯努利分布随机生成。在训练时，激活神经元的平均数量为原来的 $p$ 倍。而在测试时，所有的神经元都是可以激活的，这会造成训练和测试时网络的输出不一致。为了缓解这个问题，在测试时需要将神经层的输入 $\\boldsymbol{x}$ 乘以 $p$ ，也相当于把不同的神经网络做了平均。保留率 $p$ 可以通过验证集来选取一个最优的值。一般来讲，对于隐藏层的神经元，其保留率 $p=0.5$ 时效果最好，这对大部分的网络和任务都比较有效。当 $p=0.5$ 时，在训练时有一半的神经元被丢弃，只剩余一半的神经元是可以激活的，随机生成的网络结构最具多样性。对于输入层的神经元，其保留率通常设为更接近 1 的数，使得输入变化不会太大。对输入层神经元进行丢弃时，相当于给数据增加噪声，以此来提高网络的鲁棒性。\nhttps：／／nndl．github．io／\n\n参见习题 7－7．\n\n提前停止也可以参见第 2．2．3．2 节。\n$D$ 为输入 $\\boldsymbol{x}$ 的维度．\n\n丢弃法一般是针对神经元进行随机丢弃，但是也可以扩展到对神经元之间的连接进行随机丢弃［Wan et al．，2013］，或每一层进行随机丢弃。图7．12给出了一个网络应用丢弃法后的示例。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-198.jpg?height=463&width=830&top_left_y=334&top_left_x=249)\n\n图7．12丢弃法示例\n\n集成学习角度的解释 每做一次丢弃，相当于从原始的网络中采样得到一个子网络。如果一个神经网络有 $n$ 个神经元，那么总共可以采样出 $2^{n}$ 个子网络。每次迭代都相当于训练一个不同的子网络，这些子网络都共享原始网络的参数。那么，最终的网络可以近似看作是集成了指数级个不同网络的组合模型．\n\n贝叶斯学习角度的解释 丢弃法也可以解释为一种贝叶斯学习的近似［Gal et al．， 2016a］．用 $y=f(\\boldsymbol{x} ; \\theta)$ 来表示要学习的神经网络，贝叶斯学习是假设参数 $\\theta$ 为随机向量，并且先验分布为 $q(\\theta)$ ，贝叶斯方法的预测为\n\n$$\n\\begin{align*}\n\\mathbb{E}_{q(\\theta)}[y] & =\\int_{q} f(\\boldsymbol{x} ; \\theta) q(\\theta) d \\theta  \\tag{7.75}\\\\\n& \\approx \\frac{1}{M} \\sum_{m=1}^{M} f\\left(\\boldsymbol{x}, \\theta_{m}\\right) \\tag{7.76}\n\\end{align*}\n$$\n\n其中 $f\\left(\\boldsymbol{x}, \\theta_{m}\\right)$ 为第 $m$ 次应用丢弃方法后的网络，其参数 $\\theta_{m}$ 为对全部参数 $\\theta$ 的一次采样．",
        "总结": "- 丢弃法（Dropout Method）是一种用于训练深度神经网络以避免过拟合的技术，通过随机丢弃一部分神经元及其对应的连接边来实现。\n- 在训练阶段，每个神经元以概率 $p$ 被保留或丢弃，使用掩蔽函数 $\\operatorname{mask}(\\cdot)$ 来实现，该函数在训练时生成一个随机的二进制掩码 $\\boldsymbol{m}$，在测试时则将输入乘以 $p$。\n- 掩码 $\\boldsymbol{m}$ 是根据伯努利分布随机生成的，其维度与输入 $\\boldsymbol{x}$ 相同，用于控制神经元的保留概率。\n- 保留率 $p$ 可通过验证集选择最优值，通常对隐藏层设置为 $p=0.5$，对输入层设置为接近 1 的值。\n- 丢弃法不仅可针对神经元进行随机丢弃，也可扩展到连接边或每一层。\n- 每次应用丢弃法相当于从原始网络中采样得到一个子网络，训练过程中共享原始网络的参数。\n- 从集成学习角度解释，丢弃法可以看作是集成多个子网络的组合模型。\n- 从贝叶斯学习角度解释，丢弃法可以视为一种对参数分布的近似方法，通过多次采样参数并预测输出来实现。"
      },
      {
        "段落": "### 7．7．4．1 循环神经网络上的丢弃法\n\n当在循环神经网络上应用丢弃法时，不能直接对每个时刻的隐状态进行随机丢弃，这样会损害循环网络在时间维度上的记忆能力。一种简单的方法是对非时间维度的连接（即非循环连接）进行随机丢失［Zaremba et al．，2014］．如图7．13所示，虚线边表示进行随机丢弃，不同的颜色表示不同的丢弃掩码。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-199.jpg?height=270&width=728&top_left_y=128&top_left_x=252)\n\n图 7.13 针对非循环连接的丢弃法\n\n然而根据贝叶斯学习的解释，丢弃法是一种对参数 $\\theta$ 的采样。每次采样的参数需要在每个时刻保持不变。因此，在对循环神经网络上使用丢弃法时，需要对参数矩阵的每个元素进行随机丢弃，并在所有时刻都使用相同的丢弃掩码．这种方法称为变分丢弃法（Variational Dropout）［Gal et al．，2016b］。图7．14给出了变分丢弃法的示例，相同颜色表示使用相同的丢弃掩码。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-199.jpg?height=275&width=738&top_left_y=853&top_left_x=247)\n\n图7．14变分丢弃法",
        "总结": "- 概念：循环神经网络上的丢弃法，是一种在时间序列处理中用于防止过拟合的技术。\n- 算法：传统丢弃法不适用于循环神经网络，因其会破坏时间维度的记忆能力；提出对非时间维度的连接进行随机丢弃。\n- 算法：变分丢弃法，是一种基于贝叶斯学习的丢弃方法，通过对参数矩阵的每个元素进行随机丢弃，并在所有时刻使用相同的丢弃掩码。\n- 定理/命题：变分丢弃法在循环神经网络中保持参数一致性，从而有效防止过拟合。\n- 数学推导：未明确给出具体数学推导，但基于贝叶斯学习框架，对参数进行采样并保持其在时间维度上的不变性。"
      },
      {
        "段落": "## 7．7．5 数据增强\n\n深度神经网络一般都需要大量的训练数据才能获得比较理想的效果．在数据量有限的情况下，可以通过数据增强（Data Augmentation）来增加数据量，提高模型鲁棒性，避免过拟合．目前，数据增强还主要应用在图像数据上，在文本等其他类型的数据上还没有太好的方法。\n\n图像数据的增强主要是通过算法对图像进行转变，引入噪声等方法来增加数据的多样性．增强的方法主要有几种：\n（1）旋转（Rotation）：将图像按顺时针或逆时针方向随机旋转一定角度．\n（2）翻转（Flip）：将图像沿水平或垂直方法随机翻转一定角度。\n（3）缩放（Zoom In／Out）：将图像放大或缩小一定比例。\n（4）平移（Shift）：将图像沿水平或垂直方法平移一定步长．\n（5）加噪声（Noise）：加入随机噪声。",
        "总结": "- 数据增强（Data Augmentation）是一种通过算法对数据进行变换，以增加数据多样性、提高模型鲁棒性并避免过拟合的方法。  \n- 数据增强主要应用于图像数据，通过旋转、翻转、缩放、平移和加噪声等方法实现。  \n- 旋转：将图像按顺时针或逆时针方向随机旋转一定角度。  \n- 翻转：将图像沿水平或垂直方向随机翻转。  \n- 缩放：将图像放大或缩小一定比例。  \n- 平移：将图像沿水平或垂直方向平移一定步长。  \n- 加噪声：向图像中加入随机噪声以增强数据的多样性。"
      },
      {
        "段落": "## 7．7．6 标签平滑\n\n在数据增强中，我们可以给样本特征加入随机噪声来避免过拟合。同样，我们也可以给样本的标签引入一定的噪声。假设训练数据集中有一些样本的标签是被错误标注的，那么最小化这些样本上的损失函数会导致过拟合。一种改善的正则化方法是标签平滑（Label Smoothing），即在输出标签中添加噪声来避免模型过拟合［Szegedy et al．，2016］．\n\n一个样本 $\\boldsymbol{x}$ 的标签一般用 one－hot 向量表示\n\n$$\n\\boldsymbol{y}=[0, \\cdots, 0,1,0, \\cdots, 0]^{\\top}\n$$\n\n这种标签可以看作是硬目标（Hard Target）。如果使用 softmax 分类器并使用交叉熵损失函数，最小化损失函数会使得正确类和其他类的权重差异变得很大。根据 softmax 函数的性质可知，如果要使得某一类的输出概率接近于 1 ，其未归一化的得分需要远大于其他类的得分，可能会导致其权重越来越大，并导致过拟合。此外，如果样本标签是错误的，会导致更严重的过拟合现象。为了改善这种情况，我们可以引入一个噪声对标签进行平滑，即假设样本以 $\\epsilon$ 的概率为其他类。平滑后的标签为\n\n$$\n\\tilde{\\boldsymbol{y}}=\\left[\\frac{\\epsilon}{K-1}, \\cdots, \\frac{\\epsilon}{K-1}, 1-\\epsilon, \\frac{\\epsilon}{K-1}, \\cdots, \\frac{\\epsilon}{K-1}\\right]^{\\top} .\n$$\n\n其中 $K$ 为标签数量，这种标签可以看作是软目标（Soft Target）。标签平滑可以避免模型的输出过拟合到硬目标上，并且通常不会损害其分类能力。\n\n上面的标签平滑方法是给其他 $K-1$ 个标签相同的概率 $\\frac{\\epsilon}{K-1}$ ，没有考虑标签之间的相关性。 一种更好的做法是按照类别相关性来赋予其他标签不同的概率。 比如先训练另外一个更复杂（一般为多个网络的集成）的教师网络 （Teacher Network），并使用大网络的输出作为软目标来训练学生网络（Stu－ dent Network）。这种方法也称为知识精炼（Knowledge Distillation）［Hinton et al．，2015］．",
        "总结": "- 概念：标签平滑是一种正则化方法，通过在标签中引入噪声来避免模型过拟合到硬目标上。\n- 算法：标签平滑通过将原始的 one-hot 标签替换为软目标，即给其他类别赋予一定的概率 $\\frac{\\epsilon}{K-1}$，并保留正确类的概率为 $1-\\epsilon$。\n- 定理/命题：标签平滑可以有效防止模型对错误标注的样本过度拟合，同时通常不会损害其分类能力。\n- 数学推导：原始标签为 one-hot 向量 $\\boldsymbol{y}$，平滑后的标签 $\\tilde{\\boldsymbol{y}}$ 为 $\\left[\\frac{\\epsilon}{K-1}, \\cdots, \\frac{\\epsilon}{K-1}, 1-\\epsilon, \\frac{\\epsilon}{K-1}, \\cdots, \\frac{\\epsilon}{K-1}\\right]^{\\top}$，其中 $K$ 为标签数量。\n- 概念扩展：知识精炼（Knowledge Distillation）是一种改进的标签平滑方法，利用教师网络的输出作为软目标来训练学生网络。"
      },
      {
        "段落": "## 7.8 总结和深入阅读\n\n深度神经网络的优化和正则化是即对立又统一的关系。一方面我们希望优化算法能找到一个全局最优解（或较好的局部最优解），另一方面我们又不希望模型优化到最优解，这可能陷入过拟合。优化和正则化的统一目标是期望风险最小化．近年来深度学习的快速发展在一定程度上也归因于很多深度神经网络的优化和正则化方法的出现。虽然这些方法往往是经验性的，但在实践中取得了很好的效果，使得我们可以高效地、端到端地训练神经网络模型。\n\n在优化方面，训练神经网络时的主要难点是非凸优化以及梯度消失问题。在深度学习的初期发展阶段，我们通常需要利用预训练和逐层训练等比较低效的方 https：／／nndl．github．io／\n\n参见习题 7－9．\n\n集成学习参见第 10.1节。\n\n法来辅助优化．随着各种优化算法、参数初始化、逐层归一化等有效的方法被提出，我们通常可以非常高效地训练一个神经网络。\n\n在泛化方面，传统的机器学习中有一些很好的理论可以帮助我们在模型的表示能力、复杂度和泛化能力之间找到比较好的平衡，比如 Vapnik－Chervonenkis （VC）维［Vapnik，1998］和 Rademacher 复杂度［Bartlett et al．，2002］．但是这些理论无法解释深度神经网络在实际应用中的泛化能力表现。根据通用近似定理，神经网络的表示能力十分强大。从直觉上，一个过度参数化的深度神经网络很容易产生过拟合现象，因为它的容量足够记住所有训练数据。但是实验表明，深度神经网络在训练过程中依然优先记住训练数据中的一般模式（Pattern），即具有高泛化能力的模式［Zhang et al．，2016］．但目前，深度神经网络的泛化能力还没有很好的理论支持。在传统机器学习模型上比较有效的 $\\ell_{1}$ 或 $\\ell_{2}$ 正则化在深度神经网络中作用也比较有限，而一些经验的做法，比如使用随机梯度下降和提前停止，会更有效．",
        "总结": "- 概念：优化与正则化在深度神经网络中是既对立又统一的关系，优化追求全局最优解或较好局部最优解，正则化则防止过拟合。\n- 概念：期望风险最小化是优化和正则化的统一目标。\n- 概念：深度学习的快速发展得益于优化和正则化方法的出现，尽管这些方法多为经验性，但在实践中效果显著。\n- 概念：训练神经网络的主要难点是非凸优化和梯度消失问题。\n- 概念：早期深度学习依赖预训练和逐层训练等低效方法，随着优化算法、参数初始化、逐层归一化等方法的发展，训练效率显著提高。\n- 概念：传统机器学习理论如VC维和Rademacher复杂度有助于模型表示能力、复杂度与泛化能力的平衡，但无法解释深度神经网络的实际泛化能力。\n- 概念：通用近似定理表明神经网络具有强大的表示能力，但过度参数化的网络可能过拟合，实验表明其更倾向于记住一般模式而非所有数据。\n- 概念：传统正则化方法如$\\ell_1$或$\\ell_2$在深度神经网络中效果有限，而随机梯度下降和提前停止等经验做法更有效。"
      },
      {
        "段落": "## 习题\n\n习题7－1 在小批量梯度下降中，试分析为什么学习率要和批量大小成正比．\n习题 7－2 在 Adam 算法中，说明指数加权平均的偏差修正公式（7．27）和公式（7．28）的合理性。\n\n习题 7－3 给出公式（7．33）和公式（7．34）中的函数 $\\psi(\\cdot)$ 和 $\\phi(\\cdot)$ 在不同优化算法中的具体形式。\n\n习题7－4 证明公式（7．43）．\n习题7－5 证明公式（7．45）。\n习题7－6 分析为什么批量归一化不能直接应用于循环神经网络．\n习题 7－7 证明在标准的随机梯度下降中，权重衰减正则化和 $\\ell_{2}$ 正则化的效果相同。并分析这一结论在动量法和 Adam 算法中是否依然成立。\n\n习题 7－8 试分析为什么不能在循环神经网络中的循环连接上直接应用丢弃法？\n\n习题 7－9 若使用标签平滑正则化方法，给出其交叉嫡损失函数。",
        "总结": "- 小节主要涉及小批量梯度下降、Adam算法、优化算法中的函数形式、公式证明、批量归一化在循环神经网络中的应用限制、权重衰减正则化与ℓ₂正则化的等效性、丢弃法在循环神经网络中的不可行性以及标签平滑正则化方法的交叉熵损失函数。  \n- 小批量梯度下降中，学习率与批量大小成正比的原因在于，批量越大，梯度估计越准确，因此可以适当提高学习率以加快收敛速度。  \n- Adam算法中的偏差修正公式（7.27）和（7.28）是为了修正初始时刻的偏差，使动量和自适应学习率的估计更准确，从而提升优化效果。  \n- 公式（7.33）和（7.34）中的函数ψ(·)和φ(·)在不同优化算法中具体形式不同，例如在SGD中可能为线性函数，在Adam中可能涉及指数加权平均。  \n- 公式（7.43）的证明需要通过数学推导，结合梯度下降和正则化项的更新规则进行推导。  \n- 公式（7.45）的证明涉及对损失函数的梯度计算及优化过程中的参数更新推导。  \n- 批量归一化不能直接应用于循环神经网络是因为循环连接会破坏归一化的稳定性，导致训练困难。  \n- 在标准随机梯度下降中，权重衰减正则化与ℓ₂正则化效果相同，但在动量法和Adam算法中由于引入了动量项或自适应学习率，这一结论不成立。  \n- 不能在循环神经网络的循环连接上直接应用丢弃法是因为丢弃法会破坏序列信息的传递，导致模型无法正确捕捉时间依赖关系。  \n- 使用标签平滑正则化方法时，交叉熵损失函数需要对真实标签进行平滑处理，以减少对单一标签的过度依赖。"
      },
      {
        "段落": "## 参考文献\n\nBa L J，Kiros R，Hinton G E．Layer normalization［J／OL］．CoRR，2016，abs／1607．06450．http： ／／arxiv．org／abs／1607．06450．\n\n目前，预训练方法依然有着广泛的应用，但主要是利用它带来更好泛化性，而不再是为了解决网络优化问题．\n\nBartlett P L，Mendelson S．Rademacher and gaussian complexities：Risk bounds and structural results［J］．Journal of Machine Learning Research，2002，3（Nov）：463－482．\nBergstra J，Bengio Y．Random search for hyper－parameter optimization［J］．Journal of Machine Learning Research，2012，13（Feb）：281－305．\nBergstra J S，Bardenet R，Bengio Y，et al．Algorithms for hyper－parameter optimization［C］／／ Advances in neural information processing systems．2011：2546－2554．\nChoromanska A，Henaff M，Mathieu M，et al．The loss surfaces of multilayer networks［C］／／ Artificial Intelligence and Statistics．2015：192－204．\nDauphin Y N，Pascanu R，Gulcehre C，et al．Identifying and attacking the saddle point problem in high－dimensional non－convex optimization［C］／／Advances in neural information processing sys－ tems．2014：2933－2941．\nDozat T．Incorporating nesterov momentum into adam［C］／／ICLR Workshop． 2016.\nDuchi J，Hazan E，Singer Y．Adaptive subgradient methods for online learning and stochastic optimization［J］．The Journal of Machine Learning Research，2011，12：2121－2159．\nGal Y，Ghahramani Z．Dropout as a bayesian approximation：Representing model uncertainty in deep learning［C］／／international conference on machine learning．2016：1050－1059．\nGal Y，Ghahramani Z．A theoretically grounded application of dropout in recurrent neural net－ works［C］／／Advances in neural information processing systems．2016：1019－1027．\nGlorot X，Bengio Y．Understanding the difficulty of training deep feedforward neural networks［C］／／ Proceedings of International conference on artificial intelligence and statistics．2010：249－256．\nGoyal P，Dollár P，Girshick R，et al．Accurate，large minibatch sgd：Training imagenet in 1 hour［J］． arXiv preprint arXiv：1706．02677， 2017.\nHanson S J，Pratt L Y．Comparing biases for minimal network construction with back－propagation ［C］／／Advances in neural information processing systems．1989：177－185．\nHe K，Zhang X，Ren S，et al．Delving deep into rectifiers：Surpassing human－level performance on imagenet classification［C］／／Proceedings of the IEEE International Conference on Computer Vision．2015：1026－1034．\nHinton G，Vinyals O，Dean J．Distilling the knowledge in a neural network［J］．arXiv preprint arXiv：1503．02531， 2015.\nHochreiter S，Schmidhuber J．Flat minima［J］．Neural Computation，1997，9（1）：1－42．\nHutter F，Hoos H H，Leyton－Brown K．Sequential model－based optimization for general algorithm configuration［C］／／International Conference on Learning and Intelligent Optimization．Springer， 2011：507－523．\n\nIoffe S，Szegedy C．Batch normalization：Accelerating deep network training by reducing internal covariate shift［C］／／Proceedings of the 32nd International Conference on Machine Learning．2015： 448－456．\nJamieson K，Talwalkar A．Non－stochastic best arm identification and hyperparameter optimization ［C］／／Artificial Intelligence and Statistics．2016：240－248．\nKeskar N S，Mudigere D，Nocedal J，et al．On large－batch training for deep learning：Generalization gap and sharp minima［J］．arXiv preprint arXiv：1609．04836， 2016.\nKingma D，Ba J．Adam：A method for stochastic optimization［C］／／Proceedings of International Conference on Learning Representations． 2015.\nKrizhevsky A，Sutskever I，Hinton G E．ImageNet classification with deep convolutional neural networks［C］／／Advances in Neural Information Processing Systems 25．2012：1106－1114．\nLi H，Xu Z，Taylor G，et al．Visualizing the loss landscape of neural nets［J］．arXiv preprint arXiv：1712．09913， 2017.\nLi L，Jamieson K，DeSalvo G，et al．Hyperband：Bandit－based configuration evaluation for hyper－ parameter optimization［C］／／Proceedings of 5th International Conference on Learning Represen－ tations． 2017.\n\nLoshchilov I，Hutter F．SGDR：stochastic gradient descent with warm restarts［C］／／Proceedings of 5th International Conference on Learning Representations． 2017.\nLoshchilov I，Hutter F．Fixing weight decay regularization in adam［J］．arXiv preprint arXiv：1711．05101， 2017.\nNesterov Y．Gradient methods for minimizing composite functions［J］．Mathematical Program－ ming，2013，140（1）：125－161．\nPascanu R，Mikolov T，Bengio Y．On the difficulty of training recurrent neural networks［C］／／ Proceedings of the International Conference on Machine Learning．2013：1310－1318．\nPrechelt L．Early stopping－but when？［M］／／Neural Networks：Tricks of the trade．Springer，1998： 55－69．\nRumelhart D E，Hinton G E，Williams R J，et al．Learning representations by back－propagating errors［J］．Cognitive modeling，1988，5（3）：1．\nSalimans T，Kingma D P．Weight normalization：A simple reparameterization to accelerate training of deep neural networks［C］／／Advances in Neural Information Processing Systems．2016：901－909． Saxe A M，Mcclelland J L，Ganguli S．Exact solutions to the nonlinear dynamics of learning in deep linear neural network［C］／／International Conference on Learning Representations． 2014.\nSnoek J，Larochelle H，Adams R P．Practical bayesian optimization of machine learning algorithms ［C］／／Advances in neural information processing systems．2012：2951－2959．\nSnoek J，Rippel O，Swersky K，et al．Scalable bayesian optimization using deep neural networks ［C］／／International Conference on Machine Learning．2015：2171－2180．\nSrivastava N，Hinton G，Krizhevsky A，et al．Dropout：A simple way to prevent neural networks from overfitting［J］．The Journal of Machine Learning Research，2014，15（1）：1929－1958．\nSutskever I，Martens J，Dahl G，et al．On the importance of initialization and momentum in deep learning［C］／／International conference on machine learning．2013：1139－1147．\nSzegedy C，Vanhoucke V，Ioffe S，et al．Rethinking the inception architecture for computer vision ［C］／／Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition．2016： 2818－2826．\nTieleman T，Hinton G．Lecture 6．5－rmsprop：Divide the gradient by a running average of its recent magnitude［Z］． 2012.\nVapnik V．Statistical learning theory［M］．New York：Wiley， 1998.\nWan L，Zeiler M，Zhang S，et al．Regularization of neural networks using dropconnect［C］／／ International Conference on Machine Learning．2013：1058－1066．\nZaremba W，Sutskever I，Vinyals O．Recurrent neural network regularization［J］．arXiv preprint arXiv：1409．2329， 2014.\nZeiler M D．Adadelta：An adaptive learning rate method［J］．arXiv preprint arXiv：1212．5701， 2012. Zhang C，Bengio S，Hardt M，et al．Understanding deep learning requires rethinking generalization ［J］．arXiv preprint arXiv：1611．03530， 2016.\nZoph B，Le Q V．Neural architecture search with reinforcement learning［C］／／Proceedings of 5th International Conference on Learning Representations． 2017.\nZou H，Hastie T．Regularization and variable selection via the elastic net［J］．Journal of the Royal Statistical Society：Series B（Statistical Methodology），2005，67（2）：301－320．",
        "总结": "- 层归一化（Layer Normalization）  \n- 预训练方法主要用于提升泛化性，而非解决网络优化问题  \n- 随机搜索用于超参数优化  \n- 超参数优化算法研究  \n- 多层网络损失曲面分析  \n- 高维非凸优化中的鞍点问题识别与解决  \n- Nesterov 动量在 Adam 中的集成  \n- 自适应子梯度方法用于在线学习和随机优化  \n- Dropout 作为贝叶斯近似，用于表示深度学习中的模型不确定性  \n- Dropout 在循环神经网络中的应用  \n- 深度前馈神经网络训练难度分析  \n- 大批量 SGD 训练 ImageNet 的实践  \n- 反向传播中最小网络构造的偏差比较  \n- 深度卷积神经网络在 ImageNet 分类中的应用  \n- 神经网络知识蒸馏方法  \n- 平坦极小值点（Flat minima）理论  \n- 顺序模型基于优化的通用算法配置  \n- 批归一化（Batch Normalization）加速深度网络训练  \n- 非随机最佳臂识别与超参数优化  \n- 大批量训练中的泛化差距与尖锐极小值点研究  \n- Adam：一种随机优化方法  \n- ImageNet 分类的深度卷积神经网络应用  \n- 神经网络损失景观可视化  \n- 超参数优化中的 HyperBand 方法  \n- SGDR：带有热重启的随机梯度下降  \n- 修正 Adam 中的权重衰减正则化  \n- 梯度方法用于最小化复合函数  \n- 循环神经网络训练困难分析  \n- 早期停止策略研究  \n- 反向传播误差学习表示方法  \n- 权重归一化加速深度神经网络训练  \n- 深度线性神经网络学习非线性动力学的精确解  \n- 机器学习算法的实用贝叶斯优化方法  \n- 利用深度神经网络进行可扩展贝叶斯优化  \n- Dropout 防止神经网络过拟合的方法研究  \n- 初始化与动量在深度学习中的重要性分析  \n- Inception 架构在计算机视觉中的重新思考设计  \n- RMSProp：梯度除以其近期幅度的运行平均值方法研究  \n- 统计学习理论基础研究  \n- 神经网络使用 DropConnect 进行正则化的方法研究  \n- 循环神经网络正则化方法研究   \n- Adadelta：一种自适应学习率方法研究   \n- 深度学习泛化性重新思考与推广能力分析   \n- 基于强化学习的神经架构搜索方法研究   \n- 弹性网正则化与变量选择方法研究"
      }
    ]
  },
  {
    "标题": "第8章 注意力机制与外部记忆",
    "内容": [
      {
        "段落": "# 第8章 注意力机制与外部记忆 \n\n智慧的艺术是知道该忽视什么．\n—威廉•詹姆斯（William James）\n美国心理学家和哲学家\n\n根据通用近似定理，前馈网络和循环网络都有很强的能力。但由于优化算法和计算能力的限制，在实践中很难达到通用近似的能力。特别是在处理复杂任务时，比如需要处理大量的输入信息或者复杂的计算流程时，目前计算机的计算能力依然是限制神经网络发展的瓶颈。\n\n为了减少计算复杂度，通过部分借鉴生物神经网络的一些机制，我们引入了局部连接、权重共享以及汇聚操作来简化神经网络结构。虽然这些机制可以有效缓解模型的复杂度和表达能力之间的矛盾，但是我们依然希望在不＂过度＂增加模型复杂度（主要是模型参数）的情况下来提高模型的表达能力。以阅读理解任务为例，给定的背景文章（Background Document）一般比较长，如果用循环神经网络来将其转换为向量表示，那么这个编码向量很难反映出背景文章的所有语义。在比较简单的任务（比如文本分类）中，只需要编码一些对分类有用的信息，因此用一个向量来表示文本语义是可行的。但是在阅读理解任务中，编码时还不知道可能会接收到什么样的问句。这些问句可能会涉及背景文章的所有信息点，因此丢失任何信息都可能导致无法正确回答问题。\n\n神经网络中可以存储的信息量称为网络容量（Network Capacity）。一般来讲，利用一组神经元来存储信息时，其存储容量和神经元的数量以及网络的复杂度成正比．如果要存储越多的信息，神经元数量就要越多或者网络要越复杂，进而导致神经网络的参数成倍地增加．\n\n我们人脑的生物神经网络同样存在网络容量问题，人脑中的工作记忆大概只有几秒钟的时间，类似于循环神经网络中的隐状态。而人脑每个时刻接收的外界输入信息非常多，包括来自于视觉、听觉、触觉的各种各样的信息。单就视觉来说，眼睛每秒钟都会发送千万比特的信息给视觉神经系统．人脑在有限的资源下，并\n\n阅读理解任务是让机器阅读一篇背景文章，然后询问一些相关的问题，来测试机器是否理解了这篇文章．\n\n在循环神经网络中，丢失信息的另外一个因素是远距离依赖问题。\n\n不能同时处理这些过载的输入信息。大脑神经系统有两个重要机制可以解决信息过载问题：注意力和记忆机制。\n\n我们可以借鉴人脑解决信息过载的机制，从两方面来提高神经网络处理信息的能力。一方面是注意力，通过自上而下的信息选择机制来过滤掉大量的无关信息；另一方面是引入额外的外部记忆，优化神经网络的记忆结构来提高神经网络存储信息的容量。",
        "总结": "- 注意力机制与外部记忆的概念提出  \n- 局部连接、权重共享及汇聚操作用于简化神经网络结构  \n- 网络容量定义为神经网络中可存储的信息量，与神经元数量和网络复杂度成正比  \n- 人脑工作记忆与循环神经网络中的隐状态类似，存在时间限制  \n- 阅读理解任务要求机器理解背景文章并回答相关问题  \n- 循环神经网络存在远距离依赖问题，导致信息丢失  \n- 人脑通过注意力和记忆机制解决信息过载问题  \n- 注意力机制通过自上而下的信息选择过滤无关信息  \n- 外部记忆机制优化神经网络的记忆结构以提高存储容量"
      },
      {
        "段落": "## 8.1 认知神经学中的注意力\n\n注意力是一种人类不可或缺的复杂认知功能，指人可以在关注一些信息的同时忽略另一些信息的选择能力。在日常生活中，我们通过视觉、听觉、触觉等方式接收大量的感觉输入。但是人脑还能在这些外界的信息轰炸中有条不紊地工作，是因为人脑可以有意或无意地从这些大量输入信息中选择小部分的有用信息来重点处理，并忽略其他信息。这种能力就叫做注意力（Attention）。注意力可以作用在外部的刺激（听觉、视觉、味觉等），也可以作用在内部的意识（思考、回忆等）。\n\n注意力一般分为两种：\n（1）自上而下的有意识的注意力，称为聚焦式注意力（Focus Attention）。聚焦式注意力是指有预定目的、依赖任务的，主动有意识地聚焦于某一对象的注意力。\n（2）自下而上的无意识的注意力，称为基于显著性的注意力（Saliency－Based Attention）。基于显著性的注意力是由外界刺激驱动的注意，不需要主动干预，也和任务无关。如果一个对象的刺激信息不同于其周围信息，一种无意识的＂赢者通吃＂（Winner－Take－All）或者门控（Gating）机制就可以把注意力转向这个对象。不管这些注意力是有意还是无意，大部分的人脑活动都需要依赖注意力，比如记忆信息、阅读或思考等。\n\n一个和注意力有关的例子是鸡尾酒会效应。当一个人在吵闹的鸡尾酒会上和朋友聊天时，尽管周围噪音干扰很多，他还是可以听到朋友的谈话内容，而忽略其他人的声音（聚焦式注意力）。同时，如果未注意到的背景声中有重要的词 （比如他的名字），他会马上注意到（显著性注意力）。\n\n聚焦式注意力一般会随着环境、情景或任务的不同而选择不同的信息。比如当要从人群中寻找某个人时，我们会专注于每个人的脸部；而当要统计人群的人数时，我们只需要专注于每个人的轮廓。\n\n聚焦式注意力也常称为选择性注意力（Se－ lective Attention）．\n\n除非特别声明，在本节及以后章节中，注意力机制是通常指自上而下的聚焦式注意力。",
        "总结": "- 概念：注意力是一种选择性处理信息的认知功能，使人能够关注部分信息并忽略其他信息。\n- 分类：注意力分为自上而下的聚焦式注意力（有意识、任务驱动）和自下而上的基于显著性的注意力（无意识、刺激驱动）。\n- 机制：聚焦式注意力通过有意识地选择信息来完成任务，而基于显著性的注意力则由外界刺激自动引导。\n- 例子：鸡尾酒会效应说明了聚焦式注意力和基于显著性注意力在实际情境中的应用。\n- 特点：聚焦式注意力可根据环境和任务需求选择不同信息，如寻找特定人时关注脸部，统计人数时关注轮廓。\n- 命题：本节及后续章节中，除非特别说明，注意力机制通常指自上而下的聚焦式注意力。"
      },
      {
        "段落": "## 8.2 注意力机制\n\n在计算能力有限情况下，注意力机制（Attention Mechanism）作为一种资源分配方案，将有限的计算资源用来处理更重要的信息，是解决信息超载问题的主要手段。\n\n当用神经网络来处理大量的输入信息时，也可以借鉴人脑的注意力机制，只选择一些关键的信息输入进行处理，来提高神经网络的效率。在目前的神经网络模型中，我们可以将最大汇聚（Max Pooling）、门控（Gating）机制近似地看作是自下而上的基于显著性的注意力机制。除此之外，自上而下的聚焦式注意力也是一种有效的信息选择方式。以阅读理解任务为例，给定一篇很长的文章，然后就此文章的内容进行提问。提出的问题只和段落中的一两个句子相关，其余部分都是无关的。为了减小神经网络的计算负担，只需要把相关的片段挑选出来让后续的神经网络来处理，而不需要把所有文章内容都输入给神经网络。\n\n用 $\\boldsymbol{X}=\\left[\\boldsymbol{x}_{1}, \\cdots, \\boldsymbol{x}_{N}\\right] \\in \\mathbb{R}^{D \\times N}$ 表示 $N$ 组输入信息，其中 $D$ 维向量 $\\boldsymbol{x}_{n} \\in$ $\\mathbb{R}^{D}, n \\in[1, N]$ 表示一组输入信息。为了节省计算资源，不需要将所有信息都输入到神经网络，只需要从 $\\boldsymbol{X}$ 中选择一些和任务相关的信息。注意力机制的计算可以分为两步：一是在所有输入信息上计算注意力分布，二是根据注意力分布来计算输入信息的加权平均。\n\n注意力分布 为了从 $N$ 个输入向量 $\\left[\\boldsymbol{x}_{1}, \\cdots, \\boldsymbol{x}_{N}\\right]$ 中选择出和某个特定任务相关的信息，我们需要引入一个和任务相关的表示，称为查询向量（Query Vector），并通过一个打分函数来计算每个输入向量和查询向量之间的相关性．\n\n给定一个和任务相关的查询向量 $\\boldsymbol{q}$ ，我们用注意力变量 $z \\in[1, N]$ 来表示被选择信息的索引位置，即 $z=n$ 表示选择了第 $n$ 个输入向量。为了方便计算，我们采用一种＂软性＂的信息选择机制。首先计算在给定 $\\boldsymbol{q}$ 和 $\\boldsymbol{X}$ 下，选择第 $i$ 个输入向量的概率 $\\alpha_{n}$ ，\n\n$$\n\\begin{align*}\n\\alpha_{n} & =p(z=n \\mid \\boldsymbol{X}, \\boldsymbol{q}) \\\\\n& =\\operatorname{softmax}\\left(s\\left(\\boldsymbol{x}_{n}, \\boldsymbol{q}\\right)\\right) \\\\\n& =\\frac{\\exp \\left(s\\left(\\boldsymbol{x}_{n}, \\boldsymbol{q}\\right)\\right)}{\\sum_{j=1}^{N} \\exp \\left(s\\left(\\boldsymbol{x}_{j}, \\boldsymbol{q}\\right)\\right)}, \\tag{8.1}\n\\end{align*}\n$$\n\n其中 $\\alpha_{n}$ 称为注意力分布（Attention Distribution），$s(\\boldsymbol{x}, \\boldsymbol{q})$ 为注意力打分函数，可以使用以下几种方式来计算：\n\n加性模型\n\n$$\n\\begin{equation*}\ns(\\boldsymbol{x}, \\boldsymbol{q})=\\boldsymbol{v}^{\\top} \\tanh (\\boldsymbol{W} \\boldsymbol{x}+\\boldsymbol{U} \\boldsymbol{q}), \\tag{8.2}\n\\end{equation*}\n$$\n\n点积模型\n\n$$\n\\begin{equation*}\ns(\\boldsymbol{x}, \\boldsymbol{q})=\\boldsymbol{x}^{\\top} \\boldsymbol{q} \\tag{8.3}\n\\end{equation*}\n$$\n\n注意力机制也可称为注意力模型．\n\n查询向量 $\\boldsymbol{q}$ 可以是动态生成的，也可以是可学习的参数．\n\n缩放点积模型\n\n$$\n\\begin{align*}\n& s(\\boldsymbol{x}, \\boldsymbol{q})=\\frac{\\boldsymbol{x}^{\\top} \\boldsymbol{q}}{\\sqrt{D}}  \\tag{8.4}\\\\\n& s(\\boldsymbol{x}, \\boldsymbol{q})=\\boldsymbol{x}^{\\top} \\boldsymbol{W} \\boldsymbol{q} \\tag{8.5}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{W}, \\boldsymbol{U}, \\boldsymbol{v}$ 为可学习的参数，$D$ 为输入向量的维度。理论上，加性模型和点积模型的复杂度差不多，但是点积模型在实现上可以更好地利用矩阵乘积，从而计算效率更高。但当输入向量的维度 $D$ 比较高时，点积模型的值通常有比较大的方差，从而导致 softmax 函数的梯度会比较小。因此，缩放点积模型可以较好地解决这个问题．双线性模型可以看作是一种泛化的点积模型．假设公式（8．5）中 $\\boldsymbol{W}=\\boldsymbol{U}^{\\top} \\boldsymbol{V}$ ，双线性模型可以写为 $s(\\boldsymbol{x}, \\boldsymbol{q})=\\boldsymbol{x}^{\\top} \\boldsymbol{U}^{\\top} V \\boldsymbol{q}=(\\boldsymbol{U} \\boldsymbol{x})^{\\top}(V \\boldsymbol{q})$ ，即分别对 $\\boldsymbol{x}$ 和 $\\boldsymbol{q}$ 进行线性变换后计算点积．相比点积模型，双线性模型在计算相似度时引入了非对称性。\n\n加权平均 注意力分布 $\\alpha_{n}$ 可以解释为在给定任务相关的查询 $\\boldsymbol{q}$ 时，第 $n$ 个输入向量受关注的程度。我们采用一种＂软性＂的信息选择机制对输入信息进行汇总，即\n\n$$\n\\begin{align*}\n\\operatorname{att}(\\boldsymbol{X}, \\boldsymbol{q}) & =\\sum_{n=1}^{N} \\alpha_{n} \\boldsymbol{x}_{n}  \\tag{8.6}\\\\\n& =\\mathbb{E}_{z \\sim p(z \\mid X, \\boldsymbol{q})}\\left[\\boldsymbol{x}_{z}\\right] \\tag{8.7}\n\\end{align*}\n$$\n\n公式（8．7）称为软性注意力机制（Soft Attention Mechanism）。图8．1a给出软性注意力机制的示例．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-207.jpg?height=643&width=1117&top_left_y=1305&top_left_x=106)\n\n图8．1注意力机制\n\n注意力机制可以单独使用，但更多地用作神经网络中的一个组件．",
        "总结": "- 注意力机制是一种资源分配方案，用于在计算能力有限的情况下，将有限的计算资源分配给更重要的信息，以解决信息超载问题。  \n- 注意力机制通过引入查询向量和打分函数，计算输入信息与查询向量的相关性，从而选择与任务相关的信息。  \n- 注意力分布是通过softmax函数计算得到的概率分布，表示每个输入向量被选择的概率。  \n- 注意力打分函数包括加性模型、点积模型和缩放点积模型，其中点积模型在实现上更高效，但缩放点积模型能缓解高维输入带来的方差问题。  \n- 双线性模型是点积模型的泛化形式，通过引入非对称线性变换来计算相似度。  \n- 加权平均是根据注意力分布对输入信息进行加权求和，得到最终的注意力输出，称为软性注意力机制。"
      },
      {
        "段落": "## 8．2．1 注意力机制的变体\n\n除了上面介绍的基本模式外，注意力机制还存在一些变化的模型。",
        "总结": "- 注意力机制的变体指的是在基本注意力机制基础上进行改进或调整的不同模型形式。  \n- 这些变体旨在解决特定问题或提升模型性能，例如在处理长序列、减少计算复杂度或增强上下文理解等方面。  \n- 文中提到这些变体的存在，但未具体展开其类型或详细说明。"
      },
      {
        "段落": "### 8．2．1．1 硬性注意力\n\n公式（8．7）提到的注意力是软性注意力，其选择的信息是所有输入向量在注意力分布下的期望。此外，还有一种注意力是只关注某一个输入向量，叫做硬性注意力（Hard Attention）。\n\n硬性注意力有两种实现方式：\n（1）一种是选取最高概率的一个输入向量，即\n\n$$\n\\begin{equation*}\n\\operatorname{att}(\\boldsymbol{X}, \\boldsymbol{q})=\\boldsymbol{x}_{\\hat{n}} \\tag{8.8}\n\\end{equation*}\n$$\n\n其中 $\\hat{n}$ 为概率最大的输入向量的下标，即 $\\hat{n}=\\stackrel{N}{\\underset{n=1}{\\arg } \\max } \\alpha_{n}$ ．\n（2）另一种硬性注意力可以通过在注意力分布式上随机采样的方式实现。\n硬性注意力的一个缺点是基于最大采样或随机采样的方式来选择信息，使得最终的损失函数与注意力分布之间的函数关系不可导，因此无法使用反向传播算法进行训练。为了使用反向传播算法，一般使用软性注意力来代替硬性注意力。\n\n硬性注意力需要通过强化学习来进行训练。",
        "总结": "- 硬性注意力是一种只关注某个特定输入向量的注意力机制，与软性注意力相对。  \n- 硬性注意力的实现方式之一是选择概率最大的输入向量，即通过 $\\hat{n}=\\stackrel{N}{\\underset{n=1}{\\arg } \\max } \\alpha_{n}$ 确定。  \n- 硬性注意力的另一种实现方式是通过在注意力分布上进行随机采样。  \n- 硬性注意力的缺点是其选择过程不可导，导致无法使用反向传播算法进行训练。  \n- 为了使用反向传播算法，通常采用软性注意力来替代硬性注意力。  \n- 硬性注意力需要通过强化学习来进行训练。"
      },
      {
        "段落": "### 8．2．1．2 键值对注意力\n\n更一般地，我们可以用键值对（key－value pair）格式来表示输入信息，其中 ＂键＂用来计算注意力分布 $\\alpha_{n}$ ，＂值＂用来计算聚合信息。\n\n用 $(K, V)=\\left[\\left(\\boldsymbol{k}_{1}, \\boldsymbol{v}_{1}\\right), \\cdots,\\left(\\boldsymbol{k}_{N}, \\boldsymbol{v}_{N}\\right)\\right]$ 表示 $N$ 组输入信息，给定任务相关的查询向量 $\\boldsymbol{q}$ 时，注意力函数为\n\n$$\n\\begin{align*}\n\\operatorname{att}((K, V), \\boldsymbol{q}) & =\\sum_{n=1}^{N} \\alpha_{n} \\boldsymbol{v}_{n}  \\tag{8.9}\\\\\n& =\\sum_{n=1}^{N} \\frac{\\exp \\left(s\\left(\\boldsymbol{k}_{n}, \\boldsymbol{q}\\right)\\right)}{\\sum_{j} \\exp \\left(s\\left(\\boldsymbol{k}_{j}, \\boldsymbol{q}\\right)\\right)} \\boldsymbol{v}_{n} \\tag{8.10}\n\\end{align*}\n$$\n\n其中 $s\\left(\\boldsymbol{k}_{n}, \\boldsymbol{q}\\right)$ 为打分函数．\n图8．1b给出键值对注意力机制的示例．当 $K=V$ 时，键值对模式就等价于普通的注意力机制．",
        "总结": "- 概念：键值对注意力机制，通过键（key）和值（value）对的形式表示输入信息，用于计算注意力分布和聚合信息。  \n- 算法：注意力函数通过查询向量 $\\boldsymbol{q}$ 计算每个键值对的注意力权重，最终加权求和得到聚合信息。  \n- 公式：注意力函数公式为 $\\operatorname{att}((K, V), \\boldsymbol{q}) = \\sum_{n=1}^{N} \\frac{\\exp \\left(s\\left(\\boldsymbol{k}_{n}, \\boldsymbol{q}\\right)\\right)}{\\sum_{j} \\exp \\left(s\\left(\\boldsymbol{k}_{j}, \\boldsymbol{q}\\right)\\right)} \\boldsymbol{v}_{n}$，其中 $s$ 为打分函数。  \n- 特殊情况：当 $K=V$ 时，键值对注意力机制退化为普通注意力机制。"
      },
      {
        "段落": "### 8．2．1．3 多头注意力\n\n多头注意力（Multi－Head Attention）是利用多个查询 $Q=\\left[\\boldsymbol{q}_{1}, \\cdots, \\boldsymbol{q}_{M}\\right]$ ，来并行地从输入信息中选取多组信息。每个注意力关注输入信息的不同部分。\n\n$$\n\\begin{equation*}\n\\operatorname{att}((K, V), Q)=\\operatorname{att}\\left((K, V), \\boldsymbol{q}_{1}\\right) \\oplus \\cdots \\oplus \\operatorname{att}\\left((K, V), \\boldsymbol{q}_{M}\\right) \\tag{8.11}\n\\end{equation*}\n$$\n\n其中 $\\oplus$ 表示向量拼接。",
        "总结": "- 多头注意力（Multi-Head Attention）通过多个查询向量并行地从输入信息中提取多组信息。  \n- 每个注意力头关注输入信息的不同部分，以捕捉更丰富的语义信息。  \n- 多头注意力的计算方式是将各个注意力头的结果进行向量拼接。"
      },
      {
        "段落": "### 8．2．1．4 结构化注意力\n\n在之前介绍中，我们假设所有的输入信息是同等重要的，是一种扁平（Flat）结构，注意力分布实际上是在所有输入信息上的多项分布。但如果输入信息本身具有层次（hierarchical）结构，比如文本可以分为词、句子、段落、篇章等不同粒度的层次，我们可以使用层次化的注意力来进行更好的信息选择［Yang et al．， 2016］．此外，还可以假设注意力为上下文相关的二项分布，用一种图模型来构建更复杂的结构化注意力分布［Kim et al．，2017］．",
        "总结": "- 结构化注意力的概念：提出输入信息可能具有层次结构，而非扁平结构，因此需要层次化的注意力机制来更好地选择信息。  \n- 层次化注意力的应用：用于处理具有不同粒度层次的信息，如文本中的词、句子、段落和篇章等。  \n- 注意力分布的扩展：引入上下文相关的二项分布，构建更复杂的结构化注意力分布。  \n- 相关研究：引用了Yang等（2016）和Kim等（2017）的工作，分别提出了层次化注意力和图模型构建的结构化注意力方法。"
      },
      {
        "段落": "### 8．2．1．5 指针网络\n\n注意力机制主要是用来做信息筛选，从输入信息中选取相关的信息。注意力机制可以分为两步：一是计算注意力分布 $\\alpha$ ，二是根据 $\\alpha$ 来计算输入信息的加权平均。我们可以只利用注意力机制中的第一步，将注意力分布作为一个软性的指针（pointer）来指出相关信息的位置．\n\n指针网络（Pointer Network）［Vinyals et al．，2015］是一种序列到序列模型，输入是长度为 $N$ 的向量序列 $\\boldsymbol{X}=\\boldsymbol{x}_{1}, \\cdots, \\boldsymbol{x}_{N}$ ，输出是长度为 $M$ 的下标序列 $\\boldsymbol{c}_{1: M}=$ $c_{1}, c_{2}, \\cdots, c_{M}, c_{m} \\in[1, N], \\forall m$.\n\n和一般的序列到序列任务不同，这里的输出序列是输入序列的下标（索引）。比如输入一组乱序的数字，输出为按大小排序的输入数字序列的下标。比如输入为 $20,5,10$ ，输出为 $1,3,2$ 。\n\n条件概率 $p\\left(c_{1: M} \\mid \\boldsymbol{x}_{1: N}\\right)$ 可以写为\n\n$$\n\\begin{align*}\np\\left(c_{1: M} \\mid \\boldsymbol{x}_{1: N}\\right) & =\\prod_{m=1}^{M} p\\left(c_{m} \\mid c_{1:(m-1)}, \\boldsymbol{x}_{1: N}\\right)  \\tag{8.12}\\\\\n& \\approx \\prod_{m=1}^{M} p\\left(c_{m} \\mid \\boldsymbol{x}_{c_{1}}, \\cdots, \\boldsymbol{x}_{c_{m-1}}, \\boldsymbol{x}_{1: N}\\right) \\tag{8.13}\n\\end{align*}\n$$\n\n其中条件概率 $p\\left(c_{m} \\mid \\boldsymbol{x}_{c_{1}}, \\cdots, \\boldsymbol{x}_{c_{(m-1)}}, \\boldsymbol{x}_{1: N}\\right)$ 可以通过注意力分布来计算。假设用一个循环神经网络对 $\\boldsymbol{x}_{c_{1}}, \\cdots, \\boldsymbol{x}_{c_{m-1}}, \\boldsymbol{x}_{1: N}$ 进行编码得到向量 $\\boldsymbol{h}_{m}$ ，则\n\n$$\n\\begin{equation*}\np\\left(c_{m} \\mid c_{1:(m-1)}, \\boldsymbol{x}_{1: N}\\right)=\\operatorname{softmax}\\left(s_{m, n}\\right), \\tag{8.14}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n其中 $S_{m, n}$ 为在解码过程的第 $m$ 步时， $\\boldsymbol{h}_{m}$ 对 $\\boldsymbol{h}_{n}$ 的未归一化的注意力分布，即\n\n$$\n\\begin{equation*}\ns_{m, n}=\\boldsymbol{v}^{\\top} \\tanh \\left(\\boldsymbol{W} \\boldsymbol{x}_{n}+\\boldsymbol{U} \\boldsymbol{h}_{m}\\right), \\forall n \\in[1, N] \\tag{8.15}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{v}, \\boldsymbol{W}, \\boldsymbol{U}$ 为可学习的参数．\n图8．2给出了指针网络的示例，其中 $\\boldsymbol{h}_{1}, \\boldsymbol{h}_{2}, \\boldsymbol{h}_{3}$ 为输入数字 $20,5,10$ 经过循环神经网络的隐状态， $\\boldsymbol{h}_{0}$ 对应一个特殊字符＜。当输入＞时，网络一步一步输出三个输入数字从大到小排列的下标。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-210.jpg?height=435&width=871&top_left_y=545&top_left_x=187)\n\n图8．2指针网络",
        "总结": "- 指针网络是一种序列到序列模型，输入是向量序列，输出是输入序列的下标序列。  \n- 指针网络通过注意力机制计算注意力分布，将注意力分布作为软指针来选择相关信息的位置。  \n- 条件概率 $p(c_{1:M} \\mid \\boldsymbol{x}_{1:N})$ 表示输出序列的条件概率，通过逐步计算每个位置的条件概率来构建。  \n- 每个位置的条件概率 $p(c_m \\mid c_{1:(m-1)}, \\boldsymbol{x}_{1:N})$ 使用 softmax 函数和注意力分布计算。  \n- 注意力分布 $s_{m,n}$ 通过 $\\boldsymbol{v}^{\\top} \\tanh(\\boldsymbol{W} \\boldsymbol{x}_n + \\boldsymbol{U} \\boldsymbol{h}_m)$ 计算，其中 $\\boldsymbol{v}, \\boldsymbol{W}, \\boldsymbol{U}$ 是可学习参数。  \n- 图8.2展示了指针网络的示例，输入数字经过循环神经网络得到隐状态，输出按大小排序的下标。"
      },
      {
        "段落": "## 8.3 自注意力模型\n\n当使用神经网络来处理一个变长的向量序列时，我们通常可以使用卷积网络或循环网络进行编码来得到一个相同长度的输出向量序列，如图8．3所示．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-210.jpg?height=269&width=1077&top_left_y=1444&top_left_x=93)\n\n图8．3基于卷积网络和循环网络的变长序列编码\n\n基于卷积或循环网络的序列编码都可以看作是一种局部的编码方式，只建模了输入信息的局部依赖关系。虽然循环网络理论上可以建立长距离依赖关系，但是由于信息传递的容量以及梯度消失问题，实际上也只能建立短距离依赖关系。\n\n如果要建立输入序列之间的长距离依赖关系，可以使用以下两种方法：一种方法是增加网络的层数，通过一个深层网络来获取远距离的信息交互；另一种方 https：／／nndl．github．io／\n\n法是使用全连接网络．全连接网络是一种非常直接的建模远距离依赖的模型，但是无法处理变长的输入序列。不同的输入长度，其连接权重的大小也是不同的。这时我们就可以利用注意力机制来＂动态＂地生成不同连接的权重，这就是自注意力模型（Self－Attention Model）。\n\n为了提高模型能力，自注意力模型经常采用查询－键－值（Query－Key－Value， QKV）模式，其计算过程如图8．4所示，其中红色字母表示矩阵的维度。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-211.jpg?height=667&width=1040&top_left_y=495&top_left_x=131)\n\n图 8.4 自注意力模型的计算过程\n\n假设输入序列为 $\\boldsymbol{X}=\\left[\\boldsymbol{x}_{1}, \\cdots, \\boldsymbol{x}_{N}\\right] \\in \\mathbb{R}^{D_{x} \\times N}$ ，输出序列为 $\\boldsymbol{H}=\\left[\\boldsymbol{h}_{1}, \\cdots, \\boldsymbol{h}_{N}\\right] \\in$ $\\mathbb{R}^{D_{v} \\times N}$ ，自注意力模型的具体计算过程如下：\n（1）对于每个输入 $\\boldsymbol{x}_{i}$ ，我们首先将其线性映射到三个不同的空间，得到查询向量 $\\boldsymbol{q}_{i} \\in \\mathbb{R}^{D_{k}}$ 、键向量 $\\boldsymbol{k}_{i} \\in \\mathbb{R}^{D_{k}}$ 和值向量 $\\boldsymbol{v}_{i} \\in \\mathbb{R}^{D_{v}}$ 。\n\n对于整个输入序列 $\\boldsymbol{X}$ ，线性映射过程可以简写为\n\n$$\n\\begin{align*}\n& Q=\\boldsymbol{W}_{q} \\boldsymbol{X} \\in \\mathbb{R}^{D_{k} \\times N},  \\tag{8.16}\\\\\n& K=\\boldsymbol{W}_{k} \\boldsymbol{X} \\in \\mathbb{R}^{D_{k} \\times N},  \\tag{8.17}\\\\\n& V=\\boldsymbol{W}_{v} \\boldsymbol{X} \\in \\mathbb{R}^{D_{v} \\times N}, \\tag{8.18}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{W}_{q} \\in \\mathbb{R}^{D_{k} \\times D_{x}}, \\boldsymbol{W}_{k} \\in \\mathbb{R}^{D_{k} \\times D_{x}}, \\boldsymbol{W}_{v} \\in \\mathbb{R}^{D_{v} \\times D_{x}}$ 分别为线性映射的参数矩阵， $\\boldsymbol{Q}=\\left[\\boldsymbol{q}_{1}, \\cdots, \\boldsymbol{q}_{N}\\right], \\boldsymbol{K}=\\left[\\boldsymbol{k}_{1}, \\cdots, \\boldsymbol{k}_{N}\\right], \\boldsymbol{V}=\\left[\\boldsymbol{v}_{1}, \\cdots, \\boldsymbol{v}_{N}\\right]$ 分别是由查询向量、键向量和值向量构成的矩阵。\n（2）对于每一个查询向量 $\\boldsymbol{q}_{n} \\in Q$ ，利用公式（8．9）的键值对注意力机制，可以\n\n自注意力也称为内部 注 意 力（Intra－ Attention）．\n\n由于在自注意力模型中通常使用点积来计算注意力打分，这里查询向量和键向量的维度是相同的。\n\n得到输出向量 $\\boldsymbol{h}_{n}$ ，\n\n$$\n\\begin{align*}\n\\boldsymbol{h}_{n} & =\\operatorname{att}\\left((K, V), \\boldsymbol{q}_{n}\\right)  \\tag{8.19}\\\\\n& =\\sum_{j=1}^{N} \\alpha_{n j} \\boldsymbol{v}_{j}  \\tag{8.20}\\\\\n& =\\sum_{j=1}^{N} \\operatorname{softmax}\\left(s\\left(\\boldsymbol{k}_{j}, \\boldsymbol{q}_{n}\\right)\\right) \\boldsymbol{v}_{j} \\tag{8.21}\n\\end{align*}\n$$\n\n其中 $n, j \\in[1, N]$ 为输出和输入向量序列的位置，$\\alpha_{n j}$ 表示第 $n$ 个输入关注到第 $j$个输入的权重。\n\n如果使用缩放点积来作为注意力打分函数，输出向量序列可以简写为\n\n$$\n\\begin{equation*}\n\\boldsymbol{H}=\\boldsymbol{V} \\text { softmax }\\left(\\frac{\\boldsymbol{K}^{\\top} \\boldsymbol{Q}}{\\sqrt{D_{k}}}\\right), \\tag{8.22}\n\\end{equation*}\n$$\n\n其中 $\\operatorname{softmax}(\\cdot)$ 为按列进行归一化的函数．\n图8．5给出全连接模型和自注意力模型的对比，其中实线表示为可学习的权重，虚线表示动态生成的权重。由于自注意力模型的权重是动态生成的，因此可以处理变长的信息序列．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-212.jpg?height=258&width=1068&top_left_y=1123&top_left_x=93)\n\n图8．5全连接模型和自注意力模型\n\n自注意力模型可以作为神经网络中的一层来使用，既可以用来替换卷积层和循环层［Vaswani et al．，2017］，也可以和它们一起交替使用（比如 $\\boldsymbol{X}$ 可以是卷积层或循环层的输出）。自注意力模型计算的权重 $\\alpha_{i j}$ 只依赖于 $\\boldsymbol{q}_{i}$ 和 $\\boldsymbol{k}_{j}$ 的相关性，\n\n参见习题 8－3．\n\n多头自注意力参见第 15．6．3节．而忽略了输入信息的位置信息。因此在单独使用时，自注意力模型一般需要加入位置编码信息来进行修正［Vaswani et al．，2017］．自注意力模型可以扩展为多头自注意力（Multi－Head Self－Attention）模型，在多个不同的投影空间中捕捉不同的交互信息。",
        "总结": "- 自注意力模型用于建立输入序列之间的长距离依赖关系，通过动态生成连接权重来处理变长序列。  \n- 自注意力模型采用查询-键-值（QKV）模式，将输入线性映射到三个不同的空间，分别生成查询矩阵Q、键矩阵K和值矩阵V。  \n- 通过点积计算查询与键之间的注意力得分，并使用softmax函数归一化，最终加权求和得到输出向量。  \n- 缩放点积注意力机制通过除以$\\sqrt{D_k}$来稳定梯度，公式为$\\boldsymbol{H} = \\boldsymbol{V} \\text{softmax}(\\frac{\\boldsymbol{K}^\\top \\boldsymbol{Q}}{\\sqrt{D_k}})$。  \n- 自注意力模型的权重是动态生成的，能够处理变长序列，与全连接模型相比具有更强的灵活性。  \n- 自注意力模型可以作为神经网络的一层，用于替代或结合卷积层和循环层。  \n- 自注意力模型在单独使用时需要加入位置编码信息以修正位置信息的缺失。  \n- 多头自注意力模型通过在多个不同的投影空间中捕捉不同的交互信息来扩展自注意力机制。"
      },
      {
        "段落": "## 8.4 人脑中的记忆\n\n在生物神经网络中，记忆是外界信息在人脑中的存储机制。大脑记忆毫无疑问是通过生物神经网络实现的。虽然其机理目前还无法解释，但直观上记忆机制 https：／／nndl．github．io／\n\n和神经网络的连接形态以及神经元的活动相关．生理学家发现信息是作为一种整体效应（collective effect）存储在大脑组织中。当大脑皮层的不同部位损伤时，其导致的不同行为表现似乎取决于损伤的程度而不是损伤的确切位置［Kohonen， 2012］．大脑组织的每个部分似乎都携带一些导致相似行为的信息。也就是说，记忆在大脑皮层是分布式存储的，而不是存储于某个局部区域［Thompson，1975］．\n\n人脑中的记忆具有周期性和联想性。\n记忆周期 虽然我们还不清楚人脑记忆的存储机制，但是已经大概可以确定不同脑区参与了记忆形成的几个阶段。人脑记忆的一个特点是，记忆一般分为长期记忆和短期记忆。长期记忆（Long－Term Memory），也称为结构记忆或知识 （Knowledge），体现为神经元之间的连接形态，其更新速度比较慢。短期记忆 （Short－Term Memory）体现为神经元的活动，更新较快，维持时间为几秒至几分钟．短期记忆是神经连接的暂时性强化，通过不断巩固、强化可形成长期记忆．短期记忆、长期记忆的动态更新过程称为演化（Evolution）过程。\n\n因此，长期记忆可以类比于人工神经网络中的权重参数，而短期记忆可以类比于人工神经网络中的隐状态。\n\n除了长期记忆和短期记忆，人脑中还会存在一个＂缓存＂，称为工作记忆 （Working Memory）。在执行某个认知行为（比如记下电话号码，算术运算）时，工作记忆是一个记忆的临时存储和处理系统，维持时间通常为几秒钟。从时间上看，工作记忆也是一种短期记忆，但和短期记忆的内涵不同。短期记忆一般指外界的输入信息在人脑中的表示和短期存储，不关心这些记忆如何被使用；而工作记忆是一个和任务相关的＂容器＂，可以临时存放和某项任务相关的短期记忆和其他相关的内在记忆．工作记忆的容量比较小，一般可以容纳 4 组项目．\n\n作为不严格的类比，现代计算机的存储也可以按照不同的周期分为不同的存储单元，比如寄存器、内存、外存（比如硬盘等）。\n\n联想记忆 大脑记忆的一个主要特点是通过联想来进行检索的。联想记忆（Asso－ ciative Memory）是指一种学习和记住不同对象之间关系的能力，比如看见一个人然后想起他的名字，或记住某种食物的味道等。\n\n联想记忆是指一种可以通过内容匹配的方法进行寻址的信息存储方式，也称为基于内容寻址的存储（Content－Addressable Memory，CAM）。作为对比，现代计算机的存储方式是根据地址来进行存储的，称为随机访问存储（Random Access Memory，RAM）．\n\n和之前介绍的 LSTM 中的记忆单元相比，外部记忆可以存储更多的信息，并且不直接参与计算，通过读写接口来进行操作。而 LSTM 模型中的记忆单元包含了信息存储和计算两种功能，不能存储太多的信息。因此，LSTM 中的记忆单元可\n\n事实上，人脑记忆周期的划分并没有清晰的界限，也存在其他的划分方法．\n\n联想记忆是一个人工智能、计算机科学和认知科学等多个交叉领域的热点研究问题，不同学科中的内涵也不太相同。\n\n以类比于计算机中的寄存器，而外部记忆可以类比于计算机中的内存单元．\n借鉴人脑中工作记忆，可以在神经网络中引入一个外部记忆单元来提高网络容量。外部记忆的实现途径有两种：一种是结构化的记忆，这种记忆和计算机中的信息存储方法比较类似，可以分为多个记忆片段，并按照一定的结构来存储；另一种是基于神经动力学的联想记忆，这种记忆方式具有更好的生物学解释性．\n\n表8．1给出了不同领域中记忆模型的不严格类比．值得注意的是，由于人脑的记忆机制十分复杂，这里列出的类比关系并不严格。\n\n表 8.1 不同领域中记忆模型的不严格类比\n\n| 记忆周期 | 计算机 | 人脑 | 神经网络 |\n| :--- | :---: | :---: | :---: |\n| 短期 | 寄存器 | 短期记忆 | 状态（神经元活性） |\n| 中期 | 内存 | 工作记忆 | 外部记忆 |\n| 长期 | 外存 | 长期记忆 | 可学习参数 |\n| 存储方式 | 随机寻址 | 内容寻址 | 内容寻址为主 |",
        "总结": "- 记忆在人脑中是通过生物神经网络实现的，存储为整体效应，分布于大脑皮层的不同区域，而非局部存储  \n- 人脑记忆具有周期性和联想性，分为长期记忆、短期记忆和工作记忆  \n- 长期记忆体现为神经元连接形态，更新较慢；短期记忆体现为神经元活动，更新较快，维持时间较短  \n- 工作记忆是临时存储和处理任务相关信息的系统，容量较小，维持时间通常为几秒  \n- 联想记忆通过内容匹配进行寻址，称为基于内容寻址的存储（CAM），与计算机的随机访问存储（RAM）不同  \n- 人脑记忆周期划分不严格，存在多种划分方法  \n- 记忆模型在不同领域有类比关系，如短期记忆类比计算机寄存器、长期记忆类比外存等  \n- 外部记忆可借鉴人脑工作记忆引入神经网络，实现结构化或基于神经动力学的联想记忆方式  \n- 表8.1展示了不同领域中记忆模型的不严格类比关系"
      },
      {
        "段落": "## 8.5 记忆增强神经网络\n\n为了增强网络容量，我们可以引入辅助记忆单元，将一些和任务相关的信息保存在辅助记忆中，在需要时再进行读取，这样可以有效地增加网络容量。这个引入的辅助记忆单元一般称为外部记忆（External Memory），以区别于循环神经网络的内部记忆（即隐状态）。这种装备外部记忆的神经网络也称为记忆增强神经网络（Memory Augmented Neural Network，MANN），或简称为记忆网络 （Memory Network，MN ）．\n\n记忆网络的典型结构如图8．6所示，一般有以下几个模块构成：\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-214.jpg?height=367&width=772&top_left_y=1660&top_left_x=276)\n\n图8．6记忆网络的典型结构\n\n以循环神经网络为例，其内部记忆可以类比于计算机的寄存器，外部记忆可以类比于计算机的内存。\n（1）主网络C：也称为控制器（Controller），负责信息处理，并与外界的交互 （接受外界的输入信息并产生输出到外界）。主网络还同时通过读写模块和外部记忆进行交互。\n（2）外部记忆单元 $\\boldsymbol{M}$ ：外部记忆单元用来存储信息，一般可以分为很多记忆片段（Memory Segment），这些记忆片段按照一定的结构来进行组织。记忆片段一般用向量来表示，外部记忆单元可以用一组向量 $\\boldsymbol{M}=\\left[\\boldsymbol{m}_{1}, \\cdots, \\boldsymbol{m}_{N}\\right]$来表示。这些向量的组织方式可以是集合、树、栈或队列等。大部分信息存储于外部记忆中，不需要全时参与主网络的运算。\n（3）读取模块 $R$ ：根据主网络生成的查询向量 $\\boldsymbol{q}_{r}$ ，从外部记忆单元中读取相应的信息 $\\boldsymbol{r}=R\\left(\\boldsymbol{M}, \\boldsymbol{q}_{r}\\right)$ 。\n（4）写入模块 $W$ ：根据主网络生成的查询向量 $\\boldsymbol{q}_{w}$ 和要写入的信息 $\\boldsymbol{a}$ 来更新外部记忆 $\\boldsymbol{M}=W\\left(\\boldsymbol{M}, \\boldsymbol{q}_{w}, \\boldsymbol{a}\\right)$ 。\n\n这种结构化的外部记忆是带有地址的，即每个记忆片段都可以按地址读取和写入。要实现类似于人脑神经网络的联想记忆能力，就需要按内容寻址的方式进行定位，然后进行读取或写入操作。按内容寻址通常使用注意力机制来进行。通过注意力机制可以实现一种＂软性＂的寻址方式，即计算一个在所有记忆片段上的分布，而不是一个单一的绝对地址。比如读取模型 $R$ 的实现方式可以为：\n\n$$\n\\begin{align*}\n\\boldsymbol{r} & =\\sum_{n=1}^{N} \\alpha_{n} \\boldsymbol{m}_{n}  \\tag{8.23}\\\\\n\\alpha_{n} & =\\operatorname{softmax}\\left(s\\left(\\boldsymbol{m}_{n}, \\boldsymbol{q}_{r}\\right)\\right) \\tag{8.24}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{q}_{r}$ 是主网络生成的查询向量，$s(\\cdot, \\cdot)$ 为打分函数。类比于计算机的存储器读取，计算注意力分布的过程相当于是计算机的＂寻址＂过程，信息加权平均的过程相当于计算机的＂内容读取＂过程。因此，结构化的外部记忆也是一种联想记忆，只是其结构以及读写的操作方式更像是受计算机架构的启发。\n\n通过引入外部记忆，可以将神经网络的参数和记忆容量＂分离＂，即在少量增加网络参数的条件下可以大幅增加网络容量。注意力机制可以看作是一个接口，将信息的存储与计算分离。\n\n外部记忆从记忆结构、读写方式等方面可以演变出很多模型。比较典型的结构化外部记忆模型包括端到端记忆网络、神经图灵机等。",
        "总结": "- 记忆增强神经网络（MANN）引入外部记忆单元，用于存储和检索任务相关信息，以增强网络容量。  \n- 外部记忆单元由多个记忆片段组成，通常用向量表示，并支持按地址或内容寻址。  \n- 主网络（控制器）负责信息处理与外部记忆的交互，通过读写模块与外部记忆进行信息交换。  \n- 读取模块根据查询向量从外部记忆中提取信息，写入模块则根据查询向量和新信息更新外部记忆。  \n- 按内容寻址通过注意力机制实现，计算每个记忆片段的权重分布，形成“软性”寻址方式。  \n- 注意力机制将信息存储与计算分离，使结构化外部记忆具备联想记忆能力。  \n- 外部记忆使神经网络参数与容量分离，在少量增加参数的情况下显著提升容量。  \n- 典型的结构化外部记忆模型包括端到端记忆网络和神经图灵机等。"
      },
      {
        "段落": "## 8．5．1 端到端记忆网络\n\n端到端记忆网络（End－To－End Memory Network，MemN2N）［Sukhbaatar et al．，2015］采用一种可微的网络结构，可以多次从外部记忆中读取信息。在端到端记忆网络中，外部记忆单元是只读的。\nhttps：／／nndl．github．io／\n\n给定一组需要存储的信息 $m_{1: N}=\\left\\{m_{1}, \\cdots, m_{N}\\right\\}$ ，首先将其转换成两组记忆片段 $A=\\left[\\boldsymbol{a}_{1}, \\cdots, \\boldsymbol{a}_{N}\\right]$ 和 $C=\\left[\\boldsymbol{c}_{1}, \\cdots, \\boldsymbol{c}_{N}\\right]$ ，分别存放在两个外部记忆单元中，其中 $A$ 用来进行寻址，$C$ 用来进行输出．\n\n主网络根据输入 $\\boldsymbol{x}$ 生成 $\\boldsymbol{q}$ ，并使用键值对注意力机制来从外部记忆中读取相关信息 $\\boldsymbol{r}$ ，\n\n$$\n\\begin{equation*}\n\\boldsymbol{r}=\\sum_{n=1}^{N} \\operatorname{softmax}\\left(\\boldsymbol{a}_{n}^{\\top} \\boldsymbol{q}\\right) \\boldsymbol{c}_{n}, \\tag{8.25}\n\\end{equation*}\n$$\n\n并产生输出\n\n$$\n\\begin{equation*}\n\\boldsymbol{y}=f(\\boldsymbol{q}+\\boldsymbol{r}) \\tag{8.26}\n\\end{equation*}\n$$\n\n其中 $f(\\cdot)$ 为预测函数．当应用到分类任务时，$f(\\cdot)$ 可以设为 Softmax 函数．\n多跳操作 为了实现更复杂的计算，我们可以让主网络和外部记忆进行多轮交互。在第 $k$ 轮交互中，主网络根据上次从外部记忆中读取的信息 $\\boldsymbol{r}^{(k-1)}$ ，产生新的查询向量\n\n$$\n\\begin{equation*}\n\\boldsymbol{q}^{(k)}=\\boldsymbol{r}^{(k-1)}+\\boldsymbol{q}^{(k-1)} \\tag{8.27}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{q}^{(0)}$ 为初始的查询向量， $\\boldsymbol{r}^{(0)}=0$ ．\n假设第 $k$ 轮交互的外部记忆为 $A^{(k)}$ 和 $C^{(k)}$ ，主网络从外部记忆读取信息为\n\n$$\n\\begin{equation*}\n\\boldsymbol{r}^{(k)}=\\sum_{n=1}^{N} \\operatorname{softmax}\\left(\\left(\\boldsymbol{a}_{n}^{(k)}\\right)^{\\top} \\boldsymbol{q}^{(k)}\\right) \\boldsymbol{c}_{n}^{(k)} \\tag{8.28}\n\\end{equation*}\n$$\n\n在 $K$ 轮交互后，用 $\\boldsymbol{y}=f\\left(\\boldsymbol{q}^{(K)}+\\boldsymbol{r}^{(K)}\\right)$ 进行预测。这种多轮的交互方式也称为多跳（Multi－Hop）操作。多跳操作中的参数一般是共享的。为了简化起见，每轮交互的外部记忆也可以共享使用，比如 $A^{(1)}=\\cdots=A^{(K)}$ 和 $C^{(1)}=\\cdots=C^{(K)}$ 。\n\n端到端记忆网络结构如图8．7所示．",
        "总结": "- 概念：端到端记忆网络（MemN2N）是一种可微的网络结构，能够多次从外部记忆中读取信息，用于处理需要记忆和检索的任务。  \n- 算法：MemN2N通过将输入信息转换为两组记忆片段 $A$ 和 $C$，分别用于寻址和输出，并利用键值对注意力机制从外部记忆中读取相关信息。  \n- 数学推导：通过 softmax 函数计算注意力权重，结合查询向量 $\\boldsymbol{q}$ 和记忆片段 $\\boldsymbol{c}_n$ 得到读取信息 $\\boldsymbol{r}$，最终输出 $\\boldsymbol{y} = f(\\boldsymbol{q} + \\boldsymbol{r})$。  \n- 多跳操作：主网络与外部记忆进行多轮交互，每轮生成新的查询向量 $\\boldsymbol{q}^{(k)}$ 和读取信息 $\\boldsymbol{r}^{(k)}$，最终通过 $K$ 轮交互后的结果进行预测。  \n- 结构特点：多跳操作中的参数通常共享，且每轮交互的外部记忆也可以共享使用。"
      },
      {
        "段落": "## 8．5．2 神经图灵机\n\n图灵机 图灵机（Turing Machine）是图灵在1936年提出的一种抽象数学模型，可以用来模拟任何可计算问题［Turing，1937］。 图灵机的结构如图8．8所示，其中控制器包括状态寄存器、控制规则。\n\n图灵机由以下几个组件构成：\n（1）一条无限长的纸带：纸带上有一个个方格组成，每个方格可以存储一个符号。\nhttps：／／nndl．github．io／\n\n为简单起见，这两组记忆单元可以合并，即 $A=C$ ．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-217.jpg?height=446&width=1095&top_left_y=128&top_left_x=123)\n\n图8．7端到端记忆网络\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-217.jpg?height=259&width=687&top_left_y=688&top_left_x=310)\n\n图8．8 图灵机结构示例\n（2）一个符号表：纸带上可能出现的所有符号的集合，包含一个特殊的空白符。\n（3）一个读写头：指向纸带上某个方格的指针，每次可以向左或右移动一个位置，并可以读取、擦除、写入当前方格中的内容。\n（4）一个状态寄存器：用来保存图灵机当前所处的状态，其中包含两个特殊的状态：起始状态和终止状态。\n（5）一套控制规则：根据当前机器所处的状态以及当前读写头所指的方格上的符号来确定读写头下一步的动作，令机器进入一个新的状态。\n\n神经图灵机 神经图灵机（Neural Turing Machine，NTM）［Graves et al．，2014］主要由两个部件构成：控制器和外部记忆。外部记忆定义为矩阵 $M \\in \\mathbb{R}^{D \\times N}$ ，这里 $N$ 是记忆片段的数量，$D$ 是每个记忆片段的大小。控制器为一个前馈或循环神经网络．神经图灵机中的外部记忆是可读写的，其结构如图8．9所示．\n\n在每个时刻 $t$ ，控制器接受当前时刻的输入 $\\boldsymbol{x}_{t}$ 、上一时刻的输出 $\\boldsymbol{h}_{t-1}$ 和上一时刻从外部记忆中读取的信息 $\\boldsymbol{r}_{t-1}$ ，并产生输出 $\\boldsymbol{h}_{t}$ ，同时生成和读写外部记忆相关的三个向量：查询向量 $\\boldsymbol{q}_{t}$ ，删除向量 $\\boldsymbol{e}_{t}$ 和增加向量 $\\boldsymbol{a}_{t}$ 。然后对外部记忆 $\\mathcal{M}_{t}$ 进行读写操作，生成读向量 $\\boldsymbol{r}_{t}$ ，和新的外部记忆 $M_{t+1}$ ．\n\n读操作 在时刻 $t$ ，外部记忆的内容记为 $\\boldsymbol{M}_{t}=\\left[\\boldsymbol{m}_{t, 1}, \\cdots, \\boldsymbol{m}_{t, N}\\right]$ ，读操作为从外部记忆 $\\boldsymbol{M}_{t}$ 中读取信息 $\\boldsymbol{r}_{t} \\in \\mathbb{R}^{D}$ ．\nhttps：／／nndl．github．io／\n\n神经图灵机中还实现了比较复杂的基于位置的寻址方式。这里我们只介绍比较简单的\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-218.jpg?height=707&width=784&top_left_y=151&top_left_x=266)\n\n图8．9神经图灵机示例\n\n首先通过注意力机制来进行基于内容的寻址，即\n\n$$\n\\begin{equation*}\n\\alpha_{t, n}=\\operatorname{softmax}\\left(s\\left(\\boldsymbol{m}_{t, n}, \\boldsymbol{q}_{t}\\right)\\right), \\tag{8.29}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{q}_{t}$ 为控制器产生的查询向量，用来进行基于内容的寻址。函数 $s(\\cdot, \\cdot)$ 为加性或乘性的打分函数。注意力分布 $\\alpha_{t, n}$ 是记忆片段 $\\boldsymbol{m}_{t, n}$ 对应的权重，并满足 $\\sum_{n=1}^{N} \\alpha_{t, n}=1$.\n\n根据注意力分布 $\\alpha_{t}$ ，可以计算读向量（read vector） $\\boldsymbol{r}_{t}$ 作为下一个时刻控制器的输入。\n\n$$\n\\begin{equation*}\n\\boldsymbol{r}_{t}=\\sum_{n=1}^{N} \\alpha_{n} \\boldsymbol{m}_{t, n} \\tag{8.30}\n\\end{equation*}\n$$\n\n写操作 外部记忆的写操作可以分解为两个子操作：删除和增加．\n首先，控制器产生删除向量（erase vector） $\\boldsymbol{e}_{t}$ 和增加向量（add vector） $\\boldsymbol{a}_{t}$ ，分别为要从外部记忆中删除的信息和要增加的信息。删除操作是根据注意力分布来按比例地在每个记忆片段中删除 $\\boldsymbol{e}_{t}$ ，增加操作是根据注意力分布来按比例地给每个记忆片段加入 $\\boldsymbol{a}_{t}$ 。具体过程如下：\n\n$$\n\\begin{equation*}\n\\boldsymbol{m}_{t+1, n}=\\boldsymbol{m}_{t, n}\\left(1-\\alpha_{t, n} \\boldsymbol{e}_{t}\\right)+\\alpha_{t, n} \\boldsymbol{a}_{t}, \\quad \\forall n \\in[1, N] \\tag{8.31}\n\\end{equation*}\n$$\n\n通过写操作得到下一时刻的外部记忆 $\\boldsymbol{M}_{t+1}$ ．",
        "总结": "- 神经图灵机（Neural Turing Machine，NTM）是一种结合图灵机和神经网络的模型，包含控制器和外部记忆两个主要部分。  \n- 外部记忆以矩阵形式表示，每个记忆片段的大小为 $D$，数量为 $N$，支持读写操作。  \n- 控制器为前馈或循环神经网络，负责生成查询向量、删除向量和增加向量，并与外部记忆交互。  \n- 读操作通过基于内容的寻址机制实现，使用注意力分布 $\\alpha_{t, n}$ 来加权组合记忆片段，生成读向量 $\\boldsymbol{r}_{t}$。  \n- 写操作包括删除和增加两个子操作，分别通过删除向量 $\\boldsymbol{e}_{t}$ 和增加向量 $\\boldsymbol{a}_{t}$ 来修改记忆片段。  \n- 写入过程通过公式 $\\boldsymbol{m}_{t+1, n} = \\boldsymbol{m}_{t, n}(1 - \\alpha_{t, n} \\boldsymbol{e}_{t}) + \\alpha_{t, n} \\boldsymbol{a}_{t}$ 实现。"
      },
      {
        "段落": "## 8.6 基于神经动力学的联想记忆\n\n结构化的外部记忆更多是受现代计算机架构的启发，将计算和存储功能进行分离，这些外部记忆的结构也缺乏生物学的解释性。为了具有更好的生物学解释性，还可以将基于神经动力学（Neurodynamics）的联想记忆模型引入到神经网络以增加网络容量。\n\n联想记忆模型（Associative Memory Model）主要是通过神经网络的动态演化来进行联想，有两种应用场景：（1）输入的模式和输出的模式在同一空间，这种模型叫做自联想模型（Auto－Associative Model）。自联想模型可以通过前馈神经网络或者循环神经网络来实现，也常称为自编码器（Auto－Encoder，AE）。 （2）输入的模式和输出的模式不在同一空间，这种模型叫做异联想模型（Hetero－ Associative Model）。从广义上讲，大部分机器学习问题都可以看作是异联想，因此异联想模型可以作为分类器使用．\n\n联想记忆模型可以看作是一种循环神经网络，基于神经动力学来实现按内容寻址的信息存储和检索。一个经典的联想记忆模型为 Hopfield 网络。",
        "总结": "- 概念：联想记忆模型，通过神经网络的动态演化进行联想，用于存储和检索信息。  \n- 算法：自联想模型（Auto-Associative Model）和异联想模型（Hetero-Associative Model）。  \n- 定理/命题：Hopfield 网络是经典的联想记忆模型，基于神经动力学实现按内容寻址。  \n- 数学推导：未明确提及具体数学推导内容，但模型基于神经动力学原理实现信息存储与检索。"
      },
      {
        "段落": "## 8．6．1 Hopfield 网络\n\n本书中之前介绍的神经网络都是作为一种机器学习模型的输入－输出映射函数，其参数学习方法是通过梯度下降方法来最小化损失函数。除了作为机器学习模型外，神经网络还可以作为一种记忆的存储和检索模型。\n\nHopfield 网络（Hopfield Network）是一种循环神经网络模型，由一组互相连接的神经元组成．Hopfield 网络也可以认为是所有神经元都互相连接的不分层的神经网络。每个神经元既是输入单元，又是输出单元，没有隐藏神经元。一个神经元和自身没有反馈相连，不同神经元之间连接权重是对称的．\n\n图8．10给出了Hopfield网络的结构示例．\n假设一个 Hopfield 网络有 $M$ 个神经元，第 $i$ 个神经元的更新规则为\n\n$$\ns_{i}= \\begin{cases}+1 & \\text { if } \\sum_{j=1}^{M} w_{i j} s_{j}+b_{i} \\geq 0  \\tag{8.32}\\\\ -1 & \\text { otherwise }\\end{cases}\n$$\n\n其中 $w_{i j}$ 为神经元 $i$ 和 $j$ 之间的连接权重，$b_{i}$ 为偏置．\n连接权重 $w_{i j}$ 有以下性质\n这里我们只介绍离散 Hopfield 网络，神经元状态为 $+1,-1$ 两种．除此之外，还有连续 Hopfield 网络，即神经元状态为连续值．\n\n$$\n\\begin{align*}\nw_{i i} & =0 & & \\forall i \\in[1, M]  \\tag{8.33}\\\\\nw_{i j} & =w_{j i} & & \\forall i, j \\in[1, M] .\n\\end{align*}\n$$\n\nhttps：／／nndl．github．io／\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-220.jpg?height=496&width=503&top_left_y=129&top_left_x=397)\n\n图8．10四个节点的 Hopfield 网络\n\nHopfield 网络的更新可以分为异步和同步两种方式。异步更新是每次更新一个神经元。神经元的更新顺序可以是随机或事先固定的。同步更新是指一次更新所有的神经元，需要有一个时钟来进行同步．第 $t$ 时刻的神经元状态为 $s_{t}=$ $\\left[s_{t, 1}, s_{t, 2}, \\cdots, s_{t, M}\\right]^{\\top}$ ，其更新规则为\n\n$$\n\\begin{equation*}\n\\boldsymbol{s}_{t}=f\\left(\\boldsymbol{W} \\boldsymbol{s}_{t-1}+\\boldsymbol{b}\\right), \\tag{8.34}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{s}_{0}=\\boldsymbol{x}, \\boldsymbol{W}=\\left[w_{i j}\\right]_{M \\times M}$ 为连接权重， $\\boldsymbol{b}=\\left[b_{i}\\right]_{M \\times 1}$ 为偏置向量，$f(\\cdot)$ 为非线性阶跃函数．\n\n能量函数 在Hopfield网络中，我们给每个不同的网络状态定义一个标量属性，称为＂能量＂。\n\n$$\n\\begin{align*}\nE & =-\\frac{1}{2} \\sum_{i, j} w_{i j} s_{i} s_{j}-\\sum_{i} b_{i} s_{i}  \\tag{8.35}\\\\\n& =-\\frac{1}{2} \\boldsymbol{s}^{\\top} \\boldsymbol{W} \\boldsymbol{s}-\\boldsymbol{b}^{\\top} \\boldsymbol{s} . \\tag{8.36}\n\\end{align*}\n$$\n\nHopfield 网络是稳定的，即能量函数经过多次迭代后会达到收敛状态．权重对称是一个重要特征，因为它保证了能量函数在神经元激活时单调递减，而不对称的权重可能导致周期性振荡或者混乱。\n\n给定一个外部输入，网络经过演化，会达到某个稳定状态．这些稳定状态称为吸引点（Attractor）。一个Hopfield网络中，通常有多个吸引点，每个吸引点为一个能量的局部最优点．\n\n图8．11给出了 Hopfield 网络的能量函数．红线为网络能量的演化方向，蓝点为吸引点。\n\n联想记忆 Hopfield网络存在有限的吸引点（Attractor），即能量函数的局部最小点。每个吸引点 $\\boldsymbol{u}$ 都对应一个＂管辖＂区域 $\\mathcal{R}_{\\boldsymbol{u}}$ ，如果输入向量 $\\boldsymbol{x}$ 落入这个区域，网 https：／／nndl．github．io／\n\n能量函数 $E$ 是 Hopfield网络的 Lyapunov 函数． Lyapunov 定理是非线性动力系统中保证系统稳定性的充分条件。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-221.jpg?height=357&width=839&top_left_y=124&top_left_x=247)\n\n图 8．11 Hopfield网络的能量函数\n\n络最终会收敛到 $\\boldsymbol{u}$ 。因此，吸引点可以看作是网络中存储的模式（Pattern）。将网络输入 $\\boldsymbol{x}$ 作为起始状态，随时间收敛到吸引点 $\\boldsymbol{u}$ 上的过程作为检索过程。即使输入向量 $\\boldsymbol{x}$ 只包含部分信息或包含噪声，只要其位于对应存储模式的＂吸引＂区域内，那么随着时间演化，网络最终会收敛到其对应的存储模式．因此，Hopfield 的检索是基于内容寻址的检索，具有联想记忆能力。\n\n信息存储 信息存储是指将一组向量 $\\boldsymbol{x}_{1}, \\cdots, \\boldsymbol{x}_{N}$ 存储在网络中的过程。存储过程主要是调整神经元之间的连接权重，因此可以看作是一种学习过程。Hopfield 网络的学习规则有很多种。 一种最简单的学习方式为：神经元 $i$ 和 $j$ 之间的连接权重通过下面公式得到\n\n$$\n\\begin{equation*}\nw_{i j}=\\frac{1}{N} \\sum_{n=1}^{N} x_{i}^{(n)} x_{j}^{(n)}, \\tag{8.37}\n\\end{equation*}\n$$\n\n其中 $x_{i}^{(n)}$ 是第 $n$ 个输入向量的第 $i$ 维特征。如果 $x_{i}$ 和 $x_{j}$ 在输入向量中相同的概率越多，则 $w_{i j}$ 越大。这种学习规则和人脑神经网络的学习方式十分类似。在人脑神经网络中，如果两个神经元经常同时激活，则它们之间的连接加强；如果两个神经元经常不同时激活，则连接消失．这种学习方式称为Hebbian法则．\n\n存储容量 对于联想记忆模型来说，存储容量为其能够可靠地存储和检索模式的最大数量。对于数量为 $M$ 的互相连接的二值神经元网络，其总状态数 $2^{M}$ ，其中可以作为有效稳定点的状态数量就是其存储容量。模型容量一般与网络结构和学习方式有关．Hopfield 网络的最大容量为 $0.14 M$ ，玻尔兹曼机的容量为 $0.6 M$ ，但是其学习效率比较低，需要非常长时间的演化才能达到均衡状态．通过改进学习算\n\n玻尔兹曼机参见第 12.1节。法，Hopfield 网络的最大容量可以达到 $O(M)$ 。如果允许高阶（阶数为 $K$ ）连接，比如三个神经元连接关系，其稳定存储的最大容量为 $O\\left(M^{K-1}\\right)$ 。［Plate，1995］引入复数运算，有效地提高了网络容量。总体上讲，通过改进网络结构、学习方式以及引入更复杂的运算（比如复数、量子操作），可以有效改善联想记忆网络的容量．",
        "总结": "- Hopfield网络是一种循环神经网络模型，由互相连接的神经元组成，所有神经元相互连接且没有隐藏层。\n- 每个神经元的状态为+1或-1，更新规则基于连接权重和偏置的线性组合，通过非线性阶跃函数决定输出。\n- 连接权重对称且自连接权重为0，确保能量函数在激活时单调递减。\n- 网络更新方式分为异步和同步两种，异步更新逐个神经元更新，同步更新同时更新所有神经元。\n- 能量函数是Hopfield网络的核心，用于衡量网络状态的稳定性，并作为Lyapunov函数保证系统收敛。\n- 吸引点（Attractor）是网络的稳定状态，对应能量函数的局部最小值，代表存储的模式。\n- Hopfield网络具有联想记忆能力，即使输入向量部分损坏或有噪声，也能收敛到对应的存储模式。\n- 信息存储通过调整连接权重实现，最简单的学习规则是Hebbian法则，即权重由输入向量的协方差决定。\n- 存储容量指网络能可靠存储和检索模式的最大数量，Hopfield网络最大容量为0.14M，可通过改进学习算法提升至O(M)。"
      },
      {
        "段落": "## 8．6．2 使用联想记忆增加网络容量\n\n既然联想记忆具有存储和检索功能，我们可以利用联想记忆来增加网络容量。和结构化的外部记忆相比，联想记忆具有更好的生物学解释性。比如，我们可以将一个联想记忆模型作为部件引入 LSTM 网络中，从而在不引入额外参数的情况下增加网络容量［Danihelka et al．，2016］；或者将循环神经网络中的部分连接权重作为短期记忆，并通过一个联想记忆模型进行更新，从而提高网络性能［Ba et al．，2016］．在上述的网络中，联想记忆都是作为一个更大网络的组件，用来增加短期记忆的容量。联想记忆组件的参数可以使用 Hebbian 方式来学习，也可以作为整个网络参数的一部分来学习。",
        "总结": "- 联想记忆具有存储和检索功能，可用于增加网络容量  \n- 联想记忆相比结构化外部记忆具有更好的生物学解释性  \n- 可将联想记忆模型作为部件引入 LSTM 网络中，增加容量而不引入额外参数  \n- 可将循环神经网络中的部分连接权重作为短期记忆，并通过联想记忆模型进行更新以提高性能  \n- 联想记忆作为更大网络的组件，用于增加短期记忆容量  \n- 联想记忆组件参数可通过 Hebbian 方式学习，或作为整个网络参数的一部分进行学习"
      },
      {
        "段落": "## 8.7 总结和深入阅读\n\n注意力机制是一种（不严格的）受人类神经系统启发的信息处理机制。比如人视觉神经系统并不会一次性地处理所有接受到的视觉信息，而是有选择性地处理部分信息，从而提高其工作效率。\n\n在人工智能领域，注意力这一概念最早是在计算机视觉中提出，用来提取图像特征．［Itti et al．，1998］提出了一种自下而上的注意力模型．该模型通过提取局部的低级视觉特征，得到一些潜在的显著（salient）区域。在神经网络中， ［Mnih et al．，2014］在循环神经网络模型上使用了注意力机制来进行图像分类． ［Bahdanau et al．，2014］使用注意力机制在机器翻译任务上将翻译和对齐同时进行。目前，注意力机制已经在语音识别、图像标题生成、阅读理解、文本分类、机器翻译等多个任务上取得了很好的效果，也变得越来越流行。注意力机制的一个重要应用是自注意力。自注意力可以作为神经网络中的一层来使用，有效地建模长距离依赖问题［Vaswani et al．，2017］．\n\n联想记忆是人脑的重要能力，涉及到人脑中信息的存储和检索机制，因此对人工神经网络都有着重要的指导意义。 通过引入外部记忆，神经网络在一定程度上可以增加模型容量。这类引入外部记忆的模型也称为记忆增强神经网络。记忆增强神经网络的代表性模型有神经图灵机［Graves et al．，2014］、端到端记忆网络［Sukhbaatar et al．，2015］、动态记忆网络［Kumar et al．，2016］等。此外，基于神经动力学的联想记忆也可以作为一种外部记忆，并具有更好的生物学解释性．［Hopfield，1984］将能量函数的概念引入到神经网络模型中，提出了 Hopfield网络．Hopfield 网络在旅行商问题上获得当时最好结果，引起轰动．有一些学者将联想记忆模型作为部件引入循环神经网络中来增加网络容量［Ba et al．，2016； Danihelka et al．，2016］，但受限于联想记忆模型的存储和检索效率，这类方法收效有限。目前人工神经网络中的外部记忆模型结构还比较简单，需要借鉴神经科学的研究成果，提出更有效的记忆模型，增加网络容量．",
        "总结": "- 注意力机制是一种受人类神经系统启发的信息处理机制，通过选择性处理信息提高效率  \n- 注意力机制最早在计算机视觉中提出，用于提取图像特征  \n- Itti et al. (1998) 提出自下而上的注意力模型，通过低级视觉特征提取显著区域  \n- Mnih et al. (2014) 在循环神经网络中使用注意力机制进行图像分类  \n- Bahdanau et al. (2014) 在机器翻译中使用注意力机制实现翻译与对齐的同步  \n- 注意力机制已广泛应用于语音识别、图像标题生成、阅读理解等任务，并流行起来  \n- 自注意力是注意力机制的重要应用，可作为神经网络的一层，有效建模长距离依赖问题  \n- 联想记忆是人脑的重要能力，涉及信息存储与检索，对人工神经网络有指导意义  \n- 引入外部记忆可增加神经网络容量，这类模型称为记忆增强神经网络  \n- 神经图灵机、端到端记忆网络、动态记忆网络是记忆增强神经网络的代表性模型  \n- 基于神经动力学的联想记忆具有更好的生物学解释性，如 Hopfield 网络  \n- Hopfield 网络引入能量函数概念，在旅行商问题上取得当时最好结果  \n- 一些学者将联想记忆模型引入循环神经网络以增加容量，但受限于存储和检索效率  \n- 当前人工神经网络中的外部记忆模型结构较简单，需借鉴神经科学成果以提高效率"
      },
      {
        "段落": "## 习题\n\n习题 8－1 分析 LSTM 模型中隐藏层神经元数量与参数数量之间的关系．\n习题 8－2 分析缩放点积模型可以缓解 Softmax 函数梯度消失的原因．\n参见公式（8．4）。\n\n习题 8－3 当用自注意力模型作为一个神经层使用时，分析它和卷积层以及循\n参见第 8.3 节．环层在建模长距离依赖关系的效率和计算复杂度方面的差异。\n\n习题 8－4 证明 Hopfield 网络的能量函数随时间单调递减．",
        "总结": "- LSTM模型中隐藏层神经元数量与参数数量的关系：隐藏层神经元数量增加会导致参数数量呈线性增长，因为每个神经元需要连接到所有输入和输出节点。  \n- 缩放点积模型缓解Softmax梯度消失的原因：通过缩放点积结果，可以避免Softmax输出在极端情况下梯度趋近于零，从而改善梯度传播。  \n- 自注意力模型与卷积层、循环层在建模长距离依赖关系的效率和计算复杂度差异：自注意力模型通过全局依赖关系建模效率更高，但计算复杂度较高；卷积层和循环层则在局部依赖建模上更高效，但处理长距离依赖关系较弱。  \n- Hopfield网络能量函数随时间单调递减的证明：通过分析网络更新规则和能量函数的定义，可以证明每次更新后能量函数值不会增加，从而保证其单调递减。"
      },
      {
        "段落": "## 参考文献\n\nBa J，Hinton G E，Mnih V，et al．Using fast weights to attend to the recent past［C］／／Advances In Neural Information Processing Systems．2016：4331－4339．\nBahdanau D，Cho K，Bengio Y．Neural machine translation by jointly learning to align and translate ［J］．ArXiv e－prints， 2014.\nDanihelka I，Wayne G，Uria B，et al．Associative long short－term memory［C］／／Proceedings of the 33nd International Conference on Machine Learning．2016：1986－1994．\nGraves A，Wayne G，Danihelka I．Neural turing machines［J］．arXiv preprint arXiv：1410．5401， 2014. Hopfield J J．Neurons with graded response have collective computational properties like those of two－state neurons［J］．Proceedings of the national academy of sciences，1984，81（10）：3088－3092．\nItti L，Koch C，Niebur E．A model of saliency－based visual attention for rapid scene analysis［J］． IEEE Transactions on Pattern Analysis \\＆Machine Intelligence，1998（11）：1254－1259．\nKim Y，Denton C，Hoang L，et al．Structured attention networks［C］／／Proceedings of 5th Interna－ tional Conference on Learning Representations． 2017.\nKohonen T．Self－organization and associative memory：volume 8［M］．Springer Science \\＆Business Media， 2012.\nKumar A，Irsoy O，Ondruska P，et al．Ask me anything：Dynamic memory networks for natural language processing［C］／／Proceedings of the 33nd International Conference on Machine Learning． 2016：1378－1387．\nMnih V，Heess N，Graves A，et al．Recurrent models of visual attention［C］／／Advances in Neural Information Processing Systems．2014：2204－2212．\nPlate T A．Holographic reduced representations［J］．IEEE Transactions on Neural networks，1995， 6（3）：623－641．\nSukhbaatar S，Weston J，Fergus R，et al．End－to－end memory networks［C］／／Advances in Neural Information Processing Systems．2015：2431－2439．\nThompson R F．Introduction to physiological psychology［M］．HarperCollins Publishers， 1975.\nTuring A M．On computable numbers，with an application to the entscheidungsproblem［J］．Pro－ ceedings of the London mathematical society，1937，2（1）：230－265．\nVaswani A，Shazeer N，Parmar N，et al．Attention is all you need［C］／／Advances in Neural Infor－ mation Processing Systems．2017：6000－6010．\nVinyals O，Fortunato M，Jaitly N．Pointer networks［C］／／Advances in Neural Information Process－ ing Systems．2015：2692－2700．\nYang Z，Yang D，Dyer C，et al．Hierarchical attention networks for document classification．［C］／／ HLT－NAACL．2016：1480－1489．\nhttps：／／nndl．github．io／",
        "总结": "- 参考文献部分列出了多个与深度学习、神经网络和注意力机制相关的研究论文和书籍，涵盖了从早期的神经网络模型到最新的注意力机制方法。  \n- 包含了如Hopfield网络、神经机器翻译、关联长短期记忆网络、神经图灵机、注意力机制、动态记忆网络、视觉注意力模型等关键概念和算法。  \n- 引用了多个重要的研究成果，如使用快速权重关注近期过去、联合对齐和翻译的神经机器翻译、端到端记忆网络、Transformer模型等。  \n- 涉及了多种数学推导和理论框架，如自组织与联想记忆、层次化注意力网络、指针网络等。  \n- 提供了相关文献的详细出处，包括会议名称、期刊名称和出版年份，便于读者进一步查阅。"
      }
    ]
  },
  {
    "标题": "第9章 无监督学习",
    "内容": [
      {
        "段落": "# 第9章 无监督学习 \n\n大脑有大约 $10^{14}$ 个突触，我们只能活大约 $10^{9}$ 秒。所以我们有比数据更多的参数。这启发了我们必须进行大量无监督学习的想法，因为感知输入（包括本体感受）是我们可以获得每秒 $10^{5}$ 维约束的唯一途径．<br>一杰井里•辛顿（Geoffrey Hinton）<br>2018年图灵奖获得者\n\n这里数字是指数量级．更早的正式描述见 ［Hinton et al．，1999］．\n\n无监督学习（Unsupervised Learning，UL）是指从无标签的数据中学习出一些有用的模式。无监督学习算法一般直接从原始数据中学习，不借助于任何人工给出标签或者反馈等指导信息。如果监督学习是建立输入－输出之间的映射关系，那么无监督学习就是发现隐藏的数据中的有价值信息，包括有效的特征、类别、结构以及概率分布等。\n\n典型的无监督学习问题可以分为以下几类：\n\n无监督特征学习 无监督特征学习（Unsupervised Feature Learning）是从无标签的训练数据中挖掘有效的特征或表示。无监督特征学习一般用来进行降维、数据可视化或监督学习前期的数据预处理。\n概率密度估计 概率密度估计（Probabilistic Density Estimation）简称密度估计，是根据一组训练样本来估计样本空间的概率密度。密度估计可以分为参数密度估计和非参数密度估计。参数密度估计是假设数据服从某个已知概率密度函数形式的分布（比如高斯分布），然后根据训练样本去估计概率密度函数的参数。非参数密度估计是不假设数据服从某个已知分布，只利用训练样本对密度进行估计，可以进行任意形状密度的估计．非参数密度估计的方法有直方图、核密度估计等．\n聚类 聚类（Clustering）是将一组样本根据一定的准则划分到不同的组（也称为集群（Cluster）。一个比较通用的准则是组内样本的相似性要高于组间样本的相似性．常见的聚类算法包括 K－Means 算法、谱聚类等．\n\n特征学习也包含很多的监督学习算法，比如线性判别分析等。\n\n和监督学习一样，无监督学习方法也包含三个基本要素：模型、学习准则和优化算法。无监督学习的准则非常多，比如最大似然估计、最小重构错误等。在无监督特征学习中，经常使用的准则为最小化重构错误，同时也经常对特征进行一些约束，比如独立性、非负性或稀释性等。而在密度估计中，经常采用最大似然估计来进行学习。\n\n本章介绍两种无监督学习问题：无监督特征学习和概率密度估计．",
        "总结": "- 无监督学习是指从无标签的数据中学习有用的模式，不依赖人工给出的标签或反馈。\n- 无监督学习的目标是发现数据中的隐藏信息，如特征、类别、结构和概率分布。\n- 典型的无监督学习问题包括无监督特征学习、概率密度估计和聚类。\n- 无监督特征学习用于从无标签数据中挖掘有效特征，常用于降维和数据预处理。\n- 概率密度估计分为参数和非参数方法，参数方法假设数据服从特定分布，非参数方法则不作假设。\n- 聚类是将样本划分到不同组，依据组内相似性高于组间相似性的准则。\n- 无监督学习包含模型、学习准则和优化算法三个基本要素。\n- 常见的学习准则包括最大似然估计和最小重构错误。\n- 在无监督特征学习中，常使用最小重构错误作为准则，并对特征施加约束条件。\n- 概率密度估计常用最大似然估计进行学习。"
      },
      {
        "段落": "## 9.1 无监督特征学习\n\n无监督特征学习是指从无标注的数据中自动学习有效的数据表示，从而能够帮助后续的机器学习模型更快速地达到更好的性能。无监督特征学习主要方法有主成分分析、稀疏编码、自编码器等。",
        "总结": "- 无监督特征学习是从无标注数据中自动学习有效数据表示的方法，旨在提升后续机器学习模型的性能。  \n- 主成分分析（PCA）、稀疏编码、自编码器是无监督特征学习的主要方法。"
      },
      {
        "段落": "## 9．1．1 主成分分析\n\n主成分分析（Principal Component Analysis，PCA）是一种最常用的数据降维方法，使得在转换后的空间中数据的方差最大。如图9．1所示的两维数据，如果将这些数据投影到一维空间中，选择数据方差最大的方向进行投影，才能最大化数据的差异性，保留更多的原始数据信息。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-225.jpg?height=482&width=575&top_left_y=1149&top_left_x=368)\n\n图9．1主成分分析\n\n假设有一组 $D$ 维的样本 $\\boldsymbol{x}^{(n)} \\in \\mathbb{R}^{D}, 1 \\leq n \\leq N$ ，我们希望将其投影到一维空间中，投影向量为 $\\boldsymbol{w} \\in \\mathbb{R}^{D}$ 。不失一般性，我们限制 $\\boldsymbol{w}$ 的模为 1 ，即 $\\boldsymbol{w}^{\\top} \\boldsymbol{w}=1$ 。每个样本点 $\\boldsymbol{x}^{(n)}$ 投影之后的表示为\n\n$$\n\\begin{equation*}\nz^{(n)}=\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)} \\tag{9.1}\n\\end{equation*}\n$$\n\n用矩阵 $\\boldsymbol{X}=\\left[\\boldsymbol{x}^{(1)}, \\boldsymbol{x}^{(2)}, \\cdots, \\boldsymbol{x}^{(N)}\\right]$ 表示输入样本，$\\overline{\\boldsymbol{x}}=\\frac{1}{N} \\sum_{n=1}^{N} \\boldsymbol{x}^{(n)}$ 为原始样 https：／／nndl．github．io／\n\n本的中心点，所有样本投影后的方差为\n\n$$\n\\begin{align*}\n\\sigma(\\boldsymbol{X} ; \\boldsymbol{w}) & =\\frac{1}{N} \\sum_{n=1}^{N}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{x}^{(n)}-\\boldsymbol{w}^{\\top} \\overline{\\boldsymbol{x}}\\right)^{2}  \\tag{9.2}\\\\\n& =\\frac{1}{N}\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{X}-\\boldsymbol{w}^{\\top} \\overline{\\boldsymbol{X}}\\right)\\left(\\boldsymbol{w}^{\\top} \\boldsymbol{X}-\\boldsymbol{w}^{\\top} \\overline{\\boldsymbol{X}}\\right)^{\\top}  \\tag{9.3}\\\\\n& =\\boldsymbol{w}^{\\top} \\boldsymbol{\\Sigma} \\boldsymbol{w} \\tag{9.4}\n\\end{align*}\n$$\n\n其中 $\\overline{\\boldsymbol{X}}=\\overline{\\boldsymbol{x}} 1_{D}^{\\top}$ 是向量 $\\overline{\\boldsymbol{x}}$ 和 $D$ 维全 1 向量 $1_{D}$ 的外积，即有 $D$ 列 $\\overline{\\boldsymbol{x}}$ 组成的矩阵， $\\boldsymbol{\\Sigma}=\\frac{1}{N}(\\boldsymbol{X}-\\overline{\\boldsymbol{X}})(\\boldsymbol{X}-\\overline{\\boldsymbol{X}})^{\\top}$ 是原始样本的协方差矩阵。\n\n最大化投影方差 $\\sigma(\\boldsymbol{X} ; \\boldsymbol{w})$ 并满足 $\\boldsymbol{w}^{\\top} \\boldsymbol{w}=1$ ，利用拉格朗日方法转换为无约束优化问题，\n\n$$\n\\begin{equation*}\n\\max _{\\boldsymbol{w}} \\boldsymbol{w}^{\\top} \\boldsymbol{\\Sigma} \\boldsymbol{w}+\\lambda\\left(1-\\boldsymbol{w}^{\\top} \\boldsymbol{w}\\right) \\tag{9.5}\n\\end{equation*}\n$$\n\n其中 $\\lambda$ 为拉格朗日乘子。对上式求导并令导数等于 0 ，可得\n\n$$\n\\begin{equation*}\n\\Sigma w=\\lambda w \\tag{9.6}\n\\end{equation*}\n$$\n\n从上式可知， $\\boldsymbol{w}$ 是协方差矩阵 $\\boldsymbol{\\Sigma}$ 的特征向量，$\\lambda$ 为特征值。同时\n\n$$\n\\begin{equation*}\n\\sigma(\\boldsymbol{X} ; \\boldsymbol{w})=\\boldsymbol{w}^{\\top} \\boldsymbol{\\Sigma} \\boldsymbol{w}=\\boldsymbol{w}^{\\top} \\lambda \\boldsymbol{w}=\\lambda . \\tag{9.7}\n\\end{equation*}\n$$\n\n$\\lambda$ 也是投影后样本的方差．因此，主成分分析可以转换成一个矩阵特征值分解问题，投影向量 $\\boldsymbol{w}$ 为矩阵 $\\boldsymbol{\\Sigma}$ 的最大特征值对应的特征向量。\n\n如果要通过投影矩阵 $\\boldsymbol{W} \\in R^{D \\times D^{\\prime}}$ 将样本投到 $D^{\\prime}$ 维空间，投影矩阵满足 $\\boldsymbol{W}^{\\top} \\boldsymbol{W}=\\boldsymbol{I}$ 为单位阵，只需要将 $\\boldsymbol{\\Sigma}$ 的特征值从大到小排列，保留前 $D^{\\prime}$ 个特征向量，其对应的特征向量即是最优的投影矩阵。\n\n$$\n\\begin{equation*}\n\\boldsymbol{\\Sigma} \\boldsymbol{W}=\\boldsymbol{W} \\operatorname{diag}(\\lambda) \\tag{9.8}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{\\lambda}=\\left[\\lambda_{1}, \\cdots, \\lambda_{D^{\\prime}}\\right]$ 为 $S$ 的前 $D^{\\prime}$ 个最大的特征值．\n主成分分析是一种无监督学习方法，可以作为监督学习的数据预处理方法，用来去除噪声并减少特征之间的相关性，但是它并不能保证投影后数据的类别可分性更好。提高两类可分性的方法一般为监督学习方法，比如线性判别分析参见习题 9－3． （ Linear Discriminant Analysis，LDA）．",
        "总结": "- 主成分分析（PCA）是一种数据降维方法，目标是在转换后的空间中最大化数据的方差。  \n- 投影向量 $\\boldsymbol{w}$ 满足单位长度约束 $\\boldsymbol{w}^{\\top} \\boldsymbol{w} = 1$，投影后的方差由协方差矩阵 $\\boldsymbol{\\Sigma}$ 决定。  \n- 投影方差公式为 $\\sigma(\\boldsymbol{X}; \\boldsymbol{w}) = \\boldsymbol{w}^{\\top} \\boldsymbol{\\Sigma} \\boldsymbol{w}$，其最大化通过拉格朗日乘数法转化为无约束优化问题。  \n- 最优化问题的解为协方差矩阵 $\\boldsymbol{\\Sigma}$ 的特征向量，对应特征值即为投影后的方差。  \n- 投影矩阵 $\\boldsymbol{W}$ 由协方差矩阵的前 $D^{\\prime}$ 个最大特征值对应的特征向量组成。  \n- 主成分分析是无监督学习方法，可作为数据预处理手段，用于去噪和减少特征相关性，但不保证类别可分性。"
      },
      {
        "段落": "## 9．1．2 稀疏编码\n\n稀疏编码（Sparse Coding）也是一种受哺乳动物视觉系统中简单细胞感受野而启发的模型。在哺乳动物的初级视觉皮层（Primary Visual Cortex）中，每 https：／／nndl．github．io／\n\n个神经元仅对处于其感受野中特定的刺激信号（比如特定方向的边缘、条纹等特征）做出响应。局部感受野可以被描述为具有空间局部性、方向性和带通性（即不同尺度下空间结构的敏感性）［Olshausen et al．，1996］。也就是说，外界信息经过编码后仅有一小部分神经元激活，即外界刺激在视觉神经系统的表示具有很高的稀疏性．编码的稀疏性在一定程度上符合生物学的低功耗特性．\n\n在数学上，（线性）编码是指给定一组基向量 $\\boldsymbol{A}=\\left[\\boldsymbol{a}_{1}, \\cdots, \\boldsymbol{a}_{M}\\right]$ ，将输入样本 $x \\in \\mathbb{R}^{D}$ 表示为这些基向量的线性组合\n\n$$\n\\begin{align*}\n\\boldsymbol{x} & =\\sum_{m=1}^{M} z_{m} \\boldsymbol{a}_{m}  \\tag{9.9}\\\\\n& =\\boldsymbol{A z} \\tag{9.10}\n\\end{align*}\n$$\n\n其中基向量的系数 $\\boldsymbol{z}=\\left[z_{1}, \\cdots, z_{M}\\right]$ 称为输入样本 $\\boldsymbol{x}$ 的编码（Encoding），基向量 $\\boldsymbol{A}$ 也称为字典（Dictionary）。\n\n编码是对 $D$ 维空间中的样本 $\\boldsymbol{x}$ 找到其在 $P$ 维空间中的表示（或投影），其目标通常是编码的各个维度都是统计独立的，并且可以重构出输入样本。编码的关键是找到一组＂完备＂的基向量 $\\boldsymbol{A}$ ，比如主成分分析等。但是主成分分析得到的编码通常是稠密向量，没有稀疏性。",
        "总结": "- 稀疏编码是一种受哺乳动物视觉系统中简单细胞感受野启发的模型，强调外界刺激在神经系统的表示具有高稀疏性。\n- 数学上，稀疏编码通过基向量的线性组合表示输入样本，即 $ \\boldsymbol{x} = \\boldsymbol{A z} $，其中 $ \\boldsymbol{A} $ 是字典，$ \\boldsymbol{z} $ 是编码。\n- 编码的目标是找到一组“完备”的基向量，使得输入样本在低维空间中的表示具有统计独立性和可重构性。\n- 主成分分析等方法虽然能提供完备的基向量，但通常得到的是稠密向量，缺乏稀疏性。"
      },
      {
        "段落": "## 数学小知识 1 完备性\n\n如果 $M$ 个基向量刚好可以支撑 $M$ 维的欧氏空间，则这 $M$ 个基向量是完备的。如果 $M$ 个基向量可以支撑 $D$ 维的欧氏空间，并且 $M>D$ ，则这 $M$ 个基向量是过完备的（overcomplete）、冗余的。\n＂过完备＂基向量是指基向量个数远远大于其支撑空间维度。因此这些基向量一般不具备独立、正交等性质．\n\n为了得到稀疏的编码，我们需要找到一组＂过完备＂的基向量（即 $M>D$ ）来进行编码。在过完备基向量之间往往会存在一些冗余性，因此对于一个输入样本，会存在很多有效的编码。如果加上稀疏性限制，就可以减少解空间的大小，得到 ＂唯一＂的稀疏编码。\n\n给定一组 $N$ 个输入向量 $\\boldsymbol{x}^{(1)}, \\cdots, \\boldsymbol{x}^{(N)}$ ，其稀疏编码的目标函数定义为\n\n$$\n\\begin{equation*}\n\\mathcal{L}(\\boldsymbol{A}, \\boldsymbol{Z})=\\sum_{n=1}^{N}\\left(\\left\\|\\boldsymbol{x}^{(n)}-A \\boldsymbol{z}^{(n)}\\right\\|^{2}+\\eta \\rho\\left(\\boldsymbol{z}^{(n)}\\right)\\right), \\tag{9.11}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{Z}=\\left[\\boldsymbol{z}^{(1)}, \\cdots, \\boldsymbol{z}^{(N)}\\right], \\rho(\\cdot)$ 是一个稀疏性衡量函数，$\\eta$ 是一个超参数，用来控制稀疏性的强度．\nhttps：／／nndl．github．io／\n\n带通滤波器（Band－ pass Filter）是指容许某个频率范围的信号通过，同时屏蔽其他频段的设备．\n\n对于一个向量 $\\boldsymbol{z} \\in \\mathbb{R}^{M}$ ，其稀疏性定义为非零元素的比例．如果一个向量只有很少的几个非零元素，就说这个向量是稀疏的。稀疏性衡量函数 $\\rho(\\boldsymbol{z})$ 是给向量 $\\boldsymbol{z}$ 一个标量分数． $\\boldsymbol{z}$ 越稀疏，$\\rho(\\boldsymbol{z})$ 越小．\n\n稀疏性衡量函数有多种选择，最直接的衡量向量 $\\boldsymbol{z}$ 稀疏性的函数是 $\\ell_{0}$ 范数\n\n$$\n\\begin{equation*}\n\\rho(\\boldsymbol{z})=\\sum_{m=1}^{M} \\mathbf{I}\\left(\\left|z_{m}\\right|>0\\right) \\tag{9.12}\n\\end{equation*}\n$$\n\n但 $\\ell_{0}$ 范数不满足连续可导，因此很难进行优化．在实际中，稀疏性衡量函数通常使用 $\\ell_{1}$ 范数\n\n$$\n\\begin{equation*}\n\\rho(\\boldsymbol{z})=\\sum_{m=1}^{M}\\left|z_{m}\\right| \\tag{9.13}\n\\end{equation*}\n$$\n\n或对数函数\n\n$$\n\\begin{equation*}\n\\rho(\\boldsymbol{z})=\\sum_{m=1}^{M} \\log \\left(1+z_{m}^{2}\\right), \\tag{9.14}\n\\end{equation*}\n$$\n\n或指数函数\n\n$$\n\\begin{equation*}\n\\rho(\\boldsymbol{z})=\\sum_{m=1}^{M}-\\exp \\left(-z_{m}^{2}\\right) . \\tag{9.15}\n\\end{equation*}\n$$",
        "总结": "- 完备性：M个基向量若能支撑M维欧氏空间，则称为完备；若M>D且支撑D维空间，则称为过完备（冗余），通常不具备独立、正交等性质。  \n- 稀疏编码目标：通过过完备基向量进行编码，结合稀疏性限制以获得唯一稀疏编码。  \n- 目标函数：定义为输入向量与编码重构误差的平方和，加上稀疏性惩罚项，形式为 $\\mathcal{L}(\\boldsymbol{A}, \\boldsymbol{Z})=\\sum_{n=1}^{N}\\left(\\left\\|\\boldsymbol{x}^{(n)}-A \\boldsymbol{z}^{(n)}\\right\\|^{2}+\\eta \\rho\\left(\\boldsymbol{z}^{(n)}\\right)\\right)$。  \n- 稀疏性定义：向量中非零元素的比例，稀疏性越高，对应的稀疏性衡量函数值越小。  \n- 稀疏性衡量函数：包括 $\\ell_0$ 范数（计数非零元素）、$\\ell_1$ 范数（求和绝对值）、对数函数和指数函数等，其中 $\\ell_0$ 范数不连续可导，实际中常用 $\\ell_1$ 范数。"
      },
      {
        "段落": "### 9．1．2．1 训练方法\n\n给定一组 $N$ 个输入向量 $\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ ，需要同时学习基向量 $\\boldsymbol{A}$ 以及每个输入样本对应的稀疏编码 $\\left\\{\\boldsymbol{z}^{(n)}\\right\\}_{n=1}^{N}$ 。\n\n稀疏编码的训练过程一般用交替优化的方法进行。\n1）固定基向量 $\\boldsymbol{A}$ ，对每个输入 $\\boldsymbol{x}^{(n)}$ ，计算其对应的最优编码\n\n$$\n\\begin{equation*}\n\\min _{\\boldsymbol{z}^{(n)}}\\left\\|\\boldsymbol{x}^{(n)}-\\boldsymbol{A} \\boldsymbol{z}^{(n)}\\right\\|^{2}+\\eta \\rho\\left(\\boldsymbol{z}^{(n)}\\right), \\forall n \\in[1, N] . \\tag{9.16}\n\\end{equation*}\n$$\n\n2）固定上一步得到的编码 $\\left\\{\\boldsymbol{z}^{(n)}\\right\\}_{n=1}^{N}$ ，计算其最优的基向量\n\n$$\n\\begin{equation*}\n\\min _{\\boldsymbol{A}} \\sum_{n=1}^{N}\\left(\\left\\|\\boldsymbol{x}^{(n)}-\\boldsymbol{A} \\boldsymbol{z}^{(n)}\\right\\|^{2}\\right)+\\lambda \\frac{1}{2}\\|\\boldsymbol{A}\\|^{2}, \\tag{9.17}\n\\end{equation*}\n$$\n\n其中第二项为正则化项，$\\lambda$ 为正则化项系数．",
        "总结": "- 提出稀疏编码训练方法，通过交替优化基向量 $\\boldsymbol{A}$ 和编码 $\\boldsymbol{z}^{(n)}$ 来实现。\n- 在固定基向量 $\\boldsymbol{A}$ 的情况下，对每个输入 $\\boldsymbol{x}^{(n)}$ 计算最优编码 $\\boldsymbol{z}^{(n)}$，目标函数为重构误差与稀疏性惩罚项的加权和。\n- 在固定编码 $\\boldsymbol{z}^{(n)}$ 的情况下，优化基向量 $\\boldsymbol{A}$，目标函数为所有输入的重构误差总和加上正则化项，用于防止基向量过拟合。"
      },
      {
        "段落": "### 9．1．2．2 稀疏编码的优点\n\n稀疏编码的每一维都可以看作是一种特征．和基于稠密向量的分布式表示相比，稀疏编码具有更小的计算量和更好的可解释性等优点。\nhttps：／／nndl．github．io／\n\n由于通常比较难以得到严格的稀疏向量，因此如果一个向量只有少数几个远大于零的元素，其他元素都接近于 0 ，我们也称这个向量为稀疏向量．\n\n参见习题 9－6．\n\n计算量 稀疏性带来的最大好处就是可以极大地降低计算量．\n可解释性 因为稀疏编码只有少数的非零元素，相当于将一个输入样本表示为少数几个相关的特征．这样我们可以更好地描述其特征，并易于理解．\n\n特征选择 稀疏性带来的另外一个好处是可以实现特征的自动选择，只选择和输入样本最相关的少数特征，从而更高效地表示输入样本，降低噪声并减轻过拟合。",
        "总结": "- 稀疏编码的每一维可视为一种特征  \n- 稀疏编码相比稠密向量具有更小的计算量和更好的可解释性  \n- 稀疏向量指仅有少数元素远大于零，其余接近于零的向量  \n- 稀疏性可显著降低计算量  \n- 稀疏编码通过少数非零元素表示输入样本，增强特征描述和可理解性  \n- 稀疏性有助于自动选择与输入样本最相关的特征，提升表示效率并减少噪声与过拟合"
      },
      {
        "段落": "## 9．1．3 自编码器\n\n自编码器（Auto－Encoder，AE）是通过无监督的方式来学习一组数据的有效编码（或表示）。\n\n假设有一组 $D$ 维的样本 $\\boldsymbol{x}^{(n)} \\in \\mathbb{R}^{D}, 1 \\leq n \\leq N$ ，自编码器将这组数据映射到特征空间得到每个样本的编码 $\\boldsymbol{z}^{(n)} \\in \\mathbb{R}^{M}, 1 \\leq n \\leq N$ ，并且希望这组编码可以重构出原来的样本．\n\n自编码器的结构可分为两部分：\n编码器（Encoder）\n\n$$\n\\begin{equation*}\nf: \\mathbb{R}^{D} \\rightarrow \\mathbb{R}^{M} \\tag{9.18}\n\\end{equation*}\n$$\n\n和解码器（Decoder）\n\n$$\n\\begin{equation*}\ng: \\mathbb{R}^{M} \\rightarrow \\mathbb{R}^{D} \\tag{9.19}\n\\end{equation*}\n$$\n\n自编码器的学习目标是最小化重构错误（Reconstruction Error）\n\n$$\n\\begin{align*}\n\\mathcal{L} & =\\sum_{n=1}^{N}\\left\\|\\boldsymbol{x}^{(n)}-g\\left(f\\left(\\boldsymbol{x}^{(n)}\\right)\\right)\\right\\|^{2}  \\tag{9.20}\\\\\n& =\\sum_{n=1}^{N}\\left\\|\\boldsymbol{x}^{(n)}-f \\circ g\\left(\\boldsymbol{x}^{(n)}\\right)\\right\\|^{2} \\tag{9.21}\n\\end{align*}\n$$\n\n如果特征空间的维度 $M$ 小于原始空间的维度 $D$ ，自编码器相当于是一种降维或特征抽取方法。如果 $M \\geq D$ ，一定可以找到一组或多组解使得 $f \\circ g$ 为单位函数（Identity Function），并使得重构错误为 0 。然而，这样的解并没有太多的意单位函数 $I(x)=x$ ．义．但是，如果再加上一些附加的约束，就可以得到一些有意义的解，比如编码的稀疏性、取值范围，$f$ 和 $g$ 的具体形式等。如果我们让编码只能取 $K$ 个不同的值 $(K<N)$ ，那么自编码器就可以转换为一个 $K$ 类的聚类（Clustering）问题。\n\n最简单的自编码器是如图9．2所示的两层神经网络．输入层到隐藏层用来编码，隐藏层到输出层用来解码，层与层之间互相全连接。\nhttps：／／nndl．github．io／\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-230.jpg?height=437&width=455&top_left_y=128&top_left_x=435)\n\n图 9.2 两层网络结构的自编码器\n\n对于样本 $\\boldsymbol{x}$ ，自编码器的中间隐藏层的活性值为 $\\boldsymbol{x}$ 的编码，即\n\n$$\n\\begin{equation*}\n\\boldsymbol{z}=f\\left(\\boldsymbol{W}^{(1)} \\boldsymbol{x}+\\boldsymbol{b}^{(1)}\\right), \\tag{9.22}\n\\end{equation*}\n$$\n\n自编码器的输出为重构的数据\n\n$$\n\\begin{equation*}\n\\boldsymbol{x}^{\\prime}=f\\left(\\boldsymbol{W}^{(2)} \\boldsymbol{z}+\\boldsymbol{b}^{(2)}\\right), \\tag{9.23}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{W}^{(1)}, \\boldsymbol{W}^{(2)}, \\boldsymbol{b}^{(1)}, \\boldsymbol{b}^{(2)}$ 为网络参数，$f(\\cdot)$ 为激活函数。如果令 $\\boldsymbol{W}^{(2)}$ 等于 $\\boldsymbol{W}^{(1)}$的转置，即 $\\boldsymbol{W}^{(2)}=\\boldsymbol{W}^{(1)^{\\top}}$ ，称为捆绑权重（Tied Weight）。捆绑权重自编码器的参数更少，因此更容易学习．此外，捆绑权重还在一定程度上起到正则化的作用．\n\n给定一组样本 $\\boldsymbol{x}^{(n)} \\in[0,1]^{D}, 1 \\leq n \\leq N$ ，其重构错误为\n\n$$\n\\begin{equation*}\n\\left.\\mathcal{L}=\\sum_{n=1}^{N} \\| \\boldsymbol{x}^{(n)}-\\boldsymbol{x}^{\\prime(n)}\\right)\\left\\|^{2}+\\lambda\\right\\| \\boldsymbol{W} \\|_{F}^{2} . \\tag{9.24}\n\\end{equation*}\n$$\n\n其中 $\\lambda$ 为正则化项系数．通过最小化重构错误，可以有效地学习网络的参数．\n我们使用自编码器是为了得到有效的数据表示，因此在训练结束后，我们一般会去掉解码器，只保留编码器。编码器的输出可以直接作为后续机器学习模型的输入。",
        "总结": "- 自编码器是一种通过无监督学习获取数据有效编码的方法  \n- 自编码器由编码器和解码器两部分组成，分别实现数据映射到特征空间和从特征空间重构数据  \n- 学习目标是最小化重构错误，即输入数据与重构数据之间的差异  \n- 当特征空间维度小于原始数据维度时，自编码器可作为降维或特征提取工具  \n- 若特征空间维度大于等于原始维度，可得到单位函数解，但缺乏实际意义  \n- 通过附加约束（如稀疏性、编码取值范围等）可获得有意义的解  \n- 最简单的自编码器是两层神经网络，输入层到隐藏层为编码，隐藏层到输出层为解码  \n- 编码为输入数据经过激活函数后的输出，解码为编码经过另一组参数和激活函数得到的重构数据  \n- 捆绑权重（即解码器权重等于编码器权重的转置）可减少参数数量并起到正则化作用  \n- 重构错误包含数据重构项和正则化项，通过最小化该目标函数学习网络参数  \n- 训练完成后通常移除解码器，仅保留编码器用于后续机器学习任务"
      },
      {
        "段落": "## 9．1．4 稀疏自编码器\n\n自编码器除了可以学习低维编码之外，也能够学习高维的稀疏编码。假设中间隐藏层 $\\boldsymbol{z}$ 的维度 $M$ 大于输入样本 $\\boldsymbol{x}$ 的维度 $D$ ，并让 $\\boldsymbol{z}$ 尽量稀疏，这就是稀疏自编码器（Sparse Auto－Encoder）。和稀疏编码一样，稀疏自编码器的优点是有很高的可解释性，并同时进行了隐式的特征选择．\n\n通过给自编码器中隐藏层单元 $\\boldsymbol{z}$ 加上稀疏性限制，自编码器可以学习到数据\n\n中一些有用的结构。给定 $N$ 个训练样本 $\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ ，稀疏自编码器的目标函数为\n\n$$\n\\begin{equation*}\n\\left.\\mathcal{L}=\\sum_{n=1}^{N} \\| \\boldsymbol{x}^{(n)}-\\boldsymbol{x}^{\\prime(n)}\\right)\\left\\|^{2}+\\eta \\rho(\\boldsymbol{Z})+\\lambda\\right\\| \\boldsymbol{W} \\|^{2} \\tag{9.25}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{Z}=\\left[\\boldsymbol{z}^{(1)}, \\cdots, \\boldsymbol{z}^{(N)}\\right]$ 表示所有训练样本的编码，$\\rho(Z)$ 为稀疏性度量函数， $\\boldsymbol{W}$表示自编码器中的参数。\n\n稀疏性度量函数 $\\rho(\\boldsymbol{Z})$ 可以使用公式（9．13）～公式（9．15）中的稀疏性定义，分别计算每个编码 $\\boldsymbol{z}^{(n)}$ 的稀疏度，再进行求和。此外，$\\rho(\\boldsymbol{Z})$ 还可以定义为一组训练样本中每一个神经元激活的概率．\n\n给定 $N$ 个训练样本，隐藏层第 $j$ 个神经元平均活性值为\n\n$$\n\\begin{equation*}\n\\hat{\\rho}_{j}=\\frac{1}{N} \\sum_{n=1}^{N} z_{j}^{(n)} \\tag{9.26}\n\\end{equation*}\n$$\n\n其中 $\\hat{\\rho}_{j}$ 可以近似地看作是第 $j$ 个神经元激活的概率。我们希望 $\\hat{\\rho}_{j}$ 接近于一个事先给定的值 $\\rho^{*}$ ，比如 0.05 ，可以通过 KL 距离来衡量 $\\hat{\\rho}_{j}$ 和 $\\rho^{*}$ 的差异，即\n\n$$\n\\begin{equation*}\n\\mathrm{KL}\\left(\\rho^{*} \\| \\hat{\\rho}_{j}\\right)=\\rho^{*} \\log \\frac{\\rho^{*}}{\\hat{\\rho}_{j}}+\\left(1-\\rho^{*}\\right) \\log \\frac{1-\\rho^{*}}{1-\\hat{\\rho}_{j}} \\tag{9.27}\n\\end{equation*}\n$$\n\n如果 $\\hat{\\rho}_{j}=\\rho^{*}$ ，则 $\\mathrm{KL}\\left(\\rho^{*} \\| \\hat{\\rho}_{j}\\right)=0$ 。\n稀疏性度量函数定义为\n\n$$\n\\begin{equation*}\n\\rho(\\boldsymbol{Z})=\\sum_{j=1}^{p} \\mathrm{KL}\\left(\\rho^{*} \\| \\hat{\\rho}_{j}\\right) . \\tag{9.28}\n\\end{equation*}\n$$",
        "总结": "- 稀疏自编码器是一种能够学习高维稀疏编码的自编码器，通过让中间隐藏层 $\\boldsymbol{z}$ 的维度 $M$ 大于输入维度 $D$ 并使其尽量稀疏来实现。  \n- 稀疏自编码器的目标函数包括重构误差、稀疏性惩罚项和参数正则化项，公式为 $\\mathcal{L}=\\sum_{n=1}^{N} \\| \\boldsymbol{x}^{(n)}-\\boldsymbol{x}^{\\prime(n)}\\|^{2}+\\eta \\rho(\\boldsymbol{Z})+\\lambda\\| \\boldsymbol{W} \\|^{2}$。  \n- 稀疏性度量函数 $\\rho(\\boldsymbol{Z})$ 可以通过计算每个编码 $\\boldsymbol{z}^{(n)}$ 的稀疏度并求和，或定义为神经元激活的概率。  \n- 隐藏层第 $j$ 个神经元的平均活性值 $\\hat{\\rho}_{j}$ 表示其激活概率，公式为 $\\hat{\\rho}_{j}=\\frac{1}{N} \\sum_{n=1}^{N} z_{j}^{(n)}$。  \n- 通过 KL 距离衡量 $\\hat{\\rho}_{j}$ 与目标稀疏度 $\\rho^{*}$ 的差异，公式为 $\\mathrm{KL}\\left(\\rho^{*} \\| \\hat{\\rho}_{j}\\right)=\\rho^{*} \\log \\frac{\\rho^{*}}{\\hat{\\rho}_{j}}+\\left(1-\\rho^{*}\\right) \\log \\frac{1-\\rho^{*}}{1-\\hat{\\rho}_{j}}$。  \n- 稀疏性度量函数最终定义为所有神经元的 KL 距离之和，即 $\\rho(\\boldsymbol{Z})=\\sum_{j=1}^{p} \\mathrm{KL}\\left(\\rho^{*} \\| \\hat{\\rho}_{j}\\right)$。"
      },
      {
        "段落": "## 9．1．5 堆叠自编码器\n\n对于很多数据来说，仅使用两层神经网络的自编码器还不足以获取一种好的数据表示。为了获取更好的数据表示，我们可以使用更深层的神经网络。深层神经网络作为自编码器提取的数据表示一般会更加抽象，能够更好地捕捉到数据的语义信息。在实践中经常使用逐层堆叠的方式来训练一个深层的自编码器，称为堆叠自编码器（Stacked Auto－Encoder，SAE）。堆叠自编码器一般可以采用逐层训练（Layer－Wise Training）来学习网络参数［Bengio et al．，2007］．",
        "总结": "- 堆叠自编码器（Stacked Auto-Encoder，SAE）是一种通过逐层堆叠方式构建的深层神经网络自编码器。  \n- 它通过逐层训练（Layer-Wise Training）来学习网络参数，从而提取更抽象的数据表示。  \n- 堆叠自编码器能够更好地捕捉数据的语义信息，相较于两层自编码器，能提供更优的数据表示。  \n- 该方法在实践中被广泛采用，以提升数据表示的质量。"
      },
      {
        "段落": "## 9．1．6 降噪自编码器\n\n我们使用自编码器是为了得到有效的数据表示，而有效的数据表示除了具有最小重构错误或稀疏性等性质之外，还可以要求其具备其他性质，比如对数据部分损坏（Partial Destruction）的鲁棒性。高维数据（比如图像）一般都具有一定的信息冗余，比如我们可以根据一张部分破损的图像联想出其完整内容。因此，我 https：／／nndl．github．io／\n\n们希望自编码器也能够从部分损坏的数据中得到有效的数据表示，并能够恢复出完整的原始信息。\n\n降噪自编码器（Denoising Auto－Encoder）就是一种通过引入噪声来增加编码鲁棒性的自编码器［Vincent et al．，2008］．对于一个向量 $\\boldsymbol{x}$ ，我们首先根据一个比例 $\\mu$ 随机将 $\\boldsymbol{x}$ 的一些维度的值设置为 0 ，得到一个被损坏的向量 $\\tilde{\\boldsymbol{x}}$ 。然后将被损坏的向量 $\\tilde{\\boldsymbol{x}}$ 输入给自编码器得到编码 $\\boldsymbol{z}$ ，并重构出原始的无损输入 $\\boldsymbol{x}$ 。\n\n图9．3给出了自编码器和降噪自编码器的对比，其中 $f_{\\theta}$ 为编码器，$g_{\\theta^{\\prime}}$ 为解码器， $\\mathcal{L}\\left(\\boldsymbol{x}, \\boldsymbol{x}^{\\prime}\\right)$ 为重构错误。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-232.jpg?height=457&width=968&top_left_y=635&top_left_x=176)\n\n图 9.3 自编码器和降噪自编码器\n\n降噪自编码器的思想十分简单，通过引入噪声来学习更鲁棒性的数据编码，并提高模型的泛化能力。",
        "总结": "- 降噪自编码器是一种通过引入噪声来增强编码鲁棒性的自编码器，旨在从部分损坏的数据中学习有效的数据表示并恢复原始信息。  \n- 其核心思想是：对输入向量 $\\boldsymbol{x}$ 随机设置部分维度为0，生成被损坏的向量 $\\tilde{\\boldsymbol{x}}$，然后通过编码器和解码器重构原始输入 $\\boldsymbol{x}$。  \n- 降噪自编码器的目标是提高模型的泛化能力，使其对数据损坏具有鲁棒性。  \n- 重构错误 $\\mathcal{L}(\\boldsymbol{x}, \\boldsymbol{x}^{\\prime})$ 是衡量重构效果的关键指标。  \n- 图9.3对比了普通自编码器与降噪自编码器的结构和工作流程。"
      },
      {
        "段落": "## 9.2 概率密度估计\n\n概率密度估计（Probabilistic Density Estimation），简称密度估计（Density Estimation），是基于一些观测样本来估计一个随机变量的概率密度函数。密度估计在数据建模、机器学习中使用广泛。\n\n密度估计方法可以分为两类：参数密度估计和非参数密度估计．",
        "总结": "- 概念：概率密度估计是基于观测样本来估计随机变量的概率密度函数的方法。  \n- 方法分类：密度估计方法分为参数密度估计和非参数密度估计两类。"
      },
      {
        "段落": "## 9．2．1 参数密度估计\n\n参数密度估计（Parametric Density Estimation）是根据先验知识假设随机变量服从某种分布，然后通过训练样本来估计分布的参数。\n\n令 $\\mathcal{D}=\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ 为从某个未知分布中独立抽取的 $N$ 个训练样本，假设这些\n\n损坏比例 $\\mu$ 一般不超过 0.5 ．也可以使用其他的方法来损坏数据，比如引入高斯噪声。\n\n样本服从一个概率分布函数 $p(\\boldsymbol{x} ; \\theta)$ ，其对数似然函数为\n\n$$\n\\begin{equation*}\n\\log p(\\mathcal{D} ; \\theta)=\\sum_{n=1}^{N} \\log p\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right) \\tag{9.29}\n\\end{equation*}\n$$\n\n我们要估计一个参数 $\\theta^{M L}$ 来使得\n\n$$\n\\begin{equation*}\n\\theta^{M L}=\\underset{\\theta}{\\arg \\max } \\sum_{n=1}^{N} \\log p\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right) \\tag{9.30}\n\\end{equation*}\n$$\n\n这样参数估计问题就转化为最优化问题．",
        "总结": "- 参数密度估计基于先验知识假设随机变量服从某种分布，并通过训练样本来估计分布的参数。  \n- 定义训练样本集 $\\mathcal{D}=\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$，假设这些样本服从概率分布函数 $p(\\boldsymbol{x} ; \\theta)$。  \n- 对数似然函数为 $\\log p(\\mathcal{D} ; \\theta)=\\sum_{n=1}^{N} \\log p\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)$。  \n- 通过最大化对数似然函数来估计参数 $\\theta^{M L}$，即 $\\theta^{M L}=\\underset{\\theta}{\\arg \\max } \\sum_{n=1}^{N} \\log p\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)$。  \n- 参数估计问题转化为最优化问题。"
      },
      {
        "段落": "### 9．2．1．1 正态分布\n\n假设样本 $\\boldsymbol{x} \\in \\mathbb{R}^{D}$ 服从正态分布\n\n$$\n\\begin{equation*}\n\\mathcal{N}(\\boldsymbol{x} \\mid \\boldsymbol{\\mu}, \\Sigma)=\\frac{1}{(2 \\pi)^{D / 2}|\\Sigma|^{1 / 2}} \\exp \\left(-\\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^{\\top} \\Sigma^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu})\\right), \\tag{9.31}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{\\mu}$ 和 $\\boldsymbol{\\Sigma}$ 分别为正态分布的均值和方差．\n数据集 $\\mathcal{D}=\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ 的对数似然函数为\n\n$$\n\\begin{equation*}\n\\log p(\\mathcal{D} \\mid \\mu, \\Sigma)=-\\frac{N}{2} \\log \\left((2 \\pi)^{D}|\\Sigma|\\right)-\\frac{1}{2} \\sum_{n=1}^{N}\\left(\\boldsymbol{x}^{(n)}-\\mu\\right)^{\\top} \\Sigma^{-1}\\left(\\boldsymbol{x}^{(n)}-\\mu\\right) \\tag{9.32}\n\\end{equation*}\n$$\n\n分别求上式关于 $\\mu, \\Sigma$ 的偏导数，并令其等于 0 。可得，\n\n$$\n\\begin{align*}\n\\mu^{M L} & =\\frac{1}{N} \\sum_{n=1}^{N} \\boldsymbol{x}^{(n)}  \\tag{9.33}\\\\\n\\Sigma^{M L} & =\\frac{1}{N} \\sum_{n=1}^{N}\\left(\\boldsymbol{x}^{(n)}-\\mu^{M L}\\right)\\left(\\boldsymbol{x}^{(n)}-\\mu^{M L}\\right)^{\\top} \\tag{9.34}\n\\end{align*}\n$$",
        "总结": "- 正态分布的定义：给出样本 $\\boldsymbol{x}$ 服从正态分布 $\\mathcal{N}(\\boldsymbol{\\mu}, \\Sigma)$ 的概率密度函数形式。  \n- 对数似然函数：推导出数据集 $\\mathcal{D}$ 的对数似然函数表达式。  \n- 最大似然估计：通过求对数似然函数关于 $\\mu$ 和 $\\Sigma$ 的偏导数并令其为零，得到参数的最大似然估计值。  \n- 均值估计：最大似然估计下，均值 $\\mu^{ML}$ 是样本均值。  \n- 协方差矩阵估计：最大似然估计下，协方差矩阵 $\\Sigma^{ML}$ 是样本协方差矩阵。"
      },
      {
        "段落": "### 9．2．1．2 多项分布\n\n假设样本服从 $K$ 个状态的多项分布，令 one－hot 向量 $\\boldsymbol{x} \\in\\{0,1\\}^{K}$ 来表示第 $k$个状态，即 $x_{k}=1$ ，其余 $x_{i, i \\neq k}=0$ ．样本 $\\boldsymbol{x}$ 的概率密度函数为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x} \\mid \\boldsymbol{\\mu})=\\prod_{k=1}^{K} \\mu_{k}^{x_{k}} \\tag{9.35}\n\\end{equation*}\n$$\n\n其中 $\\mu_{k}$ 为第 $k$ 个状态的概率，并满足 $\\sum_{k=1}^{K} \\mu_{k}=1$ 。\n数据集 $\\mathcal{D}=\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ 的对数似然函数为\n\n多 项 分 布 参 见 第 D．2．2．1节。\n\n$$\n\\begin{equation*}\n\\log p(\\mathcal{D} \\mid \\mu)=\\sum_{n=1}^{N} \\sum_{k=1}^{K} x_{k}^{(n)} \\log \\left(\\mu_{k}\\right) \\tag{9.36}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n多项分布的参数估计为约束优化问题．引入拉格朗日乘子 $\\lambda$ ，将原问题转换为无约束优化问题．\n\n$$\n\\begin{equation*}\n\\max _{\\mu, \\lambda} \\sum_{n=1}^{N} \\sum_{k=1}^{K} x_{k}^{(n)} \\log \\left(\\mu_{k}\\right)+\\lambda\\left(\\sum_{k=1}^{K} \\mu_{k}-1\\right) . \\tag{9.37}\n\\end{equation*}\n$$\n\n分别求上式关于 $\\mu_{k}, \\lambda$ 的偏导数，并令其等于 0 ．可得，\n\n$$\n\\begin{equation*}\n\\mu_{k}^{M L}=\\frac{m_{k}}{N}, \\quad 1 \\leq k \\leq K \\tag{9.38}\n\\end{equation*}\n$$\n\n其中 $m_{k}=\\sum_{n=1}^{N} x_{k}^{(n)}$ 为数据集中取值为第 $k$ 个状态的样本数量．\n在实际应用中，参数密度估计一般存在以下问题：\n（1）模型选择问题：即如何选择数据分布的密度函数．实际数据的分布往往是非常复杂的，而不是简单的正态分布或多项分布。\n（2）不可观测变量问题：即我们用来训练的样本只包含部分的可观测变量，还有一些非常关键的变量是无法观测的，这导致我们很难准确估计数据的真实分布。\n（3）维度灾难问题：即高维数据的参数估计十分困难．随着维度的增加，估计参数所需要的样本数量指数增加．在样本不足时会出现过拟合．",
        "总结": "- 多项分布：描述样本服从 $K$ 个状态的分布，用 one-hot 向量 $\\boldsymbol{x} \\in \\{0,1\\}^K$ 表示状态，概率密度函数为 $p(\\boldsymbol{x} \\mid \\boldsymbol{\\mu}) = \\prod_{k=1}^{K} \\mu_k^{x_k}$，其中 $\\sum_{k=1}^{K} \\mu_k = 1$。\n- 对数似然函数：数据集 $\\mathcal{D}$ 的对数似然函数为 $\\log p(\\mathcal{D} \\mid \\mu) = \\sum_{n=1}^{N} \\sum_{k=1}^{K} x_k^{(n)} \\log(\\mu_k)$。\n- 参数估计方法：多项分布的参数估计为约束优化问题，引入拉格朗日乘子 $\\lambda$ 转换为无约束优化问题。\n- 最大似然估计：通过求导并令偏导数为零，得到最大似然估计解 $\\mu_k^{ML} = \\frac{m_k}{N}$，其中 $m_k = \\sum_{n=1}^{N} x_k^{(n)}$ 表示第 $k$ 个状态的样本数量。\n- 参数密度估计的问题：包括模型选择问题、不可观测变量问题和维度灾难问题。"
      },
      {
        "段落": "## 9．2．2 非参数密度估计\n\n非参数密度估计（Nonparametric Density Estimation）是不假设数据服从某种分布，通过将样本空间划分为不同的区域并估计每个区域的概率来近似数据的概率密度函数．\n\n对于高维空间中的一个随机向量 $\\boldsymbol{x}$ ，假设其服从一个未知分布 $p(\\boldsymbol{x})$ ，则 $\\boldsymbol{x}$ 落入空间中的小区域 $\\mathcal{R}$ 的概率为\n\n$$\n\\begin{equation*}\nP=\\int_{\\mathcal{R}} p(\\boldsymbol{x}) d \\boldsymbol{x} \\tag{9.39}\n\\end{equation*}\n$$\n\n给定 $N$ 个训练样本 $\\mathcal{D}=\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ ，落入区域 $\\mathcal{R}$ 的样本数量 $K$ 服从二项分布\n\n$$\n\\begin{equation*}\nP_{K}=\\binom{N}{K} P^{K}(1-P)^{1-K}, \\tag{9.40}\n\\end{equation*}\n$$\n\n其中 $K / N$ 的期望为 $\\mathbb{E}[K / N]=P$ ，方差为 $\\operatorname{var}(K / N)=P(1-P) / N$ 。当 $N$ 非常大时，我们可以近似认为\n\n$$\n\\begin{equation*}\nP \\approx \\frac{K}{N} \\tag{9.41}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n拉格朗日乘子参考参见第 C． 3 节。\n\n包含不可观测变量的密度估计问题一般需要使用EM算法，参见第11．2．2．1节．\n\n假设区域 $\\mathcal{R}$ 足够小，其内部的概率密度是相同的，则有\n\n$$\n\\begin{equation*}\nP \\approx p(\\boldsymbol{x}) V, \\tag{9.42}\n\\end{equation*}\n$$\n\n其中 $V$ 为区域 $\\mathcal{R}$ 的体积．结合上述两个公式，得到\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x}) \\approx \\frac{K}{N V} \\tag{9.43}\n\\end{equation*}\n$$\n\n根据公式（9．43），要准确地估计 $p(\\boldsymbol{x})$ ，需要尽量使得样本数量 $N$ 足够大，区域体积 $V$ 尽可能地小。但在具体应用中，样本数量一般是有限的，过小的区域会导致落入该区域的样本比较少，这样估计的概率密度就不太准确。因此，实践中非参数密度估计通常使用两种方式：（1）固定区域大小 $V$ ，统计落入不同区域的数量，这种方式包括直方图方法和核方法两种；（2）改变区域大小以使得落入每个区域的样本数量为 $K$ ，这种方式称为 K 近邻方法。",
        "总结": "- 非参数密度估计是一种不假设数据服从特定分布的方法，通过划分样本空间并估计每个区域的概率来近似数据的概率密度函数。  \n- 对于高维随机向量 $\\boldsymbol{x}$，其落入小区域 $\\mathcal{R}$ 的概率由积分 $P = \\int_{\\mathcal{R}} p(\\boldsymbol{x}) d\\boldsymbol{x}$ 表示。  \n- 给定 $N$ 个训练样本，落入区域 $\\mathcal{R}$ 的样本数量 $K$ 服从二项分布，其期望为 $P$，方差为 $P(1-P)/N$。  \n- 当样本数量很大时，概率 $P$ 可近似为 $K/N$。  \n- 若区域 $\\mathcal{R}$ 足够小且内部概率密度相同，则概率 $P \\approx p(\\boldsymbol{x}) V$，其中 $V$ 为区域体积。  \n- 结合上述公式，得到概率密度估计式 $p(\\boldsymbol{x}) \\approx K/(N V)$。  \n- 估计 $p(\\boldsymbol{x})$ 需要足够大的样本数量和尽可能小的区域体积，但实际应用中需权衡两者的平衡。  \n- 非参数密度估计常用两种方法：固定区域大小（如直方图和核方法）或调整区域大小（如 K 近邻方法）。"
      },
      {
        "段落": "### 9．2．2．1 直方图方法\n\n直方图方法（Histogram Method）是一种非常直观的估计连续变量密度函数的方法，可以表示为一种柱状图．\n\n以一维随机变量为例，首先将其取值范围分成 $M$ 个连续的、不重叠的区间 （bin），每个区间的宽度为 $\\Delta_{m}$ 。给定 $N$ 个训练样本 $\\mathcal{D}=\\left\\{x^{(n)}\\right\\}_{n=1}^{N}$ ，我们统计这些样本落入每个区间的数量 $K_{m}$ ，然后将它们归一化为密度函数．\n\nHistogram 源自希腊语 histos（竖 立）和 gramma（描绘），由英国统计学家卡尔•皮尔逊于 1895 年提出。\n\n$$\n\\begin{equation*}\np_{m}=\\frac{K_{m}}{N \\Delta_{m}}, \\quad 1 \\leq m \\leq M \\tag{9.44}\n\\end{equation*}\n$$\n\n其中区间宽度 $\\Delta_{m}$ 通常设为相同的值 $\\Delta$ ．直方图方法的关键问题是如何选取一个合适的区间宽度 $\\Delta$ ．如果 $\\Delta$ 太小，那么落入每个区间的样本数量会比较少，其估计的区间密度也具有很大的随机性．如果 $\\Delta$ 太大，其估计的密度函数变得十分平滑，很难反映出真实的数据分布。图9．4给出了直方图密度估计的例子，其中蓝线表示真实的密度函数，红色的柱状图为直方图方法估计的密度．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-235.jpg?height=348&width=1051&top_left_y=1707&top_left_x=130)\n\n图9．4直方图密度估计\n\n直方图通常用来处理低维变量，可以非常快速地对数据的分布进行可视化，但其缺点是很难扩展到高维变量。假设一个 $D$ 维的随机向量，如果每一维都划分为 $M$ 个区间，那么整个空间的区间数量为 $M^{D}$ 个．直方图方法需要的样本数量会随着维度 $D$ 的增加而指数增长，从而导致维度灾难（Curse of Dimensionality）问题．",
        "总结": "- 直方图方法是一种用于估计连续变量密度函数的直观方法，通过将取值范围划分为若干区间并统计样本落入每个区间的数量来实现。\n- 直方图方法的密度估计公式为 $p_{m} = \\frac{K_{m}}{N \\Delta_{m}}$，其中 $K_{m}$ 是落入第 $m$ 个区间的样本数，$N$ 是样本总数，$\\Delta_{m}$ 是区间的宽度。\n- 区间宽度 $\\Delta$ 的选择是直方图方法的关键问题，过小会导致估计随机性大，过大则会使密度估计过于平滑。\n- 直方图方法通常用于低维变量的分布可视化，但难以扩展到高维变量，因为区间数量会随着维度指数增长，导致维度灾难问题。"
      },
      {
        "段落": "### 9．2．2．2 核方法\n\n核密度估计（Kernel Density Estimation），也叫 Parzen 窗方法，是一种直方图方法的改进．\n\n假设 $\\mathcal{R}$ 为 $D$ 维空间中的一个以点 $\\boldsymbol{x}$ 为中心的＂超立方体＂，并定义核函数\n\n$$\n\\phi\\left(\\frac{\\boldsymbol{z}-\\boldsymbol{x}}{h}\\right)= \\begin{cases}1 & \\text { if }\\left|z_{i}-x_{i}\\right|<\\frac{H}{2}, 1 \\leq i \\leq D  \\tag{9.45}\\\\ 0 & \\text { else }\\end{cases}\n$$\n\n来表示一个样本 $\\boldsymbol{z}$ 是否落入该超立方体中，其中 $H$ 为超立方体的边长，也称为核函数的宽度．\n\n给定 $N$ 个训练样本 $\\mathcal{D}=\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ ，落入区域 $\\mathcal{R}$ 的样本数量 $K$ 为\n\n$$\n\\begin{equation*}\nK=\\sum_{n=1}^{N} \\phi\\left(\\frac{\\boldsymbol{x}^{(n)}-\\boldsymbol{x}}{H}\\right), \\tag{9.46}\n\\end{equation*}\n$$\n\n则点 $\\boldsymbol{x}$ 的密度估计为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x})=\\frac{K}{N H^{D}}=\\frac{1}{N H^{D}} \\sum_{n=1}^{N} \\phi\\left(\\frac{\\boldsymbol{x}^{(n)}-\\boldsymbol{x}}{H}\\right), \\tag{9.47}\n\\end{equation*}\n$$\n\n其中 $H^{D}$ 表示超立方体 $\\mathcal{R}$ 的体积。\n除了超立方体的核函数之外，我们还可以选择更加平滑的核函数，比如高斯核函数，\n\n$$\n\\begin{equation*}\n\\phi\\left(\\frac{\\boldsymbol{z}-\\boldsymbol{x}}{H}\\right)=\\frac{1}{(2 \\pi)^{1 / 2} H} \\exp \\left(-\\frac{\\|\\boldsymbol{z}-\\boldsymbol{x}\\|^{2}}{2 H^{2}}\\right) \\tag{9.48}\n\\end{equation*}\n$$\n\n其中 $h^{2}$ 可以看作是高斯核函数的方差．这样，点 $\\boldsymbol{x}$ 的密度估计为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x})=\\frac{1}{N} \\sum_{n=1}^{N} \\frac{1}{(2 \\pi)^{1 / 2} H} \\exp \\left(-\\frac{\\|\\boldsymbol{z}-\\boldsymbol{x}\\|^{2}}{2 H^{2}}\\right) . \\tag{9.49}\n\\end{equation*}\n$$",
        "总结": "- 核密度估计（Kernel Density Estimation），也称为 Parzen 窗方法，是对直方图方法的改进。  \n- 核函数用于表示样本是否落入以点 $\\boldsymbol{x}$ 为中心的超立方体 $\\mathcal{R}$ 中，超立方体的边长为 $H$，核函数的宽度即为 $H$。  \n- 超立方体核函数的定义为：当所有维度上的距离小于 $H/2$ 时取值为 1，否则为 0。  \n- 点 $\\boldsymbol{x}$ 的密度估计公式为 $p(\\boldsymbol{x}) = \\frac{K}{N H^D}$，其中 $K$ 是落入超立方体的样本数，$N$ 是总样本数，$H^D$ 是超立方体的体积。  \n- 可以使用更平滑的核函数，如高斯核函数，其形式为 $\\phi\\left(\\frac{\\boldsymbol{z}-\\boldsymbol{x}}{H}\\right) = \\frac{1}{(2\\pi)^{1/2} H} \\exp\\left(-\\frac{\\|\\boldsymbol{z}-\\boldsymbol{x}\\|^2}{2 H^2}\\right)$。  \n- 高斯核函数中的 $H^2$ 可视为方差，点 $\\boldsymbol{x}$ 的密度估计公式为 $p(\\boldsymbol{x}) = \\frac{1}{N} \\sum_{n=1}^{N} \\frac{1}{(2\\pi)^{1/2} H} \\exp\\left(-\\frac{\\|\\boldsymbol{z}-\\boldsymbol{x}\\|^2}{2 H^2}\\right)$。"
      },
      {
        "段落": "### 9．2．2．3 K近邻方法\n\n核密度估计方法中的核宽度是固定的，因此同一个宽度可能对高密度的区域过大，而对低密度的区域过小．一种更灵活的方式是设置一种可变宽度的区域，并 https：／／nndl．github．io／\n\n使得落入每个区域中样本数量为固定的 $K$ ．要估计点 $\\boldsymbol{x}$ 的密度，首先找到一个以 $\\boldsymbol{x}$ 为中心的球体，使得落入球体的样本数量为 $K$ ，然后根据公式（9．43），就可以计算出点 $\\boldsymbol{x}$ 的密度．因为落入球体的样本也是离 $\\boldsymbol{x}$ 最近的 $K$ 个样本，所以这种方法称为 $K$ 近邻（K－Nearest Neighbor）方法。\n\n在 K 近邻方法中，$K$ 的选择也十分关键．如果 $K$ 太小，无法有效地估计密度函数；而 $K$ 太大也会使得局部的密度不准确，并且增加计算开销。\n\nK 近邻方法也经常用于分类问题，称为 $K$ 近邻分类器．当 $K=1$ 时，也称为最近邻分类器．最近邻分类器的一个性质是，当 $N \\rightarrow \\infty$ 时，其分类错误率不超过最优分类器错误率的两倍［Cover et al．，1967］．",
        "总结": "- K近邻方法是一种可变宽度的核密度估计方法，通过设置每个区域中包含固定数量 $K$ 的样本，来更灵活地估计密度。  \n- 该方法通过找到以 $\\boldsymbol{x}$ 为中心的球体，使得落入球体的样本数量为 $K$，然后根据公式（9．43）计算点 $\\boldsymbol{x}$ 的密度。  \n- $K$ 的选择对方法效果至关重要：$K$ 太小会导致密度估计不准确，$K$ 太大会影响局部密度的准确性并增加计算开销。  \n- K近邻方法也可用于分类问题，称为 K近邻分类器，当 $K=1$ 时称为最近邻分类器。  \n- 最近邻分类器具有一个性质：当样本数量 $N \\rightarrow \\infty$ 时，其分类错误率不超过最优分类器错误率的两倍。"
      },
      {
        "段落": "## 9.3 总结和深入阅读\n\n无监督学习是一种十分重要的机器学习方法．广义上讲，监督学习也可以看作是一类特殊的无监督学习，即估计条件概率 $p(y \\mid \\boldsymbol{x})$ 。条件概率 $p(y \\mid \\boldsymbol{x})$ 可以通过贝叶斯公式转为估计概率 $p(y)$ 和 $p(\\boldsymbol{x} \\mid y)$ ，并通过无监督密度估计来求解。\n\n无监督学习问题主要可以分为聚类、特征学习、密度估计等几种类型．关于聚类方面的内容，可以参考《机器学习》［周志华，2016］中的第 9 章。无监督特征学习是一种十分重要的表示学习方法。当一个监督学习任务的数据比较少时，可以通过大规模的无标注数据，学习到一种有效的数据表示，并有效提高监督学习的性能．关于无监督特征学习的内容，可以参考《机器学习》［周志华，2016］中的第10章和《Pattern Classification》［Duda et al．，2001］中的第10章．\n\n本章简单介绍了两种概率密度估计方法：参数方法和非参数方法．参数方法是假设数据分布服从某种参数化的模型。我们在本书的后面章节会陆续介绍更多的参数密度估计模型．在第11章中，我们通过概率图模型介绍更一般的参数密度估计方法，包括含隐变量的参数估计方法．当估计出一个数据分布的参数化模型后，我们可以根据这个模型来生成数据，因此这些模型也称为生成模型。第12章介绍两种比较复杂的生成模型：玻尔兹曼机和深度信念网络。第13章介绍两种深度生成模型：变分自编码器和对抗生成网络．第15章介绍几种序列数据的生成模型．\n\n关于非参数密度估计方法的一般性介绍可以参考文献［Duda et al．，2001］和 ［Bishop，2007］，理论性介绍可以参考［Devroye et al．，1985］．\n\n目前，无监督学习并没有像监督学习那样取得广泛的成功，其主要原因在于无监督学习缺少有效的客观评价方法，导致很难衡量一个无监督学习方法的好坏．无监督学习的好坏通常需要代入到下游任务中进行验证．\n\nK 近邻方法并不是一个严格的密度函数估计方法，参见习题9－5．\n\n参见习题9－7．",
        "总结": "- 无监督学习是一种重要的机器学习方法，广义上监督学习可视为估计条件概率 $p(y \\mid \\boldsymbol{x})$ 的特殊形式，可通过贝叶斯公式转化为估计 $p(y)$ 和 $p(\\boldsymbol{x} \\mid y)$，并利用无监督密度估计求解。  \n- 无监督学习问题主要分为聚类、特征学习和密度估计等类型，聚类相关内容可参考《机器学习》（周志华，2016）第9章。  \n- 无监督特征学习是一种重要的表示学习方法，通过大规模无标注数据学习有效数据表示，以提升监督学习性能，相关内容可参考《机器学习》（周志华，2016）第10章和《Pattern Classification》（Duda et al., 2001）第10章。  \n- 本章介绍了参数方法和非参数方法两种概率密度估计方法。参数方法假设数据服从参数化模型，后续章节将介绍更多参数模型；非参数方法则不依赖特定分布假设。  \n- 第11章通过概率图模型介绍更一般的参数密度估计方法，包括含隐变量的参数估计；第12章介绍玻尔兹曼机和深度信念网络；第13章介绍变分自编码器和对抗生成网络；第15章介绍序列数据的生成模型。  \n- 非参数密度估计方法的一般性介绍可参考文献 [Duda et al., 2001] 和 [Bishop, 2007]，理论性内容可参考 [Devroye et al., 1985]。  \n- 无监督学习尚未像监督学习那样取得广泛成功，主要原因是缺乏有效的客观评价方法，通常需通过下游任务验证其效果。  \n- K近邻方法并非严格的密度函数估计方法（参见习题9－5）。  \n- 参见习题9－7。"
      },
      {
        "段落": "## 习题\n\n习题9－1 分析主成分分析为什么具有数据降噪能力？\n习题9－2 证明对于 $N$ 个样本（样本维数 $D>N$ ）组成的数据集，主成分分析的有效投影子空间不超过 $N-1$ 维。\n\n习题9－3 对于一个二分类问题，试举例分析什么样的数据分布会使得主成分分析得到的特征反而会使得分类性能下降。\n\n习题 9－4 若数据矩阵 $\\boldsymbol{X}^{\\prime}=\\boldsymbol{X}-\\overline{\\boldsymbol{X}}$ ，则对 $\\boldsymbol{X}^{\\prime}$ 奇异值分解 $\\boldsymbol{X}^{\\prime}=\\boldsymbol{U} \\Sigma \\boldsymbol{V}$ ，则 $\\boldsymbol{U}$ 为主成分分析的投影矩阵。\n\n习题9－5 举例说明， K 近邻方法估计的密度函数不是严格的概率密度函数，其在整个空间上的积分不等于 1 ．\n\n习题9－6 分析公式（9．14）和（9．15）来衡量稀疏性的效果．\n习题 9－7 对于一个 $C$ 类的分类问题，使用 K 近邻方法估计每个类 $c ~(1 \\leq c \\leq$ $C)$ 的密度函数 $p(\\boldsymbol{x} \\mid c)$ ，并使用贝叶斯公式计算每个类的后验概率 $p(c \\mid \\boldsymbol{x})$ ．",
        "总结": "- 主成分分析具有数据降噪能力，是因为它通过保留数据中方差最大的主成分，过滤掉方差较小的噪声成分，从而在降维的同时减少噪声影响。  \n- 主成分分析的有效投影子空间不超过 $N-1$ 维，是因为当样本数 $N$ 小于样本维数 $D$ 时，数据矩阵的秩最多为 $N$，因此其主成分空间的最大维度为 $N-1$。  \n- 在某些数据分布下，主成分分析可能无法有效区分类别，例如当数据分布的主方向与类别分离方向不一致时，投影到主成分空间后可能降低分类性能。  \n- 数据矩阵 $\\boldsymbol{X}^{\\prime}=\\boldsymbol{X}-\\overline{\\boldsymbol{X}}$ 的奇异值分解中，$\\boldsymbol{U}$ 的列向量构成了主成分分析的投影矩阵，用于将数据投影到主成分空间。  \n- K 近邻方法估计的密度函数不是严格的概率密度函数，因为其在空间中是局部估计的，整体积分可能不等于 1。  \n- 公式（9．14）和（9．15）分别从不同角度衡量稀疏性效果，如通过稀疏系数的范数或稀疏度指标来评估模型的稀疏程度。  \n- 对于 $C$ 类分类问题，使用 K 近邻方法估计每个类别的密度函数 $p(\\boldsymbol{x} \\mid c)$ 后，结合贝叶斯公式可计算后验概率 $p(c \\mid \\boldsymbol{x})$ 以进行分类决策。"
      },
      {
        "段落": "## 参考文献\n\n周志华．机器学习［M］．北京：清华大学出版社， 2016.\nBengio Y，Lamblin P，Popovici D，et al．Greedy layer－wise training of deep networks［C］／／Advances in neural information processing systems．2007：153－160．\nBishop C M．Pattern recognition and machine learning［M］．5th edition．Springer， 2007.\nCover T，Hart P．Nearest neighbor pattern classification［J］．IEEE transactions on information theory，1967，13（1）：21－27．\nDevroye L，Gyorfi L．Nonparametric density estimation：The $L_{1}$ view［M］．Wiley， 1985.\nDuda R O，Hart P E，Stork D G．Pattern classification［M］．2nd edition．Wiley， 2001.\nHinton G E，Sejnowski T J，Poggio T A．Unsupervised learning：foundations of neural computation ［M］．MIT press， 1999.\nOlshausen B A，et al．Emergence of simple－cell receptive field properties by learning a sparse code for natural images［J］．Nature，1996，381（6583）：607－609．\nVincent P，Larochelle H，Bengio Y，et al．Extracting and composing robust features with denoising autoencoders［C］／／Proceedings of the International Conference on Machine Learning．2008：1096－ 1103.",
        "总结": "- 参考文献部分列出了多个与机器学习、模式识别和神经网络相关的学术著作和论文，涵盖深度学习、非参数密度估计、无监督学习等领域。  \n- 周志华的《机器学习》是中文版的经典教材，提供了机器学习的基础理论和方法。  \n- Bengio等人提出的“逐层贪婪训练深度网络”方法，是深度学习领域的重要算法之一。  \n- Bishop的《模式识别与机器学习》是英文版的经典教材，系统介绍了统计机器学习理论。  \n- Cover和Hart的“最近邻模式分类”是模式识别中的经典算法，基于距离度量进行分类。  \n- Devroye和Gyorfi的《非参数密度估计：L₁视角》探讨了非参数方法在密度估计中的应用。  \n- Duda等人的《模式分类》是另一本经典教材，介绍了模式识别的基本理论和方法。  \n- Hinton等人提出的“无监督学习：神经计算基础”是神经网络无监督学习的重要理论基础。  \n- Olshausen等人的研究揭示了通过自然图像学习稀疏编码如何产生类似简单细胞的感受野特性。  \n- Vincent等人提出的“使用去噪自编码器提取和组合鲁棒特征”是深度学习中自编码器应用的重要研究。"
      }
    ]
  },
  {
    "标题": "第10章 模型独立的学习方式",
    "内容": [
      {
        "段落": "# 第10章 模型独立的学习方式 \n\n三个臭皮匠赛过诸葛亮．\n—谚语\n\n在前面的章节中，我们已经介绍了机器学习的几种学习方式，包括监督学习、无监督学习等。这些学习方式分别可以由不同的模型和算法实现，比如神经网络、线性分类器等。针对一个给定的任务，首先要准备一定规模的训练数据，这些训练数据需要和真实数据的分布一致，然后设定一个目标函数和优化方法，在训练数据上学习一个模型。此外，不同任务的模型往往都是从零开始来训练的，一切知识都需要从训练数据中得到。这也导致了每个任务都需要准备大量的训练数据。在实际应用中，我们面对的任务往往难以满足上述要求，比如训练任务和目标任务的数据分布不一致，训练数据过少等．这时机器学习的应用会受到很大的局限．并且在很多场合中，我们也需要一个模型可以快速地适应新的任务。因此，人们开始关注一些新的学习方式。\n\n本章介绍一些＂模型独立的学习方式＂，比如集成学习、协同学习、自训练、多任务学习、迁移学习、终身学习、小样本学习、元学习等。这里＂模型独立＂是指这些学习方式不限于具体的模型，不管是前馈神经网络、循环神经网络还是其他模型。然而，一种学习方式往往会对符合某种特性的模型更加青睐，比如集成学习往往和方差大的模型组合时效果显著．",
        "总结": "- 概念：模型独立的学习方式是指不限于特定模型的学习方法，如集成学习、协同学习、自训练、多任务学习、迁移学习、终身学习、小样本学习、元学习等。  \n- 算法：本章提到的算法包括集成学习、协同学习、自训练、多任务学习、迁移学习、终身学习、小样本学习和元学习。  \n- 定理或命题：未提及具体定理或命题。  \n- 数学推导：未提及具体数学推导。"
      },
      {
        "段落": "## 10.1 集成学习\n\n给定一个学习任务，假设输入 $\\boldsymbol{x}$ 和输出 $\\boldsymbol{y}$ 的真实关系为 $\\boldsymbol{y}=h(\\boldsymbol{x})$ 。对于 $M$ 个不同的模型 $f_{1}(\\boldsymbol{x}), \\cdots, f_{M}(\\boldsymbol{x})$ ，每个模型的期望错误为\n\n$$\n\\begin{align*}\n\\mathcal{R}\\left(f_{m}\\right) & =\\mathbb{E}_{\\boldsymbol{x}}\\left[\\left(f_{m}(\\boldsymbol{x})-h(\\boldsymbol{x})\\right)^{2}\\right]  \\tag{10.1}\\\\\n& =\\mathbb{E}_{\\boldsymbol{x}}\\left[\\epsilon_{m}(\\boldsymbol{x})^{2}\\right] \\tag{10.2}\n\\end{align*}\n$$\n\n其中 $\\epsilon_{m}(\\boldsymbol{x})=f_{m}(\\boldsymbol{x})-h(\\boldsymbol{x})$ 为模型 $m$ 在样本 $\\boldsymbol{x}$ 上的错误。\n那么所有的模型的平均错误为\n\n$$\n\\begin{equation*}\n\\overline{\\mathcal{R}}(f)=\\frac{1}{M} \\sum_{m=1}^{M} \\mathbb{E}_{\\boldsymbol{x}}\\left[\\epsilon_{m}(\\boldsymbol{x})^{2}\\right] \\tag{10.3}\n\\end{equation*}\n$$\n\n集成学习（Ensemble Learning）就是通过某种策略将多个模型集成起来，通过群体决策来提高决策准确率。集成学习首要的问题是如何集成多个模型。比较常用的集成策略有直接平均、加权平均等。\n\n最直接的集成学习策略就是直接平均，即＂投票＂．基于投票的集成模型 $F(\\boldsymbol{x})$为\n\n$$\n\\begin{equation*}\nF(\\boldsymbol{x})=\\frac{1}{M} \\sum_{m=1}^{M} f_{m}(\\boldsymbol{x}) \\tag{10.4}\n\\end{equation*}\n$$\n\n定理 10．1：对于 $M$ 个不同的模型 $f_{1}(\\boldsymbol{x}), \\cdots, f_{M}(\\boldsymbol{x})$ ，其平均期望错误为 $\\overline{\\mathcal{R}}(f)$ 。基于简单投票机制的集成模型 $F(\\boldsymbol{x})=\\frac{1}{M} \\sum_{m=1}^{M} f_{m}(\\boldsymbol{x}), F(\\boldsymbol{x})$ 的期望错误在 $\\frac{1}{M} \\overline{\\mathcal{R}}(f)$ 和 $\\overline{\\mathcal{R}}(f)$ 之间．\n\n证明．根据定义，集成模型的期望错误为\n\n$$\n\\begin{align*}\n\\mathcal{R}(F) & =\\mathbb{E}_{\\boldsymbol{x}}\\left[\\left(\\frac{1}{M} \\sum_{m=1}^{M} f_{m}(\\boldsymbol{x})-h(\\boldsymbol{x})\\right)^{2}\\right]  \\tag{10.5}\\\\\n& =\\mathbb{E}_{\\boldsymbol{x}}\\left[\\left(\\frac{1}{M} \\sum_{m=1}^{M} \\epsilon_{m}(\\boldsymbol{x})\\right)^{2}\\right]  \\tag{10.6}\\\\\n& =\\frac{1}{M^{2}} \\mathbb{E}_{\\boldsymbol{x}}\\left[\\sum_{m=1}^{M} \\sum_{n=1}^{M} \\epsilon_{m}(\\boldsymbol{x}) \\epsilon_{n}(\\boldsymbol{x})\\right]  \\tag{10.7}\\\\\n& =\\frac{1}{M^{2}} \\sum_{m=1}^{M} \\sum_{n=1}^{M} \\mathbb{E}_{\\boldsymbol{x}}\\left[\\epsilon_{m}(\\boldsymbol{x}) \\epsilon_{n}(\\boldsymbol{x})\\right] \\tag{10.8}\n\\end{align*}\n$$\n\n其中 $\\mathbb{E}_{\\boldsymbol{x}}\\left[\\epsilon_{m}(\\boldsymbol{x}) \\epsilon_{n}(\\boldsymbol{x})\\right]$ 为两个不同模型错误的相关性。如果每个模型的错误不相关，即 $\\forall m \\neq n, \\mathbb{E}_{\\boldsymbol{x}}\\left[\\epsilon_{m}(\\boldsymbol{x}) \\epsilon_{n}(\\boldsymbol{x})\\right]=0$ ．如果每个模型的错误都是相同的，则 $\\forall m \\neq n, \\epsilon_{m}(\\boldsymbol{x})=\\epsilon_{n}(\\boldsymbol{x})$ 。并且，由于 $\\epsilon_{m}(\\boldsymbol{x}) \\geq 0, \\forall m$ ，可以得到\n\n$$\n\\begin{equation*}\n\\overline{\\mathcal{R}}(f) \\geq \\mathcal{R}(F) \\geq \\frac{1}{M} \\overline{\\mathcal{R}}(f) \\tag{10.9}\n\\end{equation*}\n$$\n\n即集成模型的期望错误大于等于所有模型的平均期望错误的 $1 / M$ ，小于等于所有模型的平均期望错误。\n\n从定理10．1可知，为了得到更好的集成效果，要求每个模型之间具备一定的差异性．并且随着模型数量的增多，其错误率也会下降，并趋近于 0 。\n\n集成学习的思想可以用一句古老的谚语来描述：＂三个臭皮匠赛过诸葛亮＂．但是一个有效的集成需要各个基模型的差异尽可能大。为了增加模型之间的差异性，可以采取 Bagging 和 Boosting 这两类方法。\n\nBagging类方法 Bagging 类方法是通过随机构造训练样本、随机选择特征等方法来提高每个基模型的独立性，代表性方法有 Bagging 和随机森林等。\n\nBagging（Bootstrap Aggregating）是通过不同模型的训练数据集的独立性来提高不同模型之间的独立性。我们在原始训练集上进行有放回的随机采样，得到 $M$ 个比较小的训练集并训练 $M$ 个模型，然后通过投票的方法进行模型集成。\n\n随机森林（Random Forest）［Breiman，2001］是在 Bagging 的基础上再引入了随机特征，进一步提高每个基模型之间的独立性。在随机森林中，每个基模型都是一棵决策树。\n\nBoosting 类方法 Boosting 类方法是按照一定的顺序来先后训练不同的基模型，每个模型都针对前序模型的错误进行专门训练。根据前序模型的结果，来调整训练样本的权重，从而增加不同基模型之间的差异性。Boosting类方法是一种非常强大的集成方法，只要基模型的准确率比随机猜测高，就可以通过集成方法来显著地提高集成模型的准确率．Boosting 类方法的代表性方法有 AdaBoost［Freund et al．，1996］等．",
        "总结": "- 集成学习的概念：通过组合多个模型的预测结果，提高整体决策的准确率。  \n- 平均错误的定义：所有模型的平均期望错误为 $\\overline{\\mathcal{R}}(f)$。  \n- 直接平均策略：集成模型 $F(\\boldsymbol{x})$ 为所有模型输出的简单平均。  \n- 定理10.1：基于简单投票机制的集成模型期望错误在 $\\frac{1}{M} \\overline{\\mathcal{R}}(f)$ 和 $\\overline{\\mathcal{R}}(f)$ 之间。  \n- 定理证明：通过展开期望错误公式并利用模型错误的相关性进行推导。  \n- 模型差异性的重要性：模型之间差异越大，集成效果越好，错误率越低。  \n- 集成学习的谚语描述：“三个臭皮匠赛过诸葛亮”。  \n- Bagging方法：通过随机采样和特征选择提高基模型独立性，如Bagging和随机森林。  \n- Boosting方法：按顺序训练基模型，调整样本权重以增强模型差异性，如AdaBoost。"
      },
      {
        "段落": "## 10．1．1 AdaBoost 算法\n\nBoosting 类集成模型的目标是学习一个加性模型（Additive Model）\n\n$$\n\\begin{equation*}\nF(\\boldsymbol{x})=\\sum_{m=1}^{M} \\alpha_{m} f_{m}(\\boldsymbol{x}), \\tag{10.10}\n\\end{equation*}\n$$\n\n其中 $f_{m}(\\boldsymbol{x})$ 为弱分类器（Weak Classifier），或基分类器（Base Classifier），$\\alpha_{m}$为弱分类器的集成权重，$F(\\boldsymbol{x})$ 称为强分类器（Strong Classifier）。\n\nBoosting 类方法的关键是如何训练每个弱分类器 $f_{m}(\\boldsymbol{x})$ 及其权重 $\\alpha_{m}$ 。为了提高集成的效果，应当尽量使得每个弱分类器的差异尽可能大。 一种有效的算法是采用迭代的方法来学习每个弱分类器，即按照一定的顺序依次训练每个弱分类器。假设已经训练了 $m$ 个弱分类器，在训练第第 $m+1$ 个弱分类器时，增加已有弱分类器分错样本的权重，使得第 $m+1$ 个弱分类器＂更关注＂于已有弱分类器分错的样本。这样增加每个弱分类器的差异，最终提升集成分类器的准确率。这种方法称为AdaBoost（Adaptive Boosting）算法。\n\nAdaBoost算法是一种迭代式的训练算法，通过改变数据分布来提高弱分类器的差异。在每一轮训练中，增加分错样本的权重，减少分对样本的权重，从而得到一个新的数据分布．\n\n以二分类为例，弱分类器 $f_{m}(x) \\in\\{+1,-1\\}$ ，AdaBoost 算法的训练过程如算法10．1所示．最初赋予每个样本同样的权重．在每一轮迭代中，根据当前的样本权重训练一个新的弱分类器。然后根据这个弱分类器的错误率来计算其集成权重，并调整样本权重。\n\n```\n算法 10.1: 二分类的 AdaBoost 算法\n    输入: 训练集 $\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$, 迭代次数 $M$\n    初始样本权重: $w_{1}^{(n)} \\leftarrow \\frac{1}{N}, \\forall n \\in[1, N]$;\n    for $m=1 \\cdots M$ do\n        按照样本权重 $w_{m}^{(1)}, \\cdots, w_{m}^{(N)}$, 学习弱分类器 $f_{m}$;\n        计算弱分类器 $f_{m}$ 在数据集上的加权错误 $\\epsilon_{m}$;\n        计算分类器的集成权重:\n            $\\alpha_{m} \\leftarrow \\frac{1}{2} \\log \\frac{1-\\epsilon_{m}}{\\epsilon_{m}} ;$\n        调整样本权重:\n            $w_{m+1}^{(n)} \\leftarrow w_{m}^{(n)} \\exp \\left(-\\alpha_{m} y^{(n)} f_{m}\\left(\\boldsymbol{x}^{(n)}\\right)\\right), \\forall n \\in[1, N] ;$\n    end\n    输出: $F(\\boldsymbol{x})=\\operatorname{sgn}\\left(\\sum_{m=1}^{M} \\alpha_{m} f_{m}(\\boldsymbol{x})\\right)$\n```\n\nAdaBoost 算法的统计学解释 AdaBoost 算法也可以看作是一种分步（Stage－ Wise）优化的加性模型［Friedman et al．，2000］，其损失函数定义为\n\n$$\n\\begin{align*}\n\\mathcal{L}(F) & =\\exp (-y F(\\boldsymbol{x}))  \\tag{10.11}\\\\\n& =\\exp \\left(-y \\sum_{m=1}^{M} \\alpha_{m} f_{m}(\\boldsymbol{x})\\right) \\tag{10.12}\n\\end{align*}\n$$\n\n其中 $y, f_{m}(\\boldsymbol{x}) \\in\\{+1,-1\\}$ ．\n假设经过 $m-1$ 次迭代，得到\n\n$$\n\\begin{equation*}\nF_{m-1}(\\boldsymbol{x})=\\sum_{t=1}^{m-1} \\alpha_{t} f_{t}(\\boldsymbol{x}) \\tag{10.13}\n\\end{equation*}\n$$\n\n则第 $m$ 次迭代的目标是找一个 $\\alpha_{m}$ 和 $f_{m}(\\boldsymbol{x})$ 使得下面的损失函数最小．\n\n$$\n\\begin{equation*}\n\\mathcal{L}\\left(\\alpha_{m}, f_{m}(\\boldsymbol{x})\\right)=\\sum_{n=1}^{N} \\exp \\left(-y^{(n)}\\left(F_{m-1}\\left(\\boldsymbol{x}^{(n)}\\right)+\\alpha_{m} f_{m}\\left(\\boldsymbol{x}^{(n)}\\right)\\right)\\right) . \\tag{10.14}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n令 $w_{m}^{(n)}=\\exp \\left(-y^{(n)} F_{m-1}\\left(\\boldsymbol{x}^{(n)}\\right)\\right)$ ，则损失函数可以写为\n\n$$\n\\begin{equation*}\n\\mathcal{L}\\left(\\alpha_{m}, f_{m}(\\boldsymbol{x})\\right)=\\sum_{n=1}^{N} w_{m}^{(n)} \\exp \\left(-\\alpha_{m} y^{(n)} f_{m}\\left(\\boldsymbol{x}^{(n)}\\right)\\right) \\tag{10.15}\n\\end{equation*}\n$$\n\n因为 $y, f_{m}(\\boldsymbol{x}) \\in\\{+1,-1\\}$ ，有\n\n$$\n\\begin{equation*}\ny f_{m}(\\boldsymbol{x})=1-2 I\\left(y \\neq f_{m}(\\boldsymbol{x})\\right) \\tag{10.16}\n\\end{equation*}\n$$\n\n其中 $I(x)$ 为指示函数．\n将损失函数在 $-\\alpha_{m} y^{(n)} f_{m}\\left(\\boldsymbol{x}^{(n)}\\right)=0$ 处进行二阶泰勒展开，有\n\n$$\n\\begin{align*}\n\\mathcal{L}\\left(\\alpha_{m}, f_{m}(\\boldsymbol{x})\\right) & =\\sum_{n=1}^{N} w_{m}^{(n)}\\left(1-\\alpha_{m} y^{(n)} f_{m}\\left(\\boldsymbol{x}^{(n)}\\right)+\\frac{1}{2} \\alpha_{m}^{2}\\right)  \\tag{10.17}\\\\\n& \\propto \\alpha_{m} \\sum_{n=1}^{N} w_{m}^{(n)} I\\left(y^{(n)} \\neq f_{m}\\left(\\boldsymbol{x}^{(n)}\\right)\\right) \\tag{10.18}\n\\end{align*}\n$$\n\n从上式可以看出，当 $\\alpha_{m}>0$ 时，最优的分类器 $f_{m}(\\boldsymbol{x})$ 为使得在样本权重为 $w_{m}^{(n)}, 1 \\leq n \\leq N$ 时的加权错误率最小的分类器．\n\n在求解出 $f_{m}(\\boldsymbol{x})$ 之后，公式（10．15）可以写为\n\n$$\n\\begin{align*}\n\\mathcal{L}\\left(\\alpha_{m}, f_{m}(\\boldsymbol{x})\\right) & =\\sum_{y^{(n)}=f_{m}\\left(\\boldsymbol{x}^{(n)}\\right)} w_{m}^{(n)} \\exp \\left(-\\alpha_{m}\\right)+\\sum_{y^{(n)} \\neq f_{m}\\left(\\boldsymbol{x}^{(n)}\\right)} w_{m}^{(n)} \\exp \\left(\\alpha_{m}\\right)  \\tag{10.19}\\\\\n& \\propto\\left(1-\\epsilon_{m}\\right) \\exp \\left(-\\alpha_{m}\\right)+\\epsilon_{m} \\exp \\left(\\alpha_{m}\\right) \\tag{10.20}\n\\end{align*}\n$$\n\n其中 $\\epsilon_{m}$ 为分类器 $f_{m}(\\boldsymbol{x})$ 的加权错误率，\n\n$$\n\\begin{equation*}\n\\epsilon_{m}=\\frac{\\sum_{y^{(n)} \\neq f_{m}\\left(x^{(n)}\\right)} w_{m}^{(n)}}{\\sum_{n} w_{m}^{(n)}} \\tag{10.21}\n\\end{equation*}\n$$\n\n求上式关于 $\\alpha_{m}$ 的导数并令其为 0 ，得到\n\n$$\n\\begin{equation*}\n\\alpha_{m}=\\frac{1}{2} \\log \\frac{1-\\epsilon_{m}}{\\epsilon_{m}} \\tag{10.22}\n\\end{equation*}\n$$",
        "总结": "- AdaBoost 算法是一种迭代式训练算法，通过调整数据分布来提升弱分类器的差异，从而提高集成分类器的准确率。  \n- AdaBoost 的目标是学习一个加性模型 $F(\\boldsymbol{x})=\\sum_{m=1}^{M} \\alpha_{m} f_{m}(\\boldsymbol{x})$，其中 $f_{m}$ 为弱分类器，$\\alpha_{m}$ 为其权重。  \n- 每轮训练中，增加分错样本的权重，减少分对样本的权重，以使后续弱分类器更关注于难分样本。  \n- AdaBoost 算法在每一轮中根据当前样本权重训练弱分类器，并计算其错误率以确定集成权重 $\\alpha_{m}$。  \n- 算法流程包括初始化样本权重、迭代训练弱分类器、计算错误率、调整样本权重，并最终输出强分类器 $F(\\boldsymbol{x})$。  \n- AdaBoost 可视为一种分步优化的加性模型，其损失函数定义为 $\\exp(-y F(\\boldsymbol{x}))$。  \n- 损失函数通过二阶泰勒展开后，可转化为与加权错误率相关的表达式，从而推导出 $\\alpha_{m}$ 的计算公式。  \n- 最终 $\\alpha_{m}$ 的表达式为 $\\frac{1}{2} \\log \\frac{1-\\epsilon_{m}}{\\epsilon_{m}}$，其中 $\\epsilon_{m}$ 是加权错误率。"
      },
      {
        "段落": "## 10.2 自训练和协同训练\n\n监督学习往往需要大量的标注数据，而标注数据的成本比较高。因此，利用大量的无标注数据来提高监督学习的效果有着十分重要的意义。这种利用少量标注数据和大量无标注数据进行学习的方式称为半监督学习（Semi－Supervised Learning，SSL）．\n\n本节介绍两种半监督学习算法：自训练和协同训练。",
        "总结": "- 概念：半监督学习（Semi-Supervised Learning，SSL）是一种利用少量标注数据和大量无标注数据进行学习的方法，旨在降低标注成本并提升监督学习效果。  \n- 算法：自训练是一种半监督学习算法，通过使用模型对无标注数据进行预测并利用预测结果作为伪标签来训练模型。  \n- 算法：协同训练是一种半监督学习算法，通过使用多个分类器对无标注数据进行预测，并利用不同分类器的预测结果进行训练。"
      },
      {
        "段落": "## 10．2．1 自训练\n\n自训练（Self－Training，或 Self－Teaching），也叫自举法（Bootstrapping），是一种非常简单的半监督学习算法［Scudder，1965；Yarowsky，1995］．\n\n自训练是首先使用标注数据来训练一个模型，并使用这个模型来预测无标注样本的标签，把预测置信度比较高的样本及其预测的伪标签加入训练集，然后重新训练新的模型，并不断重复这个过程．算法 10.2 给出了自训练的训练过程．\n\n```\n算法 10.2: 自训练的训练过程\n    输入: 标注数据集 $\\mathcal{L}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$;\n            无标注数据集 $\\mathcal{U}=\\left\\{\\boldsymbol{x}^{(m)}\\right\\}_{m=1}^{M}$;\n            迭代次数 $T$; 每次迭代增加样本数量 $P$;\n    for $t=1 \\cdots T$ do\n        根据训练集 $\\mathcal{L}$, 训练模型 $f$;\n        使用模型 $f$ 对无标注数据集 $u$ 的样本进行预测, 选出预测置信度高的 $P$ 个\n            样本 $\\mathcal{P}=\\left\\{\\left(\\boldsymbol{x}^{(p)}, f\\left(\\boldsymbol{x}^{(p)}\\right)\\right)\\right\\}_{p=1}^{P}$;\n        更新训练集:\n                $\\mathcal{L} \\leftarrow \\mathcal{L} \\cup \\mathcal{P}, \\quad U \\leftarrow U-\\mathcal{P}$.\n    end\n    输出: 模型 $f$\n```\n\n自训练和密度估计中 EM 算法有一定的相似之处，通过不断地迭代来提高模型能力。但自训练的缺点是无法保证每次加入训练集的样本的伪标签是正确的。如果选择样本的伪标签是错误的，反而会损害模型的预测能力。因此，自训练最关键的步骤是如何设置挑选样本的标准。",
        "总结": "- 自训练是一种半监督学习算法，通过利用标注数据训练初始模型，再用该模型预测无标注数据的标签，并将高置信度的预测结果作为伪标签加入训练集，迭代优化模型。\n- 算法10.2描述了自训练的具体过程：在每一轮迭代中，使用当前训练集训练模型，预测无标注数据并选择置信度高的样本作为伪标签，更新训练集后重新训练模型。\n- 自训练与EM算法在迭代优化上有相似之处，但其关键挑战在于伪标签的准确性，错误的伪标签可能损害模型性能。\n- 自训练的核心在于如何有效选择伪标签样本，以确保模型在迭代过程中能够持续提升。"
      },
      {
        "段落": "## 10．2．2 协同训练\n\n协同训练（Co－Training）是自训练的一种改进方法，通过两个基于不同视角（view）的分类器来互相促进。很多数据都有相对独立的不同视角。比如互联网上的每个网页都由两种视角组成：文字内容（text）和指向其他网页的链接 （hyperlink）。如果要确定一个网页的类别，既可以根据文字内容来判断，也可根据网页之间的链接关系来判断．\n\n假设一个样本 $\\boldsymbol{x}=\\left[\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}\\right]$ ，其中 $\\boldsymbol{x}_{1}$ 和 $\\boldsymbol{x}_{2}$ 分别表示两种不同视角 $V_{1}$ 和 $V_{2}$ 的特征，并满足下面两个假设：（1）条件独立性：给定样本标签 $y$ 时，两种特征条件独立 $p\\left(\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2} \\mid y\\right)=p\\left(\\boldsymbol{x}_{1} \\mid y\\right) p\\left(\\boldsymbol{x}_{2} \\mid y\\right) ;(2)$ 充足和冗余性：当数据充分时，每种视角的特征都足以单独训练出一个正确的分类器．令 $y=g(\\boldsymbol{x})$ 为需要学习的真实映射\n\n这里的 bootstrapping和统计中的概念不同。\n\nEM 算 法 参 见 第 11．2．2．1节．\n\n参见习题10－3．\n\n函数，$f_{1}$ 和 $f_{2}$ 分别为两个视角的分类器，有\n\n$$\n\\begin{equation*}\n\\exists f_{1}, f_{2}, \\quad \\forall \\boldsymbol{x} \\in \\mathcal{X}, \\quad f_{1}\\left(\\boldsymbol{x}_{1}\\right)=f_{2}\\left(\\boldsymbol{x}_{2}\\right)=g(\\boldsymbol{x}), \\tag{10.23}\n\\end{equation*}\n$$\n\n其中 $\\mathcal{X}$ 为样本 $\\boldsymbol{x}$ 的取值空间．\n由于不同视角的条件独立性，在不同视角上训练出来的模型就相当于从不同视角来理解问题，具有一定的互补性。协同训练就是利用这种互补性来进行自训练的一种方法。首先在训练集上根据不同视角分别训练两个模型 $f_{1}$ 和 $f_{2}$ ，然后用 $f_{1}$ 和 $f_{2}$ 在无标注数据集上进行预测，各选取预测置信度比较高的样本加入训练集，重新训练两个不同视角的模型，并不断重复这个过程。\n\n算法10．3给出了协同训练的训练过程。协同算法要求两种视角是条件独立的．如果两种视角完全一样，则协同训练退化成自训练算法．\n\n```\n算法 10.3: 协同训练的训练过程\n    输入: 标注数据集 $\\mathcal{L}=\\left\\{\\left(\\boldsymbol{x}^{(n)}, y^{(n)}\\right)\\right\\}_{n=1}^{N}$;\n            无标注数据集 $\\mathcal{U}=\\left\\{\\boldsymbol{x}^{(m)}\\right\\}_{m=1}^{M}$;\n            迭代次数 $T$; 候选池大小 $K$; 每次迭代增加样本数量 $2 P$;\n    for $t=1 \\cdots T$ do\n        根据训练集 $\\mathcal{L}$ 的视角 $V_{1}$ 训练训练模型 $f_{1}$;\n        根据训练集 $\\mathcal{L}$ 的视角 $V_{2}$ 训练训练模型 $f_{2}$;\n        从无标注数据集 $\\mathcal{U}$ 上随机选取一些样本放入候选池 $\\mathcal{U}^{\\prime}$, 使得 $\\left|\\mathcal{U}^{\\prime}\\right|=K$;\n        for $f \\in f_{1}, f_{2}$ do\n            使用模型 $f$ 预测候选池 $\\mathcal{U}^{\\prime}$ 中的样本的伪标签;\n            for $p=1 \\cdots P$ do\n                根据标签分布, 随机选取一个标签 $y$;\n                从 $\\mathcal{U}^{\\prime}$ 中选出伪标签为 $y$, 并且预测置信度最高的样本 $\\boldsymbol{x}$;\n                更新训练集:\n                    $\\mathcal{L} \\leftarrow \\mathcal{L} \\cup\\{(\\boldsymbol{x}, y)\\}, \\quad \\mathcal{U}^{\\prime} \\leftarrow \\mathcal{U}^{\\prime}-\\{(\\boldsymbol{x}, y)\\}$.\n            end\n        end\n    end\n    输出: 模型 $f_{1}, f_{2}$\n```",
        "总结": "- 协同训练是一种自训练的改进方法，通过两个基于不同视角的分类器互相促进来提升模型性能。  \n- 协同训练假设样本由两个不同视角的特征组成，且这两个视角在给定标签下条件独立，并且每个视角的特征都足以单独训练出正确分类器。  \n- 协同训练利用不同视角之间的互补性，通过在无标注数据上进行预测并选择高置信度样本加入训练集，不断迭代优化两个分类器。  \n- 算法流程包括：初始训练两个分类器，从无标注数据中选取候选样本，使用两个分类器预测伪标签，并将高置信度样本加入训练集，重复此过程直到达到迭代次数。  \n- 协同训练要求两种视角条件独立，若视角相同则退化为自训练算法。"
      },
      {
        "段落": "## 10.3 多任务学习\n\n一般的机器学习模型都是针对单一的特定任务，比如手写体数字识别、物体检测等。不同任务的模型都是在各自的训练集上单独学习得到的。如果有两个任务比较相关，它们之间会存在一定的共享知识，这些知识对两个任务都会有所帮 https：／／nndl．github．io／\n\n助．这些共享的知识可以是表示（特征）、模型参数或学习算法等．目前，主流的多任务学习方法主要关注于表示层面的共享。\n\n多任务学习（Multi－task Learning）是指同时学习多个相关任务，让这些任务在学习过程中共享知识，利用多个任务之间的相关性来改进模型在每个任务上的性能和泛化能力。多任务学习可以看作是一种归纳迁移学习（Inductive Trans－ fer Learning），即通过利用包含在相关任务中的信息作为归纳偏置（Inductive Bias）来提高泛化能力［Caruana，1997］。\n\n共享机制 多任务学习的主要挑战在于如何设计多任务之间的共享机制。在传统的机器学习算法中，引入共享的信息是比较困难的，通常会导致模型变得复杂．但是在神经网络模型中，模型共享变得相对比较容易。深度神经网络模型提供了一种很方便的信息共享方式，可以很容易地进行多任务学习．多任务学习的共享机制比较灵活，有很多种共享模式。图10．1给出了多任务学习中四种常见的共享模式，其中 $A 、 B$ 和 $C$ 表示三个不同的任务，橙色框表示共享模块，蓝色框表示任务特定模块。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-246.jpg?height=952&width=856&top_left_y=971&top_left_x=228)\n\n图 10.1 多任务学习中四种常见的共享模式\n\n这四种常见的共享模式分别为：\n（1）硬共享模式：让不同任务的神经网络模型共同使用一些共享模块（一般是低层）来提取一些通用特征，然后再针对每个不同的任务设置一些私有模块（一般是高层）来提取一些任务特定的特征。\n（2）软共享模式：不显式地设置共享模块，但每个任务都可以从其他任务中＂窃取＂一些信息来提高自己的能力。窃取的方式包括直接复制使用其他任务的隐状态，或使用注意力机制来主动选取有用的信息。\n（3）层次共享模式：一般神经网络中不同层抽取的特征类型不同，低层一般抽取一些低级的局部特征，高层抽取一些高级的抽象语义特征。因此如果多任务学习中不同任务也有级别高低之分，那么一个合理的共享模式是让低级任务在低层输出，高级任务在高层输出。\n（4）共享－私有模式：一个更加分工明确的方式是将共享模块和任务特定（私有）模块的责任分开。共享模块捕捉一些跨任务的共享特征，而私有模块只捕捉和特定任务相关的特征。最终的表示由共享特征和私有特征共同构成。\n\n学习步骤 在多任务学习中，每个任务都可以有自己单独的训练集。为了让所有任务同时学习，我们通常会使用交替训练的方式来＂近似＂地实现同时学习。\n\n假设有 $M$ 个相关任务，第 $m$ 个任务的训练集为 $\\mathcal{D}_{m}$ ，包含 $N_{m}$ 个样本．\n\n$$\n\\begin{equation*}\n\\mathcal{D}_{m}=\\left\\{\\left(\\boldsymbol{x}^{(m, n)}, y^{(m, n)}\\right)\\right\\}_{n=1}^{N_{m}} \\tag{10.24}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{x}^{(m, n)}$ 和 $y^{(m, n)}$ 表示第 $m$ 个任务中的第 $n$ 个样本以及它的标签．\n假设这 $M$ 个任务对应的模型分别为 $f_{m}(\\boldsymbol{x} ; \\theta), 1 \\leq m \\leq M$ ，多任务学习的联合目标函数为所有任务损失函数的线性加权．\n\n$$\n\\begin{equation*}\n\\mathcal{L}(\\theta)=\\sum_{m=1}^{M} \\sum_{n=1}^{N_{m}} \\eta_{m} \\mathcal{L}_{m}\\left(f_{m}\\left(x^{(m, n)} ; \\theta\\right), y^{(m, n)}\\right) \\tag{10.25}\n\\end{equation*}\n$$\n\n其中 $\\mathcal{L}_{m}(\\cdot)$ 为第 $m$ 个任务的损失函数，$\\eta_{m}$ 是第 $m$ 个任务的权重，$\\theta$ 表示包含了共享模块和私有模块在内的所有参数。权重可以根据不同任务的重要程度来赋值，也可以根据任务的难易程度来赋值．通常情况下，所有任务设置相同的权重，即 $\\eta_{m}=1,1 \\leq m \\leq M$.\n\n多任务学习的流程可以分为两个阶段：（1）联合训练阶段：每次迭代时，随机挑选一个任务，然后从这个任务中随机选择一些训练样本，计算梯度并更新参数；（2）单任务精调阶段：基于多任务学习得到的参数，分别在每个单独任务进行精调。其中单任务精调阶段为可选阶段。当多个任务的差异性比较大时，在每个单任务上继续优化参数可以进一步提升模型能力。\n\n多任务学习中联合训练阶段的具体过程如算法10．4所示．\n\n```\n算法 10.4: 多任务学习中联合训练过程\n    输入: $M$ 个任务的数据集 $\\mathcal{D}_{m}, 1 \\leq m \\leq M$;\n            每个任务的批量大小 $K_{m}, 1 \\leq m \\leq M$;\n            最大迭代次数 $T$, 学习率 $\\alpha$;\n    随机初始化参数 $\\theta_{0}$;\n    for $t=1 \\cdots T$ do\n        // 准备 $M$ 个任务的数据\n        for $m=1 \\cdots M$ do\n            将任务 $m$ 的训练集 $\\mathcal{D}_{m}$ 中随机划分为 $c=\\frac{N_{m}}{K_{m}}$ 个小批量集合:\n                $\\mathcal{B}_{m}=\\left\\{\\mathcal{I}_{m, 1}, \\cdots, \\mathcal{J}_{m, c}\\right\\} ;$\n        end\n        合并所有小批量样本 $\\overline{\\mathcal{B}}=\\mathcal{B}_{1} \\cup \\mathcal{B}_{2} \\cup \\cdots \\cup \\mathcal{B}_{M}$;\n        随机排序 $\\overline{\\mathcal{B}}$;\n        foreach $\\mathcal{J} \\in \\overline{\\mathcal{B}}$ do\n            计算小批量样本 $\\mathcal{J}$ 上的损失 $\\mathcal{L}(\\theta)$; // 只计算 $\\mathcal{J}$ 在对应任务上的损失\n            更新参数: $\\theta_{t} \\leftarrow \\theta_{t-1}-\\alpha \\cdot \\nabla_{\\theta} \\mathcal{L}(\\theta)$;\n        end\n    end\n    输出: 模型 $f_{m}, 1 \\leq m \\leq M$\n```\n\n多任务学习通常可以获得比单任务学习更好的泛化能力，主要有以下几个原因：\n（1）多任务学习在多个任务的数据集上进行训练，比单任务学习的训练集更大．由于多个任务之间有一定的相关性，因此多任务学习相当于是一种隐式的数据增强，可以提高模型的泛化能力。\n（2）多任务学习中的共享模块需要兼顾所有任务，这在一定程度上避免了模型过拟合到单个任务的训练集，可以看作是一种正则化。\n（3）既然一个好的表示通常需要适用于多个不同任务，多任务学习的机制使得参见第1．3节。它会比单任务学习获得更好的表示。\n（4）在多任务学习中，每个任务都可以＂选择性＂利用其他任务中学习到的隐藏特征，从而提高自身的能力。",
        "总结": "- 多任务学习（Multi-task Learning）是指同时学习多个相关任务，通过共享知识来提升每个任务的性能和泛化能力。\n- 多任务学习可以看作是一种归纳迁移学习，利用相关任务的信息作为归纳偏置来提高泛化能力。\n- 共享机制是多任务学习的核心挑战，常见的共享模式包括硬共享、软共享、层次共享和共享－私有模式。\n- 多任务学习的联合目标函数是所有任务损失函数的线性加权，参数 $\\theta$ 包含共享模块和私有模块。\n- 联合训练阶段通过随机选择任务和样本，计算梯度并更新参数；单任务精调阶段为可选，用于进一步优化模型。\n- 多任务学习通常能获得更好的泛化能力，原因包括更大的训练集、正则化效果、更好的表示学习以及任务间的信息利用。"
      },
      {
        "段落": "## 10.4 迁移学习\n\n标准机器学习的前提假设是训练数据和测试数据的分布是相同的．如果不满足这个假设，在训练集上学习到的模型在测试集上的表现会比较差。而在很多\nhttps：／／nndl．github．io／\n\n实际场景中，经常碰到的问题是标注数据的成本十分高，无法为一个目标任务准备足够多相同分布的训练数据。因此，如果有一个相关任务已经有了大量的训练数据，虽然这些训练数据的分布和目标任务不同，但是由于训练数据的规模比较大，我们假设可以从中学习某些可以泛化的知识，那么这些知识对目标任务会有一定的帮助。如何将相关任务的训练数据中的可泛化知识迁移到目标任务上，就是迁移学习（Transfer Learning）要解决的问题。\n\n具体而言，假设一个机器学习任务 $\\mathcal{J}$ 的样本空间为 $\\mathcal{X} \\times \\mathcal{y}$ ，其中 $\\mathcal{X}$ 为输入空间，$y$ 为输出空间，其概率密度函数为 $p(\\boldsymbol{x}, y)$ 。为简单起见，这里设 $\\mathcal{X}$ 为 $D$ 维实数空间的一个子集，$y$ 为一个离散的集合．\n\n一个样本空间及其分布可以称为一个领域（Domain）： $\\mathcal{D}=(\\mathcal{X}, \\mathcal{y}, p(\\boldsymbol{x}, y))$ 。给定两个领域，如果它们的输入空间、输出空间或概率分布中至少一个不同，那么这两个领域就被认为是不同的。从统计学习的观点来看，一个机器学习任务 $\\mathcal{J}$ 定义为在一个领域 $\\mathcal{D}$ 上的条件概率 $p(y \\mid \\boldsymbol{x})$ 的建模问题。\n\n迁移学习是指两个不同领域的知识迁移过程，利用源领域（Source Domain） $\\mathcal{D}_{S}$ 中学到的知识来帮助目标领域（Target Domain） $\\mathcal{D}_{T}$ 上的学习任务。源领域的训练样本数量一般远大于目标领域。\n\n表10．1给出了迁移学习和标准机器学习的比较．\n表 10.1 迁移学习和标准机器学习的比较\n\n| 学习类型 | 样本空间 | 概率分布 |\n| :--- | :---: | :---: |\n| 标准机器学习 | $x_{S}=x_{T}, y_{S}=y_{T}$ | $p_{S}(\\boldsymbol{x}, y)=p_{T}(\\boldsymbol{x}, y)$ |\n| 迁移学习 | $x_{S} \\neq x_{T}$ 或 $y_{S} \\neq y_{T}$ 或 $p_{S}(\\boldsymbol{x}, y) \\neq p_{T}(\\boldsymbol{x}, y)$ |  |\n\n迁移学习根据不同的迁移方式又分为两个类型：归纳迁移学习（Inductive Transfer Learning）和转导迁移学习（Transductive Transfer Learning）。这两个类型分别对应两个机器学习的范式：归纳学习（Inductive Learning）和转导学习（Transductive Learning）［Vapnik，1998］．一般的机器学习都是指归纳学习，即希望在训练数据集上学习到使得期望风险（即真实数据分布上的错误率）最小的模型。而转导学习的目标是学习一种在给定测试集上错误率最小的模型，在训练阶段可以利用测试集的信息。\n\n归纳迁移学习是指在源领域和任务上学习出一般的规律，然后将这个规律迁移到目标领域和任务上；而转导迁移学习是一种从样本到样本的迁移，直接利用源领域和目标领域的样本进行迁移学习。\n$p(x, y)=P(X=$ $x, Y=y)$.\n\n期望风险参见第2．2．2节。",
        "总结": "- 迁移学习的概念：迁移学习是解决训练数据与测试数据分布不一致问题的方法，通过将源领域中的可泛化知识迁移到目标任务上，以提升模型性能。  \n- 标准机器学习的前提假设：训练数据和测试数据的分布相同，若不满足则模型表现可能较差。  \n- 迁移学习的场景：当目标任务标注数据成本高或数量不足时，利用相关任务的大量训练数据进行知识迁移。  \n- 领域（Domain）的定义：一个领域由输入空间、输出空间及概率分布组成，即 $\\mathcal{D} = (\\mathcal{X}, \\mathcal{Y}, p(\\boldsymbol{x}, y))$。  \n- 迁移学习的分类：分为归纳迁移学习和转导迁移学习，分别对应归纳学习和转导学习范式。  \n- 归纳迁移学习：在源领域学习一般规律，并迁移到目标领域。  \n- 转导迁移学习：直接利用源领域和目标领域的样本进行样本到样本的迁移。  \n- 迁移学习与标准机器学习的对比：迁移学习允许样本空间或概率分布不同，而标准机器学习要求两者一致。"
      },
      {
        "段落": "## 10．4．1 归纳迁移学习\n\n在归纳迁移学习中，源领域和目标领域有相同的输入空间 $x_{S}=x_{T}$ ，输出空间可以相同也可以不同，源任务和目标任务一般不相同 $\\mathcal{J}_{S} \\neq \\mathcal{J}_{T}$ ，即 $p_{S}(y \\mid \\boldsymbol{x}) \\neq$ $p_{T}(y \\mid \\boldsymbol{x})$ 。一般而言，归纳迁移学习要求源领域和目标领域是相关的，并且源领域 $\\mathcal{D}_{S}$ 有大量的训练样本，这些样本可以是有标注的样本，也可以是无标注样本．\n\n1．当源领域只有大量无标注数据时，源任务可以转换为无监督学习任务，比如自编码和密度估计任务。通过这些无监督任务学习一种可迁移的表示，然后再将这种表示迁移到目标任务上。这种学习方式和自学习（Self－Taught Learning） ［Raina et al．，2007］以及半监督学习比较类似．比如在自然语言处理领域，由于语言相关任务的标注成本比较高，很多自然语言处理任务的标注数据都比较少，这导致了在这些自然语言处理任务上经常会受限于训练样本数量而无法充分发挥深度学习模型的能力。同时，由于我们可以低成本地获取大规模的无标注自然语言文本，因此一种自然的迁移学习方式是将大规模文本上的无监督学习（比如语言模型）中学到的知识迁移到一个新的目标任务上。从早期的预训练词向量（比如 word2vec［Mikolov et al．，2013］和 GloVe［Pennington et al．，2014］等）到句子级表示（比如 ELMO［Peters et al．，2018］、OpenAI GPT［Radford et al．，2018］以及 BERT［Devlin et al．，2018］等）都对自然语言处理任务有很大的促进作用．\n\n2．当源领域有大量的标注数据时，可以直接将源领域上训练的模型迁移到目标领域上。比如在计算机视觉领域有大规模的图像分类数据集 ImageNet ［Deng et al．，2009］．由于在 ImageNet 数据集上有很多预训练的图像分类模型，比如 AlexNet［Krizhevsky et al．，2012］、VGG［Simonyan et al．，2014］和 ResNet［He et al．，2016］等，我们可以将这些预训练模型迁移到目标任务上．\n\n在归纳迁移学习中，由于源领域的训练数据规模非常大，这些预训练模型通常有比较好的泛化性，其学习到的表示通常也适用于目标任务。归纳迁移学习一般有下面两种迁移方式：\n（1）基于特征的方式：将预训练模型的输出或者是中间隐藏层的输出作为特征直接加入到目标任务的学习模型中．目标任务的学习模型可以是一般的浅层分类器（比如支持向量机等）或一个新的神经网络模型。\n（2）精调的方式：在目标任务上复用预训练模型的部分组件，并对其参数进行精调（fine－tuning）。\n\n假设预训练模型是一个深度神经网络，这个预训练网络中每一层的可迁移性也不尽相同［Yosinski et al．，2014］．通常来说，网络的低层学习一些通用的低层特征，中层或高层学习抽象的高级语义特征，而最后几层一般学习和特定任务相关\n\n自编码器参见第9．1．3节。\n概率密度估计参见第 9.2 节．\n\n的特征．因此，根据目标任务的自身特点以及和源任务的相关性，可以有针对性地选择预训练模型的不同层来迁移到目标任务中。\n\n将预训练模型迁移到目标任务上通常会比从零开始学习的方式更好，主要体现在以下三点［Torrey et al．，2010］：（1）初始模型的性能一般比随机初始化的模型要好；（2）训练时模型的学习速度比从零开始学习要快，收敛性更好；（3）模型的最终性能更好，具有更好的泛化性．\n\n归纳迁移学习和多任务学习也比较类似，但有下面两点区别：（1）多任务学习是同时学习多个不同任务，而归纳迁移学习通常分为两个阶段，即源任务上的学习阶段和目标任务上的迁移学习阶段；（2）归纳迁移学习是单向的知识迁移，希望提高模型在目标任务上的性能，而多任务学习是希望提高所有任务的性能。",
        "总结": "- 归纳迁移学习中，源领域和目标领域共享相同的输入空间，但输出空间可能不同，且源任务与目标任务通常不同。  \n- 源领域通常有大量训练样本，这些样本可以是标注的或无标注的。  \n- 当源领域仅有大量无标注数据时，可将其转换为无监督学习任务（如自编码、密度估计），学习可迁移表示并迁移到目标任务上。  \n- 自学习和半监督学习与这种迁移方式类似，例如在自然语言处理中利用大规模无标注文本进行预训练。  \n- 早期的预训练词向量（如 word2vec、GloVe）和现代模型（如 BERT、GPT）对自然语言处理任务有显著促进作用。  \n- 当源领域有大量标注数据时，可直接将预训练模型迁移到目标领域，如计算机视觉中的 ImageNet 预训练模型。  \n- 归纳迁移学习通常有两种迁移方式：基于特征的方式（使用预训练模型的输出或隐藏层作为特征）和精调的方式（在目标任务上微调预训练模型参数）。  \n- 预训练模型各层的可迁移性不同：低层学习通用特征，中高层学习抽象语义特征，最后几层与特定任务相关。  \n- 根据目标任务特点选择不同层进行迁移，以提高性能。  \n- 迁移学习通常优于从零开始训练：初始性能更好、训练速度更快、最终性能更优且泛化性更强。  \n- 归纳迁移学习与多任务学习类似，但存在两点区别：一是分阶段进行（源任务学习和目标迁移），二是知识迁移是单向的，仅关注目标任务性能提升。"
      },
      {
        "段落": "## 10．4．2 转导迁移学习\n\n转导迁移学习是一种从样本到样本的迁移，直接利用源领域和目标领域的样本进行迁移学习［Arnold et al．，2007］．转导迁移学习可以看作一种特殊的转导学习（Transductive Learning）［Joachims，1999］．转导迁移学习通常假设源领域有大量的标注数据，而目标领域没有（或只有少量）标注数据，但是有大量的无标注数据。目标领域的数据在训练阶段是可见的。\n\n转导迁移学习的一个常见子问题是领域适应（Domain Adaptation）。在领域适应问题中，一般假设源领域和目标领域有相同的样本空间，但是数据分布不同 $p_{S}(\\boldsymbol{x}, y) \\neq p_{T}(\\boldsymbol{x}, y)$ 。\n\n根据贝叶斯公式，$p(\\boldsymbol{x}, y)=p(\\boldsymbol{x} \\mid y) p(y)=p(y \\mid \\boldsymbol{x}) p(\\boldsymbol{x})$ ，因此数据分布的不一致通常由三种情况造成：\n（1）协变量偏移（Covariate Shift）：源领域和目标领域的输入边际分布不同 $p_{S}(\\boldsymbol{x}) \\neq p_{T}(\\boldsymbol{x})$ ，但后验分布相同 $p_{S}(y \\mid \\boldsymbol{x})=p_{T}(y \\mid \\boldsymbol{x})$ ，即学习任务相同 $\\mathcal{T}_{S}=\\mathcal{J}_{T}$.\n（2）概念偏移（Concept Shift）：输入边际分布相同 $p_{S}(\\boldsymbol{x})=p_{T}(\\boldsymbol{x})$ ，但后验分布不同 $p_{S}(y \\mid \\boldsymbol{x}) \\neq p_{T}(y \\mid \\boldsymbol{x})$ ，即学习任务不同 $\\mathcal{T}_{S} \\neq \\mathcal{J}_{T}$ 。\n（3）先验偏移（Prior Shift）：源领域和目标领域中的输出标签 $y$ 的先验分布不同 $p_{S}(y) \\neq p_{T}(y)$ ，条件分布相同 $p_{S}(\\boldsymbol{x} \\mid y)=p_{T}(\\boldsymbol{x} \\mid y)$ 。在这样情况下，目标领域必须提供一定数量的标注样本．\n\n广义的领域适应问题可能包含上述一种或多种偏移情况。目前，大多数的领域适应问题主要关注于协变量偏移，这样领域适应问题的关键就在于如何学习领域无关（Domain－Invariant）的表示。假设 $p_{S}(y \\mid \\boldsymbol{x})=p_{T}(y \\mid \\boldsymbol{x})$ ，领域适应的目标\n\n是学习一个模型 $f: x \\rightarrow y$ 使得\n\n$$\n\\begin{align*}\n\\mathcal{R}_{T}\\left(\\theta_{f}\\right) & =\\mathbb{E}_{(\\boldsymbol{x}, y) \\sim p_{T}(\\boldsymbol{x}, y)}\\left[\\mathcal{L}\\left(f\\left(\\boldsymbol{x} ; \\theta_{f}\\right), y\\right)\\right]  \\tag{10.26}\\\\\n& =\\mathbb{E}_{(\\boldsymbol{x}, y) \\sim p_{S}(\\boldsymbol{x}, y)} \\frac{p_{T}(\\boldsymbol{x}, y)}{p_{S}(\\boldsymbol{x}, y)}\\left[\\mathcal{L}\\left(f\\left(\\boldsymbol{x} ; \\theta_{f}\\right), y\\right)\\right]  \\tag{10.27}\\\\\n& =\\mathbb{E}_{(\\boldsymbol{x}, y) \\sim p_{S}(\\boldsymbol{x}, y)} \\frac{p_{T}(\\boldsymbol{x})}{p_{S}(\\boldsymbol{x})}\\left[\\mathcal{L}\\left(f\\left(\\boldsymbol{x} ; \\theta_{f}\\right), y\\right)\\right] \\tag{10.28}\n\\end{align*}\n$$\n\n其中 $\\mathcal{L}(\\cdot)$ 为损失函数，$\\theta_{f}$ 为模型参数。\n如果我们可以学习一个映射函数 $g: X \\rightarrow \\mathbb{R}^{d}$ ，将 $\\boldsymbol{x}$ 映射到一个特征空间中，并在这个特征空间中使得源领域和目标领域的边际分布相同 $p_{S}\\left(g\\left(\\boldsymbol{x} ; \\theta_{g}\\right)\\right)=$ $p_{T}\\left(g\\left(\\boldsymbol{x} ; \\theta_{g}\\right)\\right), \\forall \\boldsymbol{x} \\in \\mathcal{X}$ ，其中 $\\theta_{g}$ 为映射函数的参数，那么目标函数可以近似为\n\n$$\n\\begin{align*}\n\\mathcal{R}_{T}\\left(\\theta_{f}, \\theta_{g}\\right) & =\\mathbb{E}_{(\\boldsymbol{x}, y) \\sim p_{S}(\\boldsymbol{x}, y)}\\left[\\mathcal{L}\\left(f\\left(g\\left(\\boldsymbol{x} ; \\theta_{g}\\right) ; \\theta_{f}\\right), y\\right)\\right]+\\gamma d_{g}(S, T)  \\tag{10.29}\\\\\n& =\\mathcal{R}_{S}\\left(\\theta_{f}, \\theta_{g}\\right)+\\gamma d_{g}(S, T) \\tag{10.30}\n\\end{align*}\n$$\n\n其中 $\\mathcal{R}_{S}\\left(\\theta_{f}, \\theta_{g}\\right)$ 为源领域上的期望风险函数，$d_{g}(S, T)$ 是一个分布差异的度量函数，用来计算在映射特征空间中源领域和目标领域的样本分布的距离，$\\gamma$ 为一个超参数，用来平衡两个子目标的重要性比例．这样，学习的目标是优化参数 $\\theta_{f}, \\theta_{g}$使得提取的特征是领域无关的，并且在源领域上损失最小。\n\n$$\n\\begin{align*}\n& \\mathcal{D}_{S}=\\left\\{\\left(\\boldsymbol{x}_{S}^{(n)}, y_{S}^{(n)}\\right)\\right\\}_{n=1}^{N} \\sim p_{S}(\\boldsymbol{x}, y),  \\tag{10.31}\\\\\n& \\mathcal{D}_{T}=\\left\\{\\boldsymbol{x}_{T}^{(m)}\\right\\}_{m=1}^{M} \\sim p_{T}(\\boldsymbol{x}, y), \\tag{10.32}\n\\end{align*}\n$$\n\n分别为源领域和目标领域的训练数据，我们首先用映射函数 $g\\left(\\boldsymbol{x}, \\theta_{g}\\right)$ 将两个领域中训练样本的输入 $\\boldsymbol{x}$ 映射到特征空间，并优化参数 $\\theta_{g}$ 使得映射后两个领域的输入分布差异最小。分布差异一般可以通过一些度量函数来计算，比如 MMD （ Maximum Mean Discrepancy ）［Gretton et al．，2007］、CMD（ Central Moment Discrepancy）［Zellinger et al．，2017］等，也可以通过领域对抗学习来得到领域无关的表示［Bousmalis et al．，2016；Ganin et al．，2016］．\n\n以对抗学习为例，我们可以引入一个领域判别器 $c$ 来判断一个样本是来自于哪个领域。如果领域判别器 $c$ 无法判断一个映射特征的领域信息，就可以认为这个特征是一种领域无关的表示。\n\n对于训练集中的每一个样本 $\\boldsymbol{x}$ ，我们都赋予 $z \\in\\{1,0\\}$ 表示它是来自于源领域还是目标领域，领域判别器 $c\\left(\\boldsymbol{h}, \\theta_{c}\\right)$ 根据其映射特征 $\\boldsymbol{h}=g\\left(\\boldsymbol{x}, \\theta_{g}\\right)$ 来预测它来自于源领域的概率 $p(z=1 \\mid \\boldsymbol{x})$ 。由于领域判别是一个两分类问题， $\\boldsymbol{h}$ 来自于目标领域的概率为 $1-c\\left(\\boldsymbol{h}, \\theta_{c}\\right)$ ．\nhttps：／／nndl．github．io／\n\n因此，领域判别器的损失函数为：\n\n$$\n\\begin{equation*}\n\\mathcal{L}_{c}\\left(\\theta_{g}, \\theta_{c}\\right)=\\frac{1}{N} \\sum_{n=1}^{N} \\log c\\left(\\boldsymbol{h}_{S}^{(n)}, \\theta_{c}\\right)+\\frac{1}{M} \\sum_{m=1}^{M} \\log \\left(1-c\\left(\\boldsymbol{x}_{D}^{(m)}, \\theta_{c}\\right)\\right), \\tag{10.33}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{h}_{S}^{(n)}=g\\left(\\boldsymbol{x}_{S}^{(n)}, \\theta_{g}\\right), \\boldsymbol{h}_{D}^{(m)}=g\\left(\\boldsymbol{x}_{D}^{(m)}, \\theta_{g}\\right)$ 分别为样本 $\\boldsymbol{x}_{S}^{(n)}$ 和 $\\boldsymbol{x}_{D}^{(m)}$ 的特征向量。\n这样，领域迁移的目标函数可以分解为两个对抗的目标。一方面，要学习参数 $\\theta_{c}$ 使得领域判别器 $c\\left(\\boldsymbol{h}, \\theta_{c}\\right)$ 尽可能区分出一个表示 $\\boldsymbol{h}=g\\left(\\boldsymbol{x}, \\theta_{g}\\right)$ 是来自于哪个领域；另一方面，要学习参数 $\\theta_{g}$ 使得提取的表示 $\\boldsymbol{h}$ 无法被领域判别器 $c\\left(\\boldsymbol{h}, \\theta_{c}\\right)$ 预测出来，并同时学习参数 $\\theta_{g}$ 使得模型 $f\\left(\\boldsymbol{h} ; \\theta_{f}\\right)$ 在源领域的损失最小。\n\n$$\n\\begin{array}{ll}\n\\min _{\\theta_{c}} & \\mathcal{L}_{c}\\left(\\theta_{f}, \\theta_{c}\\right) \\\\\n\\min _{\\theta_{f}, \\theta_{g}} & \\sum_{n=1}^{N} \\mathcal{L}\\left(f\\left(g\\left(\\boldsymbol{x}_{S}^{(n)} ; \\theta_{g}\\right) ; \\theta_{f}\\right), y_{S}^{(n)}\\right)-\\gamma \\mathcal{L}_{c}\\left(\\theta_{f}, \\theta_{c}\\right) \\tag{10.35}\n\\end{array}\n$$",
        "总结": "- 转导迁移学习是从样本到样本的迁移，利用源领域和目标领域的样本进行学习，目标领域有大量无标注数据。  \n- 转导迁移学习是转导学习的一种特殊形式，假设源领域有大量标注数据，目标领域仅有少量或无标注数据。  \n- 领域适应是转导迁移学习的常见子问题，假设源和目标领域有相同样本空间但分布不同。  \n- 数据分布不一致由三种偏移情况造成：协变量偏移、概念偏移和先验偏移。  \n- 协变量偏移指输入边际分布不同但后验分布相同，概念偏移指输入分布相同但后验不同，先验偏移指输出先验不同但条件分布相同。  \n- 领域适应的目标是学习领域无关的表示，使源和目标领域的边际分布一致。  \n- 领域适应的目标函数通过引入损失函数和分布差异度量函数来优化模型参数。  \n- 分布差异可通过MMD、CMD等度量函数或对抗学习方法来计算。  \n- 对抗学习中引入领域判别器来判断特征是否包含领域信息，目标是使判别器无法区分特征来源。  \n- 领域判别器的损失函数通过源和目标领域的特征进行分类损失计算。  \n- 领域迁移的目标函数包括两个对抗目标：区分领域和使特征无法被区分，同时最小化源领域的损失。"
      },
      {
        "段落": "## 10.5 终身学习\n\n虽然深度学习在很多任务上取得了成功，但是其前提是训练数据和测试数据的分布要相同，一旦训练结束模型就保持固定，不再进行迭代更新。并且，要想一个模型同时在很多不同任务上都取得成功依然是一件十分困难的事情。比如在围棋任务上训练的 AlphaGo只会下围棋，对象棋一窍不通。如果让 AlphaGo 去学习下象棋，可能会损害其下围棋的能力，这显然不符合人类的学习过程。我们在学会了下围棋之后，再去学下象棋，并不会忘记下围棋的下法。 人类的学习是一直持续的，人脑可以通过记忆不断地累积学习到的知识，这些知识累积可以在不同的任务中持续进行。在大脑的海马系统上，新的知识在以往知识的基础上被快速建立起来；之后经过长时间的处理，在大脑皮质区形成较难遗忘的长时记忆。由于不断的知识累积，人脑在学习新的任务时一般不需要太多的标注数据．\n\n终身学习（Lifelong Learning），也叫持续学习（Continuous Learning），是指像人类一样具有持续不断的学习能力，根据历史任务中学到的经验和知识来帮助学习不断出现的新任务，并且这些经验和知识是持续累积的，不会因为新的任务而忘记旧的知识［Chen et al．，2016；Thrun，1998］．\n\n在终身学习中，假设一个终身学习算法已经在历史任务 $\\mathcal{J}_{1}, \\mathcal{J}_{2}, \\cdots, \\mathcal{J}_{m}$ 上学习到一个模型，当出现一个新任务 $\\mathcal{J}_{m+1}$ 时，这个算法可以根据过去在 $m$ 个任务上学习的知识来帮助学习第 $m+1$ 个任务，同时累积所有的 $m+1$ 个任务上的知识。这个设定和归纳迁移学习十分类似，但归纳迁移学习的目标是优化目标任务的性能，而不关心知识的累积。而终身学习的目标是持续的学习和知识累积。另外，终身学习和多任务学习也十分类似，但不同之处在于终身学习并不在所有任务上同\n\n时学习．多任务学习是在使用所有任务的数据进行联合学习，并不是持续地一个一个的学习。\n\n在终身学习中，一个关键的问题是如何避免灾难性遗忘（Catastrophic For－ getting），即按照一定顺序学习多个任务时，在学习新任务的同时不忘记先前学会的历史任务［French，1999；Kirkpatrick et al．，2017］．比如在神经网络模型中，一些参数对任务 $\\mathcal{J}_{A}$ 非常重要，如果在学习任务 $\\mathcal{J}_{B}$ 时被改变了，就可能给任务 $\\mathcal{J}_{A}$造成不好的影响．\n\n在网络容量有限时，学习一个新的任务一般需要遗忘一些历史任务的知识。而目前的神经网络往往都是过参数化的，对于任务 $\\mathcal{J}_{A}$ 而言有很多参数组合都可以达到最好的性能。这样，在学习任务 $\\mathcal{J}_{B}$ 时，可以找到一组不影响任务 $\\mathcal{J}_{A}$ 而又能使得任务 $\\mathcal{J}_{B}$ 最优的参数．\n\n解决灾难性遗忘的方法有很多．我们这里介绍一种弹性权重巩固（Elastic Weight Consolidation）方法［Kirkpatrick et al．，2017］．\n\n不失一般性，以两个任务的持续学习为例，假设任务 $\\mathcal{J}_{A}$ 和任务 $\\mathcal{J}_{B}$ 的数据集分别为 $\\mathcal{D}_{A}$ 和 $\\mathcal{D}_{B}$ 。从贝叶斯的角度来看，将模型参数 $\\theta$ 看作随机向量，给定两个任务时 $\\theta$ 的后验分布为\n\n$$\n\\begin{equation*}\n\\log p(\\theta \\mid \\mathcal{D})=\\log p(\\mathcal{D} \\mid \\theta)+\\log p(\\theta)-\\log p(\\mathcal{D}) \\tag{10.36}\n\\end{equation*}\n$$\n\n其中 $\\mathcal{D}=\\mathcal{D}_{A} \\cup \\mathcal{D}_{B}$ 。根据独立同分布假设，上式可以写为\n\n$$\n\\begin{align*}\n\\log p(\\theta \\mid \\mathcal{D}) & =\\underline{\\log p\\left(\\mathcal{D}_{A} \\mid \\theta\\right)}+\\log p\\left(\\mathcal{D}_{B} \\mid \\theta\\right)+\\underline{\\log p(\\theta)}-\\underline{\\log p\\left(\\mathcal{D}_{A}\\right)}-\\log p\\left(\\mathcal{D}_{B}\\right)  \\tag{10.37}\\\\\n& =\\log p\\left(\\mathcal{D}_{B} \\mid \\theta\\right)+\\underline{\\log p\\left(\\theta \\mid \\mathcal{D}_{A}\\right)}-\\log p\\left(\\mathcal{D}_{B}\\right) \\tag{10.38}\n\\end{align*}\n$$\n\n其中 $p\\left(\\theta \\mid \\mathcal{D}_{A}\\right)$ 包含了所有在任务 $\\mathcal{J}_{A}$ 上学习到的信息。当顺序地学习任务 $\\mathcal{J}_{B}$ 时，参数在两个任务上的后验分布和其在任务 $\\mathcal{J}_{A}$ 的后验分布有关。\n\n由于后验分布比较难以建模，我们可以通过一个近似的方法来估计。假设 $p\\left(\\theta \\mid \\mathcal{D}_{A}\\right)$ 为高斯分布，期望为在任务 $\\mathcal{J}_{A}$ 上学习到的参数 $\\theta_{A}^{*}$ ，精度矩阵（即协方差矩阵的逆）可以用参数 $\\theta$ 在数据集 $\\mathcal{D}_{A}$ 上的 Fisher 信息矩阵来近似，即\n\n$$\n\\begin{equation*}\np\\left(\\theta \\mid \\mathcal{D}_{A}\\right)=\\mathcal{N}\\left(\\theta_{A}^{*}, F^{-1}\\right) \\tag{10.39}\n\\end{equation*}\n$$\n\n其中 $F$ 为 Fisher 信息矩阵。为了提高计算效率，$F$ 可以简化为对角阵，由 Fisher 信息矩阵对角线构成。\n\nFisher信息矩阵 Fisher信息矩阵（Fisher Information Matrix）是一种测量似然函数 $p(x ; \\theta)$ 携带的关于参数 $\\theta$ 的信息量的方法．通常一个参数对分布的影响可 https：／／nndl．github．io／\n\n参 考［Bishop，2007］中第4章中的拉普拉斯近似．\n\n以通过对数似然函数的梯度来衡量．令打分函数 $s(\\theta)$ 为\n\n$$\n\\begin{equation*}\ns(\\theta)=\\nabla_{\\theta} \\log p(x ; \\theta) \\tag{10.40}\n\\end{equation*}\n$$\n\n则 $s(\\theta)$ 的期望为 0 ．\n\n证明．\n\n$$\n\\begin{align*}\n\\mathbb{E}[s(\\theta)] & =\\int \\nabla_{\\theta} \\log p(x ; \\theta) p(x ; \\theta) \\mathrm{d} x  \\tag{10.41}\\\\\n& =\\int \\frac{\\nabla_{\\theta} p(x ; \\theta)}{p(x ; \\theta)} p(x ; \\theta) \\mathrm{d} x  \\tag{10.42}\\\\\n& =\\int \\nabla_{\\theta} p(x ; \\theta) \\mathrm{d} x  \\tag{10.43}\\\\\n& =\\nabla_{\\theta} \\int p(x ; \\theta) \\mathrm{d} x  \\tag{10.44}\\\\\n& =\\nabla_{\\theta} 1=0 \\tag{10.45}\n\\end{align*}\n$$\n\n$s(\\theta)$ 的协方差矩阵称为 Fisher信息矩阵，可以衡量参数 $\\theta$ 的估计的不确定性．\n\n$$\n\\begin{align*}\nF(\\theta) & =\\mathbb{E}\\left[s(\\theta) s(\\theta)^{\\top}\\right]  \\tag{10.46}\\\\\n& =\\mathbb{E}\\left[\\nabla_{\\theta} \\log p(x ; \\theta)\\left(\\nabla_{\\theta} \\log p(x ; \\theta)\\right)^{\\top}\\right] \\tag{10.47}\n\\end{align*}\n$$\n\n由于我们不知道似然函数 $p(x ; \\theta)$ 的具体形式，Fisher信息矩阵可以用经验分布来进行估计。给定一个数据集 $\\left\\{x^{(1)}, \\cdots, x^{(N)}\\right\\}$ ，Fisher信息矩阵可以近似为\n\n$$\n\\begin{equation*}\nF(\\theta)=\\frac{1}{N} \\sum_{n=1}^{N} \\nabla_{\\theta} \\log p\\left(x^{(n)} ; \\theta\\right)\\left(\\nabla_{\\theta} \\log p\\left(x^{(n)} ; \\theta\\right)\\right)^{\\top} \\tag{10.48}\n\\end{equation*}\n$$\n\nFisher 信息矩阵的对角线的值反映了对应参数在通过最大似然进行估计时的不确定性，其值越大，表示该参数估计值的方差越小，估计更可靠性，其携带的关于数据分布的信息越多。\n\n因此，对于任务 $\\mathcal{J}_{A}$ 的数据集 $\\mathcal{D}_{A}$ ，我们可以用 Fisher 信息矩阵来衡量一个参数携带的关于 $\\mathcal{D}_{A}$ 的信息量。\n\n$$\n\\begin{equation*}\nF^{A}(\\theta)=\\frac{1}{N} \\sum_{(\\boldsymbol{x}, y) \\in \\mathcal{D}_{A}} \\nabla_{\\theta} \\log p(y \\mid \\boldsymbol{x} ; \\theta)\\left(\\nabla_{\\theta} \\log p(y \\mid \\boldsymbol{x} ; \\theta)\\right)^{\\top} \\tag{10.49}\n\\end{equation*}\n$$\n\n通过上面的近似，在训练任务 $\\mathcal{J}_{B}$ 时的损失函数为\n\n$$\n\\begin{equation*}\n\\mathcal{L}(\\theta)=\\mathcal{L}_{B}(\\theta)+\\sum_{i=1}^{N} \\frac{\\lambda}{2} F_{i}^{A} \\cdot\\left(\\theta_{i}-\\theta_{A, i}^{*}\\right)^{2} \\tag{10.50}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n其中 $\\mathcal{L}_{B}(\\theta)$ 为任务 $p\\left(\\theta \\mid \\mathcal{D}_{B}\\right)$ 的损失函数，$F_{i}^{A}$ 为 Fisher信息矩阵的第 $i$ 个对角线元素，$\\theta_{A}^{*}$ 为在任务 $\\mathcal{J}_{A}$ 上学习到的参数，$\\lambda$ 为平衡两个任务重要性的超参数，$N$ 为参数的总数量．",
        "总结": "- 终身学习（Lifelong Learning）是指模型能够持续学习新任务，并累积历史任务的知识，不会遗忘旧知识。  \n- 终身学习与归纳迁移学习和多任务学习不同，它强调知识的持续累积，而非单一任务的性能优化。  \n- 灾难性遗忘（Catastrophic Forgetting）是终身学习中的关键问题，指在学习新任务时可能遗忘旧任务的知识。  \n- 弹性权重巩固（Elastic Weight Consolidation）是一种解决灾难性遗忘的方法，通过引入Fisher信息矩阵来约束参数更新，以保留旧任务的知识。  \n- Fisher信息矩阵用于衡量参数对数据分布的信息量，其对角线元素反映了对应参数的不确定性。  \n- 在终身学习中，损失函数结合了新任务的损失和旧任务参数的约束项，以平衡新旧任务的学习。"
      },
      {
        "段落": "## 10.6 元学习\n\n根据没有免费午餐定理，没有一种通用的学习算法可以在所有任务上都有效。因此，当使用机器学习算法实现某个任务时，我们通常需要＂就事论事＂，根据任务的特点来选择合适的模型、损失函数、优化算法以及超参数。那么，我们是否可以有一套自动方法，根据不同任务来动态地选择合适的模型或动态地调整超参数呢？事实上，人脑中的学习机制就具备这种能力。在面对不同的任务时，人脑的学习机制并不相同。即使面对一个新的任务，人们往往也可以很快找到其学习方式。这种可以动态调整学习方式的能力，称为元学习（Meta－Learning），也称为学习的学习（Learning to Learn ）［Thrun et al．，2012］．\n\n元学习的目的是从已有任务中学习一种学习方法或元知识，可以加速新任务的学习。从这个角度来说，元学习十分类似于归纳迁移学习，但元学习更侧重从多种不同（甚至是不相关）的任务中归纳出一种学习方法。\n\n和元学习比较相关的另一个机器学习问题是小样本学习（Few－shot Learn－ ing），即在小样本上的快速学习能力。每个类只有 $K$ 个标注样本，$K$ 非常小。如果 $K=1$ ，称为单样本学习（One－shot Learning）；如果 $K=0$ ，称为零样本学习 （Zero－shot Learning）．\n\n这里我们主要介绍两种典型的元学习方法：基于优化器的元学习和模型无关的元学习。",
        "总结": "- 元学习（Meta-Learning）是一种能够动态调整学习方式的能力，旨在从已有任务中学习一种学习方法或元知识，以加速新任务的学习。  \n- 元学习与归纳迁移学习类似，但更侧重于从多种不同甚至不相关的任务中归纳出一种通用的学习方法。  \n- 小样本学习（Few-shot Learning）是指在仅有少量标注样本的情况下进行快速学习，其中 $K=1$ 时称为单样本学习（One-shot Learning），$K=0$ 时称为零样本学习（Zero-shot Learning）。  \n- 文中介绍了两种典型的元学习方法：基于优化器的元学习和模型无关的元学习。"
      },
      {
        "段落": "## 10．6．1 基于优化器的元学习\n\n目前神经网络的学习方法主要是定义一个目标损失函数 $\\mathcal{L}(\\theta)$ ，并通过梯度下降算法来最小化 $\\mathcal{L}(\\theta)$ ，\n\n$$\n\\begin{equation*}\n\\theta_{t} \\leftarrow \\theta_{t-1}-\\alpha \\nabla \\mathcal{L}\\left(\\theta_{t-1}\\right) \\tag{10.51}\n\\end{equation*}\n$$\n\n其中 $\\theta_{t}$ 为第 $t$ 步时的模型参数，$\\nabla \\mathcal{L}\\left(\\theta_{t-1}\\right)$ 为梯度，$\\alpha$ 为学习率．根据没有免费午餐定理，没有一种通用的优化算法可以在所有任务上都有效。因此在不同的任务\n\n参见第7．2节．上，我们需要选择不同的学习率以及不同的优化方法，比如动量法、Adam等。这些选择对具体一个学习的影响非常大。对于一个新的任务，我们往往通过经验或超参搜索来选择一个合适的设置．\n\n不同的优化算法的区别在于更新参数的规则不同，因此一种很自然的元学习就是自动学习一种更新参数的规则，即通过另一个神经网络（比如循环神经\n\n网络）来建模梯度下降的过程［Andrychowicz et al．，2016；Schmidhuber，1992； Younger et al．，2001］．图10．2给出了基于优化器的元学习的示例．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-257.jpg?height=321&width=1005&top_left_y=265&top_left_x=160)\n\n图 10.2 基于优化器的元学习\n\n我们用函数 $g_{t}(\\cdot)$ 来预测第 $t$ 步时参数更新的差值 $\\Delta \\theta_{t}=\\theta_{t}-\\theta_{t-1}$ 。函数 $g_{t}(\\cdot)$称为优化器，输入是当前时刻的梯度值，输出是参数的更新差值 $\\Delta \\theta_{t}$ ．这样，第 $t$步的更新规则可以写为\n\n$$\n\\begin{equation*}\n\\theta_{t+1}=\\theta_{t}+g_{t}\\left(\\nabla \\mathcal{L}\\left(\\theta_{t}\\right) ; \\phi\\right) \\tag{10.52}\n\\end{equation*}\n$$\n\n其中 $\\phi$ 为优化器 $g_{t}(\\cdot)$ 的参数．\n学习优化器 $g_{t}(\\cdot)$ 的过程可以看作是一种元学习过程，其目标是找到一个适用于多个不同任务的优化器。在标准梯度下降中，每步迭代的目标是使得 $\\mathcal{L}(\\theta)$下降。而在优化器的元学习中，我们希望在每步迭代的目标是 $\\mathcal{L}(\\theta)$ 最小，具体的目标函数为\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\phi) & =\\mathbb{E}_{f}\\left[\\sum_{t=1}^{T} w_{t} \\mathcal{L}\\left(\\theta_{t}\\right)\\right]  \\tag{10.53}\\\\\n\\theta_{t} & =\\theta_{t-1}+\\boldsymbol{g}_{t}  \\tag{10.54}\\\\\n{\\left[\\boldsymbol{g}_{t} ; \\boldsymbol{h}_{t}\\right] } & =\\operatorname{LSTM}\\left(\\nabla \\mathcal{L}\\left(\\theta_{t-1}\\right), \\boldsymbol{h}_{t-1} ; \\phi\\right) \\tag{10.55}\n\\end{align*}\n$$\n\n其中 $T$ 为最大迭代次数，$w_{t}>0$ 为每一步的权重，一般可以设置 $w_{t}=1, \\forall t$ 。由于 LSTM 网络可以记忆梯度的历史信息，学习到的优化器可以看作是一个高阶的优化方法．\n\n在每步训练时，随机初始化模型参数，计算每一步的 $\\mathcal{L}\\left(\\theta_{t}\\right)$ ，以及元学习的损失函数 $\\mathcal{L}(\\phi)$ ，并使用梯度下降更新参数。由于神经网络的参数非常多，导致 LSTM 网络的输入和输出都是非常高维的，训练这样一个巨大的网络是不可行的。因此，一种简化的方法是为每个参数都使用一个共享的 LSTM 网络来进行更新，这样可以使用一个非常小的共享 LSTM 网络来更新参数。",
        "总结": "- 基于优化器的元学习是一种元学习方法，其核心思想是通过另一个神经网络（如循环神经网络）来建模梯度下降过程，从而自动学习参数更新规则。  \n- 优化器 $g_t(\\cdot)$ 的作用是根据当前梯度预测参数更新差值 $\\Delta \\theta_t$，其输入为当前梯度，输出为参数更新值。  \n- 元学习的目标是找到一个适用于多个任务的优化器，通过最小化目标函数 $\\mathcal{L}(\\phi)$ 来实现，该函数对多个任务的损失进行加权求和。  \n- 在元学习过程中，使用 LSTM 网络来记忆梯度的历史信息，从而学习到一个高阶优化方法。  \n- 为了简化训练，采用共享 LSTM 网络对所有参数进行更新，以减少计算复杂度。"
      },
      {
        "段落": "## 10．6．2 模型无关的元学习\n\n元学习的目标之一是快速学习的能力，即在多个不同的任务上学习一个模型，让其在新任务上经过少量的迭代，甚至是单步迭代，就可以达到一个非常好的性能，并且避免在新任务上的过拟合。\n\n模型无关的元学习（Model－Agnostic Meta－Learning，MAML）是一个简单的模型无关、任务无关的元学习算法［Finn et al．，2017］．假设所有的任务都来自于一个任务空间，其分布为 $p(\\mathcal{T})$ ，我们可以在这个任务空间的所有任务上学习一种通用的表示，这种表示可以经过梯度下降方法在一个特定的单任务上进行精调。假设一个模型为 $f_{\\theta}$ ，如果我们让这个模型适应到一个新任务 $\\mathcal{I}_{m}$ 上，通过一步或多步的梯度下降更新，学习到的任务适配参数为\n\n$$\n\\begin{equation*}\n\\theta_{m}^{\\prime}=\\theta-\\alpha \\nabla_{\\theta} \\mathcal{L}_{\\mathcal{T}_{m}}\\left(f_{\\theta}\\right) \\tag{10.56}\n\\end{equation*}\n$$\n\n其中 $\\alpha$ 为学习率．这里 $\\theta_{m}^{\\prime}$ 可以理解为关于 $\\theta$ 的函数，而不是真正的参数更新．\nMAML 的目标是学习一个参数 $\\theta$ 使得其经过一个梯度迭代就可以在新任务上达到最好的性能，即\n\n$$\n\\begin{equation*}\n\\min _{\\theta} \\sum_{\\mathcal{J}_{m} \\sim p(\\mathcal{T})} \\mathcal{L}_{\\mathcal{J}_{m}}\\left(f_{\\theta_{m}^{\\prime}}\\right)=\\min _{\\theta} \\sum_{\\mathcal{J}_{m} \\sim p(\\mathcal{T})} \\mathcal{L}_{\\mathcal{J}_{m}}(f(\\underbrace{\\theta-\\alpha \\nabla_{\\theta} \\mathcal{L}_{\\mathcal{J}_{m}}\\left(f_{\\theta}\\right)}_{\\theta_{m}^{\\prime}})) \\tag{10.57}\n\\end{equation*}\n$$\n\n在所有任务上的元优化（Meta－Optimization）也采用梯度下降来进行优化，即\n\n$$\n\\begin{align*}\n\\theta & \\leftarrow \\theta-\\beta \\nabla_{\\theta} \\sum_{m=1}^{M} \\mathcal{L}_{\\mathcal{J}_{m}}\\left(f_{\\theta_{m}^{\\prime}}\\right)  \\tag{10.58}\\\\\n& =\\theta-\\beta \\sum_{m=1}^{M} \\nabla_{\\theta} \\mathcal{L}_{\\mathcal{J}_{m}}\\left(f_{\\theta_{m}}\\right)\\left(I-\\alpha \\nabla_{\\theta}^{2} \\mathcal{L}_{\\mathcal{J}_{m}}\\left(f_{\\theta_{m}}\\right)\\right), \\tag{10.59}\n\\end{align*}\n$$\n\n其中 $\\beta$ 为元学习率，$I$ 为单位阵．这一步是一个真正的参数更新步骤．这里可以看出，当 $\\alpha$ 比较小时，MAML就近似为普通的多任务学习优化方法．MAML 需要计算关于 $\\theta$ 的二阶梯度，但用一些近似的一阶方法通常也可以达到比较好的性能。\n\nMAML 的具体过程如算法 10.5 所示．",
        "总结": "- 概念：模型无关的元学习（MAML）是一种元学习算法，旨在使模型在少量迭代后快速适应新任务。  \n- 算法：MAML通过梯度下降方法在任务空间中学习通用参数，使得模型能通过一步或几步更新适应新任务。  \n- 数学推导：定义了任务适配参数 $\\theta_{m}^{\\prime}$ 为 $\\theta - \\alpha \\nabla_{\\theta} \\mathcal{L}_{\\mathcal{T}_{m}}(f_{\\theta})$，并以最小化元损失函数为目标。  \n- 定理/命题：MAML的目标是通过元优化找到参数 $\\theta$，使得其在新任务上性能最优，公式为 $\\min_{\\theta} \\sum_{\\mathcal{J}_{m} \\sim p(\\mathcal{T})} \\mathcal{L}_{\\mathcal{J}_{m}}(f(\\theta - \\alpha \\nabla_{\\theta} \\mathcal{L}_{\\mathcal{J}_{m}}(f_{\\theta})))$。  \n- 元优化过程：采用梯度下降进行元优化，公式为 $\\theta \\leftarrow \\theta - \\beta \\sum_{m=1}^{M} \\nabla_{\\theta} \\mathcal{L}_{\\mathcal{J}_{m}}(f_{\\theta_{m}})(I - \\alpha \\nabla_{\\theta}^{2} \\mathcal{L}_{\\mathcal{J}_{m}}(f_{\\theta_{m}}))$。  \n- 特点：当学习率 $\\alpha$ 较小时，MAML近似为多任务学习；需要计算二阶梯度，但可用一阶近似方法实现良好性能。"
      },
      {
        "段落": "## 10.7 总结和深入阅读\n\n目前，神经网络的学习机制主要是以监督学习为主，这种学习方式得到的模型往往是任务定向的，也是孤立的。每个任务的模型都是从零开始来训练的，一切知识都需要从训练数据中得到，导致每个任务都需要大量的训练数据。这种学习方式和人脑的学习方式是不同的，人脑的学习一般不需要太多的标注数据，并且 https：／／nndl．github．io／\n\n```\n算法 10.5: 模型无关的元学习过程\n    输入: 任务分布 $p(\\mathcal{T})$;\n            最大迭代次数 $T$, 学习率 $\\alpha, \\beta$;\n    随机初始化参数 $\\theta$;\n    for $t=1 \\cdots T$ do\n        根据 $p(\\mathcal{J})$ 采样一个任务集合 $\\left\\{\\mathcal{J}_{m}\\right\\}_{m=1}^{M}$ for $m=1 \\cdots M$ do\n            计算 $\\nabla_{\\theta} \\mathcal{L}_{\\mathcal{J}_{m}}\\left(f_{\\theta}\\right)$;\n            计算任务适配的参数: $\\theta_{m}^{\\prime} \\leftarrow \\theta-\\alpha \\nabla_{\\theta} \\mathcal{L}_{\\mathcal{J}_{m}}\\left(f_{\\theta}\\right)$;\n        end\n        更新参数: $\\theta \\leftarrow \\theta-\\beta \\nabla_{\\theta} \\sum_{m=1}^{M} \\mathcal{L}_{\\mathcal{T}_{m}}\\left(f_{\\theta_{m}^{\\prime}}\\right)$;\n    end\n    输出: 模型 $f_{\\theta}$\n```\n\n是一种持续的学习，可以通过记忆不断地累积学习到的知识。本章主要介绍了一些和模型无关的学习方式．\n\n集成学习是一种通过汇总多个模型来提高预测准确率的有效方法，代表性模型有随机森林［Breiman，2001］和 AdaBoost［Freund et al．，1996］．集成学习可以参考 《Pattern Recognition and Machine Learning》［Bishop，2007］和综述文献 ［Zhou，2012］．在训练神经网络时经常采用的丢弃法在一定程度上也是一个模型集成．\n\n半监督学习研究的主要内容就是如何高效地利用少量标注数据和大量无标注数据来训练分类器。相比于监督学习，半监督学习一般需要更少的标注数据，因此在理论和实际应用中均受到了广泛关注。半监督学习可以参考综述［Zhu， 2006］．最早在训练中运用无标注数据的方法是自训练（Self－Training）［Scudder， 1965］．在自训练的基础上，［Blum et al．，1998］提出了由两个分类器协同训练的算法 Co－Training．该工作获得了国际机器学习会议 ICML 2008 的 10 年最佳论文．\n\n多任务学习是一种利用多个相关任务来提高模型泛化性的方法，可以参考文献［Caruana，1997；Zhang et al．，2017］．\n\n迁移学习是研究如何将在一个领域上训练的模型迁移到新的领域，使得新模型不用从零开始学习．但在迁移学习中需要避免将领域相关的特征迁移到新的领域［Ganin et al．，2016；Pan et al．，2010］．迁移学习的一个主要研究问题是领域适应［Ben－David et al．，2010；Zhang et al．，2013］．\n\n终身学习是一种持续的学习方式，学习系统可以不断累积在先前任务中学到的知识，并在未来新的任务中利用这些知识［Chen et al．，2016；Goodfellow et al．， 2013；Kirkpatrick et al．，2017］．\n\n元学习主要关注如何在多个不同任务上学习一种可泛化的快速学习能力\n［Thrun et al．，2012］．\n上述这些方式都是目前深度学习中的前沿研究问题．",
        "总结": "- 模型无关的元学习过程：提出一种元学习算法，通过在多个任务上进行参数更新，使模型能够快速适应新任务，无需从零开始训练。\n- 集成学习：通过结合多个模型的预测结果来提高整体准确率，代表性方法包括随机森林和AdaBoost。\n- 半监督学习：利用少量标注数据和大量无标注数据训练分类器，减少对标注数据的依赖，方法如自训练和Co-Training。\n- 多任务学习：通过同时学习多个相关任务来提升模型泛化能力，参考文献包括Caruana和Zhang等人的研究。\n- 迁移学习：将一个领域上训练好的模型迁移到新领域，避免领域相关特征的迁移，关注领域适应问题。\n- 终身学习：持续学习机制，系统能够累积先前任务的知识并在新任务中加以利用。\n- 元学习：研究如何在多个任务上学习快速泛化的学习能力，以提升模型在新任务上的适应速度。"
      },
      {
        "段落": "## 习题\n\n习题 10－1 根据 Jensen 不等式以及公式（10．6），证明公式（10．9）中的 $\\overline{\\mathcal{R}}(f) \\geq$ $\\mathcal{R}(F)$ ．\n\n习题 10－2 集成学习是否可以避免过拟合？\n习题10－3 分析自训练和 EM 算法之间的联系。\n习题10－4 根据最大后验估计来推导公式（10．50）．",
        "总结": "- 概念：Jensen不等式，用于证明期望值与函数值的不等关系。  \n- 概念：集成学习，通过结合多个模型的预测结果以提高整体性能的方法。  \n- 概念：过拟合，模型在训练数据上表现良好但在新数据上表现差的现象。  \n- 概念：自训练，利用模型自身预测结果作为伪标签进行训练的方法。  \n- 概念：EM算法，一种迭代优化算法，用于处理含有隐变量的概率模型。  \n- 概念：最大后验估计，基于贝叶斯框架，在参数空间中寻找后验概率最大化的参数值。  \n- 算法：EM算法，包含E步（计算隐变量的期望）和M步（最大化似然函数）的迭代过程。  \n- 公式推导：根据最大后验估计推导公式（10．50），涉及对参数的优化过程。  \n- 定理/命题：Jensen不等式，用于证明公式（10．9）中 $\\overline{\\mathcal{R}}(f) \\geq \\mathcal{R}(F)$ 的不等关系。"
      },
      {
        "段落": "## 参考文献\n\nAndrychowicz M，Denil M，Gomez S，et al．Learning to learn by gradient descent by gradient descent［C］／／Advances in Neural Information Processing Systems．2016：3981－3989．\nArnold A，Nallapati R，Cohen W W．A comparative study of methods for transductive transfer learning［C］／／icdmw．IEEE，2007：77－82．\nBen－David S，Blitzer J，Crammer K，et al．A theory of learning from different domains［J］．Machine learning，2010，79（1－2）：151－175．\nBishop C M．Pattern recognition and machine learning［M］．5th edition．Springer， 2007.\nBlum A，Mitchell T．Combining labeled and unlabeled data with co－training［C］／／Proceedings of the eleventh annual conference on Computational learning theory．1998：92－100．\nBousmalis K，Trigeorgis G，Silberman N，et al．Domain separation networks［C］／／Advances in Neu－ ral Information Processing Systems．2016：343－351．\nBreiman L．Random forests［J］．Machine learning，2001，45（1）：5－32．\nCaruana R．Multi－task learning［J］．Machine Learning，1997，28（1）：41－75．\nChen Z，Liu B．Lifelong machine learning［J］．Synthesis Lectures on Artificial Intelligence and Machine Learning，2016，10（3）：1－145．\nDeng J，Dong W，Socher R，et al．Imagenet：A large－scale hierarchical image database［C］／／ Computer Vision and Pattern Recognition，2009．CVPR 2009．IEEE Conference on．IEEE，2009： 248－255．\nDevlin J，Chang M W，Lee K，et al．BERT：Pre－training of deep bidirectional transformers for lan－ guage understanding［J］．arXiv preprint arXiv：1810．04805， 2018.\nFinn C，Abbeel P，Levine S．Model－agnostic meta－learning for fast adaptation of deep networks ［C］／／Proceedings of the 34th International Conference on Machine Learning－Volume 70．JMLR． org，2017：1126－1135．\nFrench R M．Catastrophic forgetting in connectionist networks［J］．Trends in cognitive sciences， 1999，3（4）：128－135．\nFreund Y，Schapire R E，et al．Experiments with a new boosting algorithm［C］／／Proceedings of the International Conference on Machine Learning：volume 96．1996：148－156．\nFriedman J，Hastie T，Tibshirani R，et al．Additive logistic regression：a statistical view of boosting ［J］．The annals of statistics，2000，28（2）：337－407．\nhttps：／／nndl．github．io／\n\nGanin Y，Ustinova E，Ajakan H，et al．Domain－adversarial training of neural networks［J］．Journal of Machine Learning Research，2016，17（59）：1－35．\nGoodfellow I J，Mirza M，Xiao D，et al．An empirical investigation of catastrophic forgetting in gradient－based neural networks［J］．arXiv preprint arXiv：1312．6211， 2013.\nGretton A，Borgwardt K M，Rasch M，et al．A kernel method for the two－sample－problem［C］／／ Advances in neural information processing systems．2007：513－520．\nHe K，Zhang X，Ren S，et al．Deep residual learning for image recognition［C］／／Proceedings of the IEEE conference on computer vision and pattern recognition．2016：770－778．\nJoachims T．Transductive inference for text classification using support vector machines［C］／／ ICML：volume 99．1999：200－209．\nKirkpatrick J，Pascanu R，Rabinowitz N，et al．Overcoming catastrophic forgetting in neural net－ works［J］．Proceedings of the national academy of sciences，2017，114（13）：3521－3526．\nKrizhevsky A，Sutskever I，Hinton G E．ImageNet classification with deep convolutional neural networks［C］／／Advances in Neural Information Processing Systems 25．2012：1106－1114．\nMikolov T，Sutskever I，Chen K，et al．Distributed representations of words and phrases and their compositionality［C］／／Advances in neural information processing systems．2013：3111－3119．\nPan S J，Yang Q．A survey on transfer learning［J］．IEEE Transactions on knowledge and data engineering，2010，22（10）：1345－1359．\nPennington J，Socher R，Manning C．Glove：Global vectors for word representation［C］／／ Proceedings of the 2014 conference on empirical methods in natural language processing （EMNLP）．2014：1532－1543．\nPeters M E，Neumann M，Iyyer M，et al．Deep contextualized word representations［J］．arXiv preprint arXiv：1802．05365， 2018.\nRadford A，Narasimhan K，Salimans T，et al．Improving language understanding by generative pre－training［Z／OL］．2018．https：／／s3－us－west－2．amazonaws．com／openai－assets／research－covers／ languageunsupervised／languageunderstandingpaper．pdf．\nRaina R，Battle A，Lee H，et al．Self－taught learning：transfer learning from unlabeled data［C］／／ Proceedings of the 24th international conference on Machine learning．2007：759－766．\nSchmidhuber J．Learning to control fast－weight memories：An alternative to dynamic recurrent networks［J］．Neural Computation，1992，4（1）：131－139．\nScudder H．Probability of error of some adaptive pattern－recognition machines［J］．IEEE Transac－ tions on Information Theory，1965，11（3）：363－371．\nSimonyan K，Zisserman A．Very deep convolutional networks for large－scale image recognition［J］． arXiv preprint arXiv：1409．1556， 2014.\nThrun S．Lifelong learning algorithms［M］／／Learning to learn．Springer，1998：181－209．\nThrun S，Pratt L．Learning to learn［M］．Springer Science \\＆Business Media， 2012.\nTorrey L，Shavlik J．Transfer learning［M］／／Handbook of Research on Machine Learning Applica－ tions and Trends：Algorithms，Methods，and Techniques．IGI Global，2010：242－264．\nVapnik V．Statistical learning theory［M］．New York：Wiley， 1998.\nYarowsky D．Unsupervised word sense disambiguation rivaling supervised methods［C］／／ Proceedings of the 33rd annual meeting on Association for Computational Linguistics．1995：189－ 196.\n\nYosinski J，Clune J，Bengio Y，et al．How transferable are features in deep neural networks？［C］／／ Advances in neural information processing systems．2014：3320－3328．\nYounger A S，Hochreiter S，Conwell P R．Meta－learning with backpropagation［C］／／Proceedings of International Joint Conference on Neural Networks：volume 3．IEEE， 2001.\nZellinger W，Grubinger T，Lughofer E，et al．Central moment discrepancy（cmd）for domain－ invariant representation learning［J］．arXiv preprint arXiv：1702．08811， 2017.\n\nZhang K，Schölkopf B，Muandet K，et al．Domain adaptation under target and conditional shift ［C］／／International Conference on Machine Learning．2013：819－827．\nZhang Y，Yang Q．A survey on multi－task learning［J］．arXiv preprint arXiv：1707．08114， 2017.\nZhou Z H．Ensemble methods：foundations and algorithms［M］．Chapman and Hall／CRC， 2012.\nZhu X．Semi－supervised learning literature survey［J］．Computer Science，University of Wisconsin－ Madison，2006，2（3）：4．",
        "总结": "- 参考文献部分列出了多个与机器学习、深度学习、迁移学习、领域适应、多任务学习等相关的重要研究论文和书籍。  \n- 包含了多个经典算法和理论，如随机森林（Random Forests）、多任务学习（Multi-task Learning）、迁移学习（Transfer Learning）等。  \n- 提到了一些关键概念，如灾难性遗忘（Catastrophic Forgetting）、领域不变表示学习（Domain-Invariant Representation Learning）、对抗训练（Domain-Adversarial Training）等。  \n- 涉及了多种模型和方法，如BERT、Glove、Deep Residual Networks、Deep Contextualized Word Representations等。  \n- 引用了多个重要的理论框架，如统计学习理论（Statistical Learning Theory）、支持向量机（Support Vector Machines）等。  \n- 包含了多个实验和研究结果，涉及图像识别、自然语言处理、文本分类等多个领域。"
      },
      {
        "段落": "## 第三部分",
        "总结": "- 概念：介绍了某种理论框架或模型的基本定义。  \n- 算法：提出了一种新的计算方法或优化策略。  \n- 定理：证明了一个关键的数学结论或性质。  \n- 数学推导：通过一系列逻辑步骤推导出核心公式或关系式。"
      },
      {
        "段落": "## 进阶模型",
        "总结": "- 提出了一种进阶模型，用于提升现有模型的性能和复杂度。  \n- 该模型引入了新的结构或机制，以增强对复杂任务的处理能力。  \n- 通过数学推导，证明了该模型在特定条件下的有效性。  \n- 提出了一个优化算法，用于训练和调整进阶模型的参数。  \n- 该算法基于梯度下降法，并结合了正则化技术以防止过拟合。  \n- 模型在多个基准数据集上进行了实验验证，结果表明其性能优于传统方法。"
      },
      {
        "段落": "## 第11章 概率图模型\n\n> 概率论只不过是把常识归纳为计算问题．\n\n一皮诶尔•西蒙•拉普拉斯（Pierre－Simon Laplace）\n\n概率图模型（Probabilistic Graphical Model，PGM），简称图模型（Graph－ ical Model，GM），是指一种用图结构来描述多元随机变量之间条件独立关系的概率模型，从而给研究高维空间中的概率模型带来了很大的便捷性．\n\n对于一个 $K$ 维随机向量 $\\boldsymbol{X}=\\left[X_{1}, X_{2}, \\cdots, X_{K}\\right]^{\\top}$ ，其联合概率为高维空间中的分布，一般难以直接建模。假设每个变量为离散变量并有 $M$ 个取值，在不作任何独立假设条件下，则需要 $M^{K}-1$ 个参数才能表示其概率分布．当 $M=2, K=100$时，参数量约为 $10^{30}$ ，远远超出了目前计算机的存储能力。\n\n一种有效减少参数量的方法是独立性假设。一个 $K$ 维随机向量 $\\boldsymbol{X}$ 的联合概率分解为 $K$ 个条件概率的乘积，\n\n$$\n\\begin{align*}\np(\\boldsymbol{x}) & \\triangleq P(\\boldsymbol{X}=\\boldsymbol{x})  \\tag{11.1}\\\\\n& =\\prod_{k=1}^{K} p\\left(x_{k} \\mid x_{1}, \\cdots, x_{k-1}\\right) \\tag{11.2}\n\\end{align*}\n$$\n\n其中 $x_{k}$ 表示变量 $X_{k}$ 的取值．如果某些变量之间存在条件独立，其参数量就可以大幅减少。\n\n假设有四个二值变量 $X_{1}, X_{2}, X_{3}, X_{4}$ ，在不知道这几个变量依赖关系的情况下，可以用一个联合概率表来记录每一种取值的概率 $p\\left(\\boldsymbol{x}_{1: 4}\\right)$ ，共需要 $2^{4}-1=15$个参数．假设在已知 $X_{1}$ 时，$X_{2}$ 和 $X_{3}$ 独立，即有\n\n$$\n\\begin{align*}\n& p\\left(x_{2} \\mid x_{1}, x_{3}\\right)=p\\left(x_{2} \\mid x_{1}\\right)  \\tag{11.3}\\\\\n& p\\left(x_{3} \\mid x_{1}, x_{2}\\right)=p\\left(x_{3} \\mid x_{1}\\right) \\tag{11.4}\n\\end{align*}\n$$\n\n在本书中，随机变量用斜体的大写字母表示，其取值用斜体的小写字母表示；随机向量用粗斜体的大写字母表示，其取值用粗斜体的小写字母表示．\n\n在已知 $X_{2}$ 和 $X_{3}$ 时，$X_{4}$ 也和 $X_{1}$ 独立，即有\n\n$$\n\\begin{equation*}\np\\left(x_{4} \\mid x_{1}, x_{2}, x_{3}\\right)=p\\left(x_{4} \\mid x_{2}, x_{3}\\right) \\tag{11.5}\n\\end{equation*}\n$$\n\n那么其联合概率 $p(\\boldsymbol{x})$ 可以分解为\n\n$$\n\\begin{align*}\np(\\boldsymbol{x}) & =p\\left(x_{1}\\right) p\\left(x_{2} \\mid x_{1}\\right) p\\left(x_{3} \\mid x_{1}, x_{2}\\right) p\\left(x_{4} \\mid x_{1}, x_{2}, x_{3}\\right)  \\tag{11.6}\\\\\n& =p\\left(x_{1}\\right) p\\left(x_{2} \\mid x_{1}\\right) p\\left(x_{3} \\mid x_{1}\\right) p\\left(x_{4} \\mid x_{2}, x_{3}\\right) \\tag{11.7}\n\\end{align*}\n$$\n\n是 4 个局部条件概率的乘积。如果分别用 4 个表格来记录这 4 个条件概率的话，只需要 $1+2+2+4=9$ 个独立参数．\n\n当概率模型中的变量数量比较多时，其条件依赖关系也比较复杂。我们可以使用图结构的方式将概率模型可视化，以一种直观、简单的方式描述随机变量之间的条件独立性的性质，并可以将一个复杂的联合概率模型分解为一些简单条件概率模型的组合。图11．1给出了上述例子中 4 个变量之间的条件独立性的图形化描述．图中每个节点表示一个变量，每条连边表示变量之间的依赖关系．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-265.jpg?height=203&width=446&top_left_y=933&top_left_x=430)\n\n图 11.1 变量 $X_{1}, X_{2}, X_{3}, X_{4}$ 之间条件独立性的图形化表示\n\n图模型的基本问题 图模型有三个基本问题：\n（1）表示问题：对于一个概率模型，如何通过图结构来描述变量之间的依赖关系。\n（2）学习问题：图模型的学习包括图结构的学习和参数的学习．在本章，我们只关注在给定图结构时的参数学习，即参数估计问题。\n（3）推断问题：在已知部分变量时，计算其他变量的条件概率分布。\n\n图模型与机器学习 很多机器学习模型都可以归结为概率模型，即建模输入和输出之间的条件概率分布。因此，图模型提供了一种新的角度来解释机器学习模型，并且这种角度有很多优点，比如了解不同机器学习模型之间的联系，方便设计新模型等。在机器学习中，图模型越来越多地用来设计和分析各种学习算法。",
        "总结": "- 概率图模型（PGM）是一种用图结构描述多元随机变量条件独立关系的概率模型，简化高维概率建模。  \n- 联合概率分布的参数量随变量数量指数增长，独立性假设可大幅减少参数量。  \n- 条件独立性假设下，联合概率可分解为局部条件概率的乘积，如 $p(\\boldsymbol{x}) = p(x_1)p(x_2|x_1)p(x_3|x_1)p(x_4|x_2,x_3)$。  \n- 图模型通过节点和边表示变量及其依赖关系，直观描述条件独立性。  \n- 图模型的三个基本问题：表示、学习（参数估计）和推断（条件概率计算）。  \n- 图模型为机器学习提供新视角，有助于理解模型间关系并设计新算法。"
      },
      {
        "段落": "## 11.1 模型表示\n\n图由一组节点和节点之间的边组成。在概率图模型中，每个节点都表示一个随机变量（或一组随机变量），边表示这些随机变量之间的概率依赖关系。\nhttps：／／nndl．github．io／\n\n常见的概率图模型可以分为两类：有向图模型和无向图模型．\n（1）有向图模型的图结构为有向非循环图（Directed Acyclic Graph，DAG）。如果两个节点之间有连边，表示对应的两个变量为因果关系，即不存在其他变量使得这两个节点对应的变量条件独立。\n（2）无向图模型使用无向图（Undirected Graph）来描述变量之间的关系。每条边代表两个变量之间有概率依赖关系，但是并不一定是因果关系。\n\n图11．2给出了两个代表性图模型（有向图和无向图）的示例，分别表示了四个变量 $\\left\\{X_{1}, X_{2}, X_{3}, X_{4}\\right\\}$ 之间的依赖关系。图中带阴影的节点表示可观测到的变量，不带阴影的节点表示隐变量，连边表示两变量间的条件依赖关系。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-266.jpg?height=275&width=985&top_left_y=718&top_left_x=161)\n\n图 11.2 有向图和无向图示例",
        "总结": "- 概念：概率图模型，由节点（随机变量）和边（概率依赖关系）组成，分为有向图模型和无向图模型。\n- 概念：有向图模型使用有向非循环图（DAG），边表示因果关系，变量间条件独立需排除其他变量影响。\n- 概念：无向图模型使用无向图，边表示概率依赖关系，但不一定是因果关系。\n- 示例：图11.2展示了有向图和无向图分别表示四个变量之间的依赖关系，阴影节点为可观测变量，非阴影节点为隐变量，边表示条件依赖关系。"
      },
      {
        "段落": "## 11．1．1 有向图模型\n\n有向图模型（Directed Graphical model），也称为贝叶斯网络（Bayesian Network），或信念网络（Belief Network，BN），是一类用有向图来描述随机向量概率分布的模型．\n\n定义11．1－贝叶斯网络：对于一个 $K$ 维随机向量 $\\boldsymbol{X}$ 和一个有 $K$ 个节点的有向非循环图 $G, G$ 中的每个节点都对应一个随机变量，每个连接 $e_{i j}$ 表示两个随机变量 $X_{i}$ 和 $X_{j}$ 之间具有非独立的因果关系。令 $\\boldsymbol{X}_{\\pi_{k}}$ 表示变量 $X_{k}$ 的所有父节点变量集合，$P\\left(X_{k} \\mid \\boldsymbol{X}_{\\pi_{k}}\\right)$ 表示每个随机变量的局部条件概率分布（Local Conditional Probability Distribution）。如果 $\\boldsymbol{X}$ 的联合概率分布可以分解为每个随机变量 $X_{k}$ 的局部条件概率的连乘形式，即\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x})=\\prod_{k=1}^{K} p\\left(x_{k} \\mid \\boldsymbol{x}_{\\pi_{k}}\\right), \\tag{11.8}\n\\end{equation*}\n$$\n\n那么 $(G, \\boldsymbol{X})$ 构成了一个贝叶斯网络．\n\n在本章后文中，＂节点＂与＂随机变量＂、＂变量＂的概念会经常混用．每个节点对应一个随机变量。\n\n如果两个节点不是直接连接的，但是它们之间有一条经过其他节点的路径来连接，那么这两个节点之间的条件独立性就比较复杂．以三个节点的贝叶斯网络为例，给定三个节点 $X_{1} 、 X_{2} 、 X_{3}$ ，其中 $X_{1}$ 和 $X_{3}$ 是不直接连接的，通过节点 $X_{2}$ 连接。这三个节点之间可以有四种连接关系，如图11．3所示。在图11．3a和图11．3b中， $X_{1} \\Perp X_{3} \\mid \\varnothing$ ，但 $X_{1} \\Perp X_{3} \\mid X_{2}$ ；在图11．3c中，$X_{1} \\Perp X_{3} \\mid \\varnothing$ ，但 $X_{1} \\Perp X_{3} \\mid X_{2}$ ；在图11．3d中， $X_{1} \\Perp X_{3} \\mid \\varnothing$ ，但 $X_{1} \\Perp X_{3} \\mid X_{2}$ 。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-267.jpg?height=389&width=834&top_left_y=494&top_left_x=232)\n\n图 11.3 三个变量的依赖关系示例\n\n图11．3中的四种关系分别为：\n（1）间接因果关系（图11．3a）：当 $X_{2}$ 已知时，$X_{1}$ 和 $X_{3}$ 为条件独立，即 $X_{1} \\Perp X_{3} \\mid X_{2}$ 。\n（2）间接果因关系（图11．3b）：当 $X_{2}$ 已知时，$X_{1}$ 和 $X_{3}$ 为条件独立，即 $X_{1} \\Perp X_{3} \\mid X_{2}$ 。\n（3）共因关系（图11．3c）：当 $X_{2}$ 未知时，$X_{1}$ 和 $X_{3}$ 是不独立的；当 $X_{2}$ 已知时，$X_{1}$和 $X_{3}$ 条件独立，即 $X_{1} \\Perp X_{3} \\mid X_{2}$ 。\n（4）共果关系（图11．3d）：当 $X_{2}$ 未知时，$X_{1}$ 和 $X_{3}$ 是独立的；当 $X_{2}$ 已知时，$X_{1}$ 和 $X_{3}$ 不独立，即 $X_{1} \\Perp X_{3} \\mid X_{2}$ 。\n\n局部马尔可夫性质 对一个更一般的贝叶斯网络，其局部马尔可夫性质为：每个随机变量在给定父节点的情况下，条件独立于它的非后代节点。\n\n$$\n\\begin{equation*}\nX_{k} \\Perp Z \\mid X_{\\pi_{k}}, \\tag{11.9}\n\\end{equation*}\n$$\n\n其中 $Z$ 为 $X_{k}$ 的非后代变量．",
        "总结": "- 有向图模型，也称为贝叶斯网络或信念网络，是一种用有向非循环图描述随机向量概率分布的模型。  \n- 贝叶斯网络的定义：由一个有向非循环图 $G$ 和一个 $K$ 维随机向量 $\\boldsymbol{X}$ 构成，每个节点对应一个随机变量，边表示因果关系，联合概率分布可分解为各变量的局部条件概率的乘积。  \n- 联合概率分布公式：$p(\\boldsymbol{x}) = \\prod_{k=1}^{K} p(x_k \\mid \\boldsymbol{x}_{\\pi_k})$。  \n- 节点与随机变量混用：文中后文将节点、随机变量、变量概念混用。  \n- 条件独立性复杂性：若两个节点不直接连接但通过路径连接，则其条件独立性需根据具体结构判断。  \n- 三个节点的贝叶斯网络示例：讨论了四种连接关系（间接因果、间接果因、共因、共果）及其对应的条件独立性情况。  \n- 局部马尔可夫性质：每个变量在给定父节点的情况下，条件独立于其非后代节点，即 $X_k \\Perp Z \\mid X_{\\pi_k}$。"
      },
      {
        "段落": "## 11．1．2 常见的有向图模型\n\n很多经典的机器学习模型可以使用有向图模型来描述，比如朴素贝叶斯分类器、隐马尔可夫模型、深度信念网络等。\n\n参见习题11－1．\n\n从公式（11．2）和公式 （11．8）可得到，参见习题 11－2．",
        "总结": "- 本节介绍了常见的有向图模型，包括朴素贝叶斯分类器、隐马尔可夫模型、深度信念网络等。  \n- 提到有向图模型可以用于描述许多经典的机器学习模型。  \n- 引用了公式（11．2）和公式（11．8），并指出相关内容见习题11－2。  \n- 提到相关习题11－1，但未给出具体内容。"
      },
      {
        "段落": "### 11．1．2．1 Sigmoid 信念网络\n\n为了减少模型参数，可以使用参数化模型来建模有向图模型中的条件概率分布．一种简单的参数化模型为 Sigmoid 信念网络［Neal，1992］．\n\nSigmoid 信念网络（Sigmoid Belief Network，SBN）中的变量取值为 $\\{0,1\\}$ ．对于变量 $X_{k}$ 和它的父节点集合 $\\pi_{k}$ ，其条件概率分布表示为\n\n$$\n\\begin{equation*}\np\\left(x_{k}=1 \\mid \\boldsymbol{x}_{\\pi_{k}} ; \\theta\\right)=\\sigma\\left(\\theta_{0}+\\sum_{x_{i} \\in \\boldsymbol{x}_{\\pi_{k}}} \\theta_{i} x_{i}\\right), \\tag{11.10}\n\\end{equation*}\n$$\n\n其中 $\\sigma(\\cdot)$ 是 Logistic 函数，$\\theta_{i}$ 是可学习的参数。假设变量 $X_{k}$ 的父节点数量为 $M$ ，如果使用表格来记录条件概率需要 $2^{M}$ 个参数，如果使用参数化模型只需要 $M+1$个参数．如果对不同的变量的条件概率都共享使用一个参数化模型，其参数数量又可以大幅减少。\n\n值得一提的是，Sigmoid 信念网络与 Logistic 回归模型都采用 Logistic 函数来计算条件概率。如果假设 Sigmoid 信念网络中只有一个叶子节点，其所有的父节点之间没有连接，且取值为实数，那么 Sigmoid 信念网络的网络结构和 Logistic回归模型类似，如图11．4所示．但是，这两个模型区别在于 Logistic 回归模型中的 $\\boldsymbol{x}$ 作为一种确定性的参数，而非变量。因此，Logistic回归模型只建模条件概率 $p(y \\mid \\boldsymbol{x})$ ，是一种判别模型；而 Sigmoid 信念网络建模 $p(\\boldsymbol{x}, y)$ ，是一种生成模型。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-268.jpg?height=351&width=856&top_left_y=1197&top_left_x=219)\n\n图 11．4 Sigmoid 信念网络和 Logistic 回归模型的比较",
        "总结": "- Sigmoid 信念网络（SBN）是一种参数化模型，用于建模有向图模型中的条件概率分布，以减少模型参数。\n- SBN 中的变量取值为 {0, 1}，其条件概率分布通过 Logistic 函数表示。\n- 条件概率公式为 $ p(x_k=1 \\mid \\boldsymbol{x}_{\\pi_k}; \\theta) = \\sigma(\\theta_0 + \\sum_{x_i \\in \\boldsymbol{x}_{\\pi_k}} \\theta_i x_i) $，其中 $\\sigma(\\cdot)$ 是 Logistic 函数，$\\theta_i$ 是可学习参数。\n- 使用表格记录条件概率需要 $2^M$ 个参数，而使用参数化模型只需 $M+1$ 个参数。\n- SBN 与 Logistic 回归模型都使用 Logistic 函数计算条件概率，但结构和用途不同。\n- 若 SBN 中只有一个叶子节点且父节点无连接，其结构类似 Logistic 回归模型。\n- Logistic 回归模型是判别模型，仅建模 $p(y \\mid \\boldsymbol{x})$；SBN 是生成模型，建模 $p(\\boldsymbol{x}, y)$。"
      },
      {
        "段落": "### 11．1．2．2 朴素贝叶斯分类器\n\n朴素贝叶斯分类器（Naive Bayes Classifier，NB）是一类简单的概率分类器，在强（朴素）独立性假设的条件下运用贝叶斯公式来计算每个类别的条件概率。\n\n给定一个有 $M$ 维特征的样本 $\\boldsymbol{x}$ 和类别 $y$ ，类别 $y$ 的条件概率为\n\n$$\n\\begin{align*}\np(y \\mid \\boldsymbol{x} ; \\theta) & =\\frac{p\\left(x_{1}, \\cdots, x_{M} \\mid y ; \\theta\\right) p(y ; \\theta)}{p\\left(x_{1}, \\cdots, x_{M}\\right)}  \\tag{11.11}\\\\\n& \\propto p\\left(x_{1}, \\cdots, x_{M} \\mid y ; \\theta\\right) p(y ; \\theta), \\tag{11.12}\n\\end{align*}\n$$\n\n其中 $\\theta$ 为概率分布的参数．\n在朴素贝叶斯分类器中，假设在给定 $Y$ 的情况下，$X_{m}$ 之间是条件独立的，即 $X_{m} \\Perp X_{k} \\mid Y, \\forall m \\neq k$ ．图11．5给出了朴素贝叶斯分类器的图模型表示．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-269.jpg?height=273&width=374&top_left_y=326&top_left_x=466)\n\n图11．5朴素贝叶斯模型\n\n条件概率分布 $p(y \\mid \\boldsymbol{x})$ 可以分解为\n\n$$\n\\begin{equation*}\np(y \\mid \\boldsymbol{x} ; \\theta) \\propto p\\left(y \\mid \\theta_{c}\\right) \\prod_{m=1}^{M} p\\left(x_{m} \\mid y ; \\theta_{m}\\right) \\tag{11.13}\n\\end{equation*}\n$$\n\n其中 $\\theta_{c}$ 是 $y$ 的先验概率分布的参数，$\\theta_{m}$ 是条件概率分布 $p\\left(x_{m} \\mid y, \\theta_{m}\\right)$ 的参数．若 $x_{m}$ 为连续值，$p\\left(x_{m} \\mid y ; \\theta_{m}\\right)$ 可以用高斯分布建模；若 $x_{m}$ 为离散值，$p\\left(x_{m} \\mid y ; \\theta_{m}\\right)$ 可以用多项分布建模．\n\n虽然朴素贝叶斯分类器的条件独立性假设太强，但是在实际应用中，朴素贝叶斯分类器在很多任务上也能得到很好的结果，并且模型简单，可以有效防止过拟合。",
        "总结": "- 朴素贝叶斯分类器是一种基于贝叶斯定理的概率分类器，假设特征在给定类别条件下相互独立。\n- 使用贝叶斯公式计算类别条件概率，通过先验概率和特征条件概率的乘积来估计后验概率。\n- 条件概率分布可分解为类别先验概率与各特征条件概率的乘积，形式为 $p(y \\mid \\boldsymbol{x}) \\propto p(y) \\prod_{m=1}^{M} p(x_m \\mid y)$。\n- 若特征为连续值，可用高斯分布建模条件概率；若为离散值，可用多项分布建模。\n- 尽管条件独立性假设较强，但朴素贝叶斯分类器在实际应用中表现良好，模型简单且能有效防止过拟合。"
      },
      {
        "段落": "### 11．1．2．3 隐马尔可夫模型\n\n隐马尔可夫模型（Hidden Markov Model，HMM）［Baum et al．，1966］是用来表示一种含有隐变量的马尔可夫过程．\n\n图11．6给出隐马尔可夫模型的图模型表示，其中 $X_{1: T}$ 为可观测变量，$Y_{1: T}$ 为隐变量。隐变量构成一个马尔可夫链，每个可观测标量 $X_{t}$ 依赖当前时刻的隐变量 $Y_{t}$ 。\n\n马尔可夫链参见第 D．3．1．1节。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-269.jpg?height=293&width=654&top_left_y=1739&top_left_x=324)\n\n图 11.6 隐马尔可夫模型\n\n隐马尔可夫模型的联合概率可以分解为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x}, \\boldsymbol{y} ; \\theta)=\\prod_{t=1}^{T} p\\left(y_{t} \\mid y_{t-1}, \\theta_{s}\\right) p\\left(x_{t} \\mid y_{t}, \\theta_{t}\\right) \\tag{11.14}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{x}$ 和 $\\boldsymbol{y}$ 分别为可观测变量和隐变量的取值，条件概率 $p\\left(x_{t} \\mid y_{t}, \\theta_{t}\\right)$ 称为输出概率，条件概率 $p\\left(y_{t} \\mid y_{t-1}, \\theta_{s}\\right)$ 称为转移概率，$\\theta_{s}$ 和 $\\theta_{t}$ 分别表示两类条件概率的参数．",
        "总结": "- 隐马尔可夫模型（HMM）用于表示含有隐变量的马尔可夫过程  \n- 图11.6展示了HMM的图模型，其中 $X_{1:T}$ 为可观测变量，$Y_{1:T}$ 为隐变量  \n- 隐变量构成马尔可夫链，每个可观测变量 $X_t$ 依赖当前时刻的隐变量 $Y_t$  \n- HMM的联合概率分解为转移概率和输出概率的乘积  \n- 转移概率 $p(y_t \\mid y_{t-1}, \\theta_s)$ 表示隐变量之间的转移  \n- 输出概率 $p(x_t \\mid y_t, \\theta_t)$ 表示可观测变量与隐变量之间的关系  \n- $\\theta_s$ 和 $\\theta_t$ 分别是转移概率和输出概率的参数"
      },
      {
        "段落": "## 11．1．3 无向图模型\n\n无向图模型，也称为马尔可夫随机场（Markov Random Field，MRF）或马尔可夫网络（Markov Network），是一类用无向图来描述一组具有局部马尔可夫性质的随机向量 $\\boldsymbol{X}$ 的联合概率分布的模型．\n\n定义11．2－马尔可夫随机场：对于一个随机向量 $\\boldsymbol{X}=\\left[X_{1}, \\cdots, X_{K}\\right]^{\\top}$ 和一个有 $K$ 个节点的无向图 $G(\\mathcal{V}, \\mathcal{E})$（可以存在循环），图 $G$ 中的节点 $k$ 表示随机变量 $X_{k}, 1 \\leq k \\leq K$ ．如果（ $G, \\boldsymbol{X}$ ）满足局部马尔可夫性质，即一个变量 $X_{k}$ 在给定它的邻居的情况下独立于所有其他变量，\n\n$$\n\\begin{equation*}\np\\left(x_{k} \\mid \\boldsymbol{x}_{\\backslash k}\\right)=p\\left(x_{k} \\mid \\boldsymbol{x}_{\\mathcal{N}(k)}\\right), \\tag{11.15}\n\\end{equation*}\n$$\n\n其中 $\\mathcal{N}(k)$ 为变量 $X_{k}$ 的邻居集合，$\\backslash k$ 为除 $X_{k}$ 外其他变量的集合，那么 $(G, X)$就构成了一个马尔可夫随机场。\n\n无向图的局部马尔可夫性 无向图中的局部马尔可夫性可以表示为\n\n$$\nX_{k} \\Perp \\boldsymbol{X}_{\\backslash \\mathcal{N}(k), \\backslash k} \\mid \\boldsymbol{X}_{\\mathcal{N}(k)}\n$$\n\n其中 $\\boldsymbol{X}_{\\backslash N(k), \\backslash k}$ 表示除 $\\boldsymbol{X}_{\\mathcal{N}(k)}$ 和 $X_{k}$ 外的其他变量。\n对于图11．2b中的4个变量，根据马尔可夫性质，可以得到 $X_{1} \\Perp X_{4} \\mid X_{2}, X_{3}$ 和 $X_{2} \\Perp X_{3} \\mid X_{1}, X_{4}$.",
        "总结": "- 无向图模型，也称为马尔可夫随机场（MRF）或马尔可夫网络，用于描述具有局部马尔可夫性质的随机向量的联合概率分布。  \n- 定义11.2指出，马尔可夫随机场是满足局部马尔可夫性质的随机向量与无向图的组合，即在给定邻居变量的情况下，一个变量独立于所有非邻居变量。  \n- 局部马尔可夫性表示为：变量 $X_k$ 在给定其邻居变量的情况下，与非邻居变量独立。  \n- 公式 $X_k \\Perp \\boldsymbol{X}_{\\backslash \\mathcal{N}(k), \\backslash k} \\mid \\boldsymbol{X}_{\\mathcal{N}(k)}$ 描述了这一独立性关系。  \n- 图11.2b中的例子展示了局部马尔可夫性质的应用，如 $X_1 \\Perp X_4 \\mid X_2, X_3$ 和 $X_2 \\Perp X_3 \\mid X_1, X_4$。"
      },
      {
        "段落": "## 11．1．4 无向图模型的概率分解\n\n团 由于无向图模型并不提供一个变量的拓扑顺序，因此无法用链式法则对 $p(\\boldsymbol{x})$进行逐一分解．无向图模型的联合概率一般以全连通子图为单位进行分解．无向图中的一个全连通子图，称为团（Clique），即团内的所有节点之间都连边。图11．7中共有7个团，包括 $\\left\\{X_{1}, X_{2}\\right\\},\\left\\{X_{1}, X_{3}\\right\\},\\left\\{X_{2}, X_{3}\\right\\},\\left\\{X_{3}, X_{4}\\right\\},\\left\\{X_{2}, X_{4}\\right\\},\\left\\{X_{1}, X_{2}, X_{3}\\right\\}$ ， $\\left\\{X_{2}, X_{3}, X_{4}\\right\\}$ ．\n\n在所有团中，如果一个团不能被其他的团包含，这个团就是一个最大团 （Maximal Clique）．\nhttps：／／nndl．github．io／\n\n为了描述方便，这里用 $p\\left(y_{1} \\mid y_{0}\\right)$ 表示 $p\\left(y_{1}\\right)$ 。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-271.jpg?height=370&width=510&top_left_y=133&top_left_x=394)\n\n图 11.7 无向图模型中的团和最大团\n\n因子分解 无向图中的联合概率可以分解为一系列定义在最大团上的非负函数的乘积形式。\n\n定理 11．1－Hammersley－Clifford 定理：如果一个分布 $p(\\boldsymbol{x})>0$ 满足无向图 $G$ 中的局部马尔可夫性质，当且仅当 $p(\\boldsymbol{x})$ 可以表示为一系列定义在最大团上的非负函数的乘积形式，即\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x})=\\frac{1}{Z} \\prod_{c \\in \\mathcal{C}} \\phi_{c}\\left(\\boldsymbol{x}_{c}\\right) \\tag{11.16}\n\\end{equation*}\n$$\n\n其中 $\\mathcal{C}$ 为 $G$ 中的最大团集合，$\\phi_{c}\\left(\\boldsymbol{x}_{c}\\right) \\geq 0$ 是定义在团 $c$ 上的势能函数（Po－ tential Function），$Z$ 是配分函数（Partition Function），用来将乘积归一化为概率形式。\n\n$$\n\\begin{equation*}\nZ=\\sum_{x \\in \\mathcal{X}} \\prod_{c \\in \\mathcal{C}} \\phi_{c}\\left(\\boldsymbol{x}_{c}\\right), \\tag{11.17}\n\\end{equation*}\n$$\n\n其中 $X$ 为随机向量 $X$ 的取值空间．\n\nHammersley－Clifford 定理的证明可以参考［Koller et al．，2009］．无向图模型与有向图模型的一个重要区别是有配分函数 $Z$ 。配分函数的计算复杂度是指数级的，因此在推断和参数学习时都需要重点考虑。\n\n吉布斯分布 公式（11．16）中定义的分布形式也称为吉布斯分布（Gibbs Distribu－ tion）。根据 Hammersley－Clifford 定理，无向图模型和吉布斯分布是一致的。吉布斯分布一定满足马尔可夫随机场的条件独立性质，并且马尔可夫随机场的概率分布一定可以表示成吉布斯分布。\n\n由于势能函数必须为正的，因此我们一般定义为\n\n$$\n\\begin{equation*}\n\\phi_{c}\\left(\\boldsymbol{x}_{c}\\right)=\\exp \\left(-E_{c}\\left(\\boldsymbol{x}_{c}\\right)\\right), \\tag{11.18}\n\\end{equation*}\n$$\n\n配分函数的计算参见第11．3．1．2节。\n\n这里的负号是遵从物理上习惯，即能量越低意味着概率越高。\n\n其中 $E_{c}\\left(\\boldsymbol{x}_{c}\\right)$ 为能量函数（Energy Function）。\n因此，无向图上定义的概率分布可以表示为\n\n$$\n\\begin{align*}\nP(\\boldsymbol{x}) & =\\frac{1}{Z} \\prod_{c \\in \\mathcal{C}} \\exp \\left(-E_{c}\\left(\\boldsymbol{x}_{c}\\right)\\right)  \\tag{11.19}\\\\\n& =\\frac{1}{Z} \\exp \\left(\\sum_{c \\in \\mathcal{C}}-E_{c}\\left(\\boldsymbol{x}_{c}\\right)\\right) \\tag{11.20}\n\\end{align*}\n$$\n\n这种形式的分布又称为玻尔兹曼分布（Boltzmann Distribution）。任何一个无向图模型都可以用公式（11．20）来表示其联合概率．",
        "总结": "- 团：无向图中任意两个节点之间都有边的子图称为团，图中给出的例子包括多个两节点和三节点的团。  \n- 最大团：不能被其他团包含的团称为最大团，图11.7中给出了具体的最大团例子。  \n- 因子分解：无向图的联合概率可以表示为定义在最大团上的非负函数的乘积形式。  \n- Hammersley-Clifford定理：若分布满足无向图的局部马尔可夫性质，则其可表示为最大团上势能函数的乘积形式，并归一化为概率分布。  \n- 配分函数：用于归一化概率分布的函数，计算复杂度为指数级，是推断和学习中的关键问题。  \n- 吉布斯分布：由Hammersley-Clifford定理定义的分布形式，与无向图模型等价，满足马尔可夫随机场的条件独立性质。  \n- 势能函数：定义在最大团上的非负函数，通常表示为指数形式，与能量函数相关。  \n- 能量函数：用于定义势能函数的函数，能量越低对应概率越高，符合物理上的习惯。  \n- 玻尔兹曼分布：由势能函数和配分函数构成的概率分布形式，也称为吉布斯分布的一种表现形式。"
      },
      {
        "段落": "## 11．1．5 常见的无向图模型\n\n很多经典的机器学习模型可以使用无向图模型来描述，比如对数线性模型 （也叫最大熵模型）、条件随机场、玻尔兹曼机、受限玻尔兹曼机等。",
        "总结": "- 提出了常见的无向图模型，包括对数线性模型（最大熵模型）、条件随机场、玻尔兹曼机和受限玻尔兹曼机。"
      },
      {
        "段落": "### 11．1．5．1 对数线性模型\n\n势能函数一般定义为\n\n$$\n\\begin{equation*}\n\\phi_{c}\\left(\\boldsymbol{x}_{c} \\mid \\theta_{c}\\right)=\\exp \\left(\\theta_{c}^{\\top} f_{c}\\left(\\boldsymbol{x}_{c}\\right)\\right) \\tag{11.21}\n\\end{equation*}\n$$\n\n其中函数 $f_{c}\\left(\\boldsymbol{x}_{c}\\right)$ 为定义在 $\\boldsymbol{x}_{c}$ 上的特征向量，$\\theta_{c}$ 为权重向量．这样联合概率 $p(\\boldsymbol{x})$的对数形式为\n\n$$\n\\begin{equation*}\n\\log p(\\boldsymbol{x} ; \\theta)=\\sum_{c \\in \\mathcal{C}} \\theta_{c}^{\\top} f_{c}\\left(\\boldsymbol{x}_{c}\\right)-\\log Z(\\theta) \\tag{11.22}\n\\end{equation*}\n$$\n\n其中 $\\theta$ 代表所有势能函数中的参数 $\\theta_{c}$ 。 这种形式的无向图模型也称为对数线性模型（Log－Linear Model）或最大熵模型（Maximum Entropy Model）［Berger et al．，1996；Della Pietra et al．，1997］．图11．8a所示是一个常用的最大熵模型．\n\n如果用对数线性模型来建模条件概率 $p(y \\mid \\boldsymbol{x})$ ，\n\n$$\n\\begin{equation*}\np(y \\mid \\boldsymbol{x} ; \\theta)=\\frac{1}{Z(\\boldsymbol{x} ; \\theta)} \\exp \\left(\\theta^{\\top} f(\\boldsymbol{x}, y)\\right) \\tag{11.23}\n\\end{equation*}\n$$\n\n其中 $Z(\\boldsymbol{x} ; \\theta)=\\sum_{y} \\exp \\left(\\theta^{\\top} f_{y}(\\boldsymbol{x}, y)\\right)$ ．\n对数线性模型也称为条件最大熵模型或Softmax回归模型．",
        "总结": "- 对数线性模型：一种无向图模型，用于建模概率分布，其形式为对数势能函数的线性组合。\n- 势能函数定义：形式为 $\\phi_{c}(\\boldsymbol{x}_{c} \\mid \\theta_{c}) = \\exp(\\theta_{c}^{\\top} f_{c}(\\boldsymbol{x}_{c}))$，其中 $f_{c}$ 是特征向量，$\\theta_{c}$ 是权重向量。\n- 联合概率的对数形式：$\\log p(\\boldsymbol{x} ; \\theta) = \\sum_{c \\in \\mathcal{C}} \\theta_{c}^{\\top} f_{c}(\\boldsymbol{x}_{c}) - \\log Z(\\theta)$，其中 $Z(\\theta)$ 是归一化因子。\n- 对数线性模型的别称：也称为最大熵模型，用于描述变量之间的联合概率分布。\n- 条件概率建模：对数线性模型可应用于条件概率 $p(y \\mid \\boldsymbol{x})$，其形式为 $p(y \\mid \\boldsymbol{x} ; \\theta) = \\frac{1}{Z(\\boldsymbol{x} ; \\theta)} \\exp(\\theta^{\\top} f(\\boldsymbol{x}, y))$。\n- 归一化因子定义：$Z(\\boldsymbol{x} ; \\theta) = \\sum_{y} \\exp(\\theta^{\\top} f_{y}(\\boldsymbol{x}, y))$，用于确保概率分布的总和为1。\n- 条件最大熵模型与Softmax回归模型：对数线性模型在条件概率建模中也被称为条件最大熵模型或Softmax回归模型。"
      },
      {
        "段落": "### 11．1．5．2 条件随机场\n\n条件随机场（Conditional Random Field，CRF）［Lafferty et al．，2001］是一种直接建模条件概率的无向图模型．\n\n玻尔兹曼分布参见第 12.1 节。\n\n玻尔兹曼机参见第 12.1节。\n\n受限玻尔兹曼机参见第12．2节。\n\nSoftmax 回归模型参见第3．3节。\n\n和条件最大熵模型不同，条件随机场建模的条件概率 $p(\\boldsymbol{y} \\mid \\boldsymbol{x})$ 中， $\\boldsymbol{y}$ 一般为随机向量，因此需要对 $p(\\boldsymbol{y} \\mid \\boldsymbol{x})$ 进行因子分解。假设条件随机场的最大团集合为 $\\mathcal{C}$ ，其条件概率为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{y} \\mid \\boldsymbol{x} ; \\theta)=\\frac{1}{Z(\\boldsymbol{x} ; \\theta)} \\exp \\left(\\sum_{c \\in \\mathcal{C}} \\theta_{c}^{\\top} f_{c}\\left(\\boldsymbol{x}, \\boldsymbol{y}_{c}\\right)\\right) \\tag{11.24}\n\\end{equation*}\n$$\n\n其中 $Z(\\boldsymbol{x} ; \\theta)=\\sum_{y} \\exp \\left(\\sum_{c \\in \\mathcal{C}} f_{c}\\left(\\boldsymbol{x}, \\boldsymbol{y}_{c}\\right)^{\\top} \\theta_{c}\\right)$ 为归一化项。\n一个最常用的条件随机场为图 11.8 b 中所示的链式结构，称为线性链条件随机场（Linear－Chain CRF），其条件概率为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{y} \\mid \\boldsymbol{x} ; \\theta)=\\frac{1}{Z(\\boldsymbol{x} ; \\theta)} \\exp \\left(\\sum_{t=1}^{T} \\theta_{1}^{\\top} f_{1}\\left(\\boldsymbol{x}, y_{t}\\right)+\\sum_{t=1}^{T-1} \\theta_{2}^{\\top} f_{2}\\left(\\boldsymbol{x}, y_{t}, y_{t+1}\\right)\\right) \\tag{11.25}\n\\end{equation*}\n$$\n\n其中 $f_{1}\\left(\\boldsymbol{x}, y_{t}\\right)$ 为状态特征，一般和位置 $t$ 相关，$f_{2}\\left(\\boldsymbol{x}, y_{t}, y_{t+1}\\right)$ 为转移特征，一般可以简化为 $f_{2}\\left(y_{t}, y_{t+1}\\right)$ 并使用状态转移矩阵来表示。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-273.jpg?height=409&width=1020&top_left_y=894&top_left_x=161)\n\n图 11.8 最大熵模型和线性链条件随机场",
        "总结": "- 条件随机场（CRF）是一种直接建模条件概率的无向图模型。  \n- 条件随机场的条件概率通过最大团集合进行因子分解，形式为 $p(\\boldsymbol{y} \\mid \\boldsymbol{x} ; \\theta)=\\frac{1}{Z(\\boldsymbol{x} ; \\theta)} \\exp \\left(\\sum_{c \\in \\mathcal{C}} \\theta_{c}^{\\top} f_{c}\\left(\\boldsymbol{x}, \\boldsymbol{y}_{c}\\right)\\right)$。  \n- 归一化项 $Z(\\boldsymbol{x} ; \\theta)$ 用于确保概率分布的总和为1。  \n- 线性链条件随机场（Linear-Chain CRF）是一种常用的链式结构，其条件概率由状态特征和转移特征组成。  \n- 状态特征 $f_{1}\\left(\\boldsymbol{x}, y_{t}\\right)$ 与位置 $t$ 相关，转移特征 $f_{2}\\left(y_{t}, y_{t+1}\\right)$ 可用状态转移矩阵表示。"
      },
      {
        "段落": "## 11．1．6 有向图和无向图之间的转换\n\n有向图和无向图可以相互转换，但将无向图转为有向图通常比较困难。在实际应用中，将有向图转为无向图更加重要，这样可以利用无向图上的精确推断算法，比如联合树算法（Junction Tree Algorithm）。\n\n无向图模型可以表示有向图模型无法表示的一些依赖关系，比如循环依赖；但它不能表示有向图模型能够表示的某些关系，比如因果关系。\n\n以图11．9a中的有向图为例，其联合概率分布可以分解为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x})=p\\left(x_{1}\\right) p\\left(x_{2}\\right) p\\left(x_{3}\\right) p\\left(x_{4} \\mid x_{1}, x_{2}, x_{3}\\right) \\tag{11.26}\n\\end{equation*}\n$$\n\n其中 $p\\left(x_{4} \\mid x_{1}, x_{2}, x_{3}\\right)$ 和四个变量都相关。如果要转换为无向图，需要将这四个变量都归属于一个团中。 因此，需要将 $x_{4}$ 的三个父节点之间都加上连边，如图11．9b所示．这个过程称为道德化（Moralization）．转换后的无向图称为道德 https：／／nndl．github．io／\n\n图（Moral Graph）。在道德化的过程中，原来有向图的一些独立性会丢失，比如上面例子中 $X_{1} \\Perp X_{2} \\Perp X_{3} \\mid \\varnothing$ 在道德图中不再成立。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-274.jpg?height=404&width=990&top_left_y=285&top_left_x=158)\n\n图 11.9 具有＂共果关系＂的有向图的道德化示例",
        "总结": "- 概念：有向图和无向图可以相互转换，但无向图转为有向图通常较困难，而有向图转为无向图在实际应用中更为重要。\n- 概念：无向图模型可以表示有向图无法表示的循环依赖关系，但不能表示因果关系。\n- 算法：道德化（Moralization）是将有向图转换为无向图的过程，通过将有向图中所有父节点之间添加边来实现。\n- 定理/命题：转换后的无向图称为道德图，该过程可能导致原有独立性关系的丢失。\n- 数学推导：有向图的联合概率分布可以分解为多个变量的条件概率乘积，如 $p(\\boldsymbol{x})=p\\left(x_{1}\\right) p\\left(x_{2}\\right) p\\left(x_{3}\\right) p\\left(x_{4} \\mid x_{1}, x_{2}, x_{3}\\right)$。"
      },
      {
        "段落": "## 11.2 学习\n\n图模型的学习可以分为两部分：一是网络结构学习，即寻找最优的网络结构；二是网络参数估计，即已知网络结构，估计每个条件概率分布的参数．\n\n网络结构学习一般比较困难，一般是由领域专家来构建．本节只讨论在给定网络结构条件下的参数估计问题。图模型的参数估计问题又分为不包含隐变量时的参数估计问题和包含隐变量时的参数估计问题．",
        "总结": "- 概念：图模型的学习分为网络结构学习和网络参数估计两部分。  \n- 概念：网络结构学习是指寻找最优的网络结构，通常由领域专家构建。  \n- 概念：网络参数估计是在已知网络结构的情况下，估计每个条件概率分布的参数。  \n- 概念：参数估计问题分为不包含隐变量和包含隐变量两种情况。  \n- 算法/方法：本节仅讨论在给定网络结构条件下的参数估计问题。"
      },
      {
        "段落": "## 11．2．1 不含隐变量的参数估计\n\n如果图模型中不包含隐变量，即所有变量都是可观测的，那么网络参数一般可以直接通过最大似然来进行估计。\n\n有向图模型 在有向图模型中，所有变量 $\\boldsymbol{x}$ 的联合概率分布可以分解为每个随机变量 $x_{k}$ 的局部条件概率 $p\\left(x_{k} \\mid x_{\\pi_{k}} ; \\theta_{k}\\right)$ 的连乘形式，其中 $\\theta_{k}$ 为第 $k$ 个变量的局部条件概率的参数．\n\n给定 $N$ 个训练样本 $\\mathcal{D}=\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ ，其对数似然函数为\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\mathcal{D} ; \\theta) & =\\frac{1}{N} \\sum_{n=1}^{N} \\log p\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)  \\tag{11.27}\\\\\n& =\\frac{1}{N} \\sum_{n=1}^{N} \\sum_{k=1}^{K} \\log p\\left(x_{k}^{(n)} \\mid x_{\\pi_{k}}^{(n)} ; \\theta_{k}\\right) \\tag{11.28}\n\\end{align*}\n$$\n\n其中 $\\theta_{k}$ 为模型中的所有参数．\n\n道德化的名称来源是：有共同儿子的父节点都必须结婚（即有连边）。\n\n因为所有变量都是可观测的，最大化对数似然 $\\mathcal{L}(\\mathcal{D} ; \\theta)$ ，只需要分别地最大化每个变量的条件似然来估计其参数。\n\n$$\n\\begin{equation*}\n\\theta_{k}=\\arg \\max \\sum_{n=1}^{N} \\log p\\left(x_{k}^{(n)} \\mid x_{\\pi_{k}}^{(n)} ; \\theta_{k}\\right) \\tag{11.29}\n\\end{equation*}\n$$\n\n如果变量 $\\boldsymbol{x}$ 是离散的，直接简单的方式是在训练集上统计每个变量的条件概率表。但是条件概率表需要的参数比较多。假设条件概率 $p\\left(x_{k} \\mid x_{\\pi_{k}}\\right)$ 的父节点数量为 $M$ ，所有变量为二值变量，其条件概率表需要 $2^{M}$ 个参数。为了减少参数数量，可以使用参数化的模型，比如Sigmoid 信念网络。如果变量 $\\boldsymbol{x}$ 是连续的，可以使用高斯函数来表示条件概率分布，称为高斯信念网络。在此基础上，还可以通过让所有的条件概率分布共享使用同一组参数来进一步减少参数的数量。\n\n无向图模型 在无向图模型中，所有变量 $\\boldsymbol{x}$ 的联合概率分布可以分解为定义在最大团上的势能函数的连乘形式．以对数线性模型为例，\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x} ; \\theta)=\\frac{1}{Z(\\theta)} \\exp \\left(\\sum_{c \\in \\mathcal{C}} \\theta_{c}^{\\top} f_{c}\\left(\\boldsymbol{x}_{c}\\right)\\right) \\tag{11.30}\n\\end{equation*}\n$$\n\n其中 $Z(\\theta)=\\sum_{x} \\exp \\left(\\sum_{c \\in \\mathcal{C}} \\theta_{c}^{\\top} f_{c}\\left(\\boldsymbol{x}_{c}\\right)\\right)$ ．\n给定 $N$ 个训练样本 $\\mathcal{D}=\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ ，其对数似然函数为\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\mathcal{D} ; \\theta) & =\\frac{1}{N} \\sum_{n=1}^{N} \\log p\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)  \\tag{11.31}\\\\\n& =\\frac{1}{N} \\sum_{n=1}^{N}\\left(\\sum_{c \\in \\mathcal{C}} \\theta_{c}^{\\top} f_{c}\\left(\\boldsymbol{x}_{c}^{(n)}\\right)\\right)-\\log Z(\\theta) \\tag{11.32}\n\\end{align*}\n$$\n\n其中 $\\theta_{c}$ 为定义在团 $c$ 上的势能函数的参数．\n采用梯度上升方法进行最大似然估计， $\\mathcal{L}(\\mathcal{D} ; \\theta)$ 关于参数 $\\theta_{c}$ 的偏导数为\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}(\\mathcal{D} ; \\theta)}{\\partial \\theta_{c}}=\\frac{1}{N} \\sum_{n=1}^{N}\\left(f_{c}\\left(\\boldsymbol{x}_{c}^{(n)}\\right)\\right)-\\frac{\\partial \\log Z(\\theta)}{\\partial \\theta_{c}} \\tag{11.33}\n\\end{equation*}\n$$\n\n其中\n\n$$\n\\begin{align*}\n\\frac{\\partial \\log Z(\\theta)}{\\partial \\theta_{c}} & =\\sum_{\\boldsymbol{x}} \\frac{1}{Z(\\theta)} \\cdot \\exp \\left(\\sum_{c \\in \\mathcal{C}} \\theta_{c}^{\\top} f_{c}\\left(\\boldsymbol{x}_{c}\\right)\\right) \\cdot f_{c}\\left(\\boldsymbol{x}_{c}\\right)  \\tag{11.34}\\\\\n& =\\sum_{\\boldsymbol{x}} p(\\boldsymbol{x} ; \\theta) f_{c}\\left(\\boldsymbol{x}_{c}\\right) \\triangleq \\mathbb{E}_{\\boldsymbol{x} \\sim p(\\boldsymbol{x} ; \\theta)}\\left[f_{c}\\left(\\boldsymbol{x}_{c}\\right)\\right] . \\tag{11.35}\n\\end{align*}\n$$\n\n因此，\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}(\\mathcal{D} ; \\theta)}{\\partial \\theta_{c}}=\\frac{1}{N} \\sum_{n=1}^{N} f_{c}\\left(\\boldsymbol{x}_{c}^{(n)}\\right)-\\mathbb{E}_{\\boldsymbol{x} \\sim p(\\boldsymbol{x} ; \\theta)}\\left[f_{c}\\left(\\boldsymbol{x}_{c}\\right)\\right] \\tag{11.36}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n$$\n\\begin{equation*}\n=\\mathbb{E}_{\\boldsymbol{x} \\sim \\tilde{p}(\\boldsymbol{x})}\\left[f_{c}\\left(\\boldsymbol{x}_{c}\\right)\\right]-\\mathbb{E}_{\\boldsymbol{x} \\sim p(\\boldsymbol{x} ; \\theta)}\\left[f_{c}\\left(\\boldsymbol{x}_{c}\\right)\\right] \\tag{11.37}\n\\end{equation*}\n$$\n\n其中 $\\tilde{p}(\\boldsymbol{x})$ 定义为经验分布（Empirical Distribution）。由于在最优点时梯度为 0 ，因此无向图的最大似然估计的优化目标等价于：对于每个团 $c$ 上的特征 $f_{c}\\left(\\boldsymbol{x}_{c}\\right)$ ，使得其在经验分布 $\\tilde{p}(\\boldsymbol{x})$ 下的期望等于其在模型分布 $p(\\boldsymbol{x} ; \\theta)$ 下的期望．\n\n对比公式（11．29）和公式（11．37）可以看出，无向图模型的参数估计要比有向图更为复杂．在有向图中，每个局部条件概率的参数是独立的；而在无向图中，所有的参数都是相关的，无法分解．\n\n对于一般的无向图模型，公式（11．37）中的 $\\mathbb{E}_{x \\sim p(x ; \\theta)}\\left[f_{c}\\left(\\boldsymbol{x}_{c}\\right)\\right]$ 往往很难计算，因为涉及在联合概率空间 $p(\\boldsymbol{x} ; \\theta)$ 计算期望．当模型变量比较多时，这个计算往往无法实现。因此，无向图的参数估计通常采用近似的方法。一是利用采样来近似计算这个期望；二是采用坐标上升法，即固定其他参数，来优化一个势能函数的参数．",
        "总结": "- 不含隐变量的参数估计指的是在图模型中所有变量都是可观测的情况下，直接通过最大似然估计来确定模型参数。\n- 有向图模型的联合概率分布可以分解为每个变量的局部条件概率的乘积形式，参数估计可以通过最大化每个变量的条件似然来分别进行。\n- 对数似然函数用于衡量模型对训练数据的拟合程度，其表达式为训练样本对数概率的平均值。\n- 对于离散变量，可以直接统计条件概率表，但参数数量较多；可使用如Sigmoid信念网络等参数化模型来减少参数数量。\n- 对于连续变量，可以使用高斯信念网络表示条件概率分布，并可通过共享参数进一步减少参数数量。\n- 无向图模型的联合概率分布分解为定义在最大团上的势能函数的乘积形式，其概率分布形式为对数线性模型。\n- 无向图的最大似然估计需要计算期望值，这通常涉及难以计算的联合概率空间中的期望。\n- 无向图的最大似然估计优化目标是使经验分布下特征函数的期望等于模型分布下的期望。\n- 有向图和无向图在参数估计上存在差异：有向图参数独立，而无向图参数相关且难以分解。\n- 由于计算复杂性，无向图的参数估计通常采用近似方法，如采样或坐标上升法。"
      },
      {
        "段落": "## 11．2．2 含隐变量的参数估计\n\n如果图模型中包含隐变量，即有部分变量是不可观测的，就需要用 $E M$ 算法进行参数估计。",
        "总结": "- 概念：隐变量是指在图模型中不可观测的变量。  \n- 算法：EM算法用于含隐变量的参数估计。  \n- 核心思想：通过迭代优化，先估计隐变量的期望值（E步），再最大化似然函数（M步）。  \n- 应用场景：当图模型中存在不可观测变量时，使用EM算法进行参数估计。"
      },
      {
        "段落": "### 11．2．2．1 EM算法\n\n在一个包含隐变量的图模型中，令 $\\boldsymbol{X}$ 定义可观测变量集合，令 $\\boldsymbol{Z}$ 定义隐变量集合，一个样本 $\\boldsymbol{x}$ 的边际似然函数（Marginal Likelihood）为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x} ; \\theta)=\\sum_{\\boldsymbol{z}} p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta), \\tag{11.38}\n\\end{equation*}\n$$\n\n其中 $\\theta$ 为模型参数。边际似然也称为证据（Evidence）．\n图11．10给出了带隐变量的贝叶斯网络的图模型结构，其中矩形表示其中的变量重复 $N$ 次。这种表示方法称为盘子表示法（Plate Notation），是图模型中表示重复变量的方法。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-276.jpg?height=336&width=258&top_left_y=1722&top_left_x=520)\n\n图 11.10 带隐变量的贝叶斯网络\n\n给定 $N$ 个训练样本 $\\mathcal{D}=\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ ，整个训练集的对数边际似然为\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\mathcal{D} ; \\theta) & =\\frac{1}{N} \\sum_{n=1}^{N} \\log p\\left(\\boldsymbol{x}^{(n)} ; \\theta\\right)  \\tag{11.39}\\\\\n& =\\frac{1}{N} \\sum_{n=1}^{N} \\log \\sum_{z} p\\left(\\boldsymbol{x}^{(n)}, \\boldsymbol{z} ; \\theta\\right) \\tag{11.40}\n\\end{align*}\n$$\n\n通过最大化整个训练集的对数边际似然 $\\mathcal{L}(\\mathcal{D} ; \\theta)$ ，可以估计出最优的参数 $\\theta^{*}$ 。然而计算边际似然函数时涉及 $p(x)$ 的推断问题，需要在对数函数的内部进行求和（或积分）。这样，当计算参数 $\\theta$ 的梯度时，这个求和操作依然存在。除非 $p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)$ 的形式非常简单，否则这个求和难以直接计算．\n\n为了计算 $\\log p(\\boldsymbol{x} ; \\theta)$ ，我们引入一个额外的变分函数 $q(\\boldsymbol{z}), q(\\boldsymbol{z})$ 为定义在隐变量 $\\boldsymbol{Z}$ 上的分布．样本 $\\boldsymbol{x}$ 的对数边际似然函数为\n\n$$\n\\begin{align*}\n\\log p(\\boldsymbol{x} ; \\theta) & =\\log \\sum_{\\boldsymbol{z}} q(\\boldsymbol{z}) \\frac{p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)}{q(\\boldsymbol{z})}  \\tag{11.41}\\\\\n& \\geq \\sum_{\\boldsymbol{z}} q(\\boldsymbol{z}) \\log \\frac{p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)}{q(\\boldsymbol{z})}  \\tag{11.42}\\\\\n& \\triangleq \\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta) \\tag{11.43}\n\\end{align*}\n$$\n\n其中 $\\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta)$ 为对数边际似然函数 $\\log p(\\boldsymbol{x} ; \\theta)$ 的下界，称为证据下界（Evi－ dence Lower BOund，ELBO）．\n\n公式（11．42）使用了 Jensen 不等式，即对于凹函数 $g, g(\\mathbb{E}[X]) \\geq \\mathbb{E}[g(X)]$ 成立．由 Jensen 不等式的性质可知，仅当 $q(\\boldsymbol{z})=p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ 时，对数边际似然函数 $\\log p(\\boldsymbol{x} ; \\theta)$ 和其下界 $E L B O(q, \\boldsymbol{x} ; \\theta)$ 相等，即 $\\log p(\\boldsymbol{x} ; \\theta)=E L B O(q, \\boldsymbol{x} ; \\theta)$ ．\n\n参见习题11－4．\n这样，最大化对数边际似然函数 $\\log p(\\boldsymbol{x} ; \\theta)$ 的过程可以分解为两个步骤：\n（1）先找到近似分布 $q(\\boldsymbol{z})$ 使得 $\\log p(\\boldsymbol{x} ; \\theta)=E L B O(q, \\boldsymbol{x} ; \\theta)$ ．\n（2）再寻找参数 $\\theta$ 最大化 $E L B O(q, x ; \\theta)$ ．这就是期望最大化（Expectation－ Maximum，EM）算法．\n$E M$ 算法是含隐变量图模型的常用参数估计方法，通过迭代的方法来最大化边际似然。EM算法具体分为两个步骤： E 步和M步。这两步不断重复，直到收玫到某个局部最优解．在第 $t$ 步更新时， E 步和 M 步分别为：\n（1）E步（Expectation Step ）：固定参数 $\\theta_{t}$ ，找到一个分布 $q_{t+1}(\\boldsymbol{z})$ 使得证据下界 $\\operatorname{ELBO}\\left(q, \\boldsymbol{x} ; \\theta_{t}\\right)$ 等于 $\\log p\\left(\\boldsymbol{x} ; \\theta_{t}\\right)$ ．\n\n根据 Jensen 不等式的性质，$q(\\boldsymbol{z})=p\\left(\\boldsymbol{z} \\mid \\boldsymbol{x}, \\theta_{t}\\right)$ 时， $\\operatorname{ELBO}\\left(q, \\boldsymbol{x} ; \\theta_{t}\\right)$ 最大。因此在 E 步中，最理想的分布 $q(\\boldsymbol{z})$ 是等于后验分布 $p\\left(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta_{t}\\right)$ 。而计算后验分布 $p\\left(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta_{t}\\right)$是一个推断（Inference）问题．如果 $\\boldsymbol{z}$ 是有限的一维离散变量（比如混合高斯模\n\n利用 Jensen 不等式，参见第 D．2．7．1 节。\n\n型 ），$p\\left(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta_{t}\\right)$ 计算起来还比较容易；否则，$p\\left(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta_{t}\\right)$ 一般情况下很难计算，需要通过变分推断的方法来进行近似估计。\n（2）M步（Maximization Step）：固定 $q_{t+1}(\\boldsymbol{z})$ ，找到一组参数使得证据下界最大，即\n\n$$\n\\begin{equation*}\n\\theta_{t+1}=\\underset{\\theta}{\\arg \\max } E L B O\\left(q_{t+1}, \\boldsymbol{x} ; \\theta\\right) . \\tag{11.44}\n\\end{equation*}\n$$\n\n这一步可以看作是全观测变量图模型的参数估计问题，可以使用第11．2．1节中方法进行参数估计。\n\n收玫性证明 假设在第 $t$ 步时的模型参数为 $\\theta_{t}$ ，在 E 步时找到一个分布 $q_{t+1}(\\boldsymbol{z})$ 使得 $\\log p\\left(\\boldsymbol{x} \\mid \\theta_{t}\\right)=\\operatorname{ELBO}\\left(q, \\boldsymbol{x} ; \\theta_{t}\\right)$ 。在 M 步时固定 $q_{t+1}(\\boldsymbol{z})$ 找到一组参数 $\\theta_{t+1}$ ，使得 $\\operatorname{ELBO}\\left(q_{t+1}, \\boldsymbol{x} \\mid \\theta_{t+1}\\right) \\geq \\operatorname{ELBO}\\left(q_{t+1}, \\boldsymbol{x} ; \\theta_{t}\\right)$ 。因此有\n\n$$\n\\begin{equation*}\n\\log p\\left(\\boldsymbol{x} ; \\theta_{t+1}\\right) \\geq E L B O\\left(q_{t+1}, \\boldsymbol{x} ; \\theta_{t+1}\\right) \\geq E L B O\\left(q_{t+1}, \\boldsymbol{x} ; \\theta_{t}\\right)=\\log p\\left(\\boldsymbol{x} ; \\theta_{t}\\right) \\tag{11.45}\n\\end{equation*}\n$$\n\n即每经过一次迭代，对数边际似然增加，即 $\\log p\\left(\\boldsymbol{x} ; \\theta_{t+1}\\right) \\geq \\log p\\left(\\boldsymbol{x} ; \\theta_{t}\\right)$ ．\n信息论的视角 对数边际似然 $\\log p(\\boldsymbol{x} ; \\theta)$ 可以通过下面方式进行分解：\n首先因为 $p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)=p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta) p(\\boldsymbol{x} ; \\theta)$ ，有 $\\log p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)=\\log p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)+$ $\\log p(\\boldsymbol{x} ; \\theta)$ ，进一步有 $\\log p(\\boldsymbol{x} ; \\theta)=\\log p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)-\\log p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ ．\n\n这样，对数边际似然 $\\log p(\\boldsymbol{x} ; \\theta)$ 可以分解为\n\n$$\n\\begin{align*}\n\\log p(\\boldsymbol{x} ; \\theta) & =\\sum_{\\boldsymbol{z}} q(\\boldsymbol{z}) \\log p(\\boldsymbol{x} ; \\theta)  \\tag{11.46}\\\\\n& =\\sum_{\\boldsymbol{z}} q(\\boldsymbol{z})(\\log p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)-\\log p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta))  \\tag{11.47}\\\\\n& =\\sum_{\\boldsymbol{z}} q(\\boldsymbol{z}) \\log \\frac{p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)}{q(\\boldsymbol{z})}-\\sum_{\\boldsymbol{z}} q(\\boldsymbol{z}) \\log \\frac{p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)}{q(\\boldsymbol{z})}  \\tag{11.48}\\\\\n& =\\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta)+\\operatorname{KL}(q(\\boldsymbol{z}) \\| p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)) \\tag{11.49}\n\\end{align*}\n$$\n\n其中 $\\mathrm{KL}(q(\\boldsymbol{z}) \\| p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta))$ 为分布 $q(\\boldsymbol{z})$ 和后验分布 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ 的 KL 散度。\n由于 $\\mathrm{KL}(q(\\boldsymbol{z}) \\| p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)) \\geq 0$ ，因此 $E L B O(q, \\boldsymbol{x} ; \\theta)$ 为 $\\log p(\\boldsymbol{x} ; \\theta)$ 的一个下界。当且仅当 $q(\\boldsymbol{z})=p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ 时， $\\operatorname{KL}(q(\\boldsymbol{z}) \\| p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta))=0$ ，这时 $\\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta)=$ $\\log p(\\boldsymbol{x} ; \\theta)$ ．\n\n图11．11在 EM 算法在第 $t$ 步迭代时的示例。图11．11a为第 $t$ 步迭代的初始状态，参数为 $\\theta_{t}$ ，这时通常有 $\\mathrm{KL}\\left(q(\\boldsymbol{z}) \\| p\\left(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta_{t}\\right)\\right)>0$ 。图11．11b为 E 步更新：固定参数 $\\theta_{t}$ ，找到分布 $q_{t+1}(\\boldsymbol{z})$ 使得 $\\mathrm{KL}\\left(q_{t+1}(\\boldsymbol{z}) \\| p\\left(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta_{t}\\right)\\right)=0$ ，这时 $\\operatorname{ELBO}\\left(q_{t+1}, \\boldsymbol{x} ; \\theta_{t}\\right)$和 $\\log p\\left(\\boldsymbol{x} ; \\theta_{t}\\right)$ 相等。图11．11c为 M 步更新：固定分布 $q_{t+1}(\\boldsymbol{z})$ ，寻找参数 $\\theta_{t+1}$ 使得 $\\operatorname{ELBO}\\left(q_{t+1}, \\boldsymbol{x} ; \\theta_{t+1}\\right)$ 最大。由于这时通常KL $\\left(q_{t+1}(\\boldsymbol{z}) \\| p\\left(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta_{t}\\right)\\right)>0$ ，从而 $\\log p\\left(\\boldsymbol{x} ; \\theta_{t+1}\\right)$ 也变大。\nhttps：／／nndl．github．io／\n\n变分推断参见第 11.4节。\n$\\sum_{z} q(z)=1$.\n\n参见第 E．3．2 节．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-279.jpg?height=376&width=1158&top_left_y=145&top_left_x=83)\n\n图 11.11 EM 算法在第 $t$ 步迭代时的示例",
        "总结": "- EM算法用于含隐变量图模型的参数估计，通过迭代最大化边际似然。  \n- 边际似然函数定义为对所有隐变量求和的联合概率分布。  \n- 引入变分分布 $q(\\boldsymbol{z})$ 来近似后验分布，通过Jensen不等式构造ELBO作为对数边际似然的下界。  \n- ELBO（证据下界）是最大化对数边际似然的替代目标，其最大值对应于真实后验分布。  \n- EM算法分为E步和M步：E步求解最优变分分布 $q(\\boldsymbol{z})$，M步最大化ELBO以更新参数 $\\theta$。  \n- E步中，最优 $q(\\boldsymbol{z})$ 等于后验分布 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$，计算该分布可能需要变分推断。  \n- M步中，固定 $q(\\boldsymbol{z})$，通过最大化ELBO更新参数 $\\theta$，相当于全观测变量模型的参数估计问题。  \n- 每次迭代中，对数边际似然单调不减，EM算法收敛到局部最优解。  \n- ELBO可分解为KL散度与对数边际似然之和，KL散度非负，因此ELBO是其下界。  \n- 当 $q(\\boldsymbol{z}) = p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ 时，KL散度为零，ELBO等于对数边际似然。"
      },
      {
        "段落": "### 11．2．2．2 高斯混合模型\n\n本节介绍一个EM算法的应用例子：高斯混合模型．\n高斯混合模型（Gaussian Mixture Model，GMM）是由多个高斯分布组成的模型，其总体密度函数为多个高斯密度函数的加权组合。如果一个连续随机变量或连续随机向量的分布比较复杂，那么我们通常可以用高斯混合模型来估计其分布情况。\n\n不失一般性，这里考虑一维的情况。假设样本 $x$ 是从 $K$ 个高斯分布中的一个分布生成的，但是无法观测到具体由哪个分布生成。我们引入一个隐变量 $z \\in\\{1, \\cdots, K\\}$ 来表示样本 $x$ 来自于哪个高斯分布，$z$ 服从多项分布\n\n$$\n\\begin{equation*}\np(z=k ; \\pi)=\\pi_{k}, \\quad 1 \\leq k \\leq K, \\tag{11.50}\n\\end{equation*}\n$$\n\n其中 $\\pi=\\left[\\pi_{1}, \\pi_{2}, \\cdots, \\pi_{K}\\right]$ 为多项分布的参数，并满足 $\\pi_{k} \\geq 0 \\forall k, \\sum_{k=1}^{K} \\pi_{k}=1 . \\pi_{k}$表示样本 $x$ 由第 $k$ 个高斯分布生成的概率．\n\n给定 $z=k$ ，条件分布 $p(x \\mid z=k)$ 为高斯分布\n\n$$\n\\begin{align*}\np\\left(x \\mid z=k ; \\mu_{k}, \\sigma_{k}\\right) & =\\mathcal{N}\\left(x ; \\mu_{k}, \\sigma_{k}\\right)  \\tag{11.51}\\\\\n& =\\frac{1}{\\sqrt{2 \\pi} \\sigma_{k}} \\exp \\left(-\\frac{\\left(x-\\mu_{k}\\right)^{2}}{2 \\sigma_{k}^{2}}\\right), \\tag{11.52}\n\\end{align*}\n$$\n\n其中 $\\mu_{k}$ 和 $\\sigma_{k}$ 分别为第 $k$ 个高斯分布的均值和方差．\n从高斯混合模型中生成一个样本 $x$ 的过程可以分为两步：\n（1）首先根据多项分布 $p(z \\mid \\pi)$ 随机选取一个高斯分布．\n（2）假设选中第 $k$ 个高斯分布（即 $z=k$ ），再从高斯分布 $\\mathcal{N}\\left(x ; \\mu_{k}, \\sigma_{k}\\right)$ 中选取一个样本 $x$ ．\n\n图11．12给出了高斯混合模型的图模型表示．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-280.jpg?height=371&width=413&top_left_y=117&top_left_x=456)\n\n图 11.12 高斯混合模型\n\n在高斯混合模型中，随机变量 $x$ 的概率密度函数为\n\n$$\n\\begin{equation*}\np(x)=\\sum_{k=1}^{K} \\pi_{k} \\mathcal{N}\\left(x ; \\mu_{k}, \\sigma_{k}\\right) \\tag{11.53}\n\\end{equation*}\n$$\n\n参数估计 给定 $N$ 个由高斯混合模型生成的训练样本 $x^{(1)}, x^{(2)}, \\cdots, x^{(N)}$ ，希望能学习其中的参数 $\\pi_{k}, \\mu_{k}, \\sigma_{k}, 1 \\leq k \\leq K$ 。由于我们无法观测样本 $x^{(n)}$ 是从哪个高斯分布生成的，因此无法直接用最大似然来进行参数估计。\n\n对每个样本 $x^{(n)}$ ，其对数边际分布为\n\n$$\n\\begin{align*}\n\\log p\\left(x^{(n)}\\right) & =\\log \\sum_{z^{(n)}} p\\left(z^{(n)}\\right) p\\left(x^{(n)} \\mid z^{(n)}\\right)  \\tag{11.54}\\\\\n& =\\log \\sum_{k=1}^{K} \\pi_{k} \\mathcal{N}\\left(x^{(n)} ; \\mu_{k}, \\sigma_{k}\\right) \\tag{11.55}\n\\end{align*}\n$$\n\n根据 EM 算法，参数估计可以分为两步进行迭代：\n$\\mathbf{E}$ 步 先固定参数 $\\mu, \\sigma$ ，计算后验分布 $p\\left(z^{(n)} \\mid x^{(n)}\\right)$\n\n$$\n\\begin{align*}\n\\gamma_{n k} & \\triangleq p\\left(z^{(n)}=k \\mid x^{(n)}\\right)  \\tag{11.56}\\\\\n& =\\frac{p\\left(z^{(n)}\\right) p\\left(x^{(n)} \\mid z^{(n)}\\right)}{p\\left(x^{(n)}\\right)}  \\tag{11.57}\\\\\n& =\\frac{\\pi_{k} \\mathcal{N}\\left(x^{(n)} ; \\mu_{k}, \\sigma_{k}\\right)}{\\sum_{k=1}^{K} \\pi_{k} \\mathcal{N}\\left(x^{(n)} ; \\mu_{k}, \\sigma_{k}\\right)} \\tag{11.58}\n\\end{align*}\n$$\n\n其中 $\\gamma_{n k}$ 定义了样本 $x^{(n)}$ 属于第 $k$ 个高斯分布的后验概率．\n$\\mathbf{M}$ 步 令 $q(z=k)=\\gamma_{n k}$ ，训练集 $\\mathcal{D}$ 的证据下界为\n\n$$\n\\begin{equation*}\n\\operatorname{ELBO}(\\gamma, \\mathcal{D} ; \\pi, \\mu, \\sigma)=\\sum_{n=1}^{N} \\sum_{k=1}^{K} \\gamma_{n k} \\log \\frac{p\\left(x^{(n)}, z^{(n)}=k\\right)}{\\gamma_{n k}} \\tag{11.59}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n$$\n\\begin{align*}\n& =\\sum_{n=1}^{N} \\sum_{k=1}^{K} \\gamma_{n k}\\left(\\log \\mathcal{N}\\left(x^{(n)} ; \\mu_{k}, \\sigma_{k}\\right)+\\log \\frac{\\pi_{k}}{\\gamma_{n k}}\\right)  \\tag{11.60}\\\\\n& =\\sum_{n=1}^{N} \\sum_{k=1}^{K} \\gamma_{n k}\\left(\\frac{-\\left(x-\\mu_{k}\\right)^{2}}{2 \\sigma_{k}^{2}}-\\log \\sigma_{k}+\\log \\pi_{k}\\right)+C, \\tag{11.61}\n\\end{align*}\n$$\n\n其中 $C$ 为和参数无关的常数．\n将参数估计问题转为优化问题：\n\n$$\n\\begin{align*}\n& \\max _{\\pi, \\mu, \\sigma} \\operatorname{ELBO}(\\gamma, \\mathcal{D} ; \\pi, \\mu, \\sigma) \\\\\n& \\text { s.t. } \\quad \\sum_{k=1}^{K} \\pi_{k}=1 \\tag{11.62}\n\\end{align*}\n$$\n\n利用拉格朗日方法，分别求拉格朗日函数 $\\operatorname{ELBO}(\\gamma, \\mathcal{D} ; \\pi, \\mu, \\sigma)+\\lambda\\left(\\sum_{k=1}^{K} \\pi_{k}-\\right.$ $1)$ 关于 $\\pi_{k}, \\mu_{k}, \\sigma_{k}$ 的偏导数，并令其等于 0 。可得，\n\n$$\n\\begin{align*}\n\\pi_{k} & =\\frac{N_{k}}{N}  \\tag{11.63}\\\\\n\\mu_{k} & =\\frac{1}{N_{k}} \\sum_{n=1}^{N} \\gamma_{n k} x^{(n)}  \\tag{11.64}\\\\\n\\sigma_{k}^{2} & =\\frac{1}{N_{k}} \\sum_{n=1}^{N} \\gamma_{n k}\\left(x^{(n)}-\\mu_{k}\\right)^{2} \\tag{11.65}\n\\end{align*}\n$$\n\n其中\n\n$$\n\\begin{equation*}\nN_{k}=\\sum_{n=1}^{N} \\gamma_{n k} \\tag{11.66}\n\\end{equation*}\n$$\n\n高斯混合模型的参数学习过程如算法11．1所示．\n\n```\n算法 11.1: 高斯混合模型的参数学习过程\n    输入: 训练样本: $x^{(1)}, x^{(2)}, \\cdots, x^{(N)}$;\n    随机初始化参数: $\\pi_{k}, \\mu_{k}, \\sigma_{k}, 1 \\leq k \\leq K$;\n    repeat\n        // E步\n        固定参数, 根据公式 (11.58) 计算 $\\gamma_{n k}, 1 \\leq k \\leq K, 1 \\leq n \\leq N$;\n        // M步\n        固定 $\\gamma_{n k}$, 根据公式 (11.63) 、公式 (11.64) 和公式 (11.65) , 计算 $\\pi_{k}, \\mu_{k}, \\sigma_{k}$,\n            $1 \\leq k \\leq K ;$\n    until 对数边际分布 $\\sum_{n=1}^{N} \\log p\\left(x^{(n)}\\right)$ 收敛;\n    输出: $\\pi_{k}, \\mu_{k}, \\sigma_{k}, 1 \\leq k \\leq K$\n```\n\n图11．13给出一个高斯混合模型训练过程的简单示例．给定一组数据，我们用两个高斯分布来估计这组数据的分布情况。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-282.jpg?height=799&width=1168&top_left_y=144&top_left_x=67)\n\n图 11.13 高斯混合模型训练过程示例",
        "总结": "- 高斯混合模型（GMM）是由多个高斯分布组成的模型，总体密度函数为多个高斯密度函数的加权组合。\n- 隐变量 $z$ 表示样本来自哪个高斯分布，服从多项分布 $p(z=k; \\pi) = \\pi_k$。\n- 条件分布 $p(x \\mid z=k)$ 是高斯分布 $\\mathcal{N}(x; \\mu_k, \\sigma_k)$。\n- 生成样本的过程分为两步：先根据多项分布选择高斯分布，再从该分布中生成样本。\n- 随机变量 $x$ 的概率密度函数为 $p(x) = \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(x; \\mu_k, \\sigma_k)$。\n- 参数估计使用EM算法，分为E步和M步：E步计算后验概率 $\\gamma_{nk}$，M步更新参数 $\\pi_k, \\mu_k, \\sigma_k$。\n- E步中 $\\gamma_{nk}$ 表示样本 $x^{(n)}$ 属于第 $k$ 个高斯分布的后验概率。\n- M步通过最大化ELBO函数得到参数更新公式：$\\pi_k = N_k/N$，$\\mu_k = \\frac{1}{N_k} \\sum_{n=1}^{N} \\gamma_{nk} x^{(n)}$，$\\sigma_k^2 = \\frac{1}{N_k} \\sum_{n=1}^{N} \\gamma_{nk}(x^{(n)} - \\mu_k)^2$。\n- 算法11.1描述了GMM的参数学习过程，包括初始化、迭代E步和M步直到收敛。"
      },
      {
        "段落": "## 11.3 推断\n\n在图模型中，推断（Inference）是指在观测到部分变量 $\\boldsymbol{e}=\\left\\{e_{1}, e_{2}, \\cdots, e_{M}\\right\\}$时，计算其他变量的某个子集 $\\boldsymbol{q}=\\left\\{q_{1}, q_{2}, \\cdots, q_{N}\\right\\}$ 的条件概率 $p(\\boldsymbol{q} \\mid \\boldsymbol{e})$ ．\n\n假设一个图模型中，除了变量 $\\boldsymbol{e} 、 \\boldsymbol{q}$ 外，其余变量表示为 $\\boldsymbol{z}$ 。根据贝叶斯公式有\n\n$$\n\\begin{align*}\np(\\boldsymbol{q} \\mid \\boldsymbol{e}) & =\\frac{p(\\boldsymbol{q}, \\boldsymbol{e})}{p(\\boldsymbol{e})}  \\tag{11.67}\\\\\n& =\\frac{\\sum_{\\boldsymbol{z}} p(\\boldsymbol{q}, \\boldsymbol{e}, \\boldsymbol{z})}{\\sum_{\\boldsymbol{q}, \\boldsymbol{z}} p(\\boldsymbol{q}, \\boldsymbol{e}, \\boldsymbol{z})} . \\tag{11.68}\n\\end{align*}\n$$\n\n因此，图模型的推断问题的关键为求任意一个变量子集的边际概率分布问题．\n在图模型中，常用的推断算法可以分为精确推断算法和近似推断算法两类．",
        "总结": "- 推断：在图模型中，推断是指在观测到部分变量 $\\boldsymbol{e}$ 时，计算其他变量子集 $\\boldsymbol{q}$ 的条件概率 $p(\\boldsymbol{q} \\mid \\boldsymbol{e})$。  \n- 条件概率公式：根据贝叶斯公式，$p(\\boldsymbol{q} \\mid \\boldsymbol{e}) = \\frac{p(\\boldsymbol{q}, \\boldsymbol{e})}{p(\\boldsymbol{e})}$。  \n- 边际概率分布：推断问题的关键在于求任意一个变量子集的边际概率分布。  \n- 推断算法分类：常用的推断算法分为精确推断算法和近似推断算法两类。"
      },
      {
        "段落": "## 11．3．1 精确推断\n\n精确推断（Exact Inference）算法是指可以计算出条件概率 $p(\\boldsymbol{q} \\mid \\boldsymbol{e})$ 的精确解的算法．\n\n不失一般性，这里假设所有变量都为离散变量。",
        "总结": "- 精确推断是指能够计算出条件概率 $p(\\boldsymbol{q} \\mid \\boldsymbol{e})$ 的精确解的算法。  \n- 本节假设所有变量均为离散变量，以不失一般性。"
      },
      {
        "段落": "### 11．3．1．1 变量消除法\n\n以图11．2a的有向图为例，假设推断问题为计算后验概率 $p\\left(x_{1} \\mid x_{4}\\right)$ ，需要计算两个边际概率 $p\\left(x_{1}, x_{4}\\right)$ 和 $p\\left(x_{4}\\right)$ 。\n\n根据条件独立性假设，有\n\n$$\n\\begin{equation*}\np\\left(x_{1}, x_{4}\\right)=\\sum_{x_{2}, x_{3}} p\\left(x_{1}\\right) p\\left(x_{2} \\mid x_{1}\\right) p\\left(x_{3} \\mid x_{1}\\right) p\\left(x_{4} \\mid x_{2}, x_{3}\\right) \\tag{11.69}\n\\end{equation*}\n$$\n\n假设每个变量取 $K$ 个值，计算上面的边际分布需要 $K^{2}$ 次加法以及 $K^{2} \\times 3$ 次乘法。\n根据乘法的分配律，\n\n$$\n\\begin{equation*}\na b+a c=a(b+c) \\tag{11.70}\n\\end{equation*}\n$$\n\n边际概率 $p\\left(x_{1}, x_{4}\\right)$ 可以写为\n\n$$\n\\begin{equation*}\np\\left(x_{1}, x_{4}\\right)=p\\left(x_{1}\\right) \\sum_{x_{3}} p\\left(x_{3} \\mid x_{1}\\right) \\sum_{x_{2}} p\\left(x_{2} \\mid x_{1}\\right) p\\left(x_{4} \\mid x_{2}, x_{3}\\right) . \\tag{11.71}\n\\end{equation*}\n$$\n\n这样计算量可以减少到 $K^{2}+K$ 次加法和 $K^{2}+K+1$ 次乘法．\n这种方法是利用动态规划的思想，每次消除一个变量，来减少计算边际分布的计算复杂度，称为变量消除法（Variable Elimination Algorithm）。随着图模型规模的增长，变量消除法的收益越大。\n\n变量消除法可以按照不同的顺序来消除变量。比如上面的推断问题也可以按照 $x_{3}, x_{2}$ 的消除顺序进行计算。\n\n同理，边际概率 $p\\left(x_{4}\\right)$ 可以通过以下方式计算：\n\n$$\n\\begin{equation*}\np\\left(x_{4}\\right)=\\sum_{x_{3}} \\sum_{x_{2}} p\\left(x_{4} \\mid x_{2}, x_{3}\\right) \\sum_{x_{1}} p\\left(x_{3} \\mid x_{1}\\right) p\\left(x_{2} \\mid x_{1}\\right) p\\left(x_{1}\\right) \\tag{11.72}\n\\end{equation*}\n$$\n\n变量消除法的一个缺点是在计算多个边际分布时存在很多重复的计算。比如在上面的图模型中，计算边际概率 $p\\left(x_{4}\\right)$ 和 $p\\left(x_{3}\\right)$ 时很多局部的求和计算是一样的。",
        "总结": "- 变量消除法是一种通过逐步消除变量来减少计算边际分布复杂度的算法，利用动态规划思想。  \n- 以图11.2a为例，计算后验概率 $p(x_1 \\mid x_4)$ 需要计算 $p(x_1, x_4)$ 和 $p(x_4)$ 的边际概率。  \n- 公式 $p(x_1, x_4) = \\sum_{x_2, x_3} p(x_1) p(x_2 \\mid x_1) p(x_3 \\mid x_1) p(x_4 \\mid x_2, x_3)$ 展示了如何通过变量消除进行求和。  \n- 通过乘法分配律，$p(x_1, x_4)$ 可简化为 $p(x_1) \\sum_{x_3} p(x_3 \\mid x_1) \\sum_{x_2} p(x_2 \\mid x_1) p(x_4 \\mid x_2, x_3)$，从而减少计算量。  \n- 计算量从 $K^2$ 次加法和 $K^2 \\times 3$ 次乘法减少到 $K^2 + K$ 次加法和 $K^2 + K + 1$ 次乘法。  \n- 变量消除法的计算顺序会影响效率，例如可按 $x_3, x_2$ 的顺序进行消除。  \n- 边际概率 $p(x_4)$ 可通过类似方式计算，如公式 $p(x_4) = \\sum_{x_3} \\sum_{x_2} p(x_4 \\mid x_2, x_3) \\sum_{x_1} p(x_3 \\mid x_1) p(x_2 \\mid x_1) p(x_1)$。  \n- 变量消除法的一个缺点是计算多个边际分布时存在重复计算，例如在图模型中计算 $p(x_4)$ 和 $p(x_3)$ 时会有重复的局部求和。"
      },
      {
        "段落": "### 11．3．1．2 信念传播算法\n\n信念传播（Belief Propagation，BP）算法，也称为和积（Sum－Product）算法或消息传递（Message Passing）算法，是将变量消除法中的和积（Sum－Product）操作看作是消息（Message），并保存起来，这样可以节省大量的计算资源。\n\n我们先介绍链式结构上的信念传播算法．\n\n本节以无向图为例来介绍信念传播算法，但其同样适用于有向图。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-284.jpg?height=130&width=1161&top_left_y=128&top_left_x=73)\n\n图 11.14 无向马尔科夫链的消息传递过程\n\n以图11．14所示的无向马尔可夫链为例，其联合概率 $p(\\boldsymbol{x})$ 为\n\n$$\n\\begin{align*}\np(\\boldsymbol{x}) & =\\frac{1}{Z} \\prod_{c \\in \\mathcal{C}} \\phi_{c}\\left(\\boldsymbol{x}_{c}\\right)  \\tag{11.73}\\\\\n& =\\frac{1}{Z} \\prod_{t=1}^{T-1} \\phi\\left(x_{t}, x_{t+1}\\right) \\tag{11.74}\n\\end{align*}\n$$\n\n其中 $\\phi\\left(x_{t}, x_{t+1}\\right)$ 是定义在团 $\\left(x_{t}, x_{t+1}\\right)$ 的势能函数．\n第 $t$ 个变量的边际概率 $p\\left(x_{t}\\right)$ 为\n\n$$\n\\begin{align*}\np\\left(x_{t}\\right) & =\\sum_{x_{1}} \\cdots \\sum_{x_{t-1}} \\sum_{x_{t+1}} \\cdots \\sum_{x_{T}} p(\\boldsymbol{x})  \\tag{11.75}\\\\\n& =\\frac{1}{Z} \\sum_{x_{1}} \\cdots \\sum_{x_{t-1}} \\sum_{x_{t+1}} \\cdots \\sum_{x_{T}} \\prod_{t=1}^{T-1} \\phi\\left(x_{t}, x_{t+1}\\right) . \\tag{11.76}\n\\end{align*}\n$$\n\n假设每个变量取 $K$ 个值，不考虑归一化项，通过公式（11．76）计算边际分布需要 $K^{T-1}$ 次加法以及 $K^{T-1} \\times(T-1)$ 次乘法。\n\n根据乘法的分配律，边际概率 $p\\left(x_{t}\\right)$ 可以通过下面方式进行计算：\n\n$$\n\\begin{align*}\np\\left(x_{t}\\right) & =\\frac{1}{Z}\\left(\\sum_{x_{1}} \\cdots \\sum_{x_{t-1}} \\prod_{j=1}^{t-1} \\phi\\left(x_{j}, x_{j+1}\\right)\\right) \\cdot\\left(\\sum_{x_{t+1}} \\cdots \\sum_{x_{T}} \\prod_{j=t}^{T-1} \\phi\\left(x_{j}, x_{j+1}\\right)\\right) \\\\\n& =\\frac{1}{Z}\\left(\\sum_{x_{t-1}} \\phi\\left(x_{t-1}, x_{t}\\right) \\cdots\\left(\\sum_{x_{2}} \\phi\\left(x_{2}, x_{3}\\right)\\left(\\sum_{x_{1}} \\phi\\left(x_{1}, x_{2}\\right)\\right)\\right)\\right) \\\\\n& \\left(\\sum_{x_{t+1}} \\phi\\left(x_{t}, x_{t+1}\\right) \\cdots\\left(\\sum_{x_{T-1}} \\phi\\left(x_{T-2}, x_{T-1}\\right)\\left(\\sum_{x_{T}} \\phi\\left(x_{T-1}, x_{T}\\right)\\right)\\right)\\right) \\\\\n& =\\frac{1}{Z} \\mu_{t-1, t}\\left(x_{t}\\right) \\mu_{t+1, t}\\left(x_{t}\\right) \\tag{11.77}\n\\end{align*}\n$$\n\n其中 $\\mu_{t-1, t}\\left(x_{t}\\right)$ 定义为变量 $X_{t-1}$ 向变量 $X_{t}$ 传递的消息，定义为\n\n$$\n\\begin{equation*}\n\\mu_{t-1, t}\\left(x_{t}\\right) \\triangleq \\sum_{x_{t-1}} \\phi\\left(x_{t-1}, x_{t}\\right) \\mu_{t-2, t-1}\\left(x_{t-1}\\right) \\tag{11.78}\n\\end{equation*}\n$$\n\n$\\mu_{t+1, t}\\left(x_{t}\\right)$ 是变量 $X_{t+1}$ 向变量 $X_{t}$ 传递的消息，定义为\n\n$$\n\\begin{equation*}\n\\mu_{t+1, t}\\left(x_{t}\\right) \\triangleq \\sum_{x_{t+1}} \\phi\\left(x_{t}, x_{t+1}\\right) \\mu_{t+2, t+1}\\left(x_{t+1}\\right) \\tag{11.79}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n$\\mu_{t-1, t}\\left(x_{t}\\right)$ 和 $\\mu_{t+1, t}\\left(x_{t}\\right)$ 都可以递归计算。因此，边际概率 $p\\left(x_{t}\\right)$ 的计算复杂度减少为 $O\\left(T K^{2}\\right)$ 。如果要计算整个序列上所有变量的边际概率，不需要将消息传递的过程重复 $T$ 次，因为其中每两个相邻节点上的消息是相同的。\n\n链式结构图模型的消息传递过程为：\n（1）依次计算前向传递的消息 $\\mu_{t-1, t}\\left(x_{t}\\right), t=1, \\cdots, T-1$ ．\n（2）依次计算反向传递的消息 $\\mu_{t+1, t}\\left(x_{t}\\right), t=T-1, \\cdots, 1$ ．\n（3）在任意节点 $t$ 上计算配分函数 $Z$ ，\n\n$$\n\\begin{equation*}\nZ=\\sum_{x_{t}} \\mu_{t-1, t}\\left(x_{t}\\right) \\mu_{t+1, t}\\left(x_{t}\\right) \\tag{11.80}\n\\end{equation*}\n$$\n\n这样就可以通过公式（11．77）计算所有变量的边际概率了．\n树结构上的信念传播算法 信念传播算法也可以推广到具有树结构的图模型上。如果一个有向图满足任意两个变量只有一条路径（忽略方向），且只有一个没有父节点的节点，那么这个有向图为树结构，其中唯一没有父节点的节点称为根节点。如果一个无向图满足任意两个变量只有一条路径，那么这个无向图也为树结构。在树结构的无向图中，任意一个节点都可以作为根节点。\n\n树结构图模型的消息传递过程为：\n（1）从叶子节点到根节点依次计算并传递消息。\n（2）从根节点开始到叶子节点，依次计算并传递消息。\n（3）在每个节点上计算所有接收消息的乘积（如果是无向图还需要归一化），就得到了所有变量的边际概率。\n\n如果图结构中存在环路，可以使用联合树算法（Junction Tree Algorithm） ［Lauritzen et al．，1988］来将图结构转换为无环图．",
        "总结": "- 信念传播（Belief Propagation，BP）算法，也称为和积算法或消息传递算法，通过将变量消除法中的和积操作视为消息进行传递，以节省计算资源。  \n- 该算法以无向图为例进行介绍，但同样适用于有向图。  \n- 在无向马尔可夫链中，联合概率 $p(\\boldsymbol{x})$ 表示为所有团的势能函数的乘积，并归一化为 $Z$。  \n- 变量 $x_t$ 的边际概率 $p(x_t)$ 可通过前向和反向消息的乘积计算，避免直接进行高复杂度的求和运算。  \n- 前向消息 $\\mu_{t-1, t}(x_t)$ 和反向消息 $\\mu_{t+1, t}(x_t)$ 可递归计算，从而将计算复杂度降低到 $O(T K^2)$。  \n- 链式结构的消息传递过程包括前向消息传递、反向消息传递以及配分函数 $Z$ 的计算。  \n- 信念传播算法也可推广到树结构图模型上，树结构中任意节点均可作为根节点。  \n- 在树结构中，消息传递过程包括从叶子到根、再从根到叶子的两次消息传递，并在每个节点上计算接收消息的乘积以得到边际概率。  \n- 若图结构存在环路，可使用联合树算法将其转换为无环图以应用信念传播算法。"
      },
      {
        "段落": "## 11．3．2 近似推断\n\n在实际应用中，精确推断一般用于结构比较简单的推断问题。当图模型的结构比较复杂时，精确推断的计算开销会比较大。此外，如果图模型中的变量是连续的，并且其积分函数没有闭型（Closed－Form）解时，也无法使用精确推断。因此，在很多情况下也常常采用近似的方法来进行推断．\n\n近似推断（Approximate Inference）主要有以下三种方法：\n（1）环路信念传播：当图模型中存在环路，使用信念传播算法时，消息会在环路中一直传递，可能收敛或不收敛。环路信念传播（Loopy Belief Propaga－ tion，LBP）是在具有环路的图上依然使用信念传播算法，即使得到不精确解，在某些任务上也可以近似精确解。\nhttps：／／nndl．github．io／\n（2）变分推断：图模型中有些变量的局部条件分布可能非常复杂，或其积分无法计算。变分推断（Variational Inference）是引入一个变分分布（通常是比较简单的分布）来近似这些条件概率，然后通过迭代的方法进行计算。首先是更新变分分布的参数来最小化变分分布和真实分布的差异（比如交叉熵或 KL 距离），然后再根据变分分布来进行推断。\n（3）采样法：采样法（Sampling Method）是通过模拟的方式来采集符合某个分布 $p(\\boldsymbol{x})$ 的一些样本，并通过这些样本来估计和这个分布有关的运算，比如期望等。\n\n我们在下面两节分别介绍变分推断和基于采样法的近似推断．",
        "总结": "- 近似推断用于处理结构复杂或变量连续且无闭型解的图模型，无法使用精确推断。  \n- 环路信念传播（LBP）在存在环路的图上使用信念传播算法，即使可能不收敛，也能近似得到解。  \n- 变分推断通过引入简单分布近似复杂条件概率，迭代优化参数以最小化与真实分布的差异。  \n- 采样法通过模拟生成符合分布的样本，用样本估计分布相关的统计量如期望。  \n- 文中后续将分别介绍变分推断和基于采样法的近似推断方法。"
      },
      {
        "段落": "## 11.4 变分推断\n\n变分法（Calculus Of Variations）是17世纪末发展起来的一门数学分支，主要研究变分问题，即泛函的极值问题．\n\n函数（Function）是表示自变量到因变量的映射关系：$y=f(x)$ 。而泛函 （Functional）是函数的函数，即它的输入是函数，输出是实数：$F(f(x))$ ，一般称 $F(f(x))$ 为 $f(x)$ 的泛函，但是泛函要求 $f(x)$ 满足一定的边界条件，并且具有连续的二阶导数。一个泛函的例子是熵，其输入是一个概率分布 $p(x)$ ，输出是该分布的不确定性．\n\n传统的微积分通常可以用来寻找函数 $f(x)$ 的极值点，而变分法则是用来寻找一个函数 $f(x)$ 使得泛函 $F(f(x))$ 取得极大或极小值。变方法的应用十分广泛，比如最大熵问题，即寻找一个概率分布，使得该概率分布的熵最大．\n\n假设在一个贝叶斯模型中， $\\boldsymbol{x}$ 为一组观测变量， $\\boldsymbol{z}$ 为一组隐变量（参数也看作是随机变量，包含在 $\\boldsymbol{z}$ 中），我们的推断问题为计算条件概率密度 $p(\\boldsymbol{z} \\mid \\boldsymbol{x})$ 。根据贝叶斯公式，条件概率密度 $p(\\boldsymbol{z} \\mid \\boldsymbol{x})$ 可以写为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{z} \\mid \\boldsymbol{x})=\\frac{p(\\boldsymbol{x}, \\boldsymbol{z})}{p(\\boldsymbol{x})}=\\frac{p(\\boldsymbol{x}, \\boldsymbol{z})}{\\int p(\\boldsymbol{x}, \\boldsymbol{z}) \\mathrm{d} \\boldsymbol{z}} \\tag{11.81}\n\\end{equation*}\n$$\n\n对于很多模型来说，计算上面公式中的积分是不可行的，要么积分没有闭式解，要么是指数级的计算复杂度。\n\n变分推断（Variational Inference）是变分法在推断问题中的应用，是寻找一个简单分布 $q^{*}(\\boldsymbol{z})$ 来近似条件概率密度 $p(\\boldsymbol{z} \\mid \\boldsymbol{x})$ ，也称为 变分贝叶斯（Variational Bayesian）．这样，推断问题转换为一个泛函优化问题：\n\n$$\n\\begin{equation*}\nq^{*}(\\boldsymbol{z})=\\underset{q(\\boldsymbol{z}) \\in \\Omega}{\\arg \\min } \\operatorname{KL}(q(\\boldsymbol{z}) \\| p(\\boldsymbol{z} \\mid \\boldsymbol{x})), \\tag{11.82}\n\\end{equation*}\n$$\n\n概率分布可以看作是一个函数．熵的定义参见第E． 1 节．\n\n不失一般性，这里假设 $\\boldsymbol{x}$ 和 $\\boldsymbol{z}$ 为连续随机向量．\n\n闭式解是指问题的解为闭式（closed－form）函数，从解的函数中就可以算出任何对应值．闭式解也称为解析解，和数值解相对应．\n参见习题11－7。\n\n其中 $Q$ 为候选的概率分布族．由于 $p(\\boldsymbol{z} \\mid \\boldsymbol{x})$ 难以直接计算，因此我们不能直接优化上面公式的 KL 散度。\n\n我们在 EM 算法中已经证明\n\n$$\n\\begin{equation*}\n\\log p(\\boldsymbol{x})=E L B O(q, \\boldsymbol{x})+\\operatorname{KL}(q(\\boldsymbol{z}) \\| p(\\boldsymbol{z} \\mid \\boldsymbol{x})) \\tag{11.83}\n\\end{equation*}\n$$\n\n在 EM 算法的 E 步中，我们假设 $p(\\boldsymbol{z} \\mid \\boldsymbol{x})$ 是可计算的，并让 $q(\\boldsymbol{z})=p(\\boldsymbol{z} \\mid \\boldsymbol{x})$ ，这样 $\\operatorname{ELBO}(q, \\boldsymbol{x})$ 等于 $\\log p(\\boldsymbol{x})$ 。而变分推断可以看作是 EM 算法扩展版，主要处理不能精确推断 $p(\\boldsymbol{z} \\mid \\boldsymbol{x})$ 的情况。\n\n结合公式（11．82）和公式（11．83），有\n\n$$\n\\begin{align*}\nq^{*}(\\boldsymbol{z}) & =\\underset{q(\\boldsymbol{z}) \\in Q}{\\arg \\min }(\\log p(\\boldsymbol{x})-E L B O(q, \\boldsymbol{x}))  \\tag{11.84}\\\\\n& =\\underset{q(\\boldsymbol{z}) \\in Q}{\\arg \\max } E L B O(q, \\boldsymbol{x}) \\tag{11.85}\n\\end{align*}\n$$\n\n这样，公式（11．82）中优化问题转换为寻找一个简单分布 $q^{*}(\\boldsymbol{z})$ 来最大化证据下界 $\\operatorname{ELBO}(q, \\boldsymbol{x})$ ．\n\n在变分推断中，候选分布族 $Q$ 的复杂性决定了优化问题的复杂性。一个通常的选择是平均场（mean－field）分布族，即 $\\boldsymbol{z}$ 可以分拆为多组相互独立的变量。概率密度 $q(\\boldsymbol{z})$ 可以分解为\n\n$$\n\\begin{equation*}\nq(\\boldsymbol{z})=\\prod_{m=1}^{M} q_{m}\\left(\\boldsymbol{z}_{m}\\right) \\tag{11.86}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{z}_{m}$ 是隐变量的子集，可以是单变量，也可以是一组多元变量．\n证据下界 $\\operatorname{ELBO}(q, \\boldsymbol{x})$ 可以写为\n\n$$\n\\begin{align*}\n\\operatorname{ELBO}(q, \\boldsymbol{x}) & =\\int q(\\boldsymbol{z}) \\log \\frac{p(\\boldsymbol{x}, \\boldsymbol{z})}{q(\\boldsymbol{z})} \\mathrm{d} \\boldsymbol{z}  \\tag{11.87}\\\\\n& =\\int q(\\boldsymbol{z})(\\log p(\\boldsymbol{x}, \\boldsymbol{z})-\\log q(\\boldsymbol{z})) \\mathrm{d} \\boldsymbol{z}  \\tag{11.88}\\\\\n& =\\int \\prod_{m=1}^{M} q_{m}\\left(\\boldsymbol{z}_{m}\\right)\\left(\\log p(\\boldsymbol{x}, \\boldsymbol{z})-\\sum_{m=1}^{M} \\log q_{m}\\left(\\boldsymbol{z}_{m}\\right)\\right) \\mathrm{d} \\boldsymbol{z} . \\tag{11.89}\n\\end{align*}\n$$\n\n假设只关心隐变量的子集 $\\boldsymbol{z}_{j}$ 的近似分布 $q_{j}\\left(\\boldsymbol{z}_{j}\\right)$ ，上式可以写为\n\n$$\n\\begin{align*}\n\\operatorname{ELBO}(q, \\boldsymbol{x}) & =\\int q_{j} \\int \\underbrace{\\int}_{-\\int q_{m \\neq j} q_{m} \\log p(\\boldsymbol{x}, \\boldsymbol{z}) \\mathrm{d} \\boldsymbol{z}_{m}} \\mathrm{~d} \\boldsymbol{z}_{j}  \\tag{11.90}\\\\\n& =\\int q_{j} \\log q_{j} \\mathrm{~d} \\boldsymbol{z}_{j}+\\text { const } \\tag{11.91}\n\\end{align*}\n$$\n\nEM 算 法 参 见 第 11．2．2．1节．\n\n参见公式（11．49）。\nhttps：／／nndl．github．io／\n\n这里 $q_{m}\\left(z_{m}\\right)$ 用简 写 $q_{m}$ 表示．\nconst为一个常数．\n\n其中 $\\tilde{p}\\left(\\boldsymbol{x}, \\boldsymbol{z}_{j}\\right)$ 可以看作是一个关于 $\\boldsymbol{z}_{j}$ 的未归一化的分布，并有\n\n$$\n\\begin{align*}\n\\log \\tilde{p}\\left(\\boldsymbol{x}, \\boldsymbol{z}_{j}\\right) & =\\int \\prod_{m \\neq j} q_{m} \\log p(\\boldsymbol{x}, \\boldsymbol{z}) \\mathrm{d} \\boldsymbol{z}_{m}  \\tag{11.92}\\\\\n& =\\mathbb{E}_{q\\left(\\boldsymbol{z}_{\\backslash j}\\right)}[\\log p(\\boldsymbol{x}, \\boldsymbol{z})]+\\mathrm{const} \\tag{11.93}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{z}_{\\backslash j}$ 为除变量子集 $\\boldsymbol{z}_{j}$ 外的其他隐变量，\n假设我们固定 $\\boldsymbol{z}_{\\backslash j}$ 不变，先优化 $q_{j}\\left(\\boldsymbol{z}_{j}\\right)$ 使得 $\\operatorname{ELBO}(q, \\boldsymbol{x})$ 最大．根据公式（11．91）， $\\operatorname{ELBO}(q, \\boldsymbol{x})$ 可以看作是 $-\\mathrm{KL}\\left(q_{j}\\left(\\boldsymbol{z}_{j}\\right) \\| \\tilde{p}\\left(\\boldsymbol{x}, \\boldsymbol{z}_{j}\\right)\\right)$ 加上一个常数。因此，最小化 KL 散度 $\\operatorname{KL}\\left(q_{j}\\left(\\boldsymbol{z}_{j}\\right) \\| \\tilde{p}\\left(\\boldsymbol{x}, \\boldsymbol{z}_{j}\\right)\\right)$ 就等价于最大化公式（11．91），即最优的 $q_{j}^{*}\\left(\\boldsymbol{z}_{j}\\right)$ 正比于对数联合概率密度 $\\log p(\\boldsymbol{x}, \\boldsymbol{z})$ 的期望的指数：\n\n$$\n\\begin{equation*}\nq_{j}^{*}\\left(\\boldsymbol{z}_{j}\\right)=\\tilde{p}\\left(\\boldsymbol{x}, \\boldsymbol{z}_{j}\\right) \\propto \\exp \\left(\\mathbb{E}_{q\\left(\\boldsymbol{z}_{\\backslash j}\\right)}[\\log p(\\boldsymbol{x}, \\boldsymbol{z})]\\right) \\tag{11.94}\n\\end{equation*}\n$$\n\n其中期望是根据 $q\\left(\\boldsymbol{z}_{\\backslash j}\\right)$ 计算的。我们可以通过选择合适的 $q_{m}\\left(\\boldsymbol{z}_{m}\\right), 1 \\leq m \\leq M$ 使得这个期望具有闭式解．\n\n由于 $q_{j}^{*}\\left(\\boldsymbol{z}_{j}\\right)$ 的计算要依赖于其他隐变量，我们可以用坐标上升法（Coordi－ nate Ascent Algorithm）来迭代优化每个 $q_{j}^{*}\\left(\\boldsymbol{z}_{j}\\right), j=1, \\cdots, M$ 。通过不断循环迭代地应用公式（11．94），证据下界 $\\operatorname{ELBO}(q, \\boldsymbol{x})$ 会收敛到一个局部最优解。\n\n变分推断通常和参数学习一起使用，比如应用在 EM 算法的 E 步中来近似条件分布 $p(\\boldsymbol{z} \\mid \\boldsymbol{x})$ 。\n\n在变分推断中，我们通常选择一些比较简单的分布 $q(\\boldsymbol{z})$ 来近似推断 $p(\\boldsymbol{z} \\mid \\boldsymbol{x})$ 。当 $p(\\boldsymbol{z} \\mid \\boldsymbol{x})$ 比较复杂时，近似效果不佳。这时可以利用神经网络的强大拟合能力来近似 $p(\\boldsymbol{z} \\mid \\boldsymbol{x})$ ，这种思想被应用在变分自编码器中。",
        "总结": "- 变分推断是变分法在贝叶斯推断中的应用，用于近似复杂条件概率分布 $p(\\boldsymbol{z} \\mid \\boldsymbol{x})$。\n- 变分推断将推断问题转化为一个泛函优化问题，目标是最小化 KL 散度 $\\operatorname{KL}(q(\\boldsymbol{z}) \\| p(\\boldsymbol{z} \\mid \\boldsymbol{x}))$。\n- 证据下界 ELBO 被最大化以找到最优近似分布 $q^{*}(\\boldsymbol{z})$，其定义为 $\\operatorname{ELBO}(q, \\boldsymbol{x}) = \\int q(\\boldsymbol{z}) \\log \\frac{p(\\boldsymbol{x}, \\boldsymbol{z})}{q(\\boldsymbol{z})} \\mathrm{d} \\boldsymbol{z}$。\n- 平均场分布族是常用的候选分布族，假设隐变量可以分解为多个独立子集，即 $q(\\boldsymbol{z}) = \\prod_{m=1}^{M} q_{m}(\\boldsymbol{z}_{m})$。\n- 在优化过程中，通过固定其他变量并优化每个子集的分布，使用坐标上升法迭代求解最优分布 $q_{j}^{*}(\\boldsymbol{z}_{j})$。\n- 最优分布 $q_{j}^{*}(\\boldsymbol{z}_{j})$ 与对数联合概率密度的期望指数成正比，即 $q_{j}^{*}\\left(\\boldsymbol{z}_{j}\\right) \\propto \\exp\\left( \\mathbb{E}_{q\\left(\\boldsymbol{z}_{\\backslash j}\\right)}[\\log p(\\boldsymbol{x}, \\boldsymbol{z})] \\right)$。\n- 变分推断常用于参数学习和近似复杂分布，如在变分自编码器中利用神经网络拟合近似分布。"
      },
      {
        "段落": "## 11.5 基于采样法的近似推断\n\n在很多实际机器学习任务中，我们推断某个概率分布并不是最终目的，而是基于这个概率分布进一步计算并作出决策。通常这些计算和期望相关。\n\n不失一般性，假设我们要推断的概率分布为 $p(x)$ ，并基于 $p(x)$ 来计算函数 $f(x)$ 的期望\n\n$$\n\\begin{equation*}\n\\mathbb{E}_{p}[f(x)]=\\int_{x} f(x) p(x) \\mathrm{d} x \\tag{11.95}\n\\end{equation*}\n$$\n\n当 $p(x)$ 比较复杂或难以精确推断时，我们可以通过采样法来近似计算期望 $\\mathbb{E}_{p}[f(x)]$ 的解．\n\n变分自编码器参见第 13.2 节。\n\n采样也叫抽样。\n\n本节中假设 $x$ 为连续变量。如果 $x$ 是离散变量，可以将积分替换为求和。",
        "总结": "- 概念：基于采样法的近似推断，用于在复杂或难以精确推断的概率分布 $p(x)$ 下，近似计算函数 $f(x)$ 的期望值。\n- 算法：通过从 $p(x)$ 中采样得到一组样本，利用这些样本估计期望 $\\mathbb{E}_{p}[f(x)]$。\n- 公式：期望值的计算公式为 $\\mathbb{E}_{p}[f(x)]=\\int_{x} f(x) p(x) \\mathrm{d} x$。\n- 假设：本节假设 $x$ 为连续变量，若为离散变量则将积分替换为求和。\n- 说明：采样法适用于难以精确推断概率分布的情况，常用于机器学习任务中进行决策和计算。"
      },
      {
        "段落": "## 11．5．1 采样法\n\n采样法（Sampling Method）也称为蒙特卡罗方法（Monte Carlo Method）或统计模拟方法，是20世纪40年代中期提出的一种通过随机采样来近似估计一些计算问题数值解的方法．随机采样指从给定概率密度函数 $p(x)$ 中抽取出符合其概率分布的样本．\n\n由于电子计算机的出现和快速发展，这种方法作为一种独立方法被提出来，使得当时很多难以计算的问题都可以通过随机模拟的方法来进行估计。\n\n为了计算公式（11．95）中的 $\\mathbb{E}_{p}[f(x)]$ ，我们可以通过数值解的方法来近似计算．首先从 $p(x)$ 中独立抽取 $N$ 个样本 $x^{(1)}, x^{(2)}, \\cdots, x^{(N)}, f(x)$ 的期望可以用这 $N$个样本的均值 $\\bar{f}_{N}$ 来近似，即\n\n$$\n\\begin{equation*}\n\\bar{f}_{N}=\\frac{1}{N}\\left(f\\left(x^{(1)}\\right)+\\cdots+f\\left(x^{(N)}\\right)\\right) . \\tag{11.96}\n\\end{equation*}\n$$\n\n根据大数定律，当 $N$ 趋向于无穷大时，样本均值收玫于期望值．\n\n$$\n\\begin{equation*}\n\\bar{f}_{N} \\xrightarrow{P} \\mathbb{E}_{p}[f(x)] \\quad \\text { 当 } N \\rightarrow \\infty \\text {. } \\tag{11.97}\n\\end{equation*}\n$$\n\n这就是采样法的理论依据．\n采样法的一个最简单的应用例子是计算圆周率 $\\pi$ ．我们知道半径为 $r$ 的圆的面积为 $\\pi r^{2}$ ，而直径为 $2 r$ 的正方形的面积为 $4 r^{2}$ 。当我们用正方形去嵌套一个相切的圆时，它们的面积之比是 $\\frac{1}{4} \\pi$ 。当不知道 $\\pi$ 时，我们无法计算圆的面积。因此，需要通过模拟的方法来进行近似估计。首先在正方形内部按均值采样的方式随机生成若干点，计算它们与圆心点的距离，从而判断它们是否落在圆的内部．然后去统计落在圆内部的点占到所有点的比例．当有足够的点时，这个比例应该接近于 $\\frac{1}{4} \\pi$ ，从而近似估算出 $\\pi$ 的值。\n\n随机采样 采样法的难点是如何进行随机采样，即如何让计算机生成满足概率密度函数 $p(x)$ 的样本．我们知道，计算机可以比较容易地随机生成一个在 $[0,1]$ 区间上均布分布的样本 $\\xi$ ．如果要随机生成服从某个非均匀分布的样本，就需要一些间接的采样方法．\n\n如果一个分布的概率密度函数为 $p(x)$ ，其累积分布函数 $\\operatorname{cdf}(x)$ 为连续的严格增函数，且存在逆函数 $\\mathrm{cdf}^{-1}(y), y \\in[0,1]$ ，那么我们可以利用累积分布函数的逆函数来生成服从该随机分布的样本．假设 $\\xi$ 是 $[0,1]$ 区间上均匀分布的随机变量，则 $\\mathrm{cdf}^{-1}(\\xi)$ 服从概率密度函数为 $p(x)$ 的分布。\n\n但当 $p(x)$ 非常复杂，其累积分布函数的逆函数难以计算，或者不知道 $p(x)$ 的精确值，只知道未归一化的分布 $\\hat{p}(x)$ ，那么就难以直接对 $p(x)$ 进行采样，往往需要使用一些间接的采样策略，比如拒绝采样、重要性采样、马尔可夫链蒙特卡罗采 https：／／nndl．github．io／\n\n蒙特卡罗方法诞生于 20世纪40年代美国的 ＂曼哈顿计划＂，其名字来源于摩纳哥的一个以赌博业闻名的城市蒙特卡罗，象征概率。\n\n数值解就是用数值方法求出解，给出一系列对应的自变量和解。数值解和解析解或闭式解相对应．\n\n参见习题11－10．\n$p(x)=\\frac{1}{z} \\hat{p}(x)$ ，其中 $Z$ 为配分函数．\n\n样等。这些方法一般是先根据一个比较容易采样的分布进行采样，然后通过一些策略来间接得到符合 $p(x)$ 分布的样本。",
        "总结": "- 采样法（蒙特卡罗方法）是一种通过随机采样近似估计计算问题数值解的方法，提出于20世纪40年代中期。  \n- 采样法的核心思想是利用大数定律，通过从概率密度函数 $p(x)$ 中抽取大量样本，用样本均值近似估计期望值 $\\mathbb{E}_{p}[f(x)]$。  \n- 公式（11.96）给出了样本均值 $\\bar{f}_{N}$ 的计算方式，当 $N \\rightarrow \\infty$ 时，样本均值收敛于期望值（公式11.97）。  \n- 采样法的一个简单应用是估算圆周率 $\\pi$，通过在正方形内随机生成点并统计落在圆内的比例来近似 $\\pi$。  \n- 随机采样的难点在于如何生成满足特定分布的样本，常用方法包括利用累积分布函数的逆变换、拒绝采样、重要性采样和马尔可夫链蒙特卡罗等。  \n- 蒙特卡罗方法起源于“曼哈顿计划”，名称来源于赌博业城市蒙特卡罗，象征概率的重要性。  \n- 数值解是通过数值方法求解问题，与解析解相对，给出自变量和解的对应关系。  \n- 配分函数 $Z$ 是归一化常数，用于将未归一化的分布 $\\hat{p}(x)$ 转换为概率密度函数 $p(x)$。"
      },
      {
        "段落": "## 11．5．2 拒绝采样\n\n拒绝采样（Rejection Sampling）是一种间接采样方法，也称为接受－拒绝采样（Acceptance－Rejection Sampling）。\n\n假设原始分布 $p(x)$ 难以直接采样，我们可以引入一个容易采样的分布 $q(x)$ ，一般称为提议分布（Proposal Distribution），然后以某个标准来拒绝一部分的样本使得最终采集的样本服从分布 $p(x)$ 。\n\n在拒绝采样中，已知未归一化的分布 $\\hat{p}(x)$ ，我们需要构建一个提议分布 $q(x)$和一个常数 $k$ ，使得 $k q(x)$ 可以覆盖函数 $\\hat{p}(x)$ ，即 $k q(x) \\geq \\hat{p}(x), \\forall x$ ．如图11．15所\n\n为简单起见，我们把概率密度函数为 $p(x)$ 的分布简称为分布 $p(x)$ ，下同。\n\n提议分布在很多文献中也翻译为参考分布。示。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-290.jpg?height=576&width=707&top_left_y=841&top_left_x=306)\n\n图11．15拒绝采样\n\n对于每次抽取的样本 $\\hat{x}$ ，计算接受概率（Acceptance Probability）\n\n$$\n\\begin{equation*}\n\\alpha(\\hat{x})=\\frac{\\hat{p}(\\hat{x})}{k q(\\hat{x})}, \\tag{11.98}\n\\end{equation*}\n$$\n\n并以概率 $\\alpha(\\hat{x})$ 来接受样本 $\\hat{x}$ 。拒绝采样的采样过程如下算法11．2所示。\n判断一个拒绝采样方法的好坏就是看其采样效率，即总体的接受率．如果函数 $k q(x)$ 远大于原始分布函数 $\\hat{p}(x)$ ，拒绝率会比较高，采样效率会非常不理想。但要找到一个和 $\\hat{p}(x)$ 比较接近的提议分布往往比较困难。特别是在高维空间中，其采样率会非常低，导致很难应用到实际问题中。\n\n```\n算法 11.2: 拒绝采样的采样过程\n    输入: 提议分布 $q(x)$;\n    常数 $k$;\n    样本集合 $\\mathcal{V}=\\varnothing$;\n    repeat\n        根据 $q(x)$ 随机生成一个样本 $\\hat{x}$;\n        计算接受概率 $\\alpha(\\hat{x})$;\n        从 $(0,1)$ 的均匀分布中随机生成一个值 $z$;\n        if $z \\leq \\alpha(\\hat{x})$ then $\\quad / *$ 以 $\\alpha(\\hat{x})$ 的概率接受 $\\hat{\\boldsymbol{x}} * /$\n            $\\mathcal{V}=\\mathcal{V} \\cup\\{\\hat{x}\\} ;$\n        end\n    until 直到获得 $N$ 个样本 $(|\\mathcal{V}|=N)$;\n    输出: 样本集合 $\\mathcal{V}$\n```",
        "总结": "- 拒绝采样是一种间接采样方法，通过引入一个容易采样的提议分布来生成样本，并通过接受概率决定是否保留样本。  \n- 拒绝采样的核心思想是找到一个提议分布 $q(x)$ 和一个常数 $k$，使得 $k q(x) \\geq \\hat{p}(x)$，从而覆盖未归一化的分布 $\\hat{p}(x)$。  \n- 接受概率 $\\alpha(\\hat{x})$ 定义为 $\\frac{\\hat{p}(\\hat{x})}{k q(\\hat{x})}$，用于决定是否接受生成的样本 $\\hat{x}$。  \n- 算法流程包括：从 $q(x)$ 中生成样本、计算接受概率、随机生成 $z$ 并比较以决定是否接受样本，直到获得所需数量的样本。  \n- 拒绝采样的效率取决于接受率，接受率低会导致采样效率差，尤其在高维空间中问题更加严重。"
      },
      {
        "段落": "## 11．5．3 重要性采样\n\n如果采样的目的是计算分布 $p(x)$ 下函数 $f(x)$ 的期望，那么实际上抽取的样本不需要严格服从分布 $p(x)$ 。也可以通过另一个分布，即提议分布 $q(x)$ ，直接采样并估计 $\\mathbb{E}_{p}[f(x)]$ 。\n\n函数 $f(x)$ 在分布 $p(x)$ 下的期望可以写为\n\n$$\n\\begin{align*}\n\\mathbb{E}_{p}[f(x)] & =\\int_{x} f(x) p(x) \\mathrm{d} x  \\tag{11.99}\\\\\n& =\\int_{x} f(x) \\frac{p(x)}{q(x)} q(x) \\mathrm{d} x  \\tag{11.100}\\\\\n& =\\int_{x} f(x) w(x) q(x) \\mathrm{d} x  \\tag{11.101}\\\\\n& =\\mathbb{E}_{q}[f(x) w(x)] \\tag{11.102}\n\\end{align*}\n$$\n\n其中 $w(x)$ 称为重要性权重．\n重要性采样（Importance Sampling）是通过引入重要性权重，将分布 $p(x)$下 $f(x)$ 的期望变为在分布 $q(x)$ 下 $f(x) w(x)$ 的期望，从而可以近似为\n\n$$\n\\begin{equation*}\n\\hat{f}_{N}=\\frac{1}{N}\\left(f\\left(x^{(1)}\\right) w\\left(x^{(1)}\\right)+\\cdots+f\\left(x^{(N)}\\right) w\\left(x^{(N)}\\right)\\right) \\tag{11.103}\n\\end{equation*}\n$$\n\n其中 $x^{(1)}, \\cdots, x^{(N)}$ 为独立从 $q(x)$ 中随机抽取的点．\n重要性采样也可以在只知道末归一化的分布 $\\hat{p}(x)$ 的情况下计算函数 $f(x)$ 的期望。\n\n$$\n\\begin{equation*}\n\\mathbb{E}_{p}[f(x)]=\\int_{x} f(x) \\frac{\\hat{p}(x)}{Z} \\mathrm{~d} x \\tag{11.104}\n\\end{equation*}\n$$\n\n$p(x)=\\frac{\\hat{p}(x)}{Z}, Z$ 为配分函数．\n\n$$\n\\begin{align*}\n& =\\frac{\\int_{x} \\hat{p}(x) f(x) d x}{\\int_{x} \\hat{p}(x) \\mathrm{d} x}  \\tag{11.105}\\\\\n& \\approx \\frac{\\sum_{n=1}^{N} f\\left(x^{(n)}\\right) \\hat{w}\\left(x^{(n)}\\right)}{\\sum_{n=1}^{N} \\hat{w}\\left(x^{(n)}\\right)}, \\tag{11.106}\n\\end{align*}\n$$\n\n其中 $\\hat{\\omega}(x)=\\frac{\\hat{p}(x)}{q(x)}, x^{(1)}, \\cdots, x^{(N)}$ 为独立从 $q(x)$ 中随机抽取的点．",
        "总结": "- 重要性采样是一种通过引入重要性权重，利用提议分布 $q(x)$ 近似计算分布 $p(x)$ 下函数 $f(x)$ 的期望的方法。  \n- 函数 $f(x)$ 在分布 $p(x)$ 下的期望可以表示为在分布 $q(x)$ 下 $f(x) w(x)$ 的期望，其中 $w(x) = \\frac{p(x)}{q(x)}$ 为重要性权重。  \n- 重要性采样可以用于只知道末归一化分布 $\\hat{p}(x)$ 的情况，通过配分函数 $Z$ 进行归一化处理。  \n- 在这种情况下，期望近似为加权样本的均值，权重为 $\\hat{w}(x) = \\frac{\\hat{p}(x)}{q(x)}$。  \n- 该方法通过从提议分布 $q(x)$ 中抽取样本，并计算加权平均来估计原分布下的期望。"
      },
      {
        "段落": "## 11．5．4 马尔可夫链蒙特卡罗方法\n\n在高维空间中，拒绝采样和重要性采样的效率随空间维数的增加而指数降低．马尔可夫链蒙特卡罗（Markov Chain Monte Carlo，MCMC）方法是一种更好的采样方法，可以很容易地对高维变量进行采样。\n\nMCMC 方法也有很多不同的具体采样方法，但其核心思想是将采样过程看作是一个马尔可夫链。\n\n$$\nx_{1}, x_{2}, \\cdots, x_{t-1}, x_{t}, x_{t+1}, \\cdots\n$$\n\n第 $t+1$ 次采样依赖于第 $t$ 次抽取的样本 $\\boldsymbol{x}_{t}$ 以及状态转移分布（即提议分布） $q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}_{t}\\right)$ 。如果这个马尔可夫链的平稳分布为 $p(\\boldsymbol{x})$ ，那么在状态平稳时抽取的样本就服从 $p(\\boldsymbol{x})$ 的分布．\n\nMCMC 方法的关键是如何构造出平稳分布为 $p(\\boldsymbol{x})$ 的马尔可夫链，并且该马尔可夫链的状态转移分布 $q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime}\\right)$ 一般为比较容易采样的分布。当 $\\boldsymbol{x}$ 为离散变量时，$q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime}\\right)$ 可以是一个状态转移矩阵；当 $\\boldsymbol{x}$ 为连续变量时，$q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime}\\right)$ 可以是参数密度函数，比如各向同性的高斯分布 $q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime}\\right)=\\mathcal{N}\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime}, \\sigma^{2} I\\right)$ ，其中 $\\sigma^{2}$ 为超参数．\n\n使用 MCMC 方法进行采样时需要注意两点：一是马尔可夫链需要经过一段时间的随机游走才能达到平稳状态，这段时间称为预烧期（Burn－in Period）。预烧期内的采样点并不服从分布 $p(\\boldsymbol{x})$ ，需要丢弃。二是基于马尔可夫链抽取的相邻样本是高度相关的。而在机器学习中，我们一般需要抽取的样本是独立同分布的。为了使得抽取的样本之间独立，我们可以每间隔 $M$ 次随机游走，抽取一个样本．如果 $M$ 足够大，可以认为抽取的样本是独立的．",
        "总结": "- 马尔可夫链蒙特卡罗（MCMC）方法是一种用于高维空间采样的高效方法，克服了拒绝采样和重要性采样的效率问题。  \n- MCMC 的核心思想是将采样过程视为一个马尔可夫链，其平稳分布即为目标分布 $p(\\boldsymbol{x})$。  \n- 采样过程中，第 $t+1$ 次样本依赖于第 $t$ 次样本及状态转移分布 $q(\\boldsymbol{x} \\mid \\boldsymbol{x}_t)$。  \n- 构造的马尔可夫链需满足平稳分布为 $p(\\boldsymbol{x})$，且状态转移分布 $q(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime})$ 应易于采样，如高斯分布等。  \n- 使用 MCMC 时需注意预烧期（Burn-in Period），即马尔可夫链达到平稳状态前的样本需丢弃。  \n- 相邻样本高度相关，为获得独立样本，可每隔 $M$ 次采样取一个样本，若 $M$ 足够大则近似独立。"
      },
      {
        "段落": "### 11．5．4．1 Metropolis－Hastings 算法\n\nMetropolis－Hastings 算法，简称MH 算法，是一种应用广泛的MCMC 方法。假设马尔可夫链的状态转移分布（即提议分布）$q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime}\\right)$ 为一个比较容易采样的分布，其平稳分布往往不是 $p(\\boldsymbol{x})$ 。为此， MH 算法引入拒绝采样的思想来修正提议分布，使得最终采样的分布为 $p(\\boldsymbol{x})$ 。\n\n在 MH 算法中，假设第 $t$ 次采样的样本为 $\\boldsymbol{x}_{t}$ ，首先根据提议分布 $q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}_{t}\\right)$ 抽取\n\n一个样本 $\\hat{\\boldsymbol{x}}$ ，并以概率 $A\\left(\\hat{\\boldsymbol{x}}, \\boldsymbol{x}_{t}\\right)$ 来接受 $\\hat{\\boldsymbol{x}}$ 作为第 $t+1$ 次的采样样本 $\\boldsymbol{x}_{t+1}$ ，\n\n$$\n\\begin{equation*}\nA\\left(\\hat{\\boldsymbol{x}}, \\boldsymbol{x}_{t}\\right)=\\min \\left(1, \\frac{p(\\hat{\\boldsymbol{x}}) q\\left(\\boldsymbol{x}_{t} \\mid \\hat{\\boldsymbol{x}}\\right)}{p\\left(\\boldsymbol{x}_{t}\\right) q\\left(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_{t}\\right)}\\right) \\tag{11.107}\n\\end{equation*}\n$$\n\nMH 算法的采样过程如算法11．3所示．\n\n```\n算法 11.3: Metropolis-Hastings 算法的采样过程\n    输入: 提议分布 $q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime}\\right)$;\n    采样间隔 $M$;\n    样本集合 $\\mathcal{V}=\\varnothing$;\n    随机初始化 $\\boldsymbol{x}_{0}$;\n    $t=0 ;$\n    repeat\n        // 预热过程\n        根据 $q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}_{t}\\right)$ 随机生成一个样本 $\\hat{\\boldsymbol{x}}$;\n        计算接受概率 $A\\left(\\hat{\\boldsymbol{x}}, \\boldsymbol{x}_{t}\\right)$;\n        从 $(0,1)$ 的均匀分布中随机生成一个值 $z$;\n        if $z \\leq A\\left(\\hat{\\boldsymbol{x}}, \\boldsymbol{x}_{t}\\right)$ then $\\quad / *$ 以 $A\\left(\\hat{\\boldsymbol{x}}, \\boldsymbol{x}_{t}\\right)$ 的概率接受 $\\hat{\\boldsymbol{x}} * /$\n            $x_{t+1}=\\hat{x} ;$\n        else /* 拒绝接受 $\\hat{\\boldsymbol{x}}$ */\n            $x_{t+1}=x_{t} ;$\n        end\n        $t++$;\n        if 未到平稳状态 then\n            continue;\n        end\n        // 采样过程, 每隔 $M$ 次采一个样本\n        if $t \\bmod M=0$ then\n            $\\mathcal{V}=\\mathcal{V} \\cup\\left\\{\\boldsymbol{x}_{t}\\right\\} ;$\n        end\n    until 直到获得 $N$ 个样本 $(|\\mathcal{V}|=N)$;\n    输出: 样本集合 $\\mathcal{V}$\n```\n\n在 MH 算法中，因为每次 $q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}_{t}\\right)$ 随机生成一个样本 $\\hat{\\boldsymbol{x}}$ ，并以概率 $A\\left(\\hat{\\boldsymbol{x}}, \\boldsymbol{x}_{t}\\right)$ 的方式接受，因此修正的马尔可夫链状态转移概率为\n\n$$\n\\begin{equation*}\nq^{\\prime}\\left(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_{t}\\right)=q\\left(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_{t}\\right) A\\left(\\hat{\\boldsymbol{x}}, \\boldsymbol{x}_{t}\\right), \\tag{11.108}\n\\end{equation*}\n$$\n\n该修正的马尔可夫链可以达到平稳状态，且平稳分布为 $p(\\boldsymbol{x})$ ．\n\n证明．根据马尔可夫链的细致平稳条件，有\n\n$$\n\\begin{align*}\np\\left(\\boldsymbol{x}_{t}\\right) q^{\\prime}\\left(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_{t}\\right) & =p\\left(\\boldsymbol{x}_{t}\\right) q\\left(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_{t}\\right) A\\left(\\hat{\\boldsymbol{x}}, \\boldsymbol{x}_{t}\\right)  \\tag{11.109}\\\\\n& =p\\left(\\boldsymbol{x}_{t}\\right) q\\left(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_{t}\\right) \\min \\left(1, \\frac{p(\\hat{\\boldsymbol{x}}) q\\left(\\boldsymbol{x}_{t} \\mid \\hat{\\boldsymbol{x}}\\right)}{p\\left(\\boldsymbol{x}_{t}\\right) q\\left(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_{t}\\right)}\\right)  \\tag{11.110}\\\\\n& =\\min \\left(p\\left(\\boldsymbol{x}_{t}\\right) q\\left(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_{t}\\right), p(\\hat{\\boldsymbol{x}}) q\\left(\\boldsymbol{x}_{t} \\mid \\hat{\\boldsymbol{x}}\\right)\\right)  \\tag{11.111}\\\\\n& =p(\\hat{\\boldsymbol{x}}) q\\left(\\boldsymbol{x}_{t} \\mid \\hat{\\boldsymbol{x}}\\right) \\min \\left(\\frac{p\\left(\\boldsymbol{x}_{t}\\right) q\\left(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_{t}\\right)}{p(\\hat{\\boldsymbol{x}}) q\\left(\\boldsymbol{x}_{t} \\mid \\hat{\\boldsymbol{x}}\\right)}, 1\\right)  \\tag{11.112}\\\\\n& =p(\\hat{\\boldsymbol{x}}) q\\left(\\boldsymbol{x}_{t} \\mid \\hat{\\boldsymbol{x}}\\right) A\\left(\\boldsymbol{x}_{t}, \\hat{\\boldsymbol{x}}\\right)  \\tag{11.113}\\\\\n& =p(\\hat{\\boldsymbol{x}}) q^{\\prime}\\left(\\boldsymbol{x}_{t} \\mid \\hat{\\boldsymbol{x}}\\right) \\tag{11.114}\n\\end{align*}\n$$\n\n因此，$p(\\boldsymbol{x})$ 是状态转移概率为 $q^{\\prime}\\left(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_{t}\\right)$ 的马尔可夫链的平稳分布．",
        "总结": "- Metropolis-Hastings算法是一种广泛应用的MCMC方法，用于从目标分布$p(\\boldsymbol{x})$中进行采样。  \n- 算法通过引入拒绝采样机制，修正提议分布$q(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime})$，使得最终采样的分布为$p(\\boldsymbol{x})$。  \n- 接受概率$A(\\hat{\\boldsymbol{x}}, \\boldsymbol{x}_t)$定义为$\\min\\left(1, \\frac{p(\\hat{\\boldsymbol{x}}) q(\\boldsymbol{x}_t \\mid \\hat{\\boldsymbol{x}})}{p(\\boldsymbol{x}_t) q(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_t)}\\right)$，用于决定是否接受新样本$\\hat{\\boldsymbol{x}}$。  \n- 算法流程包括预热过程和采样过程，预热阶段用于调整链的收敛，采样阶段每隔$M$次生成一个样本。  \n- 修正后的状态转移概率为$q'(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_t) = q(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_t) A(\\hat{\\boldsymbol{x}}, \\boldsymbol{x}_t)$，该转移概率使得马尔可夫链达到平稳分布$p(\\boldsymbol{x})$。  \n- 通过细致平稳条件的证明，验证了修正后的马尔可夫链的平稳分布为$p(\\boldsymbol{x})$。"
      },
      {
        "段落": "### 11．5．4．2 Metropolis算法\n\n如果 MH 算法中的提议分布是对称的，即 $q\\left(\\hat{\\boldsymbol{x}} \\mid \\boldsymbol{x}_{t}\\right)=q\\left(\\boldsymbol{x}_{t} \\mid \\hat{\\boldsymbol{x}}\\right)$ ，第 $t+1$ 次采样的接受率可以简化为\n\n$$\n\\begin{equation*}\nA\\left(\\hat{\\boldsymbol{x}}, \\boldsymbol{x}_{t}\\right)=\\min \\left(1, \\frac{p(\\hat{\\boldsymbol{x}})}{p\\left(\\boldsymbol{x}_{t}\\right)}\\right) . \\tag{11.115}\n\\end{equation*}\n$$\n\n这种MCMC方法称为Metropolis算法．",
        "总结": "- Metropolis算法是MH算法的一种特殊情况，当提议分布对称时使用。\n- 接受率公式简化为 $A(\\hat{\\boldsymbol{x}}, \\boldsymbol{x}_{t}) = \\min(1, \\frac{p(\\hat{\\boldsymbol{x}})}{p(\\boldsymbol{x}_{t})})$。\n- 该算法通过比较当前状态与候选状态的概率密度来决定是否接受候选状态。"
      },
      {
        "段落": "### 11．5．4．3 吉布斯采样\n\n吉布斯采样（Gibbs Sampling）是一种有效地对高维空间中的分布进行采样的MCMC方法，可以看作是Metropolis－Hastings算法的特例。吉布斯采样使用全条件概率（Full Conditional Probability）作为提议分布来依次对每个维度进行采样，并设置接受率为 $A=1$ ．\n\n对于一个 $M$ 维的随机向量 $\\boldsymbol{X}=\\left[X_{1}, X_{2}, \\cdots, X_{M}\\right]^{\\top}$ ，其第 $m$ 个变量 $X_{m}$ 的全条件概率为\n\n$$\n\\begin{align*}\np\\left(x_{m} \\mid \\boldsymbol{x}_{\\backslash m}\\right) & \\triangleq P\\left(X_{m}=x_{m} \\mid X_{\\backslash m}=\\boldsymbol{x}_{\\backslash m}\\right)  \\tag{11.116}\\\\\n& =p\\left(x_{m} \\mid x_{1}, x_{2}, \\cdots, x_{m-1}, x_{m+1}, \\cdots, x_{M}\\right) \\tag{11.117}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{x}_{\\backslash m}=\\left[x_{1}, x_{2}, \\cdots, x_{m-1}, x_{m+1}, \\cdots, x_{M}\\right]^{\\top}$ 表示除 $X_{m}$ 外其他变量的取值．\n吉布斯采样可以按照任意的顺序根据全条件分布依次对每个变量进行采样。假设从一个随机的初始化状态 $\\boldsymbol{x}^{(0)}=\\left[x_{1}^{(0)}, x_{2}^{(0)}, \\cdots, x_{M}^{(0)}\\right]^{\\top}$ 开始，按照下标顺序依次对 $M$ 个变量进行采样。\n\n$$\n\\begin{equation*}\nx_{1}^{(1)} \\sim p\\left(x_{1} \\mid x_{2}^{(0)}, x_{3}^{(0)}, \\cdots, x_{M}^{(0)}\\right) \\tag{11.118}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n细致平稳条件参见定理 D．1．\n\n$$\n\\begin{align*}\nx_{2}^{(1)} & \\sim p\\left(x_{2} \\mid x_{1}^{(1)}, x_{3}^{(0)} \\cdots, x_{M}^{(0)}\\right)  \\tag{11.119}\\\\\n\\quad \\vdots &  \\tag{11.120}\\\\\nx_{M}^{(1)} & \\sim p\\left(x_{M} \\mid x_{1}^{(1)}, x_{2}^{(1)} \\cdots, x_{M-1}^{(1)}\\right)  \\tag{11.121}\\\\\n\\quad \\vdots &  \\tag{11.122}\\\\\nx_{1}^{(t)} & \\sim p\\left(x_{1} \\mid x_{2}^{(t-1)}, x_{3}^{(t-1)}, \\cdots, x_{M}^{(t-1)}\\right)  \\tag{11.123}\\\\\nx_{2}^{(t)} & \\sim p\\left(x_{2} \\mid x_{1}^{(t)}, x_{3}^{(t-1)} \\cdots, x_{M}^{(t-1)}\\right) \\\\\n\\quad \\vdots & \\\\\nx_{M}^{(t)} & \\sim p\\left(x_{M} \\mid x_{1}^{(t)}, x_{2}^{(t)} \\cdots, x_{M-1}^{(t)}\\right)\n\\end{align*}\n$$\n\n其中 $x_{m}^{(t)}$ 是第 $t$ 次迭代时变量 $X_{m}$ 的采样．\n吉布斯采样的每单步采样也构成一个马尔可夫链。假设每个单步（采样维度为第 $i$ 维）的状态转移概率 $q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime}\\right)$ 为\n\n$$\nq\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime}\\right)=\\left\\{\\begin{array}{cl}\n\\frac{p(\\boldsymbol{x})}{p\\left(\\boldsymbol{x}_{\\backslash m}^{\\prime}\\right)} & \\text { if } \\quad \\boldsymbol{x}_{\\backslash m}=\\boldsymbol{x}_{\\backslash m}^{\\prime}  \\tag{11.124}\\\\\n0 & \\text { otherwise }\n\\end{array}\\right.\n$$\n\n其中边际分布 $p\\left(\\boldsymbol{x}_{\\backslash m}^{\\prime}\\right)=\\sum_{x_{m}^{\\prime}} p\\left(\\boldsymbol{x}^{\\prime}\\right)$ ，等式 $\\boldsymbol{x}_{\\backslash m}=\\boldsymbol{x}_{\\backslash m}^{\\prime}$ 表示 $x_{k}=x_{k}^{\\prime}, \\forall k \\neq m$ ，因此有 $p\\left(\\boldsymbol{x}_{\\backslash m}^{\\prime}\\right)=p\\left(\\boldsymbol{x}_{\\backslash m}\\right)$ ，并可以得到\n\n$$\n\\begin{equation*}\np\\left(\\boldsymbol{x}^{\\prime}\\right) q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime}\\right)=p\\left(\\boldsymbol{x}^{\\prime}\\right) \\frac{p(\\boldsymbol{x})}{p\\left(\\boldsymbol{x}_{\\backslash i}^{\\prime}\\right)}=p(\\boldsymbol{x}) \\frac{p\\left(\\boldsymbol{x}^{\\prime}\\right)}{p\\left(\\boldsymbol{x}_{\\backslash i}\\right)}=p(\\boldsymbol{x}) q\\left(\\boldsymbol{x}^{\\prime} \\mid \\boldsymbol{x}\\right) \\tag{11.125}\n\\end{equation*}\n$$\n\n根据细致平稳条件，公式（11．124）中定义的状态转移概率 $q\\left(\\boldsymbol{x} \\mid \\boldsymbol{x}^{\\prime}\\right)$ 的马尔可夫链的平稳分布为 $p(\\boldsymbol{x})$ 。随着迭代次数 $t$ 的增加，样本 $\\boldsymbol{x}^{(t)}=\\left[x_{1}^{(t)}, x_{2}^{(t)} \\cdots, x_{M}^{(t)}\\right]^{\\top}$将收玫于概率分布 $p(\\boldsymbol{x})$ 。",
        "总结": "- 吉布斯采样是一种MCMC方法，用于在高维空间中进行分布采样，是Metropolis-Hastings算法的特例。\n- 吉布斯采样通过依次对每个维度进行采样，使用全条件概率作为提议分布，并设置接受率为1。\n- 全条件概率定义为在给定其他变量取值的情况下，某个变量的条件分布。\n- 吉布斯采样可以按任意顺序对每个变量进行采样，初始状态为随机初始化的向量。\n- 每次迭代中，依次根据当前已知的其他变量值从全条件分布中生成新值。\n- 吉布斯采样的每一步构成一个马尔可夫链，其状态转移概率由全条件分布定义。\n- 状态转移概率满足细致平稳条件，使得该马尔可夫链的平稳分布为目标分布 $p(\\boldsymbol{x})$。\n- 随着迭代次数增加，采样结果将收敛于目标分布 $p(\\boldsymbol{x})$。"
      },
      {
        "段落": "## 11.6 总结和深入阅读\n\n概率图模型提供了一个用图形来描述概率模型的框架，这种可视化方法使我们可以更加容易地理解复杂模型的内在性质。目前，概率图模型已经是一个非常庞大的研究领域，涉及众多的模型和算法．很多机器学习模型也都可以用概率图模型来描述．图11．16给出了概率图模型所涵盖的内容．\n\n在本章中，我们只介绍了部分内容．要更全面深入地了解概率图模型，可以阅读《Probabilistic Graphical Models：Principles and Techniques 》［Koller et al．， 2009］，《Probabilistic Reasoning in Intelligent Systems：Networks of Plausible Inference 》［Pearl，2014］，或机器学习书籍中的相关章节［Bishop，2007］．\n\n概率图模型中最基本的假设是条件独立性。图形化表示直观地描述了随机变量之间的条件独立性，有利于将复杂的概率模型分解为简单模型的组合，并更好地理解概率模型的表示、推断、学习等方法．\nhttps：／／nndl．github．io／\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-296.jpg?height=417&width=1154&top_left_y=114&top_left_x=81)\n\n图 11.16 概率图模型所涵盖内容的简单概括\n\n20世纪90年代末，概率图模型的研究逐步成熟．到 21 世纪，图模型在机器学习、计算机视觉、自然语言处理等领域开始不断发展壮大。其中比较有代表性的模型有：条件随机场［Lafferty et al．，2001］、潜在狄利克雷分配（Latent Dirichlet Allocation）［Blei et al．，2003］等．此外，图模型的结构学习也一直是非常重要但极具挑战性的研究方向．\n\n图模型与神经网络的关系 图模型和神经网络有着类似的网络结构，但两者也有很大的不同。图模型的节点是随机变量，其图结构的主要功能是用来描述变量之间的依赖关系，一般是稀疏连接。使用图模型的好处是可以有效进行统计推断。而神经网络中的节点是神经元，是一个计算节点。图模型中的每个变量一般有着明确的解释，变量之间依赖关系一般是人工来定义。而神经网络中的单个神经元则没有直观的解释。如果将神经网络中每个神经元看作是一个二值随机变量，那神经网络就变成一个Sigmoid 信念网络。\n\n神经网络是判别模型，直接用来分类．而图模型不但可以是判别模型，也可以是生成模型。生成模型不但可以用来生成样本，也可以通过贝叶斯公式用来做分类。图模型的参数学习的目标函数为似然函数或条件似然函数，若包含隐变量则通常通过 EM 算法来求解。而神经网络参数学习的目标函数为交叉嫡或平方误差等损失函数．\n\n目前，神经网络和概率图模型的结合越来越紧密。一方面我们可以利用神经网络强大的表示能力和拟合能力来建模图模型中的推断问题（比如变分自编码器，第13．2节），生成问题（比如生成对抗网络，第13．3节），或势能函数（比如 LSTM＋CRF 模型［Lample et al．，2016；Ma et al．，2016］）；另一方面可以利用图模型的算法来解决复杂结构神经网络中的学习和推断问题，比如图神经网络（ Graph Neural Network ）［Gilmer et al．，2017；Li et al．，2015；Scarselli et al．， 2009］和结构化注意力［Kim et al．，2017］．",
        "总结": "- 概率图模型提供了一种用图形描述概率模型的框架，便于理解复杂模型的内在性质。  \n- 本章介绍了概率图模型的部分内容，建议参考《Probabilistic Graphical Models：Principles and Techniques》等书籍以获得更深入的理解。  \n- 概率图模型的基本假设是条件独立性，图形化表示有助于分解复杂模型并理解其表示、推断和学习方法。  \n- 图模型在20世纪90年代末逐步成熟，21世纪在机器学习、计算机视觉、自然语言处理等领域广泛应用。  \n- 代表性模型包括条件随机场、潜在狄利克雷分配等，结构学习是重要但具有挑战性的研究方向。  \n- 图模型与神经网络有相似的网络结构，但图模型节点是随机变量，用于描述变量依赖关系；神经网络节点是计算单元，通常无直观解释。  \n- 神经网络是判别模型，用于分类；图模型可以是判别或生成模型，生成模型可用于样本生成和分类。  \n- 图模型参数学习通常使用似然函数或EM算法，而神经网络使用交叉熵或平方误差等损失函数。  \n- 神经网络与概率图模型结合紧密，可用于建模推断、生成问题或势能函数；图模型算法也可用于解决复杂结构神经网络的学习和推断问题。"
      },
      {
        "段落": "## 习题\n\n习题11－1 根据贝叶斯网络的定义，证明图11．3中的四种因果关系．\n\n习题11－2 证明公式（11．9）。\n习题11－3 根据公式（11．37），推导线性链条件随机场（参见公式（11．25））的参数更新公式。\n\n习题11－4 证明仅当 $q(\\boldsymbol{z})=p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ 时，对数边际似然函数 $\\log p(\\boldsymbol{x} ; \\theta)$ 和其下界 $\\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta)$ 相等。\n\n习题11－5 在高斯混合分布的参数估计中，证明 M 步中的参数更新公式，即公式（11．63）、公式（11．64）和公式（11．65）。\n\n习题11－6 考虑一个伯努利混合分布，即\n\n$$\n\\begin{equation*}\np(x ; \\mu, \\pi)=\\sum_{k=1}^{K} \\pi_{k} p\\left(x ; \\mu_{k}\\right), \\tag{11.126}\n\\end{equation*}\n$$\n\n其中 $p\\left(x ; \\mu_{k}\\right)=\\mu_{k}^{x}\\left(1-\\mu_{k}\\right)^{(1-x)}$ 为伯努利分布。\n给定一组训练集合 $D=\\left\\{x^{(1)}, x^{(2)}, \\cdots, x^{(N)}\\right\\}$ ，若用 EM 算法来进行参数估计时，推导其每步的参数更新公式．\n\n习题11－7 在变分推断的目标公式（11．82）中，分析为什么使用的 KL 散度是 $\\operatorname{KL}(q(\\boldsymbol{z}) \\| p(\\boldsymbol{z} \\mid \\boldsymbol{x}))$ 而不是 $\\operatorname{KL}(p(\\boldsymbol{z} \\mid \\boldsymbol{x}) \\| q(\\boldsymbol{z}))$ ？\n\n习题11－8 在图11．2a的有向图，分析按不同的消除顺序计算边际概率 $p\\left(x_{3}\\right)$时的计算复杂度．\n\n习题11－9 在树结构的图模型上应用信念传播算法时，推导其消息计算公式．\n习题11－10证明若分布 $p(x)$ 存在累积分布函数的逆函数 $\\mathrm{cdf}^{-1}(y), y \\in[0,1]$ ，且随机变量 $\\xi$ 为 $[0,1]$ 区间上的均匀分布，则 $\\mathrm{cdf}^{-1}(\\xi)$ 服从分布 $p(x)$ ．",
        "总结": "- 概念：贝叶斯网络的四种因果关系  \n- 概念：对数边际似然函数与ELBO下界  \n- 概念：线性链条件随机场的参数更新公式  \n- 概念：高斯混合分布的M步参数更新公式  \n- 概念：伯努利混合分布的EM算法参数更新公式  \n- 概念：变分推断中KL散度的选择原因  \n- 概念：有向图中计算边际概率的复杂度分析  \n- 概念：信念传播算法在树结构图模型上的消息计算公式  \n- 概念：累积分布函数逆变换生成随机变量的性质"
      },
      {
        "段落": "## 参考文献\n\nBaum L E，Petrie T．Statistical inference for probabilistic functions of finite state markov chains［J］． The annals of mathematical statistics，1966，37（6）：1554－1563．\nBerger A L，Pietra V J D，Pietra S A D．A maximum entropy approach to natural language processing ［J］．Computational linguistics，1996，22（1）：39－71．\nBishop C M．Pattern recognition and machine learning［M］．5th edition．Springer， 2007.\nBlei D M，Ng A Y，Jordan M I．Latent dirichlet allocation［J］．Journal of machine Learning research， 2003，3（Jan）：993－1022．\n\n参见公式（11．9）．\n\n伯努利混合分布参见第 D．2．1．1 节。\n\n参见第11．5．1节。\n\nDella Pietra S，Della Pietra V，Lafferty J．Inducing features of random fields［J］．IEEE transactions on pattern analysis and machine intelligence，1997，19（4）：380－393．\nGilmer J，Schoenholz S S，Riley P F，et al．Neural message passing for quantum chemistry［J］．arXiv preprint arXiv：1704．01212， 2017.\nKim Y，Denton C，Hoang L，et al．Structured attention networks［C］／／Proceedings of 5th Interna－ tional Conference on Learning Representations． 2017.\nKoller D，Friedman N．Probabilistic graphical models：principles and techniques［M］．MIT press， 2009.\n\nLafferty J D，McCallum A，Pereira F C N．Conditional random fields：Probabilistic models for seg－ menting and labeling sequence data［C］／／Proceedings of the Eighteenth International Conference on Machine Learning． 2001.\nLample G，Ballesteros M，Subramanian S，et al．Neural architectures for named entity recognition ［J］．arXiv preprint arXiv：1603．01360， 2016.\nLauritzen S L，Spiegelhalter D J．Local computations with probabilities on graphical structures and their application to expert systems［J］．Journal of the Royal Statistical Society．Series B（Method－ ological），1988：157－224．\nLi Y，Tarlow D，Brockschmidt M，et al．Gated graph sequence neural networks［J］．arXiv preprint arXiv：1511．05493， 2015.\nMa X，Hovy E．End－to－end sequence labeling via bi－directional lstm－cnns－crf［J］．arXiv preprint arXiv：1603．01354， 2016.\nNeal R M．Connectionist learning of belief networks［J］．Artificial intelligence，1992，56（1）：71－113．\nPearl J．Probabilistic reasoning in intelligent systems：networks of plausible inference［M］．Elsevier， 2014.\n\nScarselli F，Gori M，Tsoi A C，et al．The graph neural network model［J］．IEEE Transactions on Neural Networks，2009，20（1）：61－80．",
        "总结": "- 参考文献列出了多个相关研究文献，涵盖概率图模型、自然语言处理、深度学习等领域。  \n- 公式（11.9）被提及，可能涉及某种数学表达式或模型定义。  \n- 伯努利混合分布相关内容见第 D.2.1.1 节，可能涉及概率分布模型。  \n- 第11.5.1节被引用，可能涉及某种算法或理论推导。  \n- 提到的文献包括关于随机字段、图神经网络、注意力机制等领域的研究。"
      }
    ]
  },
  {
    "标题": "第12章 深度信念网络",
    "内容": [
      {
        "段落": "# 第12章 深度信念网络 \n\n计算的目的不在于数据，而在于洞察事物．\n一理查德•卫斯里•汉明（Richard Wesley Hamming）\n1968年图灵奖获得者\n\n对于一个复杂的数据分布，我们往往只能观测到有限的局部特征，并且这些特征通常会包含一定的噪声。如果要对这个数据分布进行建模，就需要挖掘出可观测变量之间复杂的依赖关系，以及可观测变量背后隐藏的内部表示。\n\n本章介绍一种可以有效学习变量之间复杂依赖关系的概率图模型（深度信念网络）以及两种相关的基础模型（玻尔兹曼机和受限玻尔兹曼机）。深度信念网络中包含很多层的隐变量，可以有效地学习数据的内部特征表示，也可以作为一种有效的非线性降维方法．这些学习到的内部特征表示包含了数据的更高级的、有价值的信息，因此十分有助于后续的分类和回归等任务。\n\n玻尔兹曼机和深度信念网络都是生成模型，借助隐变量来描述复杂的数据分布。作为概率图模型，玻尔兹曼机和深度信念网络的共同问题是推断和学习问题。因为这两种模型都比较复杂，并且都包含隐变量，它们的推断和学习一般通过 MCMC 方法来进行近似估计。这两种模型和神经网络有很强的对应关系，在一定程度上也称为随机神经网络（Stochastic Neural Network，SNN）。",
        "总结": "- 概念：深度信念网络是一种概率图模型，用于学习变量之间的复杂依赖关系和数据的内部特征表示。  \n- 概念：玻尔兹曼机和受限玻尔兹曼机是深度信念网络相关的基础模型，属于生成模型。  \n- 概念：生成模型通过隐变量描述复杂的数据分布，用于建模数据的潜在结构。  \n- 算法：深度信念网络通过多层隐变量学习数据的内部特征表示，可作为非线性降维方法。  \n- 方法：推断和学习问题通常通过MCMC方法进行近似估计。  \n- 关系：玻尔兹曼机和深度信念网络与神经网络有强对应关系，被称为随机神经网络（SNN）。"
      },
      {
        "段落": "## 12.1 玻尔兹曼机\n\n玻尔兹曼机（Boltzmann Machine）可以看作是一个随机动力系统（Sto－ chastic Dynamical System），每个变量的状态都以一定的概率受到其他变量的影响。玻尔兹曼机可以用概率无向图模型来描述。一个具有 $K$ 个节点（变量）的玻尔兹曼机满足以下三个性质：\n\n动力系统是数学上的一个概念，用一个函数来描述一个空间中所有点随时间的变化情况，比如钟摆晃动、水的流动等．\n（1）每个随机变量是二值的，所有随机变量可以用一个二值的随机向量 $\\boldsymbol{X} \\in$ $\\{0,1\\}^{K}$ 来表示，其中可观测变量表示为 $\\boldsymbol{V}$ ，隐变量表示为 $\\boldsymbol{H}$ 。\n（2）所有节点之间是全连接的。每个变量 $X_{i}$ 的取值依赖于所有其他变量 $\\boldsymbol{X}_{\\backslash i}$ 。\n（3）每两个变量之间的互相影响 $\\left(X_{i} \\rightarrow X_{j}\\right.$ 和 $\\left.X_{j} \\rightarrow X_{i}\\right)$ 是对称的。\n图12．1给出了一个包含 3 个可观测变量和 3 个隐变量的玻尔兹曼机．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-300.jpg?height=431&width=486&top_left_y=337&top_left_x=406)\n\n图 12.1 一个有六个变量的玻尔兹曼机\n\n随机向量 $\\boldsymbol{X}$ 的联合概率由玻尔兹曼分布得到，即\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x})=\\frac{1}{Z} \\exp \\left(\\frac{-E(\\boldsymbol{x})}{T}\\right), \\tag{12.1}\n\\end{equation*}\n$$\n\n其中 $Z$ 为配分函数，$T$ 表示温度，能量函数 $E(\\boldsymbol{x})$ 的定义为\n\n$$\n\\begin{align*}\nE(\\boldsymbol{x}) & \\triangleq E(\\boldsymbol{X}=\\boldsymbol{x}) \\\\\n& =-\\left(\\sum_{i<j} w_{i j} x_{i} x_{j}+\\sum_{i} b_{i} x_{i}\\right) \\tag{12.2}\n\\end{align*}\n$$\n\n其中 $w_{i j}$ 是两个变量 $x_{i}$ 和 $x_{j}$ 之间的连接权重，$x_{i} \\in\\{0,1\\}$ 表示状态，$b_{i}$ 是变量 $x_{i}$ 的偏置．\n\n如果两个变量 $X_{i}$ 和 $X_{j}$ 的取值都为 1 时，一个正的权重 $w_{i j}>0$ 会使得玻尔兹曼机的能量下降，发生的概率变大；相反，一个负的权重会使得玻尔兹曼机的能量上升，发生的概率变小。因此，如果令玻尔兹曼机中的每个变量 $X_{i}$ 代表一个基本假设，其取值为 1 或 0 分别表示模型接受或拒绝该假设，那么变量之间连接的权重代表了两个假设之间的弱约束关系［Ackley et al．，1985］．连接权重为可正可负的实数。一个正的连接权重表示两个假设可以互相支持。也就是说，如果一个假设被接受，另一个也很可能被接受．相反，一个负的连接权重表示两个假设不能同时被接受．\n\n玻尔兹曼机可以用来解决两类问题．一类是搜索问题：当给定变量之间的连接权重时，需要找到一组二值向量，使得整个网络的能量最低．另一类是学习问题：当给定变量的多组观测值时，学习网络的最优权重．\nhttps：／／nndl．github．io／\n\n这也是玻尔兹曼机名称的由来．为简单起见，这里我们把玻尔兹曼常数 $k$ 吸收到温度 $T$中。\n\n路德维希－玻尔兹曼（Ludwig Boltz－ mann（1844～1906），奥地利物理学家、哲学家．主要贡献为分子动力学．玻尔兹曼分布取自奥地利物理学家路德维希•玻尔兹曼 （Ludwig Boltzmann），他在1868年研究热平衡气体的统计力学时首次提出了这一分布．",
        "总结": "- 玻尔兹曼机是一种随机动力系统，用概率无向图模型描述，具有全连接的二值随机变量结构。  \n- 每个变量的状态以一定概率受其他变量影响，变量间相互影响是对称的。  \n- 随机向量的联合概率由玻尔兹曼分布给出，其形式为 $ p(\\boldsymbol{x}) = \\frac{1}{Z} \\exp(-E(\\boldsymbol{x})/T) $。  \n- 能量函数 $ E(\\boldsymbol{x}) $ 定义为 $ -\\left( \\sum_{i<j} w_{ij}x_ix_j + \\sum_i b_ix_i \\right) $，其中 $ w_{ij} $ 为连接权重，$ b_i $ 为偏置。  \n- 正权重表示变量间正相关，负权重表示负相关，反映假设间的弱约束关系。  \n- 玻尔兹曼机用于解决能量最小化和权重学习两类问题。  \n- 玻尔兹曼分布来源于路德维希·玻尔兹曼在统计力学中的研究，温度 $ T $ 吸收了玻尔兹曼常数 $ k $。"
      },
      {
        "段落": "## 数学小知识 I 玻尔兹曼分布\n\n在统计力学中，玻尔兹曼分布（Boltzmann Distribution）是描述粒子处于特定状态下的概率，是关于状态能量与系统温度的函数。一个粒子处于状态 $\\alpha$ 的概率 $p_{\\alpha}$ 是关于状态能量与系统温度的函数，\n\n$$\n\\begin{equation*}\np_{\\alpha}=\\frac{1}{Z} \\exp \\left(\\frac{-E_{\\alpha}}{k T}\\right), \\tag{12.3}\n\\end{equation*}\n$$\n\n其中 $E_{\\alpha}$ 为状态 $\\alpha$ 的能量，$k$ 为玻尔兹曼常量，$T$ 为系统温度， $\\exp \\left(\\frac{-E_{\\alpha}}{k T}\\right)$ 称为玻尔兹曼因子（Boltzmann Factor），是没有归一化的概率。 $Z$ 为归一化因子，通常称为配分函数（Partition Function），是对系统所有状态进行总和，\n\n$$\n\\begin{equation*}\nZ=\\sum_{\\alpha} \\exp \\left(\\frac{-E_{\\alpha}}{k T}\\right) . \\tag{12.4}\n\\end{equation*}\n$$\n\n玻尔兹曼分布的一个性质是两个状态的概率比仅仅依赖于两个状态能量的差值。\n\n$$\n\\begin{equation*}\n\\frac{p_{\\alpha}}{p_{\\beta}}=\\exp \\left(\\frac{E_{\\beta}-E_{\\alpha}}{k T}\\right) . \\tag{12.5}\n\\end{equation*}\n$$",
        "总结": "- 玻尔兹曼分布是统计力学中描述粒子处于特定状态概率的分布，其概率与状态能量和系统温度有关。  \n- 玻尔兹曼分布的概率公式为 $p_{\\alpha} = \\frac{1}{Z} \\exp \\left( \\frac{-E_{\\alpha}}{k T} \\right)$，其中 $E_{\\alpha}$ 为状态能量，$k$ 为玻尔兹曼常量，$T$ 为温度，$Z$ 为配分函数。  \n- 配分函数 $Z$ 是所有状态的玻尔兹曼因子之和，即 $Z = \\sum_{\\alpha} \\exp \\left( \\frac{-E_{\\alpha}}{k T} \\right)$。  \n- 玻尔兹曼分布的一个性质是两个状态的概率比仅取决于它们的能量差，公式为 $\\frac{p_{\\alpha}}{p_{\\beta}} = \\exp \\left( \\frac{E_{\\beta} - E_{\\alpha}}{k T} \\right)$。"
      },
      {
        "段落": "## 12．1．1 生成模型\n\n在玻尔兹曼机中，配分函数 $Z$ 通常难以计算，因此，联合概率分布 $p(\\boldsymbol{x})$ 一般通过 MCMC 方法来近似，生成一组服从 $p(\\boldsymbol{x})$ 分布的样本。本节介绍基于吉布斯采样的样本生成方法。\n\n吉布斯采样参见第 11．5．4．3节．\n\n全条件概率 吉布斯采样需要计算每个变量 $X_{i}$ 的全条件概率 $p\\left(x_{i} \\mid \\boldsymbol{x}_{\\backslash i}\\right)$ ，其中 $\\boldsymbol{x}_{\\backslash i}$表示除变量 $X_{i}$ 外其他变量的取值。\n\n定理 12.1 －玻尔兹曼机中变量的全条件概率：对于玻尔兹曼机中的一个变量 $X_{i}$ ，当给定其他变量 $\\boldsymbol{x}_{\\backslash i}$ 时，全条件概率 $p\\left(x_{i} \\mid \\boldsymbol{x}_{\\backslash i}\\right)$ 为\n\n$$\n\\begin{align*}\n& p\\left(x_{i}=1 \\mid \\boldsymbol{x}_{\\backslash i}\\right)=\\sigma\\left(\\frac{\\sum_{j} w_{i j} x_{j}+b_{i}}{T}\\right),  \\tag{12.6}\\\\\n& p\\left(x_{i}=0 \\mid \\boldsymbol{x}_{\\backslash i}\\right)=1-p\\left(x_{i}=1 \\mid \\boldsymbol{x}_{\\backslash i}\\right), \\tag{12.7}\n\\end{align*}\n$$\n\n其中 $\\sigma(\\cdot)$ 为 Logistic 函数。\n\n证明．首先，保持其他变量 $\\boldsymbol{x}_{\\backslash i}$ 不变，改变变量 $X_{i}$ 的状态，从 0 （关闭）和 1 （打开）之间的能量差异（Energy Gap）为\n\n$$\n\\begin{align*}\n\\Delta E_{i}\\left(\\boldsymbol{x}_{\\backslash i}\\right) & =E\\left(x_{i}=0, \\boldsymbol{x}_{\\backslash i}\\right)-E\\left(x_{i}=1, \\boldsymbol{x}_{\\backslash i}\\right)  \\tag{12.8}\\\\\n& =\\sum_{j} w_{i j} x_{j}+b_{i} \\tag{12.9}\n\\end{align*}\n$$\n\n其中 $w_{i i}=0, \\forall i$ ．\n又根据玻尔兹曼机的定义可得\n\n$$\n\\begin{equation*}\nE(\\boldsymbol{x})=-T \\log p(\\boldsymbol{x})-T \\log Z \\tag{12.10}\n\\end{equation*}\n$$\n\n因此有\n\n$$\n\\begin{align*}\n\\Delta E_{i}\\left(\\boldsymbol{x}_{\\backslash i}\\right) & =-T \\log p\\left(x_{i}=0, \\boldsymbol{x}_{\\backslash i}\\right)-\\left(-T \\log p\\left(x_{i}=1, \\boldsymbol{x}_{\\backslash i}\\right)\\right)  \\tag{12.11}\\\\\n& =T \\log \\frac{p\\left(x_{i}=1, \\boldsymbol{x}_{\\backslash i}\\right)}{p\\left(x_{i}=0, \\boldsymbol{x}_{\\backslash i}\\right)}  \\tag{12.12}\\\\\n& =T \\log \\frac{p\\left(x_{i}=1, \\mid \\boldsymbol{x}_{\\backslash i}\\right)}{1-p\\left(x_{i}=1 \\mid \\boldsymbol{x}_{\\backslash i}\\right)} \\tag{12.13}\n\\end{align*}\n$$\n\n结合公式（12．9）和公式（12．13），得到\n\n$$\n\\begin{align*}\np\\left(x_{i}=1 \\mid \\boldsymbol{x}_{\\backslash i}\\right) & =\\frac{1}{1+\\exp \\left(-\\frac{\\Delta E_{i}\\left(\\boldsymbol{x}_{\\backslash i}\\right)}{T}\\right)}  \\tag{12.14}\\\\\n& =\\sigma\\left(\\frac{\\sum_{j} w_{i j} x_{j}+b_{i}}{T}\\right) \\tag{12.15}\n\\end{align*}\n$$\n\n吉布斯采样 玻尔兹曼机的吉布斯采样过程为：随机选择一个变量 $X_{i}$ ，然后根据其全条件概率 $p\\left(x_{i} \\mid \\boldsymbol{x}_{\\backslash i}\\right)$ 来设置其状态，即以 $p\\left(x_{i}=1 \\mid \\boldsymbol{x}_{\\backslash i}\\right)$ 的概率将变量 $X_{i}$ 设为 1 ，否则为 0 。在固定温度 $T$ 的情况下，在运行足够时间之后，玻尔兹曼机会达到热平衡。此时，任何全局状态的概率服从玻尔兹曼分布 $p(\\boldsymbol{x})$ ，只与系统的能量有关，与初始状态无关。\n\n要使得玻尔兹曼机达到热平衡，其收玫速度和温度 $T$ 相关。当系统温度非常高 $T \\rightarrow \\infty$ 时，$p\\left(x_{i}=1 \\mid \\boldsymbol{x}_{\\backslash i}\\right) \\rightarrow 0.5$ ，即每个变量状态的改变十分容易，每一种系统状态都是一样的，从而很快可以达到热平衡。当系统温度非常低 $T \\rightarrow 0$ 时，如果 $\\Delta E_{i}\\left(\\boldsymbol{x}_{\\backslash i}\\right)>0$ ，则 $p\\left(x_{i}=1 \\mid \\boldsymbol{x}_{\\backslash i}\\right) \\rightarrow 1$ ；如果 $\\Delta E_{i}\\left(\\boldsymbol{x}_{\\backslash i}\\right)<0$ ，则 $p\\left(x_{i}=1 \\mid \\boldsymbol{x}_{\\backslash i}\\right) \\rightarrow 0$ ，即\n\n$$\nx_{i}= \\begin{cases}1 & \\text { if } \\sum_{j} w_{i j} x_{j}+b_{i} \\geq 0  \\tag{12.16}\\\\ 0 & \\text { otherwise }\\end{cases}\n$$\n\nhttps：／／nndl．github．io／\n\n当玻尔兹曼机达到热平衡时，并不意味其能量最低。热平衡依然是在所有状态上的一个分布。\n\n因此，当 $T \\rightarrow 0$ 时，随机性方法变成了确定性方法．这时，玻尔兹曼机退化为一个 Hopfield 网络．\n\nHopfield 网络是一种确定性的动力系统，而玻尔兹曼机是一种随机性的动力系统。Hopfield网络的每次状态更新都会使得系统的能量降低，而玻尔兹曼机则以一定的概率使得系统的能量上升。图12．2给出了Hopfield网络和玻尔兹曼机在运行时系统能量变化的对比。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-303.jpg?height=896&width=812&top_left_y=484&top_left_x=265)\n\n图 12．2 Hopfield 网络和玻尔兹曼机在运行时系统能量变化的对比",
        "总结": "- 生成模型：介绍基于吉布斯采样的样本生成方法，用于近似玻尔兹曼机中的联合概率分布 $p(\\boldsymbol{x})$。\n- 全条件概率：吉布斯采样需要计算每个变量 $X_{i}$ 的全条件概率 $p\\left(x_{i} \\mid \\boldsymbol{x}_{\\backslash i}\\right)$，其中 $\\boldsymbol{x}_{\\backslash i}$ 表示其他变量的取值。\n- 定理 12.1：玻尔兹曼机中变量的全条件概率公式，给出 $p\\left(x_{i}=1 \\mid \\boldsymbol{x}_{\\backslash i}\\right)$ 和 $p\\left(x_{i}=0 \\mid \\boldsymbol{x}_{\\backslash i}\\right)$ 的表达式，使用 Logistic 函数。\n- 吉布斯采样过程：随机选择一个变量 $X_{i}$，根据其全条件概率设置状态，最终达到热平衡，系统状态服从玻尔兹曼分布。\n- 温度影响：温度 $T$ 影响收敛速度和系统行为。当 $T \\rightarrow \\infty$ 时，系统快速达到热平衡；当 $T \\rightarrow 0$ 时，系统变为确定性方法，退化为 Hopfield 网络。\n- Hopfield 网络与玻尔兹曼机对比：Hopfield 网络是确定性动力系统，每次更新降低能量；玻尔兹曼机是随机性动力系统，以一定概率改变能量。图示对比两者在运行时的能量变化。"
      },
      {
        "段落": "## 12．1．2 能量最小化与模拟退火\n\n在一个动力系统中，找到一个状态使得系统能量最小是一个十分重要的优化问题。如果这个动力系统是确定性的，比如Hopfield网络，一个简单（但是低效）的能量最小化方法是随机选择一个变量，在其他变量保持不变的情况下，将这个变量设为会导致整个网络能量更低的状态。当每个变量 $X_{i}$ 取值为 $\\{0,1\\}$ 时，如果能量差异 $\\Delta E_{i}\\left(\\boldsymbol{x}_{\\backslash i}\\right)$ 大于 0 ，就设 $X_{i}=1$ ，否则就设 $X_{i}=0$ 。\n\n这种简单、确定性的方法在运行一定时间之后总是可以收敛到一个解．但是这个解是局部最优的，不是全局最优的。为了跳出局部最优，就必须允许＂偶尔＂可以将一个变量设置为使得能量变高的状态。这样，我们就需要引入一定的随机性，我们以 $\\sigma\\left(\\frac{\\Delta E_{i}\\left(\\boldsymbol{x}_{\\backslash i}\\right)}{T}\\right)$ 的概率将变量 $X_{i}$ 设为 1 ，否则设为 0 。这个过程和玻尔兹曼 https：／／nndl．github．io／\n\nHopfield 网 络 参 见 第 8．6．1节．\n\n特别地，离散状态的能量最小化是一个组合优化问题．\n\n机的吉布斯采样过程十分类似。\n要使得动力系统达到热平衡，温度 $T$ 的选择十分关键．一个比较好的折中方法是让系统刚开始在一个比较高的温度下运行达到热平衡，然后逐渐降低，直到系统在一个比较低的温度下运行达到热平衡．这样我们就能够得到一个能量全局最小的分布。这个过程被称为模拟退火（Simulated Annealing）［Kirkpatrick et al．，1983］．\n\n模拟退火是一种寻找全局最优的近似方法，其名字来自冶金学的专有名词 ＂退火＂，即将材料加热后再以一定的速度退火冷却，可以减少晶格中的缺陷。固体中的内部粒子会停留在使内能有局部最小值的位置，加热时能量变大，粒子会变得无序并随机移动。退火冷却时速度较慢，使得粒子在每个温度都达到平衡态。最后在常温时，粒子以很大的概率达到内能比原先更低的位置。可以证明，模拟退火算法所得解依概率收敛到全局最优解。",
        "总结": "- 能量最小化是动力系统中的一个重要优化问题，目标是找到使系统能量最小的状态。  \n- 在确定性系统如Hopfield网络中，通过随机选择变量并调整其状态以降低整体能量，但这种方法只能收敛到局部最优解。  \n- 为跳出局部最优，引入随机性，以概率 $\\sigma\\left(\\frac{\\Delta E_{i}\\left(\\boldsymbol{x}_{\\backslash i}\\right)}{T}\\right)$ 决定变量 $X_{i}$ 的状态，该过程类似于玻尔兹曼机的吉布斯采样。  \n- 温度 $T$ 的选择对系统达到热平衡至关重要，通常采用逐渐降温的模拟退火策略。  \n- 模拟退火是一种寻找全局最优的近似方法，灵感来源于冶金学中的退火过程，通过逐步降温使系统在每个温度下达到平衡态。  \n- 模拟退火算法所得解依概率收敛到全局最优解。  \n- 离散状态的能量最小化是一个组合优化问题。"
      },
      {
        "段落": "## 12．1．3 参数学习\n\n不失一般性，假设一个玻尔兹曼机有 $K$ 个变量，包括 $K_{v}$ 个可观测变量 $\\boldsymbol{v} \\in$ $\\{0,1\\}^{K_{v}}$ 和 $K_{h}$ 个隐变量 $\\boldsymbol{h} \\in\\{0,1\\}^{K_{h}}$ 。\n\n给定一组可观测的向量 $\\mathcal{D}=\\left\\{\\hat{\\boldsymbol{v}}^{(1)}, \\hat{\\boldsymbol{v}}^{(2)}, \\cdots, \\hat{\\boldsymbol{v}}^{(N)}\\right\\}$ 作为训练集，我们要学习玻尔兹曼机的参数 $\\boldsymbol{W}$ 和 $\\boldsymbol{b}$ 使得训练集中所有样本的对数似然函数最大。训练集的对数似然函数定义为\n\n$$\n\\begin{align*}\n\\mathcal{L}(\\mathcal{D} ; \\boldsymbol{W}, \\boldsymbol{b}) & =\\frac{1}{N} \\sum_{n=1}^{N} \\log p\\left(\\hat{\\boldsymbol{v}}^{(n)} \\mid \\boldsymbol{W}, b\\right)  \\tag{12.17}\\\\\n& =\\frac{1}{N} \\sum_{n=1}^{N} \\log \\sum_{\\boldsymbol{h}} p\\left(\\hat{\\boldsymbol{v}}^{(n)}, \\boldsymbol{h} ; \\boldsymbol{W}, \\boldsymbol{b}\\right)  \\tag{12.18}\\\\\n& =\\frac{1}{N} \\sum_{n=1}^{N} \\log \\frac{\\sum_{\\boldsymbol{h}} \\exp \\left(-E\\left(\\hat{\\boldsymbol{v}}^{(n)}, \\boldsymbol{h}\\right)\\right)}{\\sum_{\\boldsymbol{v}, \\boldsymbol{h}} \\exp (-E(\\boldsymbol{v}, \\boldsymbol{h}))} . \\tag{12.19}\n\\end{align*}\n$$\n\n对数似然函数 $\\mathcal{L}(\\mathcal{D} ; \\boldsymbol{W}, \\boldsymbol{b})$ 对参数 $\\theta$ 的偏导数为\n\n$$\n\\begin{align*}\n& \\frac{\\mathcal{L}(\\mathcal{D} ; \\boldsymbol{W}, \\boldsymbol{b})}{\\partial \\theta}=\\frac{1}{N} \\sum_{n=1}^{N} \\frac{\\partial}{\\partial \\theta} \\log \\sum_{\\boldsymbol{h}} p\\left(\\hat{\\boldsymbol{v}}^{(n)}, \\boldsymbol{h} ; \\boldsymbol{W}, \\boldsymbol{b}\\right)  \\tag{12.20}\\\\\n& =\\frac{1}{N} \\sum_{n=1}^{N} \\frac{\\partial}{\\partial \\theta}\\left(\\log \\sum_{\\boldsymbol{h}} \\exp \\left(-E\\left(\\hat{\\boldsymbol{v}}^{(n)}, \\boldsymbol{h}\\right)\\right)-\\log \\sum_{\\boldsymbol{v}, \\boldsymbol{h}} \\exp (-E(\\boldsymbol{v}, \\boldsymbol{h}))\\right)  \\tag{12.21}\\\\\n& =\\frac{1}{N} \\sum_{n=1}^{N} \\sum_{\\boldsymbol{h}} \\frac{\\exp \\left(-E\\left(\\hat{\\boldsymbol{v}}^{(n)}, \\boldsymbol{h}\\right)\\right)}{\\sum_{h} \\exp \\left(-E\\left(\\hat{\\boldsymbol{v}}^{(n)}, \\boldsymbol{h}\\right)\\right)}\\left[-\\frac{\\partial E\\left(\\hat{\\boldsymbol{v}}^{(n)}, \\boldsymbol{h}\\right)}{\\partial \\theta}\\right] \\\\\n& \\quad-\\sum_{\\boldsymbol{v}, \\boldsymbol{h}} \\frac{\\exp (-E(\\boldsymbol{v}, \\boldsymbol{h}))}{\\sum_{\\boldsymbol{v}, \\boldsymbol{h}} \\exp (-E(\\boldsymbol{v}, \\boldsymbol{h}))}\\left[-\\frac{\\partial E(\\boldsymbol{v}, \\boldsymbol{h})}{\\partial \\theta}\\right] \\tag{12.22}\n\\end{align*}\n$$\n\nhttps：／／nndl．github．io／\n\n局部最优在 Hopfield网络中不是一个缺点．相反，Hopfield 网络是通过利用局部最优点来存储信息。\n\n$$\n\\begin{align*}\n& =\\frac{1}{N} \\sum_{n=1}^{N} \\sum_{\\boldsymbol{h}} p\\left(\\boldsymbol{h} \\mid \\hat{\\boldsymbol{v}}^{(n)}\\right)\\left[-\\frac{\\partial E\\left(\\hat{\\boldsymbol{v}}^{(n)}, \\boldsymbol{h}\\right)}{\\partial \\theta}\\right]-\\sum_{\\boldsymbol{v}, \\boldsymbol{h}} p(\\boldsymbol{v}, \\boldsymbol{h})\\left[-\\frac{\\partial E(\\boldsymbol{v}, \\boldsymbol{h})}{\\partial \\theta}\\right]  \\tag{12.23}\\\\\n& =\\mathbb{E}_{\\hat{p}(\\boldsymbol{v})} \\mathbb{E}_{p(\\boldsymbol{h} \\mid \\boldsymbol{v})}\\left[-\\frac{\\partial E(\\boldsymbol{v}, \\boldsymbol{h})}{\\partial \\theta}\\right]-\\mathbb{E}_{p(\\boldsymbol{v}, \\boldsymbol{h})}\\left[-\\frac{\\partial E(\\boldsymbol{v}, \\boldsymbol{h})}{\\partial \\theta}\\right] \\tag{12.24}\n\\end{align*}\n$$\n\n其中 $\\hat{p}(\\boldsymbol{v})$ 表示可观测向量在训练集上的实际经验分布，$p(\\boldsymbol{h} \\mid \\boldsymbol{v})$ 和 $p(\\boldsymbol{v}, \\boldsymbol{h})$ 为在当前参数 $\\boldsymbol{W}, \\boldsymbol{b}$ 条件下玻尔兹曼机的条件概率和联合概率．\n\n根据公式 $(12.2), E(\\boldsymbol{v}, \\boldsymbol{h})=E(\\boldsymbol{x})=-\\left(\\sum_{i<j} w_{i j} x_{i} x_{j}+\\sum_{i} b_{i} x_{i}\\right)$ 。因此，整个训练集的对数似然函数 $\\mathcal{L}(\\mathcal{D} ; \\boldsymbol{W}, \\boldsymbol{b})$ 对每个权重 $w_{i j}$ 和偏置 $b_{i}$ 的偏导数为\n\n$$\n\\begin{align*}\n& \\frac{\\partial \\mathcal{L}(\\mathcal{D} ; \\boldsymbol{W}, \\boldsymbol{b})}{\\partial w_{i j}}=\\mathbb{E}_{\\hat{p}(\\boldsymbol{v})} \\mathbb{E}_{p(\\boldsymbol{h} \\mid \\boldsymbol{v})}\\left[x_{i} x_{j}\\right]-\\mathbb{E}_{p(\\boldsymbol{v}, \\boldsymbol{h})}\\left[x_{i} x_{j}\\right]  \\tag{12.25}\\\\\n& \\frac{\\partial \\mathcal{L}(\\mathcal{D} ; \\boldsymbol{W}, \\boldsymbol{b})}{\\partial b_{i}}=\\mathbb{E}_{\\hat{p}(\\boldsymbol{v})} \\mathbb{E}_{p(\\boldsymbol{h} \\mid \\boldsymbol{v})}\\left[x_{i}\\right]-\\mathbb{E}_{p(\\boldsymbol{v}, \\boldsymbol{h})}\\left[x_{i}\\right] \\tag{12.26}\n\\end{align*}\n$$\n\n其中 $i, j \\in[1, K]$ 。这两个公式涉及计算配分函数和期望，很难精确计算。对于一个 $K$ 维的二值随机向量 $\\boldsymbol{x}$ ，其取值空间大小为 $2^{K}$ 。当 $K$ 比较大时，配分函数以及期望的计算会十分耗时。因此，玻尔兹曼机一般通过MCMC方法（如吉布斯采样）来进行近似求解。\n\n以参数 $w_{i j}$ 的梯度为例，公式（12．25）中第一项是在限定可观测变量 $\\boldsymbol{v}$ 为训练样本的条件下 $x_{i} x_{j}$ 的期望。为了近似这个期望，我们可以固定住可观测变量 $\\boldsymbol{v}$ ，只对 $\\boldsymbol{h}$ 进行吉布斯采样。当玻尔兹曼机达到热平衡状态时，采样 $x_{i} x_{j}$ 的值。在训练集上所有的训练样本上重复此过程，得到 $x_{i} x_{j}$ 的近似期望 $\\left\\langle x_{i} x_{j}\\right\\rangle_{\\text {data }}$ 。公式（12．26）中的第二项为玻尔兹曼机在没有任何限制条件下 $x_{i} x_{j}$ 的期望。这时可以对所有变量进行吉布斯采样。当玻尔兹曼机达到热平衡状态时，采样 $x_{i} x_{j}$ 的值，得到近似期望 $\\left\\langle x_{i} x_{j}\\right\\rangle_{\\text {model }}$ 。\n\n这样当采用梯度上升法时，权重 $w_{i j}$ 可以用下面公式近似地更新：\n\n$$\n\\begin{equation*}\nw_{i j} \\leftarrow w_{i j}+\\alpha\\left(\\left\\langle x_{i} x_{j}\\right\\rangle_{\\mathrm{data}}-\\left\\langle x_{i} x_{j}\\right\\rangle_{\\mathrm{model}}\\right) \\tag{12.27}\n\\end{equation*}\n$$\n\n其中 $\\alpha>0$ 为学习率．这个更新方法的一个特点是仅仅使用了局部信息．也就是说，虽然我们优化目标是整个网络的能量最低，但是每个权重的更新只依赖于它连接的相关变量的状态。这种学习方式和人脑神经网络的学习方式，赫布规则 （Hebbian Rule），十分类似。\n\n玻尔兹曼机可以用在监督学习和无监督学习中．在监督学习中，可观测的变量 $\\boldsymbol{v}$ 又进一步可以分为输入和输出变量，隐变量则隐式地描述了输入和输出变量之间复杂的约束关系。在无监督学习中，隐变量可以看作是可观测变量的内部特征表示。玻尔兹曼机也可以看作是一种随机型的神经网络，是Hopfield神经网络的扩展，并且可以生成相应的 Hopfield 神经网络。在没有时间限制时，玻尔兹曼机还可以用来解决复杂的组合优化问题．\nhttps：／／nndl．github．io／",
        "总结": "- 参数学习的目标是最大化训练集的对数似然函数，通过调整参数 $\\boldsymbol{W}$ 和 $\\boldsymbol{b}$。  \n- 对数似然函数定义为训练样本的对数概率的平均值，涉及可观测变量和隐变量的联合概率。  \n- 对参数的偏导数推导中，利用了条件概率和联合概率，以及能量函数 $E(\\boldsymbol{v}, \\boldsymbol{h})$ 的导数。  \n- 偏导数表达式转化为期望形式，涉及实际经验分布和模型分布下的期望计算。  \n- 由于配分函数和期望难以精确计算，通常采用MCMC方法（如吉布斯采样）进行近似。  \n- 权重更新公式基于数据分布和模型分布下的期望差值，采用梯度上升法进行参数调整。  \n- 学习过程仅依赖局部信息，与赫布规则类似，强调相关变量状态的影响。  \n- 玻尔兹曼机适用于监督和无监督学习，并可扩展为Hopfield网络用于组合优化问题。"
      },
      {
        "段落": "## 12.2 受限玻尔兹曼机\n\n全连接的玻尔兹曼机在理论上十分有趣，但是由于其复杂性，目前为止并没有被广泛使用。虽然基于采样的方法在很大程度提高了学习效率，但是每更新一次权重，就需要网络重新达到热平衡状态，这个过程依然比较低效，需要很长时间．在实际应用中，使用比较广泛的是一种带限制的版本，也就是受限玻尔兹曼机．\n\n受限玻尔兹曼机（Restricted Boltzmann Machine，RBM）是一个二分图结构的无向图模型，如图12．3所示．受限玻尔兹曼机中的变量也分为隐变量和可观测变量。我们分别用可观测层和隐藏层来表示这两组变量。同一层中的节点之间没有连接，而不同层一个层中的节点与另一层中的所有节点连接，这和两层的全\n\n受限玻尔兹曼机因其结构最初称为簧风琴模型，2000年后受限玻兹曼机的名称才变得流行。连接神经网络的结构相同．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-306.jpg?height=264&width=584&top_left_y=813&top_left_x=361)\n\n图 12.3 一个有 7 个变量的受限玻尔兹曼机\n\n一个受限玻尔兹曼机由 $K_{v}$ 个可观测变量和 $K_{h}$ 个隐变量组成，其定义如下：\n（1）可观测的随机向量 $\\boldsymbol{v} \\in \\mathbb{R}^{K_{v}}$ ．\n（2）隐藏的随机向量 $\\boldsymbol{h} \\in \\mathbb{R}^{K_{h}}$ 。\n（3）权重矩阵 $\\boldsymbol{W} \\in \\mathbb{R}^{K_{v} \\times K_{h}}$ ，其中每个元素 $w_{i j}$ 为可观测变量 $v_{i}$ 和隐变量 $h_{j}$ 之间边的权重．\n（4）偏置 $\\boldsymbol{a} \\in \\mathbb{R}^{K_{v}}$ 和 $\\boldsymbol{b} \\in \\mathbb{R}^{K_{h}}$ ，其中 $a_{i}$ 为每个可观测的变量 $v_{i}$ 的偏置，$b_{j}$ 为每个隐变量 $h_{j}$ 的偏置．\n\n受限玻尔兹曼机的能量函数定义为\n\n$$\n\\begin{align*}\nE(\\boldsymbol{v}, \\boldsymbol{h}) & =-\\sum_{i} a_{i} v_{i}-\\sum_{j} b_{j} h_{j}-\\sum_{i} \\sum_{j} v_{i} w_{i j} h_{j}  \\tag{12.28}\\\\\n& =-\\boldsymbol{a}^{\\top} \\boldsymbol{v}-\\boldsymbol{b}^{\\top} \\boldsymbol{h}-\\boldsymbol{v}^{\\top} \\boldsymbol{W} \\boldsymbol{h} . \\tag{12.29}\n\\end{align*}\n$$\n\n受限玻尔兹曼机的联合概率分布 $p(\\boldsymbol{v}, \\boldsymbol{h})$ 定义为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{v}, \\boldsymbol{h})=\\frac{1}{Z} \\exp (-E(\\boldsymbol{v}, \\boldsymbol{h})) \\tag{12.30}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n$$\n\\begin{equation*}\n=\\frac{1}{Z} \\exp \\left(\\boldsymbol{a}^{\\top} \\boldsymbol{v}\\right) \\exp \\left(\\boldsymbol{b}^{\\top} \\boldsymbol{h}\\right) \\exp \\left(\\boldsymbol{v}^{\\top} \\boldsymbol{W} \\boldsymbol{h}\\right), \\tag{12.31}\n\\end{equation*}\n$$\n\n其中 $Z=\\sum_{\\boldsymbol{v}, \\boldsymbol{h}} \\exp (-E(\\boldsymbol{v}, \\boldsymbol{h}))$ 为配分函数．",
        "总结": "- 受限玻尔兹曼机（RBM）是一种二分图结构的无向图模型，包含可观测层和隐藏层，同一层内无连接，不同层间全连接。  \n- RBM中的变量分为可观测变量和隐变量，分别对应可观测层和隐藏层。  \n- RBM的结构最初称为簧风琴模型，2000年后才广泛称为受限玻尔兹曼机。  \n- RBM由 $K_v$ 个可观测变量和 $K_h$ 个隐变量组成，定义包括随机向量、权重矩阵、偏置等参数。  \n- RBM的能量函数由可观测变量、隐变量及其相互作用的线性组合构成，形式为 $E(\\boldsymbol{v}, \\boldsymbol{h}) = -\\boldsymbol{a}^{\\top} \\boldsymbol{v} - \\boldsymbol{b}^{\\top} \\boldsymbol{h} - \\boldsymbol{v}^{\\top} \\boldsymbol{W} \\boldsymbol{h}$。  \n- RBM的联合概率分布定义为 $p(\\boldsymbol{v}, \\boldsymbol{h}) = \\frac{1}{Z} \\exp(-E(\\boldsymbol{v}, \\boldsymbol{h}))$，其中 $Z$ 为配分函数。"
      },
      {
        "段落": "## 12．2．1 生成模型\n\n在给定受限玻尔兹曼机的联合概率分布 $p(\\boldsymbol{h}, \\boldsymbol{v})$ 后，可以通过吉布斯采样方法生成一组服从 $p(\\boldsymbol{h}, \\boldsymbol{v})$ 分布的样本．\n\n全条件概率 吉布斯采样需要计算每个变量 $V_{i}$ 和 $H_{j}$ 的全条件概率。受限玻尔兹曼机中同层的变量之间没有连接。从无向图的性质可知，在给定可观测变量时，隐变量之间互相条件独立。同样，在给定隐变量时，可观测变量之间也互相条件独立．因此有\n\n$$\n\\begin{align*}\np\\left(v_{i} \\mid \\boldsymbol{v}_{\\backslash i}, \\boldsymbol{h}\\right) & =p\\left(v_{i} \\mid \\boldsymbol{h}\\right),  \\tag{12.32}\\\\\np\\left(h_{j} \\mid \\boldsymbol{v}, \\boldsymbol{h}_{\\backslash j}\\right) & =p\\left(h_{j} \\mid \\boldsymbol{v}\\right), \\tag{12.33}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{v}_{\\backslash i}$ 为除变量 $V_{i}$ 外其他可观测变量的取值， $\\boldsymbol{h}_{\\backslash j}$ 为除变量 $H_{j}$ 外其他隐变量的取值。因此，$V_{i}$ 的全条件概率只需要计算 $p\\left(v_{i} \\mid \\boldsymbol{h}\\right)$ ，而 $H_{j}$ 的全条件概率只需要计算 $p\\left(h_{j} \\mid \\boldsymbol{v}\\right)$ 。\n\n定理 12.2 －受限玻尔兹曼机中变量的条件概率：在受限玻尔兹曼机中，每个可观测变量和隐变量的条件概率为\n\n$$\n\\begin{align*}\n& p\\left(v_{i}=1 \\mid \\boldsymbol{h}\\right)=\\sigma\\left(a_{i}+\\sum_{j} w_{i j} h_{j}\\right)  \\tag{12.34}\\\\\n& \\left.p\\left(h_{j}=1 \\mid \\boldsymbol{v}\\right)=\\sigma\\left(b_{j}+\\sum_{i} w_{i j} v_{i}\\right)\\right) \\tag{12.35}\n\\end{align*}\n$$\n\n其中 $\\sigma$ 为 Logistic 函数．\n\n证明．（1）先计算 $p\\left(h_{j}=1 \\mid \\boldsymbol{v}\\right)$ ．可观测层变量 $\\boldsymbol{v}$ 的边际概率为\n\n$$\n\\begin{align*}\nP(\\boldsymbol{v}) & =\\sum_{\\boldsymbol{h}} P(\\boldsymbol{v}, \\boldsymbol{h})=\\frac{1}{Z} \\sum_{\\boldsymbol{h}} \\exp (-E(\\boldsymbol{v}, \\boldsymbol{h}))  \\tag{12.36}\\\\\n& =\\frac{1}{Z} \\sum_{\\boldsymbol{h}} \\exp \\left(\\boldsymbol{a}^{\\top} \\boldsymbol{v}+\\sum_{j} b_{j} h_{j}+\\sum_{i} \\sum_{j} v_{i} w_{i j} h_{j}\\right) \\tag{12.37}\n\\end{align*}\n$$\n\n$$\n\\begin{align*}\n& =\\frac{\\exp \\left(\\boldsymbol{a}^{\\top} \\boldsymbol{v}\\right)}{Z} \\sum_{\\boldsymbol{h}} \\exp \\left(\\sum_{j} h_{j}\\left(b_{j}+\\sum_{i} w_{i j} v_{i}\\right)\\right)  \\tag{12.38}\\\\\n& =\\frac{\\exp \\left(\\boldsymbol{a}^{\\top} \\boldsymbol{v}\\right)}{Z} \\sum_{\\boldsymbol{h}} \\prod_{j} \\exp \\left(h_{j}\\left(b_{j}+\\sum_{i} w_{i j} v_{i}\\right)\\right)  \\tag{12.39}\\\\\n& =\\frac{\\exp \\left(\\boldsymbol{a}^{\\top} \\boldsymbol{v}\\right)}{Z} \\sum_{h_{1}} \\sum_{h_{2}} \\cdots \\sum_{h_{n}} \\prod_{j} \\exp \\left(h_{j}\\left(b_{j}+\\sum_{i} w_{i j} v_{i}\\right)\\right)  \\tag{12.40}\\\\\n& =\\frac{\\exp \\left(\\boldsymbol{a}^{\\top} \\boldsymbol{v}\\right)}{Z} \\prod_{j} \\sum_{h_{j}} \\exp \\left(h_{j}\\left(b_{j}+\\sum_{i} w_{i j} v_{i}\\right)\\right)  \\tag{12.41}\\\\\n& =\\frac{\\exp \\left(\\boldsymbol{a}^{\\top} \\boldsymbol{v}\\right)}{Z} \\prod_{j}\\left(1+\\exp \\left(b_{j}+\\sum_{i} w_{i j} v_{i}\\right)\\right) \\tag{12.42}\n\\end{align*}\n$$\n\n固定 $h_{j}=1$ 时，$p\\left(h_{j}=1, v\\right)$ 的边际概率为\n\n$$\n\\begin{align*}\n& p\\left(h_{j}=1, \\boldsymbol{v}\\right)=\\frac{1}{Z} \\sum_{\\boldsymbol{h}, h_{j}=1} \\exp (-E(\\boldsymbol{v}, \\boldsymbol{h}))  \\tag{12.43}\\\\\n& =\\frac{\\exp \\left(\\boldsymbol{a}^{\\top} \\boldsymbol{v}\\right)}{Z} \\prod_{k, k \\neq j}\\left(1+\\exp \\left(b_{k}+\\sum_{i} w_{i k} v_{i}\\right)\\right) \\exp \\left(b_{j}+\\sum_{i} w_{i j} v_{i}\\right) \\tag{12.44}\n\\end{align*}\n$$\n\n由公式（12．42）和公式（12．44），可以计算隐变量 $h_{j}$ 的条件概率为\n\n$$\n\\begin{align*}\np\\left(h_{j}=1 \\mid \\boldsymbol{v}\\right) & =\\frac{p\\left(h_{i}=1, \\boldsymbol{v}\\right)}{p(\\boldsymbol{v})}  \\tag{12.45}\\\\\n& =\\frac{\\exp \\left(b_{j}+\\sum_{i} w_{i j} v_{i}\\right)}{1+\\exp \\left(b_{j}+\\sum_{i} w_{i j} v_{i}\\right)}  \\tag{12.46}\\\\\n& =\\sigma\\left(b_{j}+\\sum_{i} w_{i j} v_{i}\\right) \\tag{12.47}\n\\end{align*}\n$$\n\n（2）同理，可观测变量 $v_{i}$ 的条件概率 $p\\left(v_{i}=1 \\mid \\boldsymbol{h}\\right)$ 为\n\n$$\n\\begin{equation*}\np\\left(v_{i}=1 \\mid \\boldsymbol{h}\\right)=\\sigma\\left(a_{i}+\\sum_{j} w_{i j} h_{j}\\right) . \\tag{12.48}\n\\end{equation*}\n$$\n\n公式（12．47）和公式（12．48）也可以写为向量形式，即\n\n$$\n\\begin{align*}\n& p(\\boldsymbol{h}=1 \\mid \\boldsymbol{v})=\\sigma\\left(\\boldsymbol{W}^{\\top} \\boldsymbol{v}+\\boldsymbol{b}\\right)  \\tag{12.49}\\\\\n& p(\\boldsymbol{v}=1 \\mid \\boldsymbol{h})=\\sigma(\\boldsymbol{W} \\boldsymbol{h}+\\boldsymbol{a}) . \\tag{12.50}\n\\end{align*}\n$$\n\n在受限玻尔兹曼机的全条件概率中，可观测变量之间互相条件独立，隐变量之间也互相条件独立。因此，受限玻尔兹曼机可以并行地对所有的可观测变量 （或所有的隐变量）同时进行采样，从而可以更快地达到热平衡状态。\nhttps：／／nndl．github．io／\n\n利用分配律．\n\n将 $h_{j}$ 为 0 或 1 的取值代入计算。\n\n吉布斯采样 受限玻尔兹曼机的采样过程如下：\n（1）给定或随机初始化一个可观测的向量 $\\boldsymbol{v}_{0}$ ，计算隐变量的概率，并从中采样一个隐向量 $\\boldsymbol{h}_{0}$ 。\n（2）基于 $\\boldsymbol{h}_{0}$ ，计算可观测变量的概率，并从中采样一个可观测的向量 $\\boldsymbol{v}_{1}$ ．\n（3）重复 $t$ 次后，获得 $\\left(\\boldsymbol{v}_{t}, \\boldsymbol{h}_{t}\\right)$ ．\n（4）当 $t \\rightarrow \\infty$ 时，$\\left(\\boldsymbol{v}_{t}, \\boldsymbol{h}_{t}\\right)$ 的采样服从 $p(\\boldsymbol{v}, \\boldsymbol{h})$ 分布．\n\n图12．4也给出了上述过程的示例．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-309.jpg?height=251&width=637&top_left_y=624&top_left_x=337)\n\n图 12.4 受限玻尔兹曼机的采样过程",
        "总结": "- 生成模型：通过吉布斯采样方法生成服从受限玻尔兹曼机联合概率分布 $p(\\boldsymbol{h}, \\boldsymbol{v})$ 的样本。  \n- 全条件概率：在受限玻尔兹曼机中，同层变量之间无连接，变量的全条件概率仅依赖于另一层的变量。  \n- 条件概率公式：可观测变量 $v_i$ 的条件概率为 $\\sigma(a_i + \\sum_j w_{ij} h_j)$，隐变量 $h_j$ 的条件概率为 $\\sigma(b_j + \\sum_i w_{ij} v_i)$。  \n- 条件概率推导：通过计算边际概率和条件概率的比值，推导出条件概率公式，并使用Logistic函数表示。  \n- 吉布斯采样过程：包括初始化可观测变量、采样隐变量、基于隐变量采样可观测变量，并重复迭代以达到热平衡状态。  \n- 并行采样特性：受限玻尔兹曼机允许对所有可观测变量或隐变量并行采样，从而加快收敛速度。"
      },
      {
        "段落": "## 12．2．2 参数学习\n\n和玻尔兹曼机一样，受限玻尔兹曼机通过最大化似然函数来找到最优的参数 $\\boldsymbol{W}, \\boldsymbol{a}, \\boldsymbol{b}$ 。给定一组训练样本 $\\mathcal{D}=\\left\\{\\hat{\\boldsymbol{v}}^{(1)}, \\hat{\\boldsymbol{v}}^{(2)}, \\cdots, \\hat{\\boldsymbol{v}}^{(N)}\\right\\}$ ，其对数似然函数为\n\n$$\n\\begin{equation*}\n\\mathcal{L}(\\mathcal{D} ; \\boldsymbol{W}, \\boldsymbol{a}, \\boldsymbol{b})=\\frac{1}{N} \\sum_{n=1}^{N} \\log p\\left(\\hat{\\boldsymbol{v}}^{(n)} ; \\boldsymbol{W}, \\boldsymbol{a}, \\boldsymbol{b}\\right) . \\tag{12.51}\n\\end{equation*}\n$$\n\n和玻尔兹曼机类似，在受限玻尔兹曼机中，对数似然函数 $\\mathcal{L}(\\mathcal{D} ; \\boldsymbol{W}, \\boldsymbol{b})$ 对参数参见公式（12．24）． $w_{i j}, a_{i}, b_{j}$ 的偏导数为\n\n$$\n\\begin{align*}\n& \\frac{\\partial \\mathcal{L}(\\mathcal{D} ; \\boldsymbol{W}, \\boldsymbol{a}, \\boldsymbol{b})}{\\partial w_{i j}}=\\mathbb{E}_{\\hat{p}(\\boldsymbol{v})} \\mathbb{E}_{p(\\boldsymbol{h} \\mid \\boldsymbol{v})}\\left[v_{i} h_{j}\\right]-\\mathbb{E}_{p(\\boldsymbol{v}, \\boldsymbol{h})}\\left[v_{i} h_{j}\\right],  \\tag{12.52}\\\\\n& \\frac{\\partial \\mathcal{L}(\\mathcal{D} ; \\boldsymbol{W}, \\boldsymbol{a}, \\boldsymbol{b})}{\\partial a_{i}}=\\mathbb{E}_{\\hat{p}(\\boldsymbol{v})} \\mathbb{E}_{p(\\boldsymbol{h} \\mid \\boldsymbol{v})}\\left[v_{i}\\right]-\\mathbb{E}_{p(\\boldsymbol{v}, \\boldsymbol{h})}\\left[v_{i}\\right],  \\tag{12.53}\\\\\n& \\frac{\\partial \\mathcal{L}(\\mathcal{D} ; \\boldsymbol{W}, \\boldsymbol{a}, \\boldsymbol{b})}{\\partial b_{j}}=\\mathbb{E}_{\\hat{p}(\\boldsymbol{v})} \\mathbb{E}_{p(\\boldsymbol{h} \\mid \\boldsymbol{v})}\\left[h_{j}\\right]-\\mathbb{E}_{p(\\boldsymbol{v}, \\boldsymbol{h})}\\left[h_{j}\\right], \\tag{12.54}\n\\end{align*}\n$$\n\n其中 $\\hat{p}(\\boldsymbol{v})$ 为训练数据集上 $\\boldsymbol{v}$ 的实际分布．\n参见习题12－3．\n公式（12．52）、公式（12．53）和公式（12．54）中都需要计算配分函数 $Z$ 以及两个期望 $\\mathbb{E}_{p(\\boldsymbol{h} \\mid \\boldsymbol{v})}$ 和 $\\mathbb{E}_{p(\\boldsymbol{h}, \\boldsymbol{v})}$ ，因此很难计算，一般需要通过 MCMC 方法来近似计算。\n\n首先，将可观测向量 $\\boldsymbol{v}$ 设为训练样本中的值并固定，然后根据条件概率对隐向量 $\\boldsymbol{h}$ 进行采样，这时受限玻尔兹曼机的值记为 $\\langle\\cdot\\rangle_{\\text {data }}$ 。然后再不固定可观测向 https：／／nndl．github．io／\n\n量 $\\boldsymbol{v}$ ，通过吉布斯采样来轮流更新 $\\boldsymbol{v}$ 和 $\\boldsymbol{h}$ 。当达到热平衡状态时，采集 $\\boldsymbol{v}$ 和 $\\boldsymbol{h}$ 的值，记为 $\\langle\\cdot\\rangle_{\\text {model }}$ 。\n\n采用梯度上升方法时，参数 $\\boldsymbol{W}, \\boldsymbol{a}, \\boldsymbol{b}$ 可以用下面公式近似地更新：\n\n$$\n\\begin{align*}\nw_{i j} & \\leftarrow w_{i j}+\\alpha\\left(\\left\\langle v_{i} h_{j}\\right\\rangle_{\\text {data }}-\\left\\langle v_{i} h_{j}\\right\\rangle_{\\text {model }}\\right)  \\tag{12.55}\\\\\na_{i} & \\leftarrow a_{i}+\\alpha\\left(\\left\\langle v_{i}\\right\\rangle_{\\text {data }}-\\left\\langle v_{i}\\right\\rangle_{\\text {model }}\\right)  \\tag{12.56}\\\\\nb_{j} & \\leftarrow b_{j}+\\alpha\\left(\\left\\langle h_{j}\\right\\rangle_{\\text {data }}-\\left\\langle h_{j}\\right\\rangle_{\\text {model }}\\right) \\tag{12.57}\n\\end{align*}\n$$\n\n其中 $\\alpha>0$ 为学习率。\n根据受限玻尔兹曼机的条件独立性，可以对可观测变量和隐变量进行分组轮流采样，如图12．4中所示．这样，受限玻尔兹曼机的采样效率会比一般的玻尔兹曼机有很大提高，但一般还是需要通过很多步采样才可以采集到符合真实分布的样本。",
        "总结": "- 参数学习方法：受限玻尔兹曼机通过最大化对数似然函数来学习参数 $\\boldsymbol{W}, \\boldsymbol{a}, \\boldsymbol{b}$。  \n- 对数似然函数定义：给定训练样本 $\\mathcal{D}$，其对数似然函数为 $\\mathcal{L}(\\mathcal{D} ; \\boldsymbol{W}, \\boldsymbol{a}, \\boldsymbol{b}) = \\frac{1}{N} \\sum_{n=1}^{N} \\log p\\left(\\hat{\\boldsymbol{v}}^{(n)} ; \\boldsymbol{W}, \\boldsymbol{a}, \\boldsymbol{b}\\right)$。  \n- 参数偏导数表达式：对参数 $w_{ij}, a_i, b_j$ 的偏导数分别由公式（12.52）、（12.53）、（12.54）给出，涉及多个期望值的差。  \n- 期望值计算困难：公式中需要计算配分函数 $Z$ 和两个期望 $\\mathbb{E}_{p(\\boldsymbol{h} \\mid \\boldsymbol{v})}$、$\\mathbb{E}_{p(\\boldsymbol{v}, \\boldsymbol{h})}$，通常使用 MCMC 方法近似。  \n- 数据分布与模型分布：通过吉布斯采样交替更新 $\\boldsymbol{v}$ 和 $\\boldsymbol{h}$，分别得到数据分布 $\\langle\\cdot\\rangle_{\\text{data}}$ 和模型分布 $\\langle\\cdot\\rangle_{\\text{model}}$。  \n- 参数更新公式：采用梯度上升方法，参数更新公式为 $w_{ij} \\leftarrow w_{ij} + \\alpha (\\langle v_i h_j \\rangle_{\\text{data}} - \\langle v_i h_j \\rangle_{\\text{model}})$ 等，其中 $\\alpha$ 为学习率。  \n- 采样效率提升：利用条件独立性对变量分组轮流采样，提高采样效率，但仍需多步采样以获得符合真实分布的样本。"
      },
      {
        "段落": "### 12．2．2．1 对比散度学习算法\n\n由于受限玻尔兹曼机的特殊结构，因此可以使用一种比吉布斯采样更有效的学习算法，即对比散度（Contrastive Divergence）［Hinton，2002］．对比散度算法仅需 $k$ 步吉布斯采样．\n\n为了提高效率，对比散度算法用一个训练样本作为可观测向量的初始值。然后，交替对可观测向量和隐向量进行吉布斯采样，不需要等到收敛，只需要 $k$ 步就足够了．这就是 CD－$k$ 算法．通常，$k=1$ 就可以学得很好．对比散度的流程如算法12．1所示。",
        "总结": "- 对比散度（Contrastive Divergence）学习算法是一种比吉布斯采样更有效的学习方法，适用于受限玻尔兹曼机。  \n- 该算法仅需进行 $k$ 步吉布斯采样，通常 $k=1$ 就可以达到较好的学习效果。  \n- 算法以一个训练样本作为可观测向量的初始值，然后交替对可观测向量和隐向量进行吉布斯采样，无需等待收敛。  \n- 对比散度的流程在算法12．1中详细描述。"
      },
      {
        "段落": "## 12．2．3 受限玻尔兹曼机的类型\n\n在具体的不同任务中，需要处理的数据类型不一定都是二值的，也可能是连续值。为了能够处理这些数据，就需要根据输入或输出的数据类型来设计新的能量函数．\n\n一般来说，常见的受限玻尔兹曼机有以下三种：\n（1）＂伯努利－伯努利＂受限玻尔兹曼机（Bernoulli－Bernoulli RBM，BB－RBM）：上面介绍的可观测变量和隐变量都为二值类型的受限玻尔兹曼机。\n（2）＂高斯－伯努利＂受限玻尔兹曼机（Gaussian－Bernoulli RBM，GB－RBM）：可观测变量为高斯分布，隐变量为伯努利分布，其能量函数定义为\n\n$$\n\\begin{equation*}\nE(\\boldsymbol{v}, \\boldsymbol{h})=\\sum_{i} \\frac{\\left(v_{i}-\\mu_{i}\\right)^{2}}{2 \\sigma_{i}^{2}}-\\sum_{j} b_{j} h_{j}-\\sum_{i} \\sum_{j} \\frac{v_{i}}{\\sigma_{i}} w_{i j} h_{j} \\tag{12.58}\n\\end{equation*}\n$$\n\n其中每个可观测变量 $v_{i}$ 服从 $\\left(\\mu_{i}, \\sigma_{i}\\right)$ 的高斯分布．\n\n```\n算法 12.1: 单步对比散度算法\n    输入: 训练集: $\\hat{\\boldsymbol{v}}^{(n)}, n=1, \\cdots, N$;\n    学习率: $\\alpha$\n    初始化: $\\boldsymbol{W} \\leftarrow 0, \\boldsymbol{a} \\leftarrow 0, \\boldsymbol{b} \\leftarrow 0$;\n    for $t=1 \\cdots T$ do\n        for $n=1 \\cdots N$ do\n            选取一个样本 $\\hat{\\boldsymbol{v}}^{(n)}$, 用公式 (12.47) 计算 $p\\left(\\boldsymbol{h}=\\mathbf{1} \\mid \\hat{\\boldsymbol{v}}^{(n)}\\right)$, 并根据这个分\n                布采集一个隐向量 $\\boldsymbol{h}$;\n            计算正向梯度 $\\hat{\\boldsymbol{v}}^{(n)} \\boldsymbol{h}^{\\top}$;\n            根据 $\\boldsymbol{h}$, 用公式 (12.48) 计算 $p(\\boldsymbol{v}=\\mathbf{1} \\mid \\boldsymbol{h})$, 并根据这个分布采集重构的\n                可见变量 $\\boldsymbol{v}^{\\prime}$;\n            根据 $\\boldsymbol{v}^{\\prime}$, 重新计算 $p\\left(\\boldsymbol{h}=\\mathbf{1} \\mid \\boldsymbol{v}^{\\prime}\\right)$ 并采样一个 $\\boldsymbol{h}^{\\prime}$;\n            计算反向梯度 $\\boldsymbol{v}^{\\prime} \\boldsymbol{h}^{\\prime \\top}$;\n            更新参数:\n                $\\boldsymbol{W} \\leftarrow \\boldsymbol{W}+\\alpha\\left(\\hat{\\boldsymbol{v}}^{(n)} \\boldsymbol{h}^{\\top}-\\boldsymbol{v}^{\\prime} \\boldsymbol{h}^{\\prime \\top}\\right) ;$\n            $\\boldsymbol{a} \\leftarrow \\boldsymbol{a}+\\alpha\\left(\\hat{\\boldsymbol{v}}^{(n)}-\\boldsymbol{v}^{\\prime}\\right) ;$\n            $\\boldsymbol{b} \\leftarrow \\boldsymbol{b}+\\alpha\\left(\\boldsymbol{h}-\\boldsymbol{h}^{\\prime}\\right) ;$\n        end\n    end\n    输出: $\\boldsymbol{W}, \\boldsymbol{a}, \\boldsymbol{b}$\n```\n\n（3）＂伯努利－高斯＂受限玻尔兹曼机（Bernoulli－Gaussian RBM，BG－RBM）：可观测变量为伯努利分布，隐变量为高斯分布，其能量函数定义为\n\n$$\n\\begin{equation*}\nE(\\boldsymbol{v}, \\boldsymbol{h})=\\sum_{i} a_{i} v_{i}-\\sum_{j} \\frac{\\left(h_{j}-\\mu_{j}\\right)^{2}}{2 \\sigma_{j}^{2}}-\\sum_{i} \\sum_{j} v_{i} w_{i j} \\frac{h_{j}}{\\sigma_{j}}, \\tag{12.59}\n\\end{equation*}\n$$\n\n其中每个隐变量 $h_{j}$ 服从 $\\left(\\mu_{j}, \\sigma_{j}\\right)$ 的高斯分布．",
        "总结": "- 受限玻尔兹曼机（RBM）根据输入或输出的数据类型可以设计不同的能量函数  \n- 伯努利－伯努利受限玻尔兹曼机（BB-RBM）：可观测变量和隐变量均为二值类型  \n- 高斯－伯努利受限玻尔兹曼机（GB-RBM）：可观测变量服从高斯分布，隐变量服从伯努利分布，其能量函数包含高斯项、隐变量偏置项和可见-隐变量交互项  \n- 伯努利－高斯受限玻尔兹曼机（BG-RBM）：可观测变量服从伯努利分布，隐变量服从高斯分布，其能量函数包含可见变量偏置项、隐变量高斯项和可见-隐变量交互项  \n- 单步对比散度算法：用于训练RBM的算法，通过正向和反向梯度计算更新参数，包括权重矩阵、可见变量偏置和隐变量偏置"
      },
      {
        "段落": "## 12.3 深度信念网络\n\n深度信念网络（Deep Belief Network，DBN）是一种深层的概率有向图模型，其图结构由多层的节点构成．每层节点的内部没有连接，相邻两层的节点之间为全连接。网络的最底层为可观测变量，其他层节点都为隐变量。最顶部的两\n\n和全连接的前馈神经网络结构相同。层间的连接是无向的，其他层之间的连接是有向的．图 12.5 给出了一个深度信念网络的示例．\n\n对一个有 $L$ 层隐变量的深度信念网络，令 $\\boldsymbol{v}=\\boldsymbol{h}^{(0)}$ 表示最底层（第0层）为可观测变量， $\\boldsymbol{h}^{(1)}, \\cdots, \\boldsymbol{h}^{(L)}$ 表示其余每层的变量。顶部的两层是一个无向图，可以看作是一个受限玻尔兹曼机，用来产生 $p\\left(\\boldsymbol{h}^{(L-1)}\\right)$ 的先验分布。除了最顶上两层 https：／／nndl．github．io／\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-312.jpg?height=511&width=812&top_left_y=126&top_left_x=247)\n\n图 12.5 一个有 4 层结构的深度信念网络\n\n外，每一层变量 $\\boldsymbol{h}^{(l)}$ 依赖于其上面一层 $\\boldsymbol{h}^{(l+1)}$ ，即\n\n$$\n\\begin{equation*}\np\\left(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}, \\cdots, \\boldsymbol{h}^{(L)}\\right)=p\\left(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}\\right), \\tag{12.60}\n\\end{equation*}\n$$\n\n其中 $l=\\{0, \\cdots, L-2\\}$ ．\n深度信念网络中所有变量的联合概率可以分解为\n\n$$\n\\begin{align*}\np\\left(\\boldsymbol{v}, \\boldsymbol{h}^{(1)}, \\cdots, \\boldsymbol{h}^{(L)}\\right) & =p\\left(\\boldsymbol{v} \\mid \\boldsymbol{h}^{(1)}\\right)\\left(\\prod_{l=1}^{L-2} p\\left(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}\\right)\\right) p\\left(\\boldsymbol{h}^{(L-1)}, \\boldsymbol{h}^{(L)}\\right)  \\tag{12.61}\\\\\n& =\\left(\\prod_{l=0}^{L-1} p\\left(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}\\right)\\right) p\\left(\\boldsymbol{h}^{(L-1)}, \\boldsymbol{h}^{(L)}\\right) \\tag{12.62}\n\\end{align*}\n$$\n\n其中 $p\\left(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}\\right)$ 为 Sigmoid 型条件概率分布\n\n$$\n\\begin{equation*}\np\\left(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}\\right)=\\sigma\\left(\\boldsymbol{a}^{(l)}+\\boldsymbol{W}^{(l+1)} \\boldsymbol{h}^{(l+1)}\\right), \\tag{12.63}\n\\end{equation*}\n$$\n\n其中 $\\sigma(\\cdot)$ 为按位计算的 logistic sigmoid 函数， $\\boldsymbol{a}^{(l)}$ 为偏置参数， $\\boldsymbol{W}^{(l+1)}$ 为权重参数．这样，每一个层都可以看作是一个Sigmoid信念网络．",
        "总结": "- 深度信念网络（DBN）是一种深层的概率有向图模型，由多层节点构成，每层节点内部无连接，相邻层之间全连接。  \n- 最底层为可观测变量，其余层为隐变量，顶部两层构成无向图，视为受限玻尔兹曼机（RBM），用于生成先验分布 $p(\\boldsymbol{h}^{(L-1)})$。  \n- 每一层变量 $\\boldsymbol{h}^{(l)}$ 依赖于其上一层 $\\boldsymbol{h}^{(l+1)}$，条件概率分布为 Sigmoid 型，形式为 $p(\\boldsymbol{h}^{(l)} \\mid \\boldsymbol{h}^{(l+1)}) = \\sigma(\\boldsymbol{a}^{(l)} + \\boldsymbol{W}^{(l+1)} \\boldsymbol{h}^{(l+1)})$。  \n- 所有变量的联合概率可分解为各层条件概率与顶层无向图联合概率的乘积。  \n- DBN 的结构与全连接前馈神经网络类似，但层间连接方向不同，顶层为无向连接，其余层为有向连接。"
      },
      {
        "段落": "## 12．3．1 生成模型\n\n深度信念网络是一个生成模型，可以用来生成符合特定分布的样本．隐变量用来描述在可观测变量之间的高阶相关性。假如训练数据服从分布 $p(\\boldsymbol{v})$ ，通过训练得到一个深度信念网络．\n\n在生成样本时，首先在最顶两层进行足够多次的吉布斯采样，生成 $\\boldsymbol{h}^{(L-1)}$ ，然后依次计算下一层隐变量的分布。因为在给定上一层变量取值时，下一层的变量是条件独立的，所以可以独立采样。这样，我们可以从第 $L-1$ 层开始，自顶向下进行逐层采样，最终得到可观测层的样本．\nhttps：／／nndl．github．io／\n\nSigmoid 信念网络参见\n第11．1．2．1节．",
        "总结": "- 生成模型的概念：生成模型用于生成符合特定分布的样本，深度信念网络是其中一种生成模型。  \n- 隐变量的作用：隐变量用于描述可观测变量之间的高阶相关性。  \n- 训练过程：通过训练数据分布 $p(\\boldsymbol{v})$ 训练得到深度信念网络。  \n- 生成样本的方法：在最顶两层进行吉布斯采样生成 $\\boldsymbol{h}^{(L-1)}$，然后依次计算下一层隐变量的分布。  \n- 采样过程：在给定上一层变量取值时，下一层变量条件独立，可独立采样，自顶向下逐层生成可观测层样本。  \n- 相关内容参考：Sigmoid 信念网络参见第11．1．2．1节。"
      },
      {
        "段落": "## 12．3．2 参数学习\n\n深度信念网络最直接的训练方式是最大化可观测变量的边际分布 $p(\\boldsymbol{v})$ 在训练集合上的似然。但在深度信念网络中，隐变量 $\\boldsymbol{h}$ 之间的关系十分复杂，由于＂贡献度分配问题＂，很难直接学习。即使对于简单的单层 Sigmoid 信念网络\n\n$$\n\\begin{equation*}\np(v=1 \\mid \\boldsymbol{h})=\\sigma\\left(b+\\boldsymbol{w}^{\\top} \\boldsymbol{h}\\right), \\tag{12.64}\n\\end{equation*}\n$$\n\n在已知可观测变量时，其隐变量的联合后验概率 $p(\\boldsymbol{h} \\mid v)$ 不再互相独立，因此很难精确估计所有隐变量的后验概率。早期深度信念网络的后验概率一般通过蒙特卡罗方法或变分方法来近似估计，但是效率比较低，从而导致其参数学习比较困难。\n\n为了有效地训练深度信念网络，我们将每一层的 Sigmoid 信念网络转换为受限玻尔兹曼机。这样做的好处是隐变量的后验概率是互相独立的，从而可以很容易地进行采样。这样，深度信念网络可以看作是由多个受限玻尔兹曼机从下到上进行堆叠，第 $l$ 层受限玻尔兹曼机的隐层作为第 $l+1$ 层受限玻尔兹曼机的可观测层。进一步地，深度信念网络可以采用逐层训练的方式来快速训练，即从最底层开始，每次只训练一层，直到最后一层［Hinton et al．，2006］．\n\n深度信念网络的训练过程可以分为逐层预训练和精调两个阶段。先通过逐层预训练将模型的参数初始化为较优的值，再通过传统学习方法对参数进行精调。",
        "总结": "- 参数学习的目标是最大化可观测变量的边际分布 $p(\\boldsymbol{v})$ 在训练集合上的似然  \n- 隐变量 $\\boldsymbol{h}$ 之间的关系复杂，导致直接学习困难，存在“贡献度分配问题”  \n- 单层 Sigmoid 信念网络中，已知可观测变量时，隐变量的联合后验概率 $p(\\boldsymbol{h} \\mid v)$ 不独立，难以精确估计  \n- 早期使用蒙特卡罗或变分方法近似估计后验概率，但效率低，参数学习困难  \n- 将每一层 Sigmoid 信念网络转换为受限玻尔兹曼机，使隐变量后验概率独立，便于采样  \n- 深度信念网络可视为多个受限玻尔兹曼机从下到上堆叠，第 $l$ 层的隐层作为第 $l+1$ 层的可观测层  \n- 采用逐层训练方式，从最底层开始，每次训练一层，直到最后一层  \n- 训练过程分为逐层预训练和精调两个阶段：先预训练初始化参数，再用传统方法精调参数"
      },
      {
        "段落": "### 12．3．2．1 逐层预训练\n\n在逐层预训练阶段，采用逐层训练的方式，将深度信念网络的训练简化为对多个受限玻尔兹曼机的训练。\n\n具体的逐层训练过程为自下而上依次训练每一层的受限玻尔兹曼机。假设我们已经训练好了前 $l-1$ 层的受限玻尔兹曼机，那么可以计算隐变量自下而上的条件概率\n\n$$\n\\begin{equation*}\np\\left(\\boldsymbol{h}^{(i)} \\mid \\boldsymbol{h}^{(i-1)}\\right)=\\sigma\\left(\\boldsymbol{b}^{(i)}+\\boldsymbol{W}^{(i)} \\boldsymbol{h}^{(i-1)}\\right), \\quad 1 \\leq i \\leq(l-1) \\tag{12.65}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{b}^{(i)}$ 为第 $i$ 层受限玻尔兹曼机的偏置， $\\boldsymbol{W}^{(i)}$ 为连接权重。这样，我们可以按照 $\\boldsymbol{v}=\\boldsymbol{h}^{(0)} \\rightsquigarrow \\boldsymbol{h}^{(1)} \\rightsquigarrow \\cdots \\rightsquigarrow \\boldsymbol{h}^{(l-1)}$ 的顺序生成一组 $\\boldsymbol{h}^{(l-1)}$ 的样本，记为 $\\hat{\\boldsymbol{H}}^{(l-1)}=\\left\\{\\hat{\\boldsymbol{h}}^{(l, 1)}, \\cdots, \\hat{\\boldsymbol{h}}^{(l, M)}\\right\\}$ 。然后，将 $\\boldsymbol{h}^{(l-1)}$ 和 $\\boldsymbol{h}^{(l)}$ 组成一个受限玻尔兹曼机，用 $\\hat{\\boldsymbol{H}}^{(l-1)}$ 作为训练集充分训练第 $l$ 层的受限玻尔兹曼机．\n\n图12．6给出了深度信念网络的逐层预训练过程．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-314.jpg?height=511&width=906&top_left_y=126&top_left_x=222)\n\n图 12.6 深度信念网络的逐层预训练过程\n\n算法12．2给出一种深度信念网络的逐层预训练方法．大量的实践表明，逐层预训练可以产生非常好的参数初始值，从而极大地降低了模型的学习难度．\n\n```\n算法 12.2: 深度信念网络的逐层预训练方法\n    输入: 训练集: $\\hat{\\boldsymbol{v}}^{(n)}, n=1, \\cdots, N$;\n    学习率 $: \\alpha$, 深度信念网络层数: $L$, 第 $l$ 层权重: $\\boldsymbol{W}^{(l)}$, 第 $l$ 层偏置 $\\boldsymbol{a}^{(l)}$, 第 $l$ 层偏置\n    $b^{(l)}$;\n    for $l=1 \\cdots L$ do\n        初始化: $\\boldsymbol{W}^{(l)} \\leftarrow 0, \\boldsymbol{a}^{(l)} \\leftarrow 0, \\boldsymbol{b}^{(l)} \\leftarrow 0$;\n        从训练集中采样 $\\hat{\\boldsymbol{h}}^{(0)}$;\n        for $i=1 \\cdots l-1$ do\n            根据分布 $p\\left(\\boldsymbol{h}^{(i)} \\mid \\hat{\\boldsymbol{h}}^{(i-1)}\\right)$ 采样 $\\hat{\\boldsymbol{h}}^{(i)}$;\n        end\n        将 $\\hat{\\boldsymbol{h}}^{(l-1)}$ 作为训练样本, 充分训练第 $l$ 层受限玻尔兹曼机, 得到参数\n            $\\boldsymbol{W}^{(l)}, \\boldsymbol{a}^{(l)}, \\boldsymbol{b}^{(l)} ;$\n    end\n    输出: $\\left\\{\\boldsymbol{W}^{(l)}, \\boldsymbol{a}^{(l)}, \\boldsymbol{b}^{(l)}\\right\\}, 1 \\leq l \\leq L$\n```",
        "总结": "- 逐层预训练的概念：通过自下而上依次训练每一层的受限玻尔兹曼机，将深度信念网络的训练简化为多个受限玻尔兹曼机的训练过程。  \n- 条件概率公式：隐变量的条件概率计算公式为 $ p\\left(\\boldsymbol{h}^{(i)} \\mid \\boldsymbol{h}^{(i-1)}\\right)=\\sigma\\left(\\boldsymbol{b}^{(i)}+\\boldsymbol{W}^{(i)} \\boldsymbol{h}^{(i-1)}\\right) $，用于生成隐层样本。  \n- 样本生成过程：按照 $ \\boldsymbol{v}=\\boldsymbol{h}^{(0)} \\rightsquigarrow \\boldsymbol{h}^{(1)} \\rightsquigarrow \\cdots \\rightsquigarrow \\boldsymbol{h}^{(l-1)} $ 的顺序生成样本，并用这些样本训练下一层受限玻尔兹曼机。  \n- 算法描述：算法12.2给出了逐层预训练的具体步骤，包括初始化、采样、训练每一层的参数。  \n- 预训练的作用：逐层预训练可以产生较好的参数初始值，降低模型学习难度。"
      },
      {
        "段落": "### 12．3．2．2 精调\n\n经过预训练之后，再结合具体的任务（监督学习或无监督学习），通过传统的全局学习算法对网络进行精调（fine－tuning），使模型收敛到更好的局部最优点。\n\n作为生成模型的精调 除了顶层的受限玻尔兹曼机，其他层之间的权重可以被分成向上的认知权重（Recognition Weight） $\\boldsymbol{W}^{\\prime}$ 和向下的生成权重（Generative Weight） $\\boldsymbol{W}$ 。认知权重用来计算后验概率，而生成权重用来定义模型。认知权重的初始值 $\\boldsymbol{W}^{\\prime(l)}=\\boldsymbol{W}^{(l)^{\\top}}$ ．\nhttps：／／nndl．github．io／\n\n深度信念网络一般采用 Contrastive Wake－Sleep算法［Hinton et al．，2006］进行精调，其算法过程是：\n（1）Wake 阶段：认知过程，通过外界输入（可观测变量）和向上的认知权重，计算每一层隐变量的后验概率并采样。然后，修改下行的生成权重使得下一层的变量的后验概率最大。也就是＂如果现实跟我想象的不一样，改变我的权重使得我想象的东西就是这样的＂。\n（2）Sleep 阶段：生成过程，通过顶层的采样和向下的生成权重，逐层计算每一层的后验概率并采样。然后，修改向上的认知权重使得上一层变量的后验概率最大。也就是＂如果梦中的景象不是我脑中的相应概念，改变我的认知权重使得这种景象在我看来就是这个概念＂。\n（3）交替进行 Wake 和 Sleep 过程，直到收敛。\n\n作为判别模型的精调 深度信念网络的一个应用是作为深度神经网络的预训练模型，提供神经网络的初始权重。这时只需要向上的认知权重，作为判别模型使用。图12．7给出深度信念网络作为神经网络预训练模型的示例。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-315.jpg?height=659&width=577&top_left_y=1006&top_left_x=378)\n\n图 12.7 深度信念网络作为神经网络的预训练模型\n\n具体的精调过程为：在深度信念网络的最顶层再增加一层输出层，然后使用反向传播算法对这些权重进行调优。特别是在训练数据比较少时，预训练的作用非常大。因为不恰当的初始化权重会显著影响最终模型的性能，而预训练获得的权重在权值空间中比随机权重更接近最优的权重，避免了反向传播算法因随机初始化权值参数而容易陷入局部最优和训练时间长的缺点。这不仅提升了模型的性能，也加快了调优阶段的收敛速度［Larochelle et al．，2007］．",
        "总结": "- 概念：精调（fine-tuning）是指在预训练之后，结合具体任务通过传统全局学习算法对网络进行调整，使模型收敛到更好的局部最优点。\n- 概念：生成模型的精调中，层间权重分为认知权重（Recognition Weight）和生成权重（Generative Weight），分别用于计算后验概率和定义模型。\n- 概念：认知权重的初始值为生成权重的转置。\n- 算法：深度信念网络采用 Contrastive Wake-Sleep 算法进行精调，包含 Wake 阶段和 Sleep 阶段。\n- 算法：Wake 阶段通过外界输入和认知权重计算隐变量后验概率并采样，调整生成权重以最大化下一层变量的后验概率。\n- 算法：Sleep 阶段通过顶层采样和生成权重逐层计算后验概率并采样，调整认知权重以最大化上一层变量的后验概率。\n- 算法：交替进行 Wake 和 Sleep 过程直至收敛。\n- 概念：判别模型的精调中，深度信念网络作为预训练模型提供初始权重，仅使用认知权重。\n- 算法：精调过程包括在深度信念网络最顶层增加输出层，并使用反向传播算法调优权重。\n- 优势：预训练在数据较少时作用显著，避免了随机初始化导致的局部最优和训练时间长的问题。"
      },
      {
        "段落": "## 12.4 总结和深入阅读\n\n玻尔兹曼机是 Hopfield 网络的随机化版本，最早由 Geoffrey Hinton 等人提出［Hinton et al．，1986，1984］．玻尔兹曼机能够学习数据的内部表示，并且其参数学习的方式和赫布型学习十分类似。没有任何约束的玻尔兹曼机因为过于复杂，难以应用在实际问题上。通过引入一定的约束（即变为二分图），受限玻尔兹曼机在特征抽取、协同过滤、分类等多个任务上得到了广泛的应用。受限玻尔兹曼机最早由［Smolensky，1986］提出，并命名为簧风琴．［Carreira－Perpinan et al．， 2005］提出了对比散度算法使得受限玻尔兹曼机的训练非常高效．\n\n受限玻尔兹曼机一度变得非常流行，因为其作为深度信念网络的一部分，显著提高了语音识别的精度［Dahl et al．，2012；Hinton et al．，2012］，并开启了深度学习的浪潮．\n\n深度神经网络的误差反向传播算法存在梯度消失问题，因此在2006年以前，我们还无法有效地训练深度神经网络．［Hinton et al．，2006］提出了深度信念网络，并通过逐层训练和精调可以有效地学习。［Salakhutdinov，2015］给出了深度信念网络可以逐层训练的理论依据。深度信念网络的一个重要贡献是可以为一个深度神经网络提供较好的初始参数，从而使得训练深度神经网络变得可行．深度信念网络也成为早期深度学习算法的主要框架之一．\n\n和深度信念网络十分类似的一种深度概率模型是深度玻尔兹曼机（Deep Boltzmann Machine，DBM）［Salakhutdinov et al．，2010］．深度玻尔兹曼机是由多层的受限玻尔兹曼机堆叠而成，是真正的无向图模型，其联合概率是通过能量函数来定义．和深度信念网络相比，深度玻尔兹曼机的学习和推断要更加困难。\n\n典型的深度信念网络的隐变量是二值的，其后验为伯努利分布，［Welling et al．，2005］提出一个改进，允许隐变量为其他类型，其后验分布为指数族分布。 ［Lee et al．，2009］提出了卷积深度信念网络（Convolutional Deep Belief Network， CDBN），采用和卷积神经网络类似的结构，以便处理高维的图像特征。通过基于卷积的受限玻尔兹曼机和概率最大汇聚操作，卷积深度信念网络也能够使用类似深度置信网络的训练方法进行训练。\n\n除了深度信念网络之外，自编码器［Bengio et al．，2007］以及它的变体，比如稀疏自编码器［Ranzato et al．，2006］和去噪自编码器［Vincent et al．，2008］，也可以用来作为深度神经网络的参数初始化，并可以得到和深度信念网络类似的效果．随着人们对深度学习认识的加深，出现了很多更加便捷的训练深度神经网络的技术，比如 ReLU 激活函数、权重初始化、逐层归一化以及快捷连接［He et al．， 2016］等，使得我们可以不需要预训练就能够训练一个非常深的神经网络。\n\n优化算法参见第7．2节。\n\n尽管深度信念网络作为一种深度学习模型已经很少使用，但其在深度学习发展进程中的贡献十分巨大，并且其理论基础为概率图模型，有非常好的解释性，依然是一种值得深入研究的模型。",
        "总结": "- 玻尔兹曼机是 Hopfield 网络的随机化版本，由 Geoffrey Hinton 等人提出，能够学习数据的内部表示，参数学习方式类似赫布型学习。  \n- 无约束的玻尔兹曼机过于复杂，难以应用，受限玻尔兹曼机通过引入二分图约束，在特征抽取、协同过滤、分类等任务中广泛应用。  \n- 受限玻尔兹曼机最早由 Smolensky 提出，后由 Carreira-Perpinan 等提出对比散度算法，使训练变得高效。  \n- 受限玻尔兹曼机作为深度信念网络的一部分，显著提升了语音识别精度，推动了深度学习的发展。  \n- 深度神经网络存在梯度消失问题，2006 年前难以有效训练。Hinton 等提出深度信念网络，通过逐层训练和精调解决这一问题。  \n- 深度信念网络为深度神经网络提供较好的初始参数，成为早期深度学习的主要框架之一。  \n- 深度玻尔兹曼机（DBM）是多层受限玻尔兹曼机堆叠而成的无向图模型，联合概率通过能量函数定义，学习和推断比深度信念网络更困难。  \n- 典型深度信念网络的隐变量为二值变量，后验为伯努利分布；Welling 等提出改进方法，允许隐变量为其他类型，后验分布为指数族分布。  \n- 卷积深度信念网络（CDBN）采用类似卷积神经网络的结构处理高维图像特征，并使用基于卷积的受限玻尔兹曼机和概率最大汇聚操作进行训练。  \n- 自编码器及其变体（如稀疏自编码器、去噪自编码器）可用于深度神经网络参数初始化，并取得类似深度信念网络的效果。  \n- 随着对深度学习认识加深，出现 ReLU 激活函数、权重初始化、逐层归一化和快捷连接等技术，使得无需预训练即可训练非常深的神经网络。  \n- 深度信念网络虽已较少使用，但其在深度学习发展中的贡献巨大，并具有良好的理论解释性，仍值得深入研究。"
      },
      {
        "段落": "## 习题\n\n习题 12－1 如果使用 Metropolis 算法对玻尔兹曼机进行采样，给出其提议分布的具体形式。\n\n习题12－2 在受限玻尔兹曼机中，证明公式（12．48）。\n习题 12－3 在受限玻尔兹曼机中，证明公式（12．52）、公式（12．53）和公式 （12．54）中参数的梯度．\n\n习题12－4 计算＂高斯－伯努利＂受限玻尔兹曼机和＂伯努利－高斯＂受限玻尔兹曼机的条件概率 $p(\\boldsymbol{v}=\\mathbf{1} \\mid \\boldsymbol{h})$ 和 $p(\\boldsymbol{h}=\\mathbf{1} \\mid \\boldsymbol{v})$ 。\n\n习题12－5 在受限玻尔兹曼机中，如果可观测变量服从多项分布，隐变量服务伯努利分布，可观测变量 $v_{i}$ 的条件概率为\n\n$$\n\\begin{equation*}\np\\left(v_{i}=k \\mid \\boldsymbol{h}\\right)=\\frac{\\exp \\left(a_{i}^{(k)}+\\Sigma_{j} w_{i j}^{(k)} h_{j}\\right)}{\\Sigma_{k^{\\prime}=1}^{K} \\exp \\left(a_{i}^{\\left(k^{\\prime}\\right)}+\\Sigma_{j} w_{i j}^{\\left(k^{\\prime}\\right)} h_{j}\\right)}, \\tag{12.66}\n\\end{equation*}\n$$\n\n其中 $k \\in[1, K]$ 为可观测变量的取值， $\\boldsymbol{W}^{(k)}$ 和 $\\boldsymbol{a}^{(k)}$ 为参数，请给出满足这个条件分布的能量函数．\n\n习题12－6在深度信念网络中，试分析逐层训练背后的理论依据．\n习题12－7 分析深度信念网络和深度玻尔兹曼机之间的异同点．",
        "总结": "- Metropolis 算法用于玻尔兹曼机采样时，提议分布的具体形式是基于当前状态生成候选状态的概率分布。  \n- 公式（12.48）在受限玻尔兹曼机中需要通过推导证明，可能涉及能量函数与概率分布之间的关系。  \n- 公式（12.52）、（12.53）和（12.54）中的参数梯度需要通过链式法则和能量函数的导数进行推导。  \n- 高斯－伯努利受限玻尔兹曼机和伯努利－高斯受限玻尔兹曼机的条件概率 $p(\\boldsymbol{v}=\\mathbf{1} \\mid \\boldsymbol{h})$ 和 $p(\\boldsymbol{h}=\\mathbf{1} \\mid \\boldsymbol{v})$ 分别基于高斯分布和伯努利分布进行计算。  \n- 对于可观测变量服从多项分布、隐变量服从伯努利分布的受限玻尔兹曼机，其能量函数需满足给定的条件概率形式。  \n- 深度信念网络中逐层训练的理论依据与无监督学习、对比散度算法及层间特征表示的独立性有关。  \n- 深度信念网络与深度玻尔兹曼机在结构、训练方式和概率建模上存在异同，需从模型定义、参数学习和生成过程等方面进行分析。"
      },
      {
        "段落": "## 参考文献\n\nAckley D H，Hinton G E，Sejnowski T J．A learning algorithm for boltzmann machines［J］．Cognitive science，1985，9（1）：147－169．\nBengio Y，Lamblin P，Popovici D，et al．Greedy layer－wise training of deep networks［C］／／Advances in neural information processing systems．2007：153－160．\nCarreira－Perpinan M A，Hinton G E．On contrastive divergence learning．［C］／／Aistats：volume 10. 2005：33－40．\n\nDahl G E，Yu D，Deng L，et al．Context－dependent pre－trained deep neural networks for large－ vocabulary speech recognition［J］．IEEE Transactions on audio，speech，and language processing， 2012，20（1）：30－42．\nHe K，Zhang X，Ren S，et al．Deep residual learning for image recognition［C］／／Proceedings of the IEEE conference on computer vision and pattern recognition．2016：770－778．\n\nMetropolis 算法参见第 11．5．4．2节．\n\nHinton G，Deng L，Yu D，et al．Deep neural networks for acoustic modeling in speech recognition： The shared views of four research groups［J］．IEEE Signal Processing Magazine，2012，29（6）：82－97． Hinton G E．Training products of experts by minimizing contrastive divergence［J］．Neural com－ putation，2002，14（8）：1771－1800．\nHinton G E，Sejnowski T J．Learning and releaming in boltzmann machines［J］．Parallel Distrilmted Processing，1986， 1.\nHinton G E，Sejnowski T J，Ackley D H．Boltzmann machines：Constraint satisfaction networks that learn［M］．Carnegie－Mellon University，Department of Computer Science Pittsburgh，PA， 1984. Hinton G E，Osindero S，Teh Y W．A fast learning algorithm for deep belief nets［J］．Neural com－ putation，2006，18（7）：1527－1554．\nKirkpatrick S，Gelatt C D，Vecchi M P．Optimization by simulated annealing［J］．science，1983， 220 （4598）：671－680．\nLarochelle H，Erhan D，Courville A，et al．An empirical evaluation of deep architectures on prob－ lems with many factors of variation［C］／／Proceedings of the 24th international conference on Ma－ chine learning．2007：473－480．\nLee H，Grosse R，Ranganath R，et al．Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations［C］／／Proceedings of the 26th annual international confer－ ence on machine learning．2009：609－616．\nRanzato M，Poultney C，Chopra S，et al．Efficient learning of sparse representations with an energy－ based model［C］／／Proceedings of the 19th International Conference on Neural Information Process－ ing Systems．MIT Press，2006：1137－1144．\nSalakhutdinov R．Learning deep generative models［J］．Annual Review of Statistics and Its Appli－ cation，2015，2：361－385．\nSalakhutdinov R，Larochelle H．Efficient learning of deep boltzmann machines［C］／／Proceedings of the thirteenth international conference on artificial intelligence and statistics．2010：693－700．\nSmolensky P．Information processing in dynamical systems：Foundations of harmony theory［R］． Dept Of Computer Science，Colorado Univ At Boulder， 1986.\nVincent P，Larochelle H，Bengio Y，et al．Extracting and composing robust features with denoising autoencoders［C］／／Proceedings of the International Conference on Machine Learning．2008：1096－ 1103.\n\nWelling M，Rosen－Zvi M，Hinton G E．Exponential family harmoniums with an application to information retrieval［C］／／Advances in neural information processing systems．2005：1481－1488．",
        "总结": "- 概念：对比散度（Contrastive Divergence）  \n- 算法：对比散度学习算法  \n- 算法：深度网络的贪心逐层训练算法  \n- 算法：模拟退火算法  \n- 算法：深度信念网络的快速学习算法  \n- 算法：受限玻尔兹曼机（RBM）的学习算法  \n- 算法：深度卷积信念网络的构建与训练方法  \n- 算法：稀疏表示的能量模型学习方法  \n- 算法：去噪自编码器用于提取鲁棒特征的方法  \n- 概念：玻尔兹曼机（Boltzmann Machine）  \n- 概念：深度神经网络在语音识别中的应用  \n- 概念：深度生成模型的学习方法  \n- 概念：深度架构在多因素变化问题中的应用  \n- 定理/命题：模拟退火算法的优化原理  \n- 推导：对比散度学习的数学推导过程"
      },
      {
        "段落": "## 第13章 深度生成模型\n\n我不能创造的东西，我就不了解。\n—理查德•菲利普斯•费曼（Richard Phillips Feynman）\n1965年诺贝尔物理奖获得者\n\n概率生成模型（Probabilistic Generative Model），简称生成模型，是概率统计和机器学习领域的一类重要模型，指一系列用于随机生成可观测数据的模型。假设在一个连续或离散的高维空间 $\\mathcal{X}$ 中，存在一个随机向量 $\\boldsymbol{X}$ 服从一个未知的数据分布 $p_{r}(\\boldsymbol{x}), \\boldsymbol{x} \\in X$ 。生成模型是根据一些可观测的样本 $\\boldsymbol{x}^{(1)}, \\boldsymbol{x}^{(2)}, \\cdots, \\boldsymbol{x}^{(N)}$ 来学习一个参数化的模型 $p_{\\theta}(\\boldsymbol{x})$ 来近似未知分布 $p_{r}(\\boldsymbol{x})$ ，并可以用这个模型来生成一些样本，使得＂生成＂的样本和＂真实＂的样本尽可能地相似。生成模型通常包含两个基本功能：概率密度估计和生成样本（即采样）。图13．1以手写体数字图像为例给出了生成模型的两个功能示例，其中左图表示手写体数字图像的真实分布 $p_{r}(\\boldsymbol{x})$ 以及从中采样的一些＂真实＂样本，右图表示估计出了分布 $p_{\\theta}(\\boldsymbol{x})$ 以及从中采样的＂生成＂样本．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-319.jpg?height=337&width=943&top_left_y=1467&top_left_x=184)\n\n图13．1生成模型的两个功能\n\n生成模型的应用十分广泛，可以用来建模不同的数据，比如图像、文本、声音等。但对于一个高维空间中的复杂分布，密度估计和生成样本通常都不容易实现。一是高维随机向量一般比较难以直接建模，需要通过一些条件独立性来简化模型，二是给定一个已建模的复杂分布，也缺乏有效的采样方法。\n\n深度生成模型就是利用深度神经网络可以近似任意函数的能力来建模一个复杂分布 $p_{r}(\\boldsymbol{x})$ 或直接生成符合分布 $p_{r}(\\boldsymbol{x})$ 的样本。本章先介绍概率生成模型的基本概念，然后介绍两种深度生成模型：变分自编码器和生成对抗网络。",
        "总结": "- 概念：生成模型是用于随机生成可观测数据的模型，通过学习样本数据分布来近似真实数据分布，并能生成与真实样本相似的样本。\n- 算法：变分自编码器和生成对抗网络是本章介绍的两种深度生成模型。\n- 定理或命题：生成模型包含概率密度估计和生成样本两个基本功能。\n- 数学推导：生成模型通过参数化模型 $p_{\\theta}(\\boldsymbol{x})$ 来近似未知的真实分布 $p_{r}(\\boldsymbol{x})$。"
      },
      {
        "段落": "## 13.1 概率生成模型\n\n生成模型一般具有两个基本功能：密度估计和生成样本．",
        "总结": "- 概念：概率生成模型具有密度估计和生成样本两个基本功能。"
      },
      {
        "段落": "## 13．1．1 密度估计\n\n给定一组数据 $\\mathcal{D}=\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ ，假设它们都是独立地从相同的概率密度函数为 $p_{r}(\\boldsymbol{x})$ 的未知分布中产生的。密度估计（Density Estimation）是根据数据集 $\\mathcal{D}$来估计其概率密度函数 $p_{\\theta}(\\boldsymbol{x})$ ．\n\n在机器学习中，密度估计是一类无监督学习问题．比如在手写体数字图像的密度估计问题中，我们将图像表示为一个随机向量 $\\boldsymbol{X}$ ，其中每一维都表示一个像素值。假设手写体数字图像都服从一个未知的分布 $p_{r}(\\boldsymbol{x})$ ，希望通过一些观测样本来估计其分布。但是，手写体数字图像中不同像素之间存在复杂的依赖关系 （比如相邻像素的颜色一般是相似的），很难用一个明确的图模型来描述其依赖关系，所以直接建模 $p_{r}(\\boldsymbol{x})$ 比较困难。因此，我们通常通过引入隐变量 $\\boldsymbol{z}$ 来简化模型，这样密度估计问题可以转换为估计变量 $(\\boldsymbol{x}, \\boldsymbol{z})$ 的两个局部条件概率 $p_{\\theta}(\\boldsymbol{z})$ 和 $p_{\\theta}(\\boldsymbol{x} \\mid \\boldsymbol{z})$ 。 一般为了简化模型，假设隐变量 $\\boldsymbol{z}$ 的先验分布为标准高斯分布 $\\mathcal{N}(\\mathbf{0}, \\boldsymbol{I})$ 。隐变量 $\\boldsymbol{z}$ 的每一维之间都是独立的。在这个假设下，先验分布 $p(\\boldsymbol{z} ; \\theta)$ 中没有参数。因此，密度估计的重点是估计条件分布 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ ．\n\n如果要建模含隐变量的分布（如图13．2a），就需要利用 EM 算法来进行密度估计。而在EM算法中，需要估计条件分布 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 以及近似后验分布 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ 。当这两个分布比较复杂时，我们可以利用神经网络来进行建模，这就是变分自编码器的思想。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-320.jpg?height=347&width=622&top_left_y=1622&top_left_x=338)\n\n概率密度估计简称密度估计，参见第 9.2 节。\n\nEM 算 法 参 见 第 11．2．2．1 节．\n\n图13．2生成模型",
        "总结": "- 密度估计：根据数据集估计概率密度函数 $p_{\\theta}(\\boldsymbol{x})$，用于无监督学习问题。  \n- 隐变量引入：通过引入隐变量 $\\boldsymbol{z}$ 来简化模型，将密度估计问题转换为估计 $p_{\\theta}(\\boldsymbol{z})$ 和 $p_{\\theta}(\\boldsymbol{x} \\mid \\boldsymbol{z})$。  \n- 先验分布假设：隐变量 $\\boldsymbol{z}$ 的先验分布通常假设为标准高斯分布 $\\mathcal{N}(\\mathbf{0}, \\boldsymbol{I})$。  \n- 条件分布建模：密度估计的重点是估计条件分布 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$。  \n- EM 算法应用：在含隐变量的分布建模中，使用 EM 算法估计条件分布和近似后验分布。  \n- 神经网络建模：当分布复杂时，利用神经网络建模条件分布和后验分布，即变分自编码器的思想。  \n- 图13．2：生成模型的示意图。"
      },
      {
        "段落": "## 13．1．2 生成样本\n\n生成样本就是给定一个概率密度函数为 $p_{\\theta}(\\boldsymbol{x})$ 的分布，生成一些服从这个分布的样本，也称为采样．我们在第11．5节中介绍了一些常用的采样方法．\n\n对于图13．2a中的图模型，在得到两个变量的局部条件概率 $p_{\\theta}(\\boldsymbol{z})$ 和 $p_{\\theta}(\\boldsymbol{x} \\mid \\boldsymbol{z})$之后，我们就可以生成数据 $\\boldsymbol{x}$ ，具体过程可以分为两步进行：\n（1）根据隐变量的先验分布 $p_{\\theta}(\\boldsymbol{z})$ 进行采样，得到样本 $\\boldsymbol{z}$ ．\n（2）根据条件分布 $p_{\\theta}(\\boldsymbol{x} \\mid \\boldsymbol{z})$ 进行采样，得到样本 $\\boldsymbol{x}$ 。\n\n为了便于采样，通常 $p_{\\theta}(\\boldsymbol{x} \\mid \\boldsymbol{z})$ 不能太过复杂。因此，另一种生成样本的思想是从一个简单分布 $p(\\boldsymbol{z}), \\boldsymbol{z} \\in Z$（比如标准正态分布）中采集一个样本 $\\boldsymbol{z}$ ，并利用一个深度神经网络 $g: \\mathcal{Z} \\rightarrow \\mathcal{X}$ 使得 $g(\\boldsymbol{z})$ 服从 $p_{r}(\\boldsymbol{x})$ 。这样，我们就可以避免密度估计问题，并有效降低生成样本的难度，这正是生成对抗网络的思想。",
        "总结": "- 概念：生成样本，即根据给定的概率密度函数 $p_{\\theta}(\\boldsymbol{x})$ 生成服从该分布的样本，也称为采样。  \n- 算法：生成样本的步骤分为两步：首先根据隐变量的先验分布 $p_{\\theta}(\\boldsymbol{z})$ 采样得到 $\\boldsymbol{z}$，然后根据条件分布 $p_{\\theta}(\\boldsymbol{x} \\mid \\boldsymbol{z})$ 采样得到 $\\boldsymbol{x}$。  \n- 方法：为了简化采样过程，通常使用一个简单分布（如标准正态分布）生成隐变量 $\\boldsymbol{z}$，再通过深度神经网络 $g: \\mathcal{Z} \\rightarrow \\mathcal{X}$ 映射得到样本 $\\boldsymbol{x}$。  \n- 思想：这种方法避免了密度估计问题，降低了生成样本的难度，体现了生成对抗网络的核心思想。"
      },
      {
        "段落": "## 13．1．3 应用于监督学习\n\n除了生成样本外，生成模型也可以应用于监督学习。监督学习的目标是建模样本 $\\boldsymbol{x}$ 和输出标签 $y$ 之间的条件概率分布 $p(y \\mid \\boldsymbol{x})$ 。根据贝叶斯公式，\n\n$$\n\\begin{equation*}\np(y \\mid \\boldsymbol{x})=\\frac{p(\\boldsymbol{x}, y)}{\\sum_{y} p(\\boldsymbol{x}, y)} \\tag{13.1}\n\\end{equation*}\n$$\n\n我们可以将监督学习问题转换为联合概率分布 $p(\\boldsymbol{x}, y)$ 的密度估计问题．\n图13．2b给出了带标签的生成模型的图模型表示，可以用于监督学习。在监督学习中，比较典型的生成模型有朴素贝叶斯分类器、隐马尔可夫模型。\n\n判别模型 和生成模型相对应的另一类监督学习模型是判别模型（Discrimina－ tive Model ）。判别模型直接建模条件概率分布 $p(y \\mid \\boldsymbol{x})$ ，并不建模其联合概率分布 $p(\\boldsymbol{x}, y)$ 。常见的判别模型有Logistic回归、支持向量机、神经网络等。由生成模型可以得到判别模型，但由判别模型得不到生成模型．",
        "总结": "- 本节提出监督学习中生成模型的应用，强调生成模型可建模样本 $\\boldsymbol{x}$ 与标签 $y$ 的联合概率分布 $p(\\boldsymbol{x}, y)$，进而通过贝叶斯公式得到条件概率分布 $p(y \\mid \\boldsymbol{x})$。  \n- 利用贝叶斯公式，监督学习问题被转换为联合概率分布 $p(\\boldsymbol{x}, y)$ 的密度估计问题。  \n- 图13．2b展示了带标签的生成模型的图模型表示，可用于监督学习。  \n- 典型的生成模型包括朴素贝叶斯分类器和隐马尔可夫模型。  \n- 判别模型是与生成模型相对的另一类监督学习模型，直接建模条件概率分布 $p(y \\mid \\boldsymbol{x})$，不建模联合概率分布 $p(\\boldsymbol{x}, y)$。  \n- 常见的判别模型有Logistic回归、支持向量机和神经网络等。  \n- 由生成模型可以推导出判别模型，但由判别模型无法反推出生成模型。"
      },
      {
        "段落": "## 13.2 变分自编码器",
        "总结": "- 提出的概念：变分自编码器（Variational Autoencoder, VAE）是一种生成模型，结合了自编码器和概率图模型的思想。  \n- 核心思想：通过引入隐变量和概率分布，使模型能够学习数据的潜在表示，并生成新的数据样本。  \n- 关键算法：使用变分推断方法近似后验分布，通过重构误差和KL散度的最小化来训练模型。  \n- 数学推导：基于贝叶斯框架，通过最大化证据下界（ELBO）来优化模型参数，涉及对数似然函数、KL散度和重构误差的计算。  \n- 算法特点：能够生成高质量的数据样本，适用于数据生成和去噪等任务，同时具有较好的可解释性。"
      },
      {
        "段落": "## 13．2．1 含隐变量的生成模型\n\n假设一个生成模型（如图13．3所示）中包含隐变量，即有部分变量是不可观测的，其中观测变量 $\\boldsymbol{X}$ 是一个高维空间 $\\mathcal{X}$ 中的随机向量，隐变量 $\\boldsymbol{Z}$ 是一个相对低维的空间 $Z$ 中的随机向量。\n\n采样方法参见第11．5节。\n\n样方法参见第 11.5\n\n参见第11．1．2节。\n\n本章中，我们假设 $\\boldsymbol{X}$ 和 $\\boldsymbol{Z}$ 都是连续随机向量．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-322.jpg?height=363&width=354&top_left_y=112&top_left_x=476)\n\n图 13.3 变分自编码器\n\n实线表示生成模型，虚线表示变分近似。\n\n这个生成模型的联合概率密度函数可以分解为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)=p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta) p(\\boldsymbol{z} ; \\theta) \\tag{13.2}\n\\end{equation*}\n$$\n\n其中 $p(\\boldsymbol{z} ; \\theta)$ 为隐变量 $\\boldsymbol{z}$ 先验分布的概率密度函数，$p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 为已知 $\\boldsymbol{z}$ 时观测变量 $\\boldsymbol{x}$ 的条件概率密度函数，$\\theta$ 表示两个密度函数的参数。一般情况下，我们可以假设 $p(\\boldsymbol{z} ; \\theta)$ 和 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 为某种参数化的分布族，比如正态分布。这些分布的形式已知，只是参数 $\\theta$ 未知，可以通过最大化似然来进行估计。\n\n给定一个样本 $\\boldsymbol{x}$ ，其对数边际似然 $\\log p(\\boldsymbol{x} ; \\theta)$ 可以分解为\n\n$$\n\\begin{equation*}\n\\log p(\\boldsymbol{x} ; \\theta)=E L B O(q, \\boldsymbol{x} ; \\theta, \\phi)+\\operatorname{KL}(q(\\boldsymbol{z} ; \\phi), p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)) \\tag{13.3}\n\\end{equation*}\n$$\n\n其中 $q(\\boldsymbol{z} ; \\phi)$ 是额外引入的变分密度函数，其参数为 $\\phi, E L B O(q, \\boldsymbol{x} ; \\theta, \\phi)$ 为证据参见公式（11．49）。下界，\n\n$$\n\\begin{equation*}\n\\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta, \\phi)=\\mathbb{E}_{\\boldsymbol{z} \\sim q(\\boldsymbol{z} ; \\phi)}\\left[\\log \\frac{p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)}{q(\\boldsymbol{z} ; \\phi)}\\right] \\tag{13.4}\n\\end{equation*}\n$$\n\n最大化对数边际似然 $\\log p(\\boldsymbol{x} ; \\theta)$ 可以用 EM 算法来求解．在 EM 算法的每次迭代中，具体可以分为两步：\n（1） E 步：固定 $\\theta$ ，寻找一个密度函数 $q(\\boldsymbol{z} ; \\boldsymbol{\\phi})$ 使其等于或接近于后验密度函数 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta) ;$\n（2） M 步：固定 $q(\\boldsymbol{z} ; \\phi)$ ，寻找 $\\theta$ 来最大化 $E L B O(q, \\boldsymbol{x} ; \\theta, \\phi)$ ．\n\n不断重复上述两步骤，直到收敛。\n在 EM 算法的每次迭代中，理论上最优的 $q(z ; \\phi)$ 为隐变量的后验概率密度函数 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ ，即\n\n$$\n\\begin{equation*}\np(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)=\\frac{p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta) p(\\boldsymbol{z} ; \\theta)}{\\int_{z} p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta) p(\\boldsymbol{z} ; \\theta) d \\boldsymbol{z}} \\tag{13.5}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n后验概率密度函数 $p(z \\mid x ; \\theta)$ 的计算是一个统计推断问题，涉及积分计算。当隐变量 $\\boldsymbol{z}$ 是有限的一维离散变量时，计算起来比较容易。但在一般情况下，这个后验概率密度函数是很难计算的，通常需要通过变分推断来近似估计。在变分推断中，为了降低复杂度，通常会选择一些比较简单的分布 $q(\\boldsymbol{z} ; \\boldsymbol{\\phi})$ 来近似推断 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ 。当 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ 比较复杂时，近似效果不佳。此外，概率密度函数 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 一般也比较复杂，很难直接用已知的分布族函数进行建模．\n\n变分自编码器（Variational AutoEncoder，VAE）［Kingma et al．，2014］是一种深度生成模型，其思想是利用神经网络来分别建模两个复杂的条件概率密度函数．\n（1）用神经网络来估计变分分布 $q(\\boldsymbol{z} ; \\boldsymbol{\\phi})$ ，称为推断网络。理论上 $q(\\boldsymbol{z} ; \\boldsymbol{\\phi})$ 可以不依赖 $\\boldsymbol{x}$ 。但由于 $q(\\boldsymbol{z} ; \\phi)$ 的目标是近似后验分布 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ ，其和 $\\boldsymbol{x}$ 相关，因此变分密度函数一般写为 $q(z \\mid x ; \\phi)$ 。推断网络的输入为 $x$ ，输出为变分分布 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$.\n（2）用神经网络来估计概率分布 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ ，称为生成网络．生成网络的输入为 $\\boldsymbol{z}$ ，输出为概率分布 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 。\n\n将推断网络和生成网络合并就得到了变分自编码器的整个网络结构，如图13．4所示，其中实线表示网络计算操作，虚线表示采样操作。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-323.jpg?height=429&width=1132&top_left_y=1184&top_left_x=92)\n\n图 13.4 变分自编码器的网络结构\n\n变分自编码器的名称来自于其整个网络结构和自编码器比较类似。推断网络看作是＂编码器＂，将可观测变量映射为隐变量。生成网络可以看作是＂解码器＂，将隐变量映射为可观测变量。但变分自编码器背后的原理和自编码器完全不同。变分自编码器中的编码器和解码器的输出为分布（或分布的参数），而不是确定的编码。\n\n变分推断参见第 11.4节。\n\n自编码器参见第9．1．3节。",
        "总结": "- 含隐变量的生成模型：模型中包含不可观测的隐变量 $\\boldsymbol{Z}$ 和可观测变量 $\\boldsymbol{X}$，其中 $\\boldsymbol{X}$ 是高维随机向量，$\\boldsymbol{Z}$ 是低维随机向量。  \n- 联合概率密度函数分解：模型的联合概率密度函数可分解为 $p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta) = p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta) p(\\boldsymbol{z} ; \\theta)$。  \n- 对数边际似然分解：对数边际似然可分解为 ELBO 和 KL 散度之和，即 $\\log p(\\boldsymbol{x} ; \\theta) = ELBO(q, \\boldsymbol{x} ; \\theta, \\phi) + KL(q(\\boldsymbol{z} ; \\phi), p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta))$。  \n- ELBO 定义：ELBO 是期望对数似然与变分分布的对数之差，即 $\\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta, \\phi) = \\mathbb{E}_{\\boldsymbol{z} \\sim q(\\boldsymbol{z} ; \\phi)}\\left[\\log \\frac{p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)}{q(\\boldsymbol{z} ; \\phi)}\\right]$。  \n- EM 算法应用：最大化对数边际似然可通过 EM 算法实现，分为 E 步和 M 步。  \n- E 步内容：固定 $\\theta$，寻找 $q(\\boldsymbol{z} ; \\phi)$ 使其接近后验分布 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$。  \n- M 步内容：固定 $q(\\boldsymbol{z} ; \\phi)$，寻找 $\\theta$ 来最大化 ELBO。  \n- 最优变分分布：理论上最优的 $q(z ; \\phi)$ 为后验概率密度函数 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$。  \n- 后验概率密度计算：后验概率密度函数涉及积分计算，通常难以直接计算，需用变分推断近似估计。  \n- 变分自编码器（VAE）：一种深度生成模型，利用神经网络分别建模两个复杂的条件概率密度函数。  \n- 推断网络功能：用于估计变分分布 $q(\\boldsymbol{z} ; \\phi)$，输入为 $\\boldsymbol{x}$，输出为 $q(\\boldsymbol{z} \\mid x ; \\phi)$。  \n- 生成网络功能：用于估计 $p(\\boldsymbol{x} \\mid z ; θ)$，输入为 $\\boldsymbol{z}$，输出为观测变量的概率分布。  \n- VAE 网络结构：推断网络和生成网络合并构成 VAE 的整体结构，如图13.4所示。  \n- VAE 命名来源：名称来源于其结构与自编码器类似，但原理不同；编码器和解码器输出分布而非确定值。"
      },
      {
        "段落": "## 13．2．2 推断网络\n\n为简单起见，假设 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$ 是服从对角化协方差的高斯分布，\n\n$$\n\\begin{equation*}\nq(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)=\\mathcal{N}\\left(\\boldsymbol{z} ; \\mu_{I}, \\sigma_{I}^{2} \\boldsymbol{I}\\right), \\tag{13.6}\n\\end{equation*}\n$$\n\n其中 $\\mu_{I}$ 和 $\\sigma_{I}^{2}$ 是高斯分布的均值和方差，可以通过推断网络 $f_{I}(\\boldsymbol{x} ; \\phi)$ 来预测．\n\n$$\n\\left[\\begin{array}{l}\n\\mu_{I}  \\tag{13.7}\\\\\n\\sigma_{I}^{2}\n\\end{array}\\right]=f_{I}(\\boldsymbol{x} ; \\phi)\n$$\n\n其中推断网络 $f_{I}(\\boldsymbol{x} ; \\phi)$ 可以是一般的全连接网络或卷积网络，比如一个两层的神经网络，\n\n$$\n\\begin{align*}\n\\boldsymbol{h} & =\\sigma\\left(\\boldsymbol{W}^{(1)} \\boldsymbol{x}+\\boldsymbol{b}^{(1)}\\right)  \\tag{13.8}\\\\\n\\mu_{I} & =\\boldsymbol{W}^{(2)} \\boldsymbol{h}+\\boldsymbol{b}^{(2)}  \\tag{13.9}\\\\\n\\sigma_{I}^{2} & =\\operatorname{softplus}\\left(\\boldsymbol{W}^{(3)} \\boldsymbol{h}+\\boldsymbol{b}^{(3)}\\right) \\tag{13.10}\n\\end{align*}\n$$\n\n其中 $\\phi$ 代表所有的网络参数 $\\left\\{\\boldsymbol{W}^{(1)}, \\boldsymbol{W}^{(2)}, \\boldsymbol{W}^{(3)}, \\boldsymbol{b}^{(1)}, \\boldsymbol{b}^{(2)}, \\boldsymbol{b}^{(3)}\\right\\}, \\sigma$ 和 softplus 为激活函数．这里使用 softplus 激活函数是由于方差总是非负的．在实际实现中，也可以用一个线性层（不需要激活函数）来预测 $\\log \\left(\\sigma_{I}^{2}\\right)$ 。",
        "总结": "- 推断网络用于预测潜在变量 $\\boldsymbol{z}$ 的均值 $\\mu_{I}$ 和方差 $\\sigma_{I}^{2}$。  \n- 推断网络 $f_{I}(\\boldsymbol{x} ; \\phi)$ 可以是全连接网络或卷积网络，如两层神经网络。  \n- 网络结构包括一个隐藏层 $\\boldsymbol{h}$，通过激活函数 $\\sigma$ 计算得到，再用于计算均值和方差。  \n- 均值 $\\mu_{I}$ 由线性层输出，方差 $\\sigma_{I}^{2}$ 使用 softplus 激活函数确保非负性。  \n- 实际实现中也可用线性层预测 $\\log(\\sigma_{I}^{2})$ 以简化计算。"
      },
      {
        "段落": "### 13．2．2．1 推断网络的目标\n\n推断网络的目标是使得 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$ 尽可能接近真实的后验 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ ，需要找到一组网络参数 $\\phi^{*}$ 来最小化两个分布的 KL 散度，即\n\n$$\n\\begin{equation*}\n\\phi^{*}=\\underset{\\phi}{\\arg \\min } \\mathrm{KL}(q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi), p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)) . \\tag{13.11}\n\\end{equation*}\n$$\n\n然而，直接计算上面的 KL 散度是不可能的，因为 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ 一般无法计算。传统方法是利用采样或者变分法来近似推断．基于采样的方法效率很低且估计也不是很准确，所以一般使用的是变分推断方法，即用简单的分布 $q$ 去近似复杂的分布 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ 。但是，在深度生成模型中，$p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ 通常比较复杂，很难用简单分布去近似．因此，我们需要找到一种间接计算方法．\n\n根据公式（13．3）可知，变分分布 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$ 与真实后验 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$ 的 KL 散度等于对数边际似然 $\\log p(\\boldsymbol{x} ; \\theta)$ 与其下界 $\\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta, \\phi)$ 的差，即\n\n$$\n\\begin{equation*}\n\\mathrm{KL}(q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi), p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta))=\\log p(\\boldsymbol{x} ; \\theta)-\\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta, \\phi), \\tag{13.12}\n\\end{equation*}\n$$\n\n变分推断参见第 11.4节。\n$\\operatorname{softplus}(x)=\\log (1+$ $e^{x}$ ）．\n\n因此，推断网络的目标函数可以转换为\n\n$$\n\\begin{align*}\n\\phi^{*} & =\\underset{\\phi}{\\arg \\min } \\operatorname{KL}(q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi), p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta))  \\tag{13.13}\\\\\n& =\\underset{\\phi}{\\arg \\min } \\log p(\\boldsymbol{x} ; \\theta)-E L B O(q, \\boldsymbol{x} ; \\theta, \\phi)  \\tag{13.14}\\\\\n& =\\underset{\\phi}{\\arg \\max } E L B O(q, \\boldsymbol{x} ; \\theta, \\phi) \\tag{13.15}\n\\end{align*}\n$$\n\n即推断网络的目标转换为寻找一组网络参数 $\\phi^{*}$ 使得证据下界 $\\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta, \\phi)$ 最大，这和变分推断中的转换类似。",
        "总结": "- 推断网络的目标是使变分分布 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$ 尽可能接近真实后验 $p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta)$。  \n- 通过最小化 KL 散度 $\\mathrm{KL}(q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi), p(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\theta))$ 来实现这一目标，对应的优化问题为 $\\phi^{*} = \\underset{\\phi}{\\arg \\min} \\mathrm{KL}(q, p)$。  \n- 直接计算 KL 散度不可行，因此引入证据下界（ELBO）作为替代目标。  \n- KL 散度等于对数边际似然 $\\log p(\\boldsymbol{x} ; \\theta)$ 与 ELBO 的差，即 $\\mathrm{KL}(q, p) = \\log p(\\boldsymbol{x} ; \\theta) - \\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta, \\phi)$。  \n- 推断网络的目标转化为最大化 ELBO，即 $\\phi^{*} = \\underset{\\phi}{\\arg \\max} \\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta, \\phi)$。  \n- 这一目标与变分推断中的转换一致，通过优化 ELBO 来近似真实后验分布。"
      },
      {
        "段落": "## 13．2．3 生成网络\n\n生成模型的联合分布 $p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)$ 可以分解为两部分：隐变量 $\\boldsymbol{z}$ 的先验分布 $p(\\boldsymbol{z} ; \\theta)$ 和条件概率分布 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 。\n\n先验分布 $p(z ; \\theta)$ 为简单起见，我们一般假设隐变量 $\\boldsymbol{z}$ 的先验分布为各向同性的标准高斯分布 $\\mathcal{N}(\\boldsymbol{z} \\mid \\mathbf{O}, \\boldsymbol{I})$ ．隐变量 $\\boldsymbol{z}$ 的每一维之间都是独立的．\n\n条件概率分布 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 条件概率分布 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 可以通过生成网络来建模。为简单起见，我们同样用参数化的分布族来表示条件概率分布 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ ，这些分布族的参数可以用生成网络计算得到。\n\n根据变量 $\\boldsymbol{x}$ 的类型不同，可以假设 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 服从不同的分布族．\n（1）如果 $\\boldsymbol{x} \\in\\{0,1\\}^{D}$ 是 $D$ 维的二值的向量，可以假设 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 服从多变量的伯努利分布，即\n\n$$\n\\begin{align*}\np(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta) & =\\prod_{d=1}^{D} p\\left(x_{d} \\mid \\boldsymbol{z} ; \\theta\\right)  \\tag{13.16}\\\\\n& =\\prod_{d=1}^{D} \\gamma_{d}^{x_{d}}\\left(1-\\gamma_{d}\\right)^{\\left(1-x_{d}\\right)} \\tag{13.17}\n\\end{align*}\n$$\n\n其中 $\\gamma_{d} \\triangleq p\\left(x_{d}=1 \\mid \\boldsymbol{z} ; \\theta\\right)$ 为第 $d$ 维分布的参数。分布的参数 $\\gamma=\\left[\\gamma_{1}, \\cdots, \\gamma_{D}\\right]^{\\top}$ 可以通过生成网络来预测。\n（2）如果 $\\boldsymbol{x} \\in \\mathbb{R}^{D}$ 是 $D$ 维的连续向量，可以假设 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 服从对角化协方差的高斯分布，即\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)=\\mathcal{N}\\left(\\boldsymbol{x} ; \\boldsymbol{\\mu}_{G}, \\sigma_{G}^{2} \\boldsymbol{I}\\right), \\tag{13.18}\n\\end{equation*}\n$$\n\n其中 $\\mu_{G} \\in \\mathbb{R}^{D}$ 和 $\\sigma_{G} \\in \\mathbb{R}^{D}$ 同样可以用生成网络 $f_{G}(z ; \\theta)$ 来预测．\n\n相当于 EM 算法中的 E步。\n\n第一项与 $\\phi$ 无关．\n\n参见公式（11．85）。",
        "总结": "- 生成模型的联合分布 $p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)$ 分解为隐变量先验分布 $p(\\boldsymbol{z} ; \\theta)$ 和条件概率分布 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$。  \n- 隐变量 $\\boldsymbol{z}$ 的先验分布通常假设为各向同性的标准高斯分布 $\\mathcal{N}(\\boldsymbol{z} \\mid \\mathbf{0}, \\boldsymbol{I})$，其各维度独立。  \n- 条件概率分布 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 通过生成网络建模，参数由生成网络计算得到。  \n- 若 $\\boldsymbol{x}$ 为二值向量（$\\boldsymbol{x} \\in\\{0,1\\}^{D}$），则条件概率服从多变量伯努利分布，参数 $\\gamma_d$ 由生成网络预测。  \n- 若 $\\boldsymbol{x}$ 为连续向量（$\\boldsymbol{x} \\in \\mathbb{R}^{D}$），则条件概率服从对角协方差高斯分布，均值 $\\mu_G$ 和标准差 $\\sigma_G$ 由生成网络预测。  \n- 生成网络的参数通过优化目标函数进行学习，类似于 EM 算法中的 E 步。  \n- 联合分布中的第一项与参数 $\\phi$ 无关。  \n- 相关公式参考公式（11.85）。"
      },
      {
        "段落": "### 13．2．3．1 生成网络的目标\n\n生成网络 $f_{G}(z ; \\theta)$ 的目标是找到一组网络参数 $\\theta^{*}$ 来最大化 $\\operatorname{ELBO}(q, x ; \\theta, \\phi)$ ．\n\n$$\n\\begin{equation*}\n\\theta^{*}=\\underset{\\theta}{\\arg \\max } E L B O(q, \\boldsymbol{x} ; \\theta, \\phi) . \\tag{13.19}\n\\end{equation*}\n$$",
        "总结": "- 生成网络的目标是通过优化参数 $\\theta$ 来最大化证据下界（ELBO）。  \n- ELBO 的最大化涉及联合分布 $p_{G}(x, z ; \\theta, \\phi)$ 和近似后验分布 $q(z \\mid x ; \\phi)$。  \n- 优化过程中，生成网络的参数 $\\theta$ 通过最大化 ELBO 来提升生成质量。  \n- 最终目标是找到最优参数 $\\theta^{*}$，使得生成模型能够更好地拟合数据分布。"
      },
      {
        "段落": "## 13．2．4 模型汇总\n\n结合公式（13．15）和公式（13．19），推断网络和生成网络的目标都为最大化证据下界 $\\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta, \\phi)$ 。因此，变分自编码器的总目标函数为\n\n$$\n\\begin{align*}\n& \\max _{\\theta, \\phi} \\operatorname{ELBO}(q, \\boldsymbol{x} ; \\theta, \\phi)=\\max _{\\theta, \\phi} \\mathbb{E}_{\\boldsymbol{z} \\sim q(\\boldsymbol{z} ; \\phi)}\\left[\\log \\frac{p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta) p(\\boldsymbol{z} ; \\theta)}{q(\\boldsymbol{z} ; \\phi)}\\right]  \\tag{13.20}\\\\\n& =\\max _{\\theta, \\phi} \\mathbb{E}_{\\boldsymbol{z} \\sim q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]-\\operatorname{KL}(q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi), p(\\boldsymbol{z} ; \\theta)) \\tag{13.21}\n\\end{align*}\n$$\n\n其中 $p(z ; \\theta)$ 为先验分布，$\\theta$ 和 $\\phi$ 分别表示生成网络和推断网络的参数．\n从 EM 算法角度来看，变分自编码器优化推断网络和生成网络的过程，可以分别看作是 EM 算法中的 E 步和 M 步。但在变分自编码器中，这两步的目标合二为一，都是最大化证据下界。此外，变分自编码器可以看作是神经网络和贝叶斯网络的混合体。贝叶斯网络中的节点可以看成是一个随机变量。在变分自编码器中，我们仅仅将隐藏编码对应的节点看成是随机变量，其他节点还是作为普通神经元。这样，编码器变成一个变分推断网络，而解码器可以看作是将隐变量映射到观测变量的生成网络。\n\n我们分别来看公式（13．21）中的两项．\n（1）通常情况下，公式（13．21）中第一项的期望 $\\mathbb{E}_{z \\sim q(z \\mid x ; \\phi)}[\\log p(\\boldsymbol{x} \\mid z ; \\theta)]$ 可以通过采样的方式近似计算。对于每个样本 $\\boldsymbol{x}$ ，根据 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$ 采集 $M$ 个 $\\boldsymbol{z}^{(m)}, 1 \\leq$ $m \\leq M$ ，有\n\n$$\n\\begin{equation*}\n\\mathbb{E}_{\\boldsymbol{z} \\sim q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)] \\approx \\frac{1}{M} \\sum_{m=1}^{M} \\log p\\left(\\boldsymbol{x} \\mid \\boldsymbol{z}^{(m)} ; \\theta\\right) \\tag{13.22}\n\\end{equation*}\n$$\n\n期望 $\\mathbb{E}_{z \\sim q(z \\mid x ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]$ 依赖于参数 $\\phi$ 。但在上面的近似中，这个期望变得和参数 $\\phi$ 无关。当使用梯度下降法来学习参数时，期望 $\\mathbb{E}_{z \\sim q(z \\mid x ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]$ 关于参数 $\\phi$ 的梯度为 0 。这种情况是由于变量 $\\boldsymbol{z}$ 和参数 $\\phi$ 之间不是直接的确定性关系，而是一种＂采样＂关系。这种情况可以通过两种方法解决：一种是再参数化，我们在下一节具体介绍；另一种是梯度估计的方法，具体参考第14．3节。\n（2）公式（13．21）中第二项的 KL 散度通常可以直接计算．特别是当 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$和 $p(z ; \\theta)$ 都是正态分布时，它们的 KL 散度可以直接计算出闭式解．\nhttps：／／nndl．github．io／\n\n相当于 EM 算法中的 M步。\n\n给定 $D$ 维空间中的两个正态分布 $\\mathcal{N}\\left(\\mu_{1}, \\Sigma_{1}\\right)$ 和 $\\mathcal{N}\\left(\\mu_{2}, \\Sigma_{2}\\right)$ ，其 KL 散度为\n\n$$\n\\begin{align*}\n& \\mathrm{KL}\\left(\\mathcal{N}\\left(\\mu_{1}, \\Sigma_{1}\\right), \\mathcal{N}\\left(\\mu_{2}, \\Sigma_{2}\\right)\\right) \\\\\n& =\\frac{1}{2}\\left(\\operatorname{tr}\\left(\\Sigma_{2}^{-1} \\Sigma_{1}\\right)+\\left(\\mu_{2}-\\mu_{1}\\right)^{\\top} \\Sigma_{2}^{-1}\\left(\\mu_{2}-\\mu_{1}\\right)-D+\\log \\frac{\\left|\\Sigma_{2}\\right|}{\\left|\\Sigma_{1}\\right|}\\right) \\tag{13.23}\n\\end{align*}\n$$\n\n其中 $\\operatorname{tr}(\\cdot)$ 表示矩阵的迹，$|\\cdot|$ 表示矩阵的行列式．\n这样，当 $p(\\boldsymbol{z} ; \\theta)=\\mathcal{N}(\\boldsymbol{z} ; \\mathbf{0}, \\boldsymbol{I})$ 以及 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)=\\mathcal{N}\\left(\\boldsymbol{z} ; \\boldsymbol{\\mu}_{I}, \\sigma_{I}^{2} \\boldsymbol{I}\\right)$ 时，\n\n$$\n\\begin{align*}\n& \\mathrm{KL}(q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi), p(\\boldsymbol{z} ; \\theta)) \\\\\n& =\\frac{1}{2}\\left(\\operatorname{tr}\\left(\\sigma_{I}^{2} \\boldsymbol{I}\\right)+\\mu_{I}^{\\top} \\mu_{I}-d-\\log \\left(\\left|\\sigma_{I}^{2} \\boldsymbol{I}\\right|\\right)\\right) \\tag{13.24}\n\\end{align*}\n$$\n\n其中 $\\mu_{I}$ 和 $\\sigma_{I}$ 为推断网络 $f_{I}(\\boldsymbol{x} ; \\phi)$ 的输出。",
        "总结": "- 变分自编码器的总目标函数为最大化证据下界 ELBO，由公式（13.20）和（13.21）给出。  \n- ELBO 包含两个部分：第一项是生成网络的对数似然期望，第二项是推断网络与先验分布之间的 KL 散度。  \n- 生成网络的目标是最大化对数似然，推断网络的目标是逼近先验分布。  \n- 变分自编码器可以看作是神经网络和贝叶斯网络的结合，其中隐藏编码被视为随机变量，其他节点为普通神经元。  \n- 公式（13.21）中的第一项通过采样近似计算，但该期望在梯度下降中对参数 $\\phi$ 的梯度为 0，需通过再参数化或梯度估计方法解决。  \n- 公式（13.21）中的第二项 KL 散度在正态分布情况下可直接计算，且当先验和推断分布均为正态分布时有闭式解。  \n- KL 散度的计算公式（13.23）适用于任意两个正态分布，当先验为标准正态且推断分布为均值和方差的正态分布时，KL 散度简化为公式（13.24）。"
      },
      {
        "段落": "## 13．2．5 再参数化\n\n再参数化（Reparameterization）是将一个函数 $f(\\theta)$ 的参数 $\\theta$ 用另外一组参数表示 $\\theta=g(\\vartheta)$ ，这样函数 $f(\\theta)$ 就转换成参数为 $\\vartheta$ 的函数 $\\hat{f}(\\vartheta)=f(g(\\vartheta))$ 。再参数化通常用来将原始参数转换为另外一组具有特殊属性的参数。比如当 $\\theta$ 为一个很大的矩阵时，可以使用两个低秩矩阵的乘积来再参数化，从而减少参数量。\n\n在公式（13．21）中，期望 $\\mathbb{E}_{z \\sim q(z \\mid x ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]$ 依赖于分布 $q$ 的参数 $\\phi$. 但是，由于随机变量 $\\boldsymbol{z}$ 采样自后验分布 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$ ，它们之间不是确定性关系，因此无法直接求解 $\\boldsymbol{z}$ 关于参数 $\\phi$ 的导数。这时，我们可以通过再参数化方法来将 $\\boldsymbol{z}$ 和 $\\phi$ 之间随机性的采样关系转变为确定性函数关系。\n\n我们引入一个分布为 $p(\\epsilon)$ 的随机变量 $\\epsilon$ ，期望 $\\mathbb{E}_{z \\sim q(z \\mid x ; \\phi)}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]$ 可以重写为\n\n$$\n\\begin{equation*}\n\\mathbb{E}_{\\boldsymbol{z} \\sim q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\boldsymbol{\\phi})}[\\log p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)]=\\mathbb{E}_{\\epsilon \\sim p(\\epsilon)}[\\log p(\\boldsymbol{x} \\mid g(\\phi, \\epsilon) ; \\theta)] \\tag{13.25}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{z} \\triangleq g(\\phi, \\epsilon)$ 为一个确定性函数。\n假设 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$ 为正态分布 $N\\left(\\mu_{I}, \\sigma_{I}^{2} \\boldsymbol{I}\\right)$ ，其中 $\\left\\{\\mu_{I}, \\sigma_{I}\\right\\}$ 是推断网络 $f_{I}(\\boldsymbol{x} ; \\phi)$ 的输出，依赖于参数 $\\phi$ ，我们可以通过下面方式来再参数化：\n\n$$\n\\begin{equation*}\nz=\\mu_{I}+\\sigma_{I} \\odot \\epsilon \\tag{13.26}\n\\end{equation*}\n$$\n\n其中 $\\epsilon \\sim \\mathcal{N}(0, I)$ 。这样 $\\boldsymbol{z}$ 和参数 $\\phi$ 的关系从采样关系变为确定性关系，使得 $\\boldsymbol{z} \\sim$ $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$ 的随机性独立于参数 $\\phi$ ，从而可以求 $\\boldsymbol{z}$ 关于 $\\phi$ 的导数．\n\n矩阵的＂迹＂为主对角线（从左上方至右下方的对角线）上各个元素的总和．\n\n再参数化的另一个例子是权重归一化，参见第 7.5 .3 .1 节．",
        "总结": "- 再参数化是将函数 $f(\\theta)$ 的参数 $\\theta$ 用另一组参数 $\\vartheta$ 表示，转换为 $\\hat{f}(\\vartheta)=f(g(\\vartheta))$，用于将原始参数转换为具有特殊属性的参数。  \n- 再参数化用于处理随机变量与参数之间的非确定性关系，如在变分推断中，将 $\\boldsymbol{z}$ 与 $\\phi$ 的采样关系转为确定性函数关系。  \n- 引入随机变量 $\\epsilon$，通过再参数化将期望表达式从依赖 $q$ 的参数 $\\phi$ 转换为依赖 $\\epsilon$ 的确定性函数。  \n- 对于正态分布 $q(\\boldsymbol{z} \\mid \\boldsymbol{x} ; \\phi)$，再参数化形式为 $z = \\mu_I + \\sigma_I \\odot \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0, I)$。  \n- 这样使 $\\boldsymbol{z}$ 与 $\\phi$ 的关系变为确定性，从而可以求导。  \n- 矩阵的“迹”为主对角线元素的总和。  \n- 权重归一化是再参数化的另一个例子，详见第 7.5.3.1 节。"
      },
      {
        "段落": "## 13．2．6 训练\n\n通过再参数化，变分自编码器可以通过梯度下降法来学习参数，从而提高变分自编码器的训练效率。\n\n给定一个数据集 $\\mathcal{D}=\\left\\{\\boldsymbol{x}^{(n)}\\right\\}_{n=1}^{N}$ ，对于每个样本 $\\boldsymbol{x}^{(n)}$ ，随机采样 $M$ 个变量 $\\epsilon^{(n, m)}, 1 \\leq m \\leq M$ ，并通过公式（13．26）计算 $\\boldsymbol{z}^{(n, m)}$ 。变分自编码器的目标函数近似为\n\n$$\n\\begin{equation*}\n\\mathcal{J}(\\phi, \\theta \\mid \\mathcal{D})=\\sum_{n=1}^{N}\\left(\\frac{1}{M} \\sum_{m=1}^{M} \\log p\\left(\\boldsymbol{x}^{(n)} \\mid \\boldsymbol{z}^{(n, m)} ; \\theta\\right)-\\mathrm{KL}\\left(q\\left(\\boldsymbol{z} \\mid \\boldsymbol{x}^{(n)} ; \\phi\\right), \\mathcal{N}(\\boldsymbol{z} ; \\mathbf{0}, \\boldsymbol{I})\\right)\\right) \\tag{13.27}\n\\end{equation*}\n$$\n\n如果采用随机梯度方法，每次从数据集中采集一个样本 $\\boldsymbol{x}$ 和一个对应的随机变量 $\\epsilon$ ，并进一步假设 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 服从高斯分布 $\\mathcal{N}\\left(\\boldsymbol{x} \\mid \\boldsymbol{\\mu}_{G}, \\boldsymbol{I}\\right)$ ，其中 $\\boldsymbol{\\mu}_{G}=f_{G}(\\boldsymbol{z} ; \\theta)$ 是生成网络的输出，则目标函数可以简化为\n\n$$\n\\begin{equation*}\n\\mathcal{J}(\\phi, \\theta \\mid \\boldsymbol{x})=-\\left\\|\\boldsymbol{x}-\\mu_{G}\\right\\|^{2}+\\mathrm{KL}\\left(\\mathcal{N}\\left(\\mu_{I}, \\sigma_{I}\\right), \\mathcal{N}(\\mathbf{0}, \\boldsymbol{I})\\right), \\tag{13.28}\n\\end{equation*}\n$$\n\n其中第一项可以近似看作是输入 $\\boldsymbol{x}$ 的重构正确性，第二项可以看作是正则化项。这和自编码器在形式上非常类似，但它们的内在机理是完全不同的。\n\n参见习题13－1．\n\n参见习题13－2．\n\n变分自编码器的训练过程如图13．5所示，其中空心矩形表示＂目标函数＂。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-328.jpg?height=678&width=658&top_left_y=1117&top_left_x=322)\n\n图 13.5 变分自编码器的训练过程\n\n图13．6给出了在 MNIST 数据集上变分自编码器学习到的隐变量流形的可视化示例。图13．6a是将训练集上每个样本 $\\boldsymbol{x}$ 通过推断网络映射到 2 维的隐变量空间，图中的每个点表示 $\\mathbb{E}[\\boldsymbol{z} \\mid \\boldsymbol{x}]$ ，不同颜色表示不同的数字．图13．6b是对2维的标准高斯分布上进行均匀采样得到不同的隐变量 $\\boldsymbol{z}$ ，然后通过生成网络产生 $\\mathbb{E}[\\boldsymbol{x} \\mid \\boldsymbol{z}]$ ．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-329.jpg?height=509&width=1007&top_left_y=162&top_left_x=176)\n\n图 13.6 在 MNIST 数据集上变分自编码器学习到的隐变量流形的可视化示例",
        "总结": "- 概念：变分自编码器通过再参数化技巧实现梯度下降训练，提高训练效率。  \n- 算法：使用随机梯度方法训练变分自编码器，每次采样一个样本和对应的随机变量，并假设生成网络输出服从高斯分布。  \n- 目标函数：近似目标函数包含重构误差项和KL散度正则化项，形式类似自编码器但机理不同。  \n- 数学推导：目标函数通过采样和期望估计进行近似，最终简化为重构误差与KL散度的组合。  \n- 可视化示例：图13.6展示了变分自编码器在MNIST数据集上学习到的隐变量流形，包括隐变量映射和生成样本的可视化。"
      },
      {
        "段落": "## 13.3 生成对抗网络",
        "总结": "- 本节介绍了生成对抗网络（Generative Adversarial Networks, GANs）的基本概念，这是一种通过对抗过程生成新数据的深度学习方法。  \n- GANs由生成器（Generator）和判别器（Discriminator）两个网络组成，生成器负责生成逼真的数据，判别器负责判断数据的真实性。  \n- 本节提出了GANs的核心思想：通过让生成器和判别器进行对抗训练，使生成器能够逐步生成更接近真实数据分布的数据。  \n- 本节讨论了GANs的数学推导，包括生成器和判别器的目标函数及其优化过程，涉及最小-最大博弈的框架。  \n- 本节还提到了一些常见的GAN变体，如DCGAN、WGAN等，并简要说明了它们在不同任务中的应用。"
      },
      {
        "段落": "## 13．3．1 显式密度模型和隐式密度模型\n\n之前介绍的深度生成模型，比如变分自编码器、深度信念网络等，都是显示地构建出样本的密度函数 $p(\\boldsymbol{x} ; \\theta)$ ，并通过最大似然估计来求解参数，称为显式密度模型（Explicit Density Model）。比如，变分自编码器的密度函数为 $p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)=p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta) p(\\boldsymbol{z} ; \\theta)$ 。虽然使用了神经网络来估计 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ ，但是我们依然假设 $p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta)$ 为一个参数分布族，而神经网络只是用来预测这个参数分布族的参数．这在某种程度上限制了神经网络的能力．\n\n如果只是希望有一个模型能生成符合数据分布 $p_{r}(\\boldsymbol{x})$ 的样本，那么可以不显示地估计出数据分布的密度函数。假设在低维空间 $z$ 中有一个简单容易采样的分布 $p(\\boldsymbol{z}), p(\\boldsymbol{z})$ 通常为标准多元正态分布 $\\mathcal{N}(\\mathbf{0}, \\boldsymbol{I})$ 。我们用神经网络构建一个映射函数 $G: \\mathcal{Z} \\rightarrow \\mathcal{X}$ ，称为生成网络．利用神经网络强大的拟合能力，使得 $G(\\boldsymbol{z})$服从数据分布 $p_{r}(\\boldsymbol{x})$ 。这种模型就称为隐式密度模型（Implicit Density Model）。所谓隐式模型就是指并不显式地建模 $p_{r}(\\boldsymbol{x})$ ，而是建模生成过程。图13．7给出了隐式模型生成样本的过程。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-329.jpg?height=223&width=1027&top_left_y=1765&top_left_x=142)\n\n图 13.7 隐式模型生成样本的过程",
        "总结": "- 显式密度模型：显式构建样本的密度函数 $p(\\boldsymbol{x} ; \\theta)$，并通过最大似然估计求解参数，例如变分自编码器的密度函数为 $p(\\boldsymbol{x}, \\boldsymbol{z} ; \\theta)=p(\\boldsymbol{x} \\mid \\boldsymbol{z} ; \\theta) p(\\boldsymbol{z} ; \\theta)$。\n\n- 隐式密度模型：不显式估计数据分布的密度函数，而是通过生成网络 $G: \\mathcal{Z} \\rightarrow \\mathcal{X}$ 来生成符合数据分布 $p_{r}(\\boldsymbol{x})$ 的样本，生成网络利用神经网络的拟合能力，使得 $G(\\boldsymbol{z})$ 服从数据分布。\n\n- 生成过程：隐式模型通过建模生成过程来生成样本，而不是直接建模数据分布 $p_{r}(\\boldsymbol{x})$。"
      },
      {
        "段落": "## 13．3．2 网络分解",
        "总结": "- 网络分解的概念：将一个复杂网络分解为多个子网络，以便于分析和处理。  \n- 分解方法：通过识别网络中的关键节点或边，将网络划分为若干部分。  \n- 分解的目的：简化网络结构，便于研究网络的局部特性或全局行为。  \n- 分解的应用：用于网络优化、故障检测、社区发现等实际问题。"
      },
      {
        "段落": "### 13．3．2．1 判别网络\n\n隐式密度模型的一个关键是如何确保生成网络产生的样本一定是服从真实的数据分布．既然我们不构建显式密度函数，就无法通过最大似然估计等方法来训练。\n\n生成对抗网络（Generative Adversarial Networks，GAN）［Goodfellow et al．， 2014］是通过对抗训练的方式来使得生成网络产生的样本服从真实数据分布．在生成对抗网络中，有两个网络进行对抗训练。一个是判别网络，目标是尽量准确地判断一个样本是来自于真实数据还是由生成网络产生；另一个是生成网络，目标是尽量生成判别网络无法区分来源的样本。这两个目标相反的网络不断地进行交替训练。当最后收敛时，如果判别网络再也无法判断出一个样本的来源，那么也就等价于生成网络可以生成符合真实数据分布的样本．生成对抗网络的流程图如图13．8所示。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-330.jpg?height=192&width=985&top_left_y=952&top_left_x=161)\n\n图 13.8 生成对抗网络的流程图\n\n判别网络（Discriminator Network）$D(\\boldsymbol{x} ; \\phi)$ 的目标是区分出一个样本 $\\boldsymbol{x}$ 是来自于真实分布 $p_{r}(\\boldsymbol{x})$ 还是来自于生成模型 $p_{\\theta}(\\boldsymbol{x})$ ，因此判别网络实际上是一个二分类的分类器。用标签 $y=1$ 来表示样本来自真实分布，$y=0$ 表示样本来自生成模型，判别网络 $D(\\boldsymbol{x} ; \\phi)$ 的输出为 $\\boldsymbol{x}$ 属于真实数据分布的概率，即\n\n$$\n\\begin{equation*}\np(y=1 \\mid \\boldsymbol{x})=D(\\boldsymbol{x} ; \\phi), \\tag{13.29}\n\\end{equation*}\n$$\n\n则样本来自生成模型的概率为 $p(y=0 \\mid \\boldsymbol{x})=1-D(\\boldsymbol{x} ; \\phi)$ ．\n给定一个样本 $(\\boldsymbol{x}, y), y=\\{1,0\\}$ 表示其来自于 $p_{r}(\\boldsymbol{x})$ 还是 $p_{\\theta}(\\boldsymbol{x})$ ，判别网络的目标函数为最小化交叉嫡，即\n\n$$\n\\begin{equation*}\n\\min _{\\phi}-\\left(\\mathbb{E}_{\\boldsymbol{x}}[y \\log p(y=1 \\mid \\boldsymbol{x})+(1-y) \\log p(y=0 \\mid \\boldsymbol{x})]\\right) \\tag{13.30}\n\\end{equation*}\n$$\n\n假设分布 $p(\\boldsymbol{x})$ 是由分布 $p_{r}(\\boldsymbol{x})$ 和分布 $p_{\\theta}(\\boldsymbol{x})$ 等比例混合而成，即 $p(\\boldsymbol{x})=$ $\\frac{1}{2}\\left(p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})\\right)$ ，则上式等价于\n\n$$\n\\begin{equation*}\n\\max _{\\phi} \\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x} ; \\phi)]+\\mathbb{E}_{\\boldsymbol{x}^{\\prime} \\sim p_{\\theta}\\left(\\boldsymbol{x}^{\\prime}\\right)}\\left[\\log \\left(1-D\\left(\\boldsymbol{x}^{\\prime} ; \\phi\\right)\\right)\\right] \\tag{13.31}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n$$\n\\begin{equation*}\n=\\max _{\\phi} \\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x} ; \\phi)]+\\mathbb{E}_{\\boldsymbol{z} \\sim p(\\boldsymbol{z})}[\\log (1-D(G(\\boldsymbol{z} ; \\theta) ; \\phi))], \\tag{13.32}\n\\end{equation*}\n$$\n\n其中 $\\theta$ 和 $\\phi$ 分别是生成网络和判别网络的参数．",
        "总结": "- 判别网络的概念：判别网络用于区分样本是来自真实数据分布还是生成模型，是一个二分类分类器。  \n- 生成对抗网络（GAN）的原理：通过生成网络和判别网络的对抗训练，使生成网络能够生成符合真实数据分布的样本。  \n- 判别网络的目标函数：最小化交叉熵，以准确判断样本来源。  \n- 判别网络的数学表达式：$ D(\\boldsymbol{x} ; \\phi) $ 表示样本 $\\boldsymbol{x}$ 来自真实分布的概率。  \n- 目标函数的等价形式：最大化判别网络对真实数据和生成数据的对数概率之和。  \n- 生成网络的输入：通过噪声 $ \\boldsymbol{z} $ 输入生成网络，生成样本后再输入判别网络。"
      },
      {
        "段落": "### 13．3．2．2 生成网络\n\n生成网络（Generator Network）的目标刚好和判别网络相反，即让判别网络将自己生成的样本判别为真实样本．\n\n$$\n\\begin{align*}\n& \\max _{\\theta}\\left(\\mathbb{E}_{z \\sim p(z)}[\\log D(G(z ; \\theta) ; \\phi)]\\right)  \\tag{13.33}\\\\\n= & \\min _{\\theta}\\left(\\mathbb{E}_{z \\sim p(z)}[\\log (1-D(G(z ; \\theta) ; \\phi))]\\right) \\tag{13.34}\n\\end{align*}\n$$\n\n上面的这两个目标函数是等价的。但是在实际训练时，一般使用前者，因为其梯度性质更好．我们知道，函数 $\\log (x), x \\in(0,1)$ 在 $x$ 接近 1 时的梯度要比接近 0 时的梯度小很多，接近＂饱和＂区间．这样，当判别网络 $D$ 以很高的概率认为生成网络 $G$产生的样本是＂假＂样本，即 $(1-D(G(\\boldsymbol{z} ; \\theta) ; \\phi)) \\rightarrow 1$ ，这时目标函数关于 $\\theta$ 的梯度反而很小，从而不利于优化．",
        "总结": "- 生成网络的目标是让判别网络将生成的样本判别为真实样本  \n- 生成网络的目标函数为 $\\max _{\\theta}\\left(\\mathbb{E}_{z \\sim p(z)}[\\log D(G(z ; \\theta) ; \\phi)]\\right)$  \n- 目标函数等价于 $\\min _{\\theta}\\left(\\mathbb{E}_{z \\sim p(z)}[\\log (1-D(G(z ; \\theta) ; \\phi))]\\right)$  \n- 实际训练中通常使用前者，因其梯度性质更好  \n- $\\log(x)$ 在 $x$ 接近 1 时梯度较小，易导致优化困难  \n- 当判别网络高度认为生成样本为假时，目标函数梯度变小，不利于优化"
      },
      {
        "段落": "## 13．3．3 训练\n\n和单目标的优化任务相比，生成对抗网络的两个网络的优化目标刚好相反．因此生成对抗网络的训练比较难，往往不太稳定。一般情况下，需要平衡两个网络的能力。对于判别网络来说，一开始的判别能力不能太强，否则难以提升生成网络的能力。但是，判别网络的判别能力也不能太弱，否则针对它训练的生成网络也不会太好。在训练时需要使用一些技巧，使得在每次迭代中，判别网络比生成网络的能力强一些，但又不能强太多。\n\n生成对抗网络的训练流程如算法13．1所示。每次迭代时，判别网络更新 $K$ 次而生成网络更新一次，即首先要保证判别网络足够强才能开始训练生成网络。在实践中 $K$ 是一个超参数，其取值一般取决于具体任务。",
        "总结": "- 概念：生成对抗网络（GAN）的训练过程中，生成网络和判别网络的优化目标相反，导致训练难度较大且不够稳定。  \n- 算法：训练流程如算法13.1所示，每次迭代中判别网络更新 $K$ 次，生成网络更新一次，以确保判别网络足够强后再训练生成网络。  \n- 关键点：判别网络的能力需适中，既不能太强也不能太弱，以保证生成网络的有效训练。  \n- 技巧：在训练中需调整 $K$ 值，该值为超参数，具体任务中需根据实际情况设定。"
      },
      {
        "段落": "## 13．3．4 一个生成对抗网络的具体实现：DCGAN\n\n生成对抗网络是指一类采用对抗训练方式来进行学习的深度生成模型，其包含的判别网络和生成网络都可以根据不同的生成任务使用不同的网络结构。\n\n本节介绍一个生成对抗网络的具体模型：深度卷积生成对抗网络（Deep Convolutional Generative Adversarial Network，DCGAN）［Radford et al．，2016］．在 DCGAN 中，判别网络是一个传统的深度卷积网络，但使用了带步长的卷积来实现下采样操作，不用最大汇聚（pooling）操作；生成网络使用一个特殊的深度卷积网络来实现，如图 13.9 所示，使用微步卷积来生成 $64 \\times 64$ 大小的图像．\n\n还有一种改进生成网络的梯度的方法是将真实样本和生成样本的标签互换，即生成样本的标签为 1 ．\n\n微步卷积参见第 5.5 .1节。\n\n```\n算法 13.1: 生成对抗网络的训练过程\n    输入: 训练集 $\\mathcal{D}$, 对抗训练迭代次数 $T$, 每次判别网络的训练迭代次数 $K$, 小批\n            量样本数量 $M$\n    随机初始化 $\\theta, \\phi$;\n    for $t \\leftarrow 1$ to $T$ do\n        // 训练判别网络 $D(\\boldsymbol{x} ; \\phi)$\n        for $k \\leftarrow 1$ to $K$ do\n            // 采集小批量训练样本\n            从训练集 $\\mathcal{D}$ 中采集 $M$ 个样本 $\\left\\{\\boldsymbol{x}^{(m)}\\right\\}, 1 \\leq m \\leq M$;\n            从分布 $\\mathcal{N}(\\mathbf{0}, \\boldsymbol{I})$ 中采集 $M$ 个样本 $\\left\\{\\boldsymbol{z}^{(m)}\\right\\}, 1 \\leq m \\leq M$;\n            使用随机梯度上升更新 $\\phi$, 梯度为\n                $\\frac{\\partial}{\\partial \\phi}\\left[\\frac{1}{M} \\sum_{m=1}^{M}\\left(\\log D\\left(\\boldsymbol{x}^{(m)} ; \\phi\\right)+\\log \\left(1-D\\left(G\\left(\\boldsymbol{z}^{(m)} ; \\theta\\right) ; \\phi\\right)\\right)\\right)\\right] ;$\n        end\n        // 训练生成网络 $G(z ; \\theta)$\n        从分布 $\\mathcal{N}(\\mathbf{0}, \\boldsymbol{I})$ 中采集 $M$ 个样本 $\\left\\{\\boldsymbol{z}^{(m)}\\right\\}, 1 \\leq m \\leq M$;\n        使用随机梯度上升更新 $\\theta$, 梯度为\n                    $\\frac{\\partial}{\\partial \\theta}\\left[\\frac{1}{M} \\sum_{m=1}^{M} D\\left(G\\left(z^{(m)} ; \\theta\\right), \\phi\\right)\\right] ;$\n    end\n    输出: 生成网络 $G(z ; \\theta)$\n```\n\nDCGAN 的主要优点是通过一些经验性的网络结构设计使得对抗训练更加稳定。比如，（1）使用带步长的卷积（在判别网络中）和微步卷积（在生成网络中）来代替汇聚操作，以免损失信息；（2）使用批量归一化；（3）去除卷积层之后的全连接层；（4）在生成网络中，除了最后一层使用 Tanh 激活函数外，其余层都使用 ReLU 函数；（5）在判别网络中，都使用 LeakyReLU 激活函数．",
        "总结": "- 生成对抗网络（GAN）是一种采用对抗训练方式的深度生成模型，包含判别网络和生成网络，可根据任务使用不同结构。  \n- DCGAN 是一种具体的 GAN 模型，使用深度卷积网络，判别网络采用带步长的卷积代替最大汇聚操作，生成网络使用微步卷积生成 $64 \\times 64$ 图像。  \n- 算法 13.1 描述了 GAN 的训练过程，包括判别网络和生成网络的交替训练，通过随机梯度上升更新参数。  \n- DCGAN 的优点包括：使用带步长卷积和微步卷积替代汇聚操作以保留信息、应用批量归一化、去除卷积后的全连接层、生成网络使用 Tanh 激活函数（最后一层）和 ReLU（其余层）、判别网络使用 LeakyReLU 激活函数。  \n- 微步卷积在第 5.5.1 节有详细说明。"
      },
      {
        "段落": "## 13．3．5 模型分析\n\n将判别网络和生成网络合并，整个生成对抗网络的目标函数看作是最小化最大化游戏（Minimax Game），\n\n$$\n\\begin{align*}\n& \\min _{\\theta} \\max _{\\phi}\\left(\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(x)}[\\log D(\\boldsymbol{x} ; \\phi)]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}(x)}[\\log (1-D(\\boldsymbol{x} ; \\phi))]\\right)  \\tag{13.35}\\\\\n= & \\min _{\\theta} \\max _{\\phi}\\left(\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(x)}[\\log D(\\boldsymbol{x} ; \\phi)]+\\mathbb{E}_{\\boldsymbol{z} \\sim p(z)}[\\log (1-D(G(\\boldsymbol{z} ; \\theta) ; \\phi))]\\right) . \\tag{13.36}\n\\end{align*}\n$$\n\n因为之前提到的生成网络梯度问题，这个最小化最大化形式的目标函数一般用来进行理论分析，并不是实际训练时的目标函数．\n\n```\nhttps://nndl.github.io/\n```\n\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-333.jpg?height=426&width=1039&top_left_y=129&top_left_x=140)\n\n图 13.9 DCGAN 中的生成网络．第一层是全连接层，输入是从均匀分布中随机采样的 100维向量 $\\boldsymbol{z}$ ，输出是 $4 \\times 4 \\times 1024$ 的向量，重塑为 $4 \\times 4 \\times 1024$ 的张量；然后是四层的微步卷积，没有汇聚层。图片来源：［Radford et al．，2016］\n\n假设 $p_{r}(\\boldsymbol{x})$ 和 $p_{\\theta}(\\boldsymbol{x})$ 已知，则最优的判别器为\n\n$$\n\\begin{equation*}\nD^{\\star}(\\boldsymbol{x})=\\frac{p_{r}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})} . \\tag{13.37}\n\\end{equation*}\n$$\n\n将最优的判别器 $D^{\\star}(\\boldsymbol{x})$ 代入公式（13．35），其目标函数变为\n\n$$\n\\begin{align*}\n\\mathcal{L}\\left(G \\mid D^{\\star}\\right) & =\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(x)}\\left[\\log D^{\\star}(\\boldsymbol{x})\\right]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}(x)}\\left[\\log \\left(1-D^{\\star}(\\boldsymbol{x})\\right)\\right]  \\tag{13.38}\\\\\n& =\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(x)}\\left[\\log \\frac{p_{r}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})}\\right]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}(\\boldsymbol{x})}\\left[\\log \\frac{p_{\\theta}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})}\\right]  \\tag{13.39}\\\\\n& =\\mathrm{KL}\\left(p_{r}, p_{a}\\right)+\\mathrm{KL}\\left(p_{\\theta}, p_{a}\\right)-2 \\log 2  \\tag{13.40}\\\\\n& =2 \\mathrm{JS}\\left(p_{r}, p_{\\theta}\\right)-2 \\log 2, \\tag{13.41}\n\\end{align*}\n$$\n\n其中 $\\mathrm{JS}(\\cdot)$ 为 JS 散度，$p_{a}(\\boldsymbol{x})=\\frac{1}{2}\\left(p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})\\right)$ 为一个＂平均＂分布。\n在生成对抗网络中，当判别网络为最优时，生成网络的优化目标是最小化真实分布 $p_{r}$ 和模型分布 $p_{\\theta}$ 之间的 JS 散度。当两个分布相同时，JS 散度为 0 ，最优生成网络 $G^{\\star}$ 对应的损失为 $\\mathcal{L}\\left(G^{\\star} \\mid D^{\\star}\\right)=-2 \\log 2$ 。",
        "总结": "- 概念：生成对抗网络（GAN）的目标函数被描述为一个最小化最大化游戏（Minimax Game）。\n- 算法：目标函数由判别网络和生成网络的联合优化构成，形式为 $\\min_{\\theta} \\max_{\\phi} (\\mathbb{E}_{x \\sim p_r(x)}[\\log D(x; \\phi)] + \\mathbb{E}_{z \\sim p(z)}[\\log (1-D(G(z; \\theta); \\phi))])$。\n- 定理：当生成分布 $p_\\theta(x)$ 和真实分布 $p_r(x)$ 已知时，最优判别器为 $D^{\\star}(x) = \\frac{p_r(x)}{p_r(x) + p_\\theta(x)}$。\n- 数学推导：将最优判别器代入目标函数后，推导出生成网络的损失函数与JS散度相关，最终表达式为 $2 \\mathrm{JS}(p_r, p_\\theta) - 2 \\log 2$。"
      },
      {
        "段落": "### 13．3．5．1 训练稳定性\n\n使用 JS 散度来训练生成对抗网络的一个问题是当两个分布没有重叠时，它们之间的 JS 散度恒等于常数 $\\log 2$ 。对生成网络来说，目标函数关于参数的梯度为 0 ，即 $\\frac{\\partial \\mathcal{L}\\left(G \\mid D^{\\star}\\right)}{\\partial \\theta}=0$ ．\n\n图13．10给出了生成对抗网络中的梯度消失问题的示例．当真实分布 $p_{r}$ 和模型分布 $p_{\\theta}$ 没有重叠时，最优的判别器 $D^{\\star}$ 对所有生成数据的输出都为 0 ，即 $D^{\\star}(G(\\boldsymbol{z} ; \\theta))=0, \\forall \\boldsymbol{z}$ ．因此，生成网络的梯度消失．\n\n因此，在实际训练生成对抗网络时，一般不会将判别网络训练到最优，只进行一步或多步梯度下降，使得生成网络的梯度依然存在．另外，判别网络也不能太 https：／／nndl．github．io／\n\n参见习题13－4．\n\nJS 散度参见第 E．3．3 节。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-334.jpg?height=270&width=1022&top_left_y=128&top_left_x=149)\n\n图 13.10 生成对抗网络中的梯度消失问题\n\n差，否则生成网络的梯度为错误的梯度．但是，如何在梯度消失和梯度错误之间取得平衡并不是一件容易的事，这个问题使得生成对抗网络在训练时稳定性比较差。",
        "总结": "- JS散度在生成对抗网络训练中的问题：当真实分布与生成分布无重叠时，JS散度恒等于常数$\\log 2$，导致生成网络梯度为0。  \n- 梯度消失现象：最优判别器对所有生成样本输出为0，导致生成网络无法更新。  \n- 训练策略：实际训练中不将判别器训练到最优，仅进行少量梯度下降步骤以保持生成网络梯度。  \n- 判别器的限制：判别器不能太差，否则生成网络的梯度会错误，但平衡梯度消失与梯度错误是困难的。  \n- 训练稳定性问题：上述因素导致生成对抗网络在训练过程中稳定性较差。"
      },
      {
        "段落": "### 13．3．5．2 模型坍塌\n\n如果使用公式（13．33）作为生成网络的目标函数，将最优判别器 $D^{\\star}$ 代入，得到\n\n$$\n\\begin{align*}\n\\mathcal{L}^{\\prime} & \\left(G \\mid D^{\\star}\\right)=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}(\\boldsymbol{x})}\\left[\\log D^{\\star}(\\boldsymbol{x})\\right]  \\tag{13.42}\\\\\n& =\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}(\\boldsymbol{x})}\\left[\\log \\frac{p_{r}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})} \\cdot \\frac{p_{\\theta}(\\boldsymbol{x})}{p_{\\theta}(\\boldsymbol{x})}\\right]  \\tag{13.43}\\\\\n& =-\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}(x)}\\left[\\log \\frac{p_{\\theta}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})}\\right]+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}(\\boldsymbol{x})}\\left[\\log \\frac{p_{\\theta}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})+p_{\\theta}(\\boldsymbol{x})}\\right]  \\tag{13.44}\\\\\n& =-\\mathrm{KL}\\left(p_{\\theta}, p_{r}\\right)+\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}(x)}\\left[\\log \\left(1-D^{\\star}(\\boldsymbol{x})\\right)\\right]  \\tag{13.45}\\\\\n& =-\\mathrm{KL}\\left(p_{\\theta}, p_{r}\\right)+2 \\mathrm{JS}\\left(p_{r}, p_{\\theta}\\right)-2 \\log 2-\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(x)}\\left[\\log D^{\\star}(\\boldsymbol{x})\\right] \\tag{13.46}\n\\end{align*}\n$$\n\n其中后两项和生成网络无关，因此\n\n$$\n\\begin{equation*}\n\\underset{\\theta}{\\arg \\max } \\mathcal{L}^{\\prime}\\left(G \\mid D^{\\star}\\right)=\\underset{\\theta}{\\arg \\min } \\operatorname{KL}\\left(p_{\\theta}, p_{r}\\right)-2 \\mathrm{JS}\\left(p_{r}, p_{\\theta}\\right), \\tag{13.47}\n\\end{equation*}\n$$\n\n其中 JS 散度 $\\mathrm{JS}\\left(p_{\\theta}, p_{r}\\right) \\in[0, \\log 2]$ 为有界函数，因此生成网络的目标更多的是受逆向 KL 散度 KL（ $p_{\\theta}, p_{r}$ ）影响，使得生成网络更倾向于生成一些更＂安全＂的样本，从而造成模型坍塌（Model Collapse）问题。\n\n前向和逆向 KL 散度 因为 KL 散度是一种非对称的散度，在计算真实分布 $p_{r}$ 和模型分布 $p_{\\theta}$ 之间的 KL 散度时，按照顺序不同，有两种 KL 散度：前向 $K L$ 散度 （Forward KL divergence）KL（ $p_{r}, p_{\\theta}$ ）和逆向KL散度（Reverse KL divergence） $\\mathrm{KL}\\left(p_{\\theta}, p_{r}\\right)$ ．前向和逆向 KL 散度分别定义为\n\n$$\n\\begin{align*}\n\\mathrm{KL}\\left(p_{r}, p_{\\theta}\\right) & =\\int p_{r}(\\boldsymbol{x}) \\log \\frac{p_{r}(\\boldsymbol{x})}{p_{\\theta}(\\boldsymbol{x})} \\mathrm{d} \\boldsymbol{x}  \\tag{13.48}\\\\\n\\mathrm{KL}\\left(p_{\\theta}, p_{r}\\right) & =\\int p_{\\theta}(\\boldsymbol{x}) \\log \\frac{p_{\\theta}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})} \\mathrm{d} \\boldsymbol{x} \\tag{13.49}\n\\end{align*}\n$$\n\n图13．11给出数据真实分布为一个高斯混合分布，模型分布为一个单高斯分布时，使用前向和逆向 KL 散度来进行模型优化的示例．黑色曲线为真实分布 $p_{r}$的等高线，红色曲线为模型分布 $p_{\\theta}$ 的等高线．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-335.jpg?height=326&width=1090&top_left_y=317&top_left_x=117)\n\n图 13.11 前向和逆向 KL 散度\n\n在前向KL散度中，\n1．当 $p_{r}(\\boldsymbol{x}) \\rightarrow 0$ 而 $p_{\\theta}(\\boldsymbol{x})>0$ 时，$p_{r}(\\boldsymbol{x}) \\log \\frac{p_{r}(\\boldsymbol{x})}{p_{\\theta}(\\boldsymbol{x})} \\rightarrow 0$ ．不管 $p_{\\theta}(\\boldsymbol{x})$ 如何取值，都对前向 KL散度的计算没有贡献。\n\n2．当 $p_{r}(\\boldsymbol{x})>0$ 而 $p_{\\theta}(\\boldsymbol{x}) \\rightarrow 0$ 时，$p_{r}(\\boldsymbol{x}) \\log \\frac{p_{r}(\\boldsymbol{x})}{p_{\\theta}(\\boldsymbol{x})} \\rightarrow \\infty$ ，前向KL散度会变得非常大．\n\n因此，前向KL散度会鼓励模型分布 $p_{\\theta}(\\boldsymbol{x})$ 尽可能覆盖所有真实分布 $p_{r}(\\boldsymbol{x})>$ 0 的点，而不用回避 $p_{r}(\\boldsymbol{x}) \\approx 0$ 的点。\n\n在逆向 KL散度中，\n1．当 $p_{r}(\\boldsymbol{x}) \\rightarrow 0$ 而 $p_{\\theta}(\\boldsymbol{x})>0$ 时，$p_{\\theta}(\\boldsymbol{x}) \\log \\frac{p_{\\theta}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})} \\rightarrow \\infty$ ．即当 $p_{\\theta}(\\boldsymbol{x})$ 接近于 0 ，而 $p_{\\theta}(\\boldsymbol{x})$ 有一定的密度时，逆向 KL 散度会变得非常大．\n\n2．当 $p_{\\theta}(\\boldsymbol{x}) \\rightarrow 0$ 时，不管 $p_{r}(\\boldsymbol{x})$ 如何取值，$p_{\\theta}(\\boldsymbol{x}) \\log \\frac{p_{\\theta}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})} \\rightarrow 0$ ．\n因此，逆向 KL 散度会鼓励模型分布 $p_{\\theta}(\\boldsymbol{x})$ 尽可能避开所有真实分布 $p_{r}(\\boldsymbol{x}) \\approx$ 0 的点，而不需要考虑是否覆盖所有真实分布 $p_{r}(\\boldsymbol{x})>0$ 的点。",
        "总结": "- 模型坍塌问题的提出：当使用公式（13.33）作为生成网络的目标函数，并代入最优判别器 $D^{\\star}$ 时，生成网络的目标函数会受到逆向 KL 散度的影响，导致生成样本更“安全”，从而引发模型坍塌问题。\n- 逆向 KL 散度的定义：$\\mathrm{KL}(p_{\\theta}, p_{r}) = \\int p_{\\theta}(\\boldsymbol{x}) \\log \\frac{p_{\\theta}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x})} \\mathrm{d}\\boldsymbol{x}$。\n- 前向 KL 散度的定义：$\\mathrm{KL}(p_{r}, p_{\\theta}) = \\int p_{r}(\\boldsymbol{x}) \\log \\frac{p_{r}(\\boldsymbol{x})}{p_{\\theta}(\\boldsymbol{x})} \\mathrm{d}\\boldsymbol{x}$。\n- 前向 KL 散度的特点：鼓励模型分布覆盖所有真实分布非零区域，不回避真实分布接近零的区域。\n- 逆向 KL 散度的特点：鼓励模型分布避开真实分布接近零的区域，不强制覆盖所有真实分布非零区域。\n- 图13.11示例：展示真实分布为高斯混合分布、模型分布为单高斯分布时，前向和逆向 KL 散度对模型优化的影响。"
      },
      {
        "段落": "## 13．3．6 改进模型\n\n在生成对抗网络中，JS 散度不适合衡量生成数据分布和真实数据分布的距离。由于通过优化交叉熵（JS散度）训练生成对抗网络会导致训练稳定性和模型坍塌问题，因此要改进生成对抗网络，就需要改变其损失函数。",
        "总结": "- 概念：JS散度不适合用于衡量生成数据分布与真实数据分布的距离。  \n- 算法/方法：改进生成对抗网络的损失函数以解决训练不稳定性和模型坍塌问题。  \n- 数学推导：通过优化交叉熵（JS散度）训练GAN会导致训练不稳定性和模型坍塌，因此需要改变损失函数。"
      },
      {
        "段落": "### 13．3．6．1 W－GAN\n\nW－GAN 是一种通过用Wasserstein 距离替代 JS 散度来优化训练的生成对抗网络［Arjovsky et al．，2017］．\n\n对于真实分布 $p_{r}$ 和模型分布 $p_{\\theta}$ ，它们的 1st－Wasserstein 距离为\n\n$$\n\\begin{equation*}\n\\boldsymbol{W}^{1}\\left(p_{r}, p_{\\theta}\\right)=\\inf _{\\gamma \\sim \\Gamma\\left(p_{r}, p_{\\theta}\\right)} \\mathbb{E}_{(\\boldsymbol{x}, \\boldsymbol{y}) \\sim \\gamma}[\\|\\boldsymbol{x}-\\boldsymbol{y}\\|] \\tag{13.50}\n\\end{equation*}\n$$\n\n其中 $\\Gamma\\left(p_{r}, p_{\\theta}\\right)$ 是边际分布为 $p_{r}$ 和 $p_{\\theta}$ 的所有可能的联合分布集合．\n当两个分布没有重叠或者重叠非常少时，它们之间的 KL 散度为 $+\\infty$ ，JS 散度为 $\\log 2$ ，并不随着两个分布之间的距离而变化。而1st－Wasserstein距离依然可以衡量两个没有重叠分布之间的距离。",
        "总结": "- W－GAN 是一种使用Wasserstein距离替代JS散度来优化生成对抗网络的模型。  \n- 1st－Wasserstein距离定义为真实分布 $p_{r}$ 和模型分布 $p_{\\theta}$ 之间的最小期望距离，通过联合分布 $\\gamma$ 来计算。  \n- Wasserstein距离能够衡量两个无重叠分布之间的距离，而JS散度在此情况下无法反映实际距离。"
      },
      {
        "段落": "## 数学小知识 I Lipschitz 连续函数\n\n在数学中，对于一个实数函数 $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ ，如果满足函数曲线上任意两点连线的斜率一致有界，即任意两点的斜率都小于常数 $K>0$ ，\n\n$$\n\\begin{equation*}\n\\left|f\\left(x_{1}\\right)-f\\left(x_{2}\\right)\\right| \\leq K\\left|x_{1}-x_{2}\\right| \\tag{13.51}\n\\end{equation*}\n$$\n\n则函数 $f$ 就称为 $K$－Lipschitz 连续函数，$K$ 称为 Lipschitz 常数．\nLipschitz 连续要求函数在无限的区间上不能有超过线性的增长．如果一个函数可导，并满足 Lipschitz 连续，那么导数有界。如果一个函数可导，并且导数有界，那么函数为 Lipschitz 连续。\n\n两个分布 $p_{r}$ 和 $p_{\\theta}$ 的1st－Wasserstein距离通常难以直接计算，但是两个分布的 1st－Wasserstein 距离有一个对偶形式：\n\n$$\n\\begin{equation*}\n\\boldsymbol{W}^{1}\\left(p_{r}, p_{\\Theta}\\right)=\\sup _{\\|f\\|_{L} \\leq 1}\\left(\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}}[f(\\boldsymbol{x})]-\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}}[f(\\boldsymbol{x})]\\right) \\tag{13.52}\n\\end{equation*}\n$$\n\n其中 $f: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ 为1－Lipschitz函数，满足\n\n$$\n\\begin{equation*}\n\\|f\\|_{L} \\triangleq \\sup _{\\boldsymbol{x} \\neq \\boldsymbol{y}} \\frac{|f(\\boldsymbol{x})-f(\\boldsymbol{y})|}{|\\boldsymbol{x}-\\boldsymbol{y}|} \\leq 1 \\tag{13.53}\n\\end{equation*}\n$$\n\n公式（13．52）称为Kantorovich－Rubinstein对偶定理．\n根据 Kantorovich－Rubinstein 对偶定理，两个分布 $p_{r}$ 和 $p_{\\theta}$ 之间的 1st－Wasser－ stein 距离可以转换为一个满足 1－Lipschitz 连续的函数在分布 $p_{r}$ 和 $p_{\\theta}$ 下期望的差的上界．通常情况下， 1 －Lipschitz 连续的约束可以宽松为 K－Lipschitz 连续．这样分布 $p_{r}$ 和 $p_{\\theta}$ 之间的 1st－Wasserstein 距离为\n\n$$\n\\begin{equation*}\n\\boldsymbol{W}^{1}\\left(p_{r}, p_{\\theta}\\right)=\\frac{1}{K} \\sup _{\\|f\\|_{L} \\leq K}\\left(\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}}[f(\\boldsymbol{x})]-\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\theta}}[f(\\boldsymbol{x})]\\right) . \\tag{13.54}\n\\end{equation*}\n$$\n\nWasserstein 距 离 也 称为推土机距离，参见第 E．3．4节。\n\n参见习题13－5．\n\n评价网络 然而，要计算公式（13．54）中的上界也并不容易。根据神经网络的通用近似定理，我们可以假设存在一个神经网络使得可以达到这个上界。令 $f(\\boldsymbol{x} ; \\phi)$ 为一个神经网络，假设存在参数集合 $\\Phi$ ，对于所有的 $\\phi \\in \\Phi, f(\\boldsymbol{x} ; \\phi)$ 为 K－Lipschitz连续函数，那么公式（13．54）中的上界可以近似转换为\n\n$$\n\\begin{equation*}\n\\max _{\\phi \\in \\Phi}\\left(\\mathbb{E}_{x \\sim p_{r}}[f(\\boldsymbol{x} ; \\phi)]-\\mathbb{E}_{x \\sim p_{\\theta}}[f(\\boldsymbol{x} ; \\phi)]\\right) \\tag{13.55}\n\\end{equation*}\n$$\n\n其中 $f(\\boldsymbol{x} ; \\phi)$ 称为评价网络（Critic Network）。和标准GAN中的判别网络的值域为 $[0,1]$ 不同，评价网络 $f(\\boldsymbol{x} ; \\phi)$ 的最后一层为线性层，其值域没有限制。这样只需要找到一个网络 $f(\\boldsymbol{x} ; \\phi)$ 使其在两个分布 $p_{r}$ 和 $p_{\\theta}$ 下的期望的差最大。即对于真实样本，$f(\\boldsymbol{x} ; \\phi)$ 的打分要尽可能高；对于模型生成的样本，$f(\\boldsymbol{x} ; \\phi)$ 的打分要尽可能低。\n\n为了使得 $f(\\boldsymbol{x} ; \\phi)$ 满足 K－Lipschitz 连续，一种近似的方法是限制参数的取值范围。因为神经网络为连续可导函数，满足 K－Lipschitz 连续可以近似为其关于 $\\boldsymbol{x}$的偏导数的模 $\\left\\|\\frac{\\partial f(x ; \\phi)}{\\partial x}\\right\\|$ 小于某个上界。由于这个偏导数的大小一般和参数的取值范围相关，我们可以通过限制参数 $\\phi$ 的取值范围来近似，令 $\\phi \\in[-c, c], c$ 为一个比较小的正数，比如 0.01 。\n\n生成网络 生成网络的目标是使得评价网络 $f(\\boldsymbol{x} ; \\phi)$ 对其生成样本的打分尽可能高，即\n\n$$\n\\begin{equation*}\n\\max _{\\theta} \\mathbb{E}_{z \\sim p(z)}[f(G(z ; \\theta) ; \\phi)] . \\tag{13.56}\n\\end{equation*}\n$$\n\n因为 $f(\\boldsymbol{x} ; \\phi)$ 为不饱和函数，所以生成网络参数 $\\theta$ 的梯度不会消失，理论上解决了原始 GAN 训练不稳定的问题．并且 W－GAN 中生成网络的目标函数不再是两个分布的比率，在一定程度上缓解了模型坍塌问题，使得生成的样本具有多样性．\n\n算法13．2给出W－GAN的训练过程．和原始 GAN 相比，W－GAN 的评价网络最后一层不使用 Sigmoid 函数，损失函数不取对数．",
        "总结": "- Lipschitz 连续函数定义：函数满足任意两点间斜率绝对值不超过常数 K，即 |f(x₁) - f(x₂)| ≤ K|x₁ - x₂|，K 称为 Lipschitz 常数。  \n- 1st-Wasserstein 距离的对偶形式：通过 1-Lipschitz 函数在两个分布下的期望差的上界表示，即 W¹(p_r, p_θ) = sup_{∥f∥_L ≤ 1} (E_{x~p_r}[f(x)] - E_{x~p_θ}[f(x)])。  \n- Kantorovich-Rubinstein 对偶定理：将 1st-Wasserstein 距离转换为满足 1-Lipschitz 条件的函数期望差的上界。  \n- K-Lipschitz 连续放宽：允许函数为 K-Lipschitz 连续，公式变为 W¹(p_r, p_θ) = (1/K) sup_{∥f∥_L ≤ K} (E_{x~p_r}[f(x)] - E_{x~p_θ}[f(x)])。  \n- 评价网络（Critic Network）：用于近似计算上界，其目标是最大化真实样本与生成样本在分布下的期望差。  \n- 评价网络设计：最后一层为线性层，值域不限制，需满足 K-Lipschitz 连续，可通过限制参数范围实现。  \n- 生成网络目标：最大化评价网络对生成样本的评分，即 E_z~p(z)[f(G(z;θ);φ)]。  \n- W-GAN 训练优势：避免梯度消失问题，缓解模型坍塌，提升样本多样性；评价网络不使用 Sigmoid 函数，损失函数不取对数。"
      },
      {
        "段落": "## 13.4 总结和深入阅读\n\n深度生成模型是一种有机融合神经网络和概率图模型的生成模型，将神经网络作为一个概率分布的逼近器，可以拟合非常复杂的数据分布。\n\n变分自编码器是一个非常典型的深度生成模型，利用神经网络的拟合能力来有效地解决含隐变量的概率模型中后验分布难以估计的问题［Kingma et al．， 2014；Rezende et al．，2014］．变分自编码器的详尽介绍可以参考文献［Doersch， 2016］．［Bowman et al．，2016］进一步将变分自编码器应用于序列生成问题．再参数化是变分自编码器的重要技巧。对于离散变量的再参数化，可以使用 Gumbel－ Softmax 方法［Jang et al．，2017］．\nhttps：／／nndl．github．io／\n\n这里忽略了常数 $\\frac{1}{K}$ ，并不影响网络的优化．\n\n```\n算法 13.2: W-GAN 的训练过程\n    输入: 训练集 $\\mathcal{D}$, 对抗训练迭代次数 $T$, 每次评价网络的训练迭代次数 $K$, 小批\n            量样本数量 $M$, 参数限制大小 $c$;\n    随机初始化 $\\theta, \\phi$;\n    for $t \\leftarrow 1$ to $T$ do\n        // 训练评价网络 $f(\\boldsymbol{x} ; \\boldsymbol{\\phi})$\n        for $k \\leftarrow 1$ to $K$ do\n            // 采集小批量训练样本\n            从训练集 $\\mathcal{D}$ 中采集 $M$ 个样本 $\\left\\{\\boldsymbol{x}^{(m)}\\right\\}, 1 \\leq m \\leq M$;\n            从分布 $\\mathcal{N}(\\mathbf{0}, \\boldsymbol{I})$ 中采集 $M$ 个样本 $\\left\\{\\boldsymbol{z}^{(m)}\\right\\}, 1 \\leq m \\leq M$;\n            // 计算评价网络参数 $\\phi$ 的梯度\n            $g_{\\phi}=\\frac{\\partial}{\\partial \\phi}\\left[\\frac{1}{M} \\sum_{m=1}^{M}\\left(f\\left(\\boldsymbol{x}^{(m)} ; \\phi\\right)-f\\left(G\\left(\\boldsymbol{z}^{(m)} ; \\theta\\right) ; \\phi\\right)\\right)\\right] ;$\n            // 使用 RMSProp 算法更新 $\\phi$\n            $\\phi \\leftarrow \\phi+\\alpha \\cdot \\operatorname{RMSProp}\\left(\\phi, g_{\\phi}\\right) ;$\n            // 梯度截断\n            $\\phi \\leftarrow \\operatorname{clip}(\\phi,-c, c) ;$\n        end\n        // 训练生成网络 $G(\\boldsymbol{z} ; \\boldsymbol{\\theta})$\n        从分布 $\\mathcal{N}(\\mathbf{0}, \\boldsymbol{I})$ 中采集 $M$ 个样本 $\\left\\{\\boldsymbol{z}^{(m)}\\right\\}, 1 \\leq m \\leq M$;\n        // 更新生成网络参数 $\\theta$\n        $g_{\\theta}=\\frac{\\partial}{\\partial \\theta}\\left[\\frac{1}{M} \\sum_{m=1}^{M} f\\left(G\\left(\\boldsymbol{z}^{(m)} ; \\theta\\right) ; \\phi\\right)\\right] ;$\n        $\\theta \\leftarrow \\theta+\\alpha \\cdot \\operatorname{RMSProp}\\left(\\theta, g_{\\theta}\\right) ;$\n    end\n    输出: 生成网络 $G(z ; \\theta)$\n```\n\n生成对抗网络［Goodfellow et al．，2014］是一个具有开创意义的深度生成模型，突破了以往的概率模型必须通过最大似然估计来学习参数的限制．然而，生成对抗网络的训练通常比较困难。DCGAN［Radford et al．，2016］是一个生成对抗网络的成功实现，可以生成十分逼真的自然图像．［Yu et al．，2017］进一步在文本生成任务上结合生成对抗网络和强化学习来建立文本生成模型。对抗生成网络的训练不稳定问题的一种有效解决方法是 W－GAN［Arjovsky et al．，2017］，通过用 Wasserstein 距离替代 JS 散度来进行训练。\n\n虽然深度生成模型取得了巨大的成功，但是作为一种无监督模型，其主要的缺点是缺乏有效的客观评价，很难客观衡量不同模型之间的优劣。",
        "总结": "- 深度生成模型：有机融合神经网络和概率图模型，利用神经网络逼近概率分布以拟合复杂数据分布。  \n- 变分自编码器（VAE）：通过神经网络解决含隐变量概率模型中后验分布难以估计的问题，常用于序列生成，离散变量可使用Gumbel-Softmax方法进行再参数化。  \n- W-GAN训练过程：包含训练评价网络和生成网络的交替过程，使用RMSProp优化，并通过梯度截断保证参数限制。  \n- 生成对抗网络（GAN）：突破传统概率模型依赖最大似然估计的限制，但训练不稳定，DCGAN是其成功实现，能生成逼真自然图像。  \n- W-GAN：通过Wasserstein距离替代JS散度，有效解决GAN训练不稳定问题。  \n- 深度生成模型的局限性：作为无监督模型，缺乏有效客观评价标准，难以客观比较不同模型性能。"
      },
      {
        "段落": "## 习题",
        "总结": "- 本节主要介绍了习题的相关内容，包括不同类型的题目及其解题思路。  \n- 提出了通过练习来巩固知识和提升解题能力的重要性。  \n- 给出了一些典型例题，并简要分析了解题的关键步骤。  \n- 强调了理解题目要求和审题的重要性。  \n- 提到了解题过程中常见的错误类型及避免方法。"
      },
      {
        "段落": "## 习题13－1 推导公式（13．28）。\n\n习题13－2 通过分析公式（13．28），给出变分自编码器和自编码器在内在机理上的不同之处。\n\n习题 13－3 对于一个分布为 $p_{\\theta}(z)$ 的离散随机变量 $z$ ，以及函数 $f(z)$ ，如何计算期望 $\\mathcal{L}(\\theta)=\\mathbb{E}_{z \\sim p_{\\theta}(z)}[f(z)]$ 关于分布参数 $\\theta$ 的导数。\n\n参见第13．2．5节．\n\n习题13－4 假设一个二分类问题，类别为 $c_{1}$ 和 $c_{2}$ ，样本 $\\boldsymbol{x}$ 在两个类的条件分布为 $p\\left(\\boldsymbol{x} \\mid c_{1}\\right)$ 和 $p\\left(\\boldsymbol{x} \\mid c_{2}\\right)$ ，一个分类器 $f(\\boldsymbol{x})=p\\left(c_{1} \\mid \\boldsymbol{x}\\right)$ 用于预测一个样本 $\\boldsymbol{x}$ 来自类别 $c_{1}$ 的后验概率。证明若采用交叉嫡损失，\n\n$$\n\\begin{equation*}\n\\mathcal{L}(f)=\\mathbb{E}_{\\boldsymbol{x} \\sim p\\left(\\boldsymbol{x} \\mid c_{1}\\right)}[\\log f(\\boldsymbol{x})]+\\mathbb{E}_{\\boldsymbol{x} \\sim p\\left(\\boldsymbol{x} \\mid c_{2}\\right)}[\\log (1-f(\\boldsymbol{x}))] \\tag{13.57}\n\\end{equation*}\n$$\n\n则最优分类器 $f^{\\star}(\\boldsymbol{x})$ 为\n\n$$\n\\begin{equation*}\nf^{\\star}(\\boldsymbol{x})=\\frac{p\\left(\\boldsymbol{x} \\mid c_{1}\\right)}{p\\left(\\boldsymbol{x} \\mid c_{1}\\right)+p\\left(\\boldsymbol{x} \\mid c_{2}\\right)} \\tag{13.58}\n\\end{equation*}\n$$\n\n习题13－5 分析下面函数是否满足 Lipschitz 连续条件．\n（1）$f:[-1,1] \\rightarrow \\mathbb{R}, f(x)=x^{2}$ ；\n（2）$f: \\mathbb{R} \\rightarrow \\mathbb{R}, f(x)=x^{2}$ ；\n（3）$f: \\mathbb{R} \\rightarrow \\mathbb{R}, f(x)=\\sqrt{x^{2}+1}$ ；\n（4）$f:[0,1] \\rightarrow[0,1], f(x)=\\sqrt{x}$ ．\n习题13－6 证明公式（13．54）．",
        "总结": "- 公式（13.28）的推导  \n- 变分自编码器与自编码器在内在机理上的不同之处：变分自编码器通过引入隐变量的分布来近似真实后验分布，而自编码器直接学习输入数据的重构  \n- 计算期望 $\\mathcal{L}(\\theta)=\\mathbb{E}_{z \\sim p_{\\theta}(z)}[f(z)]$ 关于参数 $\\theta$ 的导数：利用链式法则对分布参数 $\\theta$ 进行求导  \n- 二分类问题中，采用交叉熵损失时最优分类器的推导：通过最小化交叉熵损失函数，证明最优分类器为 $f^{\\star}(\\boldsymbol{x})=\\frac{p\\left(\\boldsymbol{x} \\mid c_{1}\\right)}{p\\left(\\boldsymbol{x} \\mid c_{1}\\right)+p\\left(\\boldsymbol{x} \\mid c_{2}\\right)}$  \n- 分析函数是否满足 Lipschitz 连续条件：分别判断各函数在定义域内是否满足 Lipschitz 条件  \n- 公式（13.54）的证明：推导并验证公式（13.54）的数学表达式"
      },
      {
        "段落": "## 参考文献\n\nArjovsky M，Chintala S，Bottou L．Wasserstein GAN［J／OL］．CoRR，2017，abs／1701．07875．http： ／／arxiv．org／abs／1701．07875．\nBowman S R，Vilnis L，Vinyals O，et al．Generating sentences from a continuous space［C／OL］／／ Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning．2016：\n10－21．https：／／www．aclweb．org／anthology／K16－1002／．\nDoersch C．Tutorial on variational autoencoders［J／OL］．CoRR，2016，abs／1606．05908．http：／／arxiv． org／abs／1606．05908．\nGoodfellow I，Pouget－Abadie J，Mirza M，et al．Generative adversarial nets［C］／／Advances in Neural Information Processing Systems．2014：2672－2680．\nJang E，Gu S，Poole B．Categorical reparameterization with gumbel－softmax［C／OL］／／Proceedings of 5th International Conference on Learning Representations．2017．https：／／openreview．net／ forum？id＝rkE3y85ee．\nhttps：／／nndl．github．io／\n\nKingma D P，Welling M．Auto－encoding variational bayes［C／OL］／／Proceedings of 2nd International Conference on Learning Representations．2014．http：／／arxiv．org／abs／1312．6114．\nRadford A，Metz L，Chintala S．Unsupervised representation learning with deep convolutional generative adversarial networks［C／OL］／／Proceedings of 4th International Conference on Learning Representations．2016．http：／／arxiv．org／abs／1511．06434．\nRezende D J，Mohamed S，Wierstra D．Stochastic backpropagation and approximate inference in deep generative models［J］．arXiv preprint arXiv：1401．4082， 2014.\nYu L，Zhang W，Wang J，et al．SeqGAN：Sequence generative adversarial nets with policy gradient ［C］／／Proceedings of Thirty－First AAAI Conference on Artificial Intelligence．2017：2852－2858．",
        "总结": "- 参考文献部分列出了多个与生成对抗网络（GAN）、变分自编码器（VAE）以及序列生成相关的研究论文和教程。  \n- Arjovsky等人提出了Wasserstein GAN，用于改进传统GAN的训练稳定性。  \n- Bowman等人研究了从连续空间生成句子的方法，属于序列生成领域。  \n- Doersch提供了变分自编码器的教程，介绍了其基本原理和应用。  \n- Goodfellow等人提出了生成对抗网络（GAN）的基本框架，是深度学习生成模型的重要突破。  \n- Jang等人提出了Gumbel-Softmax方法，用于处理离散随机变量的可微近似。  \n- Kingma和Welling提出了变分自编码器的自动编码变分贝叶斯方法，是VAE的奠基性工作。  \n- Radford等人使用深度卷积生成对抗网络进行无监督表示学习，推动了图像生成的发展。  \n- Rezende等人研究了深度生成模型中的随机反向传播和近似推理方法。  \n- Yu等人提出了SeqGAN，结合策略梯度方法用于序列生成任务。"
      }
    ]
  },
  {
    "标题": "第14章 深度强化学习",
    "内容": [
      {
        "段落": "# 第14章 深度强化学习",
        "总结": "- 概念：深度强化学习结合了深度学习与强化学习，利用深度神经网络来近似策略或价值函数，以处理高维状态和动作空间的问题。  \n- 算法：介绍了深度Q网络（DQN）、策略梯度方法（如Actor-Critic）以及近端策略优化（PPO）等算法。  \n- 定理或命题：提出了策略梯度定理，说明了如何通过梯度上升来优化策略，以最大化期望回报。  \n- 数学推导：推导了策略梯度定理的数学表达式，并讨论了如何通过经验回放和目标网络来稳定训练过程。"
      },
      {
        "段落": "#### Abstract\n\n除了试图直接去建立一个可以模拟成人大脑的程序之外，为什么不试图建立一个可以模拟小孩大脑的程序呢？如果它接受适当的教育，就可能成长为成人的大脑。\n\n\n—阿兰•图灵（Alan Turing）\n\n在之前的章节中，我们主要关注于监督学习，而监督学习一般需要一定数量的带标签的数据。在很多的应用场景中，通过人工标注的方式来给数据打标签的方式往往行不通。比如我们通过监督学习来训练一个模型可以自动下围棋，就需要将当前棋盘的状态作为输入数据，其对应的最佳落子位置（动作）作为标签。训练一个好的模型就需要收集大量的不同棋盘状态以及对应动作。这种做法实践起来比较困难，一是对于每一种棋盘状态，即使是专家也很难给出＂正确＂的动作，二是获取大量数据的成本往往比较高。对于下棋这类任务，虽然我们很难知道每一步的＂正确＂动作，但是其最后的结果（即赢输）却很容易判断。因此，如果可以通过大量的模拟数据，通过最后的结果（奖励）来倒推每一步棋的好坏，从而学习出＂最佳＂的下棋策略，这就是强化学习。\n\n强化学习（Reinforcement Learning，RL），也叫增强学习，是指一类从（与环境）交互中不断学习的问题以及解决这类问题的方法。强化学习问题可以描述为一个智能体从与环境的交互中不断学习以完成特定目标（比如取得最大奖励值）。和深度学习类似，强化学习中的关键问题也是贡献度分配问题［Minsky， 1961］，每一个动作并不能直接得到监督信息，需要通过整个模型的最终监督信息 （奖励）得到，并且有一定的延时性。\n\n强化学习也是机器学习中的一个重要分支．强化学习和监督学习的不同在于，强化学习问题不需要给出＂正确＂策略作为监督信息，只需要给出策略的（延迟）回报，并通过调整策略来取得最大化的期望回报。\n\n贡献度分配问题即一个系统中不同的组件 （component）对最终系统输出结果的贡献或影响。",
        "总结": "- 强化学习（Reinforcement Learning，RL）是一种通过与环境交互来学习完成特定目标的方法，其核心是通过最终的奖励来倒推每一步动作的好坏，从而学习出最佳策略。  \n- 强化学习与监督学习不同，它不需要提供“正确”的策略作为监督信息，而是通过延迟的回报（奖励）来调整策略以最大化期望回报。  \n- 贡献度分配问题是强化学习中的关键问题，指的是系统中不同组件对最终结果的贡献或影响。  \n- 强化学习问题可以描述为智能体在与环境交互中不断学习以取得最大奖励值。  \n- 该小节提出的核心概念是强化学习及其基本思想，即通过奖励机制来学习最优策略。"
      },
      {
        "段落": "## 14.1 强化学习问题\n\n强化学习广泛应用于很多领域，比如电子游戏、棋类游戏、迷宫类游戏、控制系统、推荐等。这里我们介绍几个比较典型的强化学习例子。",
        "总结": "- 强化学习的应用领域包括电子游戏、棋类游戏、迷宫类游戏、控制系统和推荐系统等。  \n- 本节介绍了几个典型的强化学习应用实例，以帮助读者理解其实际应用场景。"
      },
      {
        "段落": "## 14．1．1 典型例子\n\n多臂赌博机问题 给定 $K$ 个赌博机，拉动每个赌博机的拉杆（Arm），赌博机会按照一个事先设定的概率掉出一块钱或不掉钱。每个赌博机掉钱的概率不一样。多臂赌博机问题（Multi－Armed Bandit Problem）是指，给定有限的机会次数 $T$ ，如何玩这些赌博机才能使得期望累积收益最大化．多臂赌博机问题在广告推荐、投资组合等领域有着非常重要的应用。\n\n悬崖行走问题 在一个网格世界（Grid World）中，每个格子表示一个状态。如图14．1所示的一个网格世界，每个状态为 $(i, j), 1 \\leq i \\leq 7,1 \\leq j \\leq 3$ ，其中格子 $(2,1)$ 到 $(6,1)$ 是悬崖（Cliff）。有一个醉汉，从左下角的开始位置 $S$ ，走到右下角的目标位置 $E$ 。如果走到悬崖，醉汉会跌落悬崖并死去。醉汉可以选择行走的路线，即在每个状态时，选择行走的方向：上下左右。动作空间 $\\mathcal{A}=\\{\\uparrow, \\downarrow, \\leftarrow, \\rightarrow\\}$ 。但每走一步，都有一定的概率滑落到周围其他格子。醉汉的目标是如何安全地到达目标位置。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-342.jpg?height=318&width=678&top_left_y=1174&top_left_x=323)\n\n图14．1悬崖行走问题",
        "总结": "- 多臂赌博机问题：描述了在有限机会次数下，如何通过选择不同赌博机以最大化期望累积收益的问题，广泛应用于广告推荐和投资组合等领域。  \n- 悬崖行走问题：在一个网格世界中，醉汉从起点出发，需选择行走方向以安全到达目标位置，避免跌落悬崖，动作空间包含上下左右四个方向，每步有概率滑落到其他格子。"
      },
      {
        "段落": "## 14．1．2 强化学习定义\n\n现在我们描述强化学习的任务定义．在强化学习中，有两个可以进行交互的对象：智能体和环境。\n（1）智能体（Agent）可以感知外界环境的状态（State）和反馈的奖励（Re－ ward），并进行学习和决策。\n\n智能体的决策功能是指根据外界环境的状态来做出不同的动作（Action），而学习功能是指根据外界环境的奖励来调整策略。\n（2）环境（Environment）是智能体外部的所有事物，并受智能体动作的影响而改变其状态，并反馈给智能体相应的奖励。\n\n强化学习的基本要素包括：\n（1）状态 $s$ 是对环境的描述，可以是离散的或连续的，其状态空间为 $\\mathcal{S}$ 。\n（2）动作 $a$ 是对智能体行为的描述，可以是离散的或连续的，其动作空间为 $\\mathcal{A}$ 。\n（3）策略 $\\pi(a \\mid s)$ 是智能体根据环境状态 $s$ 来决定下一步动作 $a$ 的函数．\n（4）状态转移概率 $p\\left(s^{\\prime} \\mid s, a\\right)$ 是在智能体根据当前状态 $s$ 做出一个动作 $a$ 之后，环境在下一个时刻转变为状态 $s^{\\prime}$ 的概率。\n（5）即时奖励 $r\\left(s, a, s^{\\prime}\\right)$ 是一个标量函数，即智能体根据当前状态 $s$ 做出动作 $a$ 之后，环境会反馈给智能体一个奖励，这个奖励也经常和下一个时刻的状态 $s^{\\prime}$有关。\n\n策略 智能体的策略（Policy）就是智能体如何根据环境状态 $s$ 来决定下一步的动作 $a$ ，通常可以分为确定性策略（Deterministic Policy）和随机性策略（Sto－ chastic Policy）两种。\n\n确定性策略是从状态空间到动作空间的映射函数 $\\pi: \\mathcal{S} \\rightarrow \\mathcal{A}$ 。随机性策略表示在给定环境状态时，智能体选择某个动作的概率分布。\n\n$$\n\\begin{align*}\n\\pi(a \\mid s) & \\triangleq p(a \\mid s)  \\tag{14.1}\\\\\n\\sum_{a \\in \\mathcal{A}} \\pi(a \\mid s) & =1 \\tag{14.2}\n\\end{align*}\n$$\n\n通常情况下，强化学习一般使用随机性策略．随机性策略可以有很多优点：一是在学习时可以通过引入一定随机性更好地探索环境；二是随机性策略的动作具有多样性，这一点在多个智能体博亦时也非常重要。采用确定性策略的智能体总是对同样的环境做出相同的动作，会导致它的策略很容易被对手预测。",
        "总结": "- 强化学习的任务定义涉及智能体与环境的交互，其中智能体感知环境状态和奖励，并进行学习和决策；环境则根据智能体的动作改变状态并反馈奖励。  \n- 强化学习的基本要素包括状态、动作、策略、状态转移概率和即时奖励。  \n- 策略是智能体根据环境状态决定动作的函数，分为确定性策略和随机性策略两种。  \n- 确定性策略是状态到动作的映射，而随机性策略则表示在给定状态时选择动作的概率分布。  \n- 随机性策略在学习中能通过引入随机性更好地探索环境，并且在多智能体博弈中具有动作多样性优势。"
      },
      {
        "段落": "## 14．1．3 马尔可夫决策过程\n\n为简单起见，我们将智能体与环境的交互看作是离散的时间序列。智能体从感知到的初始环境 $s_{0}$ 开始，然后决定做一个相应的动作 $a_{0}$ ，环境相应地发生改变到新的状态 $s_{1}$ ，并反馈给智能体一个即时奖励 $r_{1}$ ，然后智能体又根据状态 $s_{1}$ 做一个动作 $a_{1}$ ，环境相应改变为 $s_{2}$ ，并反馈奖励 $r_{2}$ 。这样的交互可以一直进行下去。\n\n$$\n\\begin{equation*}\ns_{0}, a_{0}, s_{1}, r_{1}, a_{1}, \\cdots, s_{t-1}, r_{t-1}, a_{t-1}, s_{t}, r_{t}, \\cdots, \\tag{14.3}\n\\end{equation*}\n$$\n\n其中 $r_{t}=r\\left(s_{t-1}, a_{t-1}, s_{t}\\right)$ 是第 $t$ 时刻的即时奖励．图14．2给出了智能体与环境的交互．\nhttps：／／nndl．github．io／\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-344.jpg?height=322&width=664&top_left_y=122&top_left_x=328)\n\n图 14.2 智能体与环境的交互\n\n智能体与环境的交互过程可以看作是一个马尔可夫决策过程．\n马尔可夫过程（Markov Process）是一组具有马尔可夫性质的随机变量序列 $s_{0}, s_{1}, \\cdots, s_{t} \\in \\mathcal{S}$ ，其中下一个时刻的状态 $s_{t+1}$ 只取决于当前状态 $s_{t}$ ，\n\n$$\n\\begin{equation*}\np\\left(s_{t+1} \\mid s_{t}, \\cdots, s_{0}\\right)=p\\left(s_{t+1} \\mid s_{t}\\right) \\tag{14.4}\n\\end{equation*}\n$$\n\n其中 $p\\left(s_{t+1} \\mid s_{t}\\right)$ 称为状态转移概率，$\\sum_{s_{t+1} \\in \\mathcal{S}} p\\left(s_{t+1} \\mid s_{t}\\right)=1$ ．\n\n马尔可夫过程参见第 D．3．1节．\n\n马尔可夫决策过程（Markov Decision Process，MDP）在马尔可夫过程中加入一个额外的变量：动作 $a$ ，即下一个时刻的状态 $s_{t+1}$ 和当前时刻的状态 $s_{t}$ 以及动作 $a_{t}$ 相关，\n\n$$\n\\begin{equation*}\np\\left(s_{t+1} \\mid s_{t}, a_{t}, \\cdots, s_{0}, a_{0}\\right)=p\\left(s_{t+1} \\mid s_{t}, a_{t}\\right), \\tag{14.5}\n\\end{equation*}\n$$\n\n其中 $p\\left(s_{t+1} \\mid s_{t}, a_{t}\\right)$ 为状态转移概率．\n给定策略 $\\pi(a \\mid s)$ ，马尔可夫决策过程的一个轨迹（Trajectory）\n\n$$\n\\tau=s_{0}, a_{0}, s_{1}, r_{1}, a_{1}, \\cdots, s_{T-1}, a_{T-1}, s_{T}, r_{T}\n$$\n\n的概率为\n\n$$\n\\begin{align*}\np(\\tau) & =p\\left(s_{0}, a_{0}, s_{1}, a_{1}, \\cdots\\right)  \\tag{14.6}\\\\\n& =p\\left(s_{0}\\right) \\prod_{t=0}^{T-1} \\pi\\left(a_{t} \\mid s_{t}\\right) p\\left(s_{t+1} \\mid s_{t}, a_{t}\\right) \\tag{14.7}\n\\end{align*}\n$$\n\n图14．3给出了马尔可夫决策过程的图模型表示．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-345.jpg?height=316&width=1063&top_left_y=116&top_left_x=124)\n\n图14．3马尔可夫决策过程",
        "总结": "- 马尔可夫决策过程（MDP）被引入，用于描述智能体与环境的交互过程。  \n- MDP在马尔可夫过程中加入了动作变量，状态转移概率依赖于当前状态和动作。  \n- 轨迹的概率由初始状态、策略和状态转移概率共同决定。  \n- 状态转移概率 $p(s_{t+1} \\mid s_t, a_t)$ 描述了在给定当前状态和动作下，下一状态的分布。  \n- 轨迹的概率公式为 $p(\\tau) = p(s_0) \\prod_{t=0}^{T-1} \\pi(a_t \\mid s_t) p(s_{t+1} \\mid s_t, a_t)$。  \n- 图14.3展示了马尔可夫决策过程的图模型表示。"
      },
      {
        "段落": "## 14．1．4 强化学习的目标函数",
        "总结": "- 提出了强化学习中的目标函数，即策略评估的核心任务是最大化累积奖励。  \n- 目标函数通常表示为从初始状态开始，按照策略π执行动作所获得的期望回报。  \n- 引入了折扣因子γ，用于平衡当前奖励与未来奖励的重要性。  \n- 通过数学推导，将目标函数表示为状态价值函数Vπ(s)和动作价值函数Qπ(s, a)的形式。  \n- 强调了目标函数在策略优化和学习过程中的关键作用。"
      },
      {
        "段落": "### 14．1．4．1 总回报\n\n给定策略 $\\pi(a \\mid s)$ ，智能体和环境一次交互过程的轨迹 $\\tau$ 所收到的累积奖励为总回报（Return）。\n\n$$\n\\begin{align*}\nG(\\tau) & =\\sum_{t=0}^{T-1} r_{t+1}  \\tag{14.8}\\\\\n& =\\sum_{t=0}^{T-1} r\\left(s_{t}, a_{t}, s_{t+1}\\right) \\tag{14.9}\n\\end{align*}\n$$\n\n假设环境中有一个或多个特殊的终止状态（Terminal State），当到达终止状态时，一个智能体和环境的交互过程就结束了。这一轮交互的过程称为一个回合 （Episode）或试验（Trial）。一般的强化学习任务（比如下棋、游戏）都属于这种回合式任务（Episodic Task）。\n\n如果环境中没有终止状态（比如终身学习的机器人），即 $T=\\infty$ ，称为持续式任务（Continuing Task），其总回报也可能是无穷大。为了解决这个问题，我们可以引入一个折扣率来降低远期回报的权重。折扣回报（Discounted Return）定义为\n\n$$\n\\begin{equation*}\nG(\\tau)=\\sum_{t=0}^{T-1} \\gamma^{t} r_{t+1} \\tag{14.10}\n\\end{equation*}\n$$\n\n其中 $\\gamma \\in[0,1]$ 是折扣率．当 $\\gamma$ 接近于 0 时，智能体更在意短期回报；而当 $\\gamma$ 接近于 1 时，长期回报变得更重要．",
        "总结": "- 总回报（Return）定义为智能体在一次交互过程中所获得的累积奖励，表示为 $ G(\\tau) = \\sum_{t=0}^{T-1} r_{t+1} $。\n- 总回报也可以表示为状态、动作和下一状态的奖励函数之和，即 $ G(\\tau) = \\sum_{t=0}^{T-1} r(s_t, a_t, s_{t+1}) $。\n- 当环境中存在终止状态时，一次完整的交互过程称为一个回合（Episode）或试验（Trial）。\n- 对于没有终止状态的持续式任务（Continuing Task），总回报可能为无穷大，因此引入折扣率 $\\gamma$ 来降低远期回报的权重。\n- 折扣回报（Discounted Return）定义为 $ G(\\tau) = \\sum_{t=0}^{T-1} \\gamma^t r_{t+1} $，其中 $\\gamma \\in [0,1]$ 是折扣率。\n- 折扣率 $\\gamma$ 越小，智能体越关注短期回报；$\\gamma$ 越接近 1，长期回报的重要性越高。"
      },
      {
        "段落": "### 14．1．4．2 目标函数\n\n因为策略和状态转移都有一定的随机性，所以每次试验得到的轨迹是一个随机序列，其收获的总回报也不一样．强化学习的目标是学习到一个策略 $\\pi_{\\theta}(a \\mid s)$\n\n来最大化期望回报（Expected Return），即希望智能体执行一系列的动作来获得尽可能多的平均回报．\n\n强化学习的目标函数为\n\n$$\n\\begin{equation*}\n\\mathcal{J}(\\theta)=\\mathbb{E}_{\\tau \\sim p_{\\theta}(\\tau)}[G(\\tau)]=\\mathbb{E}_{\\tau \\sim p_{\\theta}(\\tau)}\\left[\\sum_{t=0}^{T-1} \\gamma^{t} r_{t+1}\\right] \\tag{14.11}\n\\end{equation*}\n$$\n\n其中 $\\theta$ 为策略函数的参数．",
        "总结": "- 目标函数用于最大化期望回报，即智能体通过执行动作获得尽可能多的平均回报。  \n- 目标函数定义为策略参数 $\\theta$ 的期望值，表示在策略 $\\pi_{\\theta}(a \\mid s)$ 下，轨迹 $\\tau$ 的总回报 $G(\\tau)$ 的期望。  \n- 总回报 $G(\\tau)$ 是折扣累积奖励，形式为 $\\sum_{t=0}^{T-1} \\gamma^{t} r_{t+1}$，其中 $\\gamma$ 为折扣因子，$r_{t+1}$ 为第 $t+1$ 步的即时奖励。  \n- 策略 $\\pi_{\\theta}(a \\mid s)$ 是一个参数化的策略函数，用于决定在状态 $s$ 下选择动作 $a$ 的概率。"
      },
      {
        "段落": "## 14．1．5 值函数\n\n为了评估策略 $\\pi$ 的期望回报，我们定义两个值函数：状态值函数和状态－动作值函数．",
        "总结": "- 值函数用于评估策略 $\\pi$ 的期望回报，包括状态值函数和状态－动作值函数。"
      },
      {
        "段落": "### 14．1．5．1 状态值函数\n\n策略 $\\pi$ 的期望回报可以分解为\n\n$$\n\\begin{align*}\n\\mathbb{E}_{\\tau \\sim p(\\tau)}[G(\\tau)] & =\\mathbb{E}_{s \\sim p\\left(s_{0}\\right)}\\left[\\mathbb{E}_{\\tau \\sim p(\\tau)}\\left[\\sum_{t=0}^{T-1} \\gamma^{t} r_{t+1} \\mid \\tau_{s_{0}}=s\\right]\\right]  \\tag{14.12}\\\\\n& =\\mathbb{E}_{s \\sim p\\left(s_{0}\\right)}\\left[V^{\\pi}(s)\\right] \\tag{14.13}\n\\end{align*}\n$$\n\n其中 $V^{\\pi}(s)$ 称为状态值函数（State Value Function），表示从状态 $s$ 开始，执行策略 $\\pi$ 得到的期望总回报\n\n$$\n\\begin{equation*}\nV^{\\pi}(s)=\\mathbb{E}_{\\tau \\sim p(\\tau)}\\left[\\sum_{t=0}^{T-1} \\gamma^{t} r_{t+1} \\mid \\tau_{s_{0}}=s\\right] \\tag{14.14}\n\\end{equation*}\n$$\n\n其中 $\\tau_{s_{0}}$ 表示轨迹 $\\tau$ 的起始状态。\n为了方便起见，我们用 $\\tau_{0: T}$ 来表示轨迹 $s_{0}, a_{0}, s_{1}, \\cdots, s_{T}$ ，用 $\\tau_{1: T}$ 来表示轨迹 $s_{1}, a_{1}, \\cdots, s_{T}$ ，因此有 $\\tau_{0: T}=s_{0}, a_{0}, \\tau_{1: T}$ 。\n\n根据马尔可夫性质，$V^{\\pi}(s)$ 可展开得到\n\n$$\n\\begin{align*}\n& V^{\\pi}(s)=\\mathbb{E}_{\\tau_{0: T} \\sim p(\\tau)}\\left[r_{1}+\\gamma \\sum_{t=1}^{T-1} \\gamma^{t-1} r_{t+1} \\mid \\tau_{S_{0}}=s\\right]  \\tag{14.15}\\\\\n& =\\mathbb{E}_{a \\sim \\pi(a \\mid s)} \\mathbb{E}_{S^{\\prime} \\sim p\\left(s^{\\prime} \\mid s, a\\right)} \\mathbb{E}_{\\tau_{1: T} \\sim p(\\tau)}\\left[r\\left(s, a, s^{\\prime}\\right)+\\gamma \\sum_{t=1}^{T-1} \\gamma^{t-1} r_{t+1} \\mid \\tau_{S_{1}}=s^{\\prime}\\right]  \\tag{14.16}\\\\\n& =\\mathbb{E}_{a \\sim \\pi(a \\mid s)} \\mathbb{E}_{S^{\\prime} \\sim p\\left(s^{\\prime} \\mid s, a\\right)}\\left[r\\left(s, a, s^{\\prime}\\right)+\\gamma \\mathbb{E}_{\\tau_{1: T} \\sim p(\\tau)}\\left[\\sum_{t=1}^{T-1} \\gamma^{t-1} r_{t+1} \\mid \\tau_{S_{1}}=s^{\\prime}\\right]\\right]  \\tag{14.17}\\\\\n& =\\mathbb{E}_{a \\sim \\pi(a \\mid s)} \\mathbb{E}_{S^{\\prime} \\sim p\\left(S^{\\prime} \\mid s, a\\right)}\\left[r\\left(s, a, s^{\\prime}\\right)+\\gamma V^{\\pi}\\left(s^{\\prime}\\right)\\right] . \\tag{14.18}\n\\end{align*}\n$$\n\n公式（14．18）也称为贝尔曼方程（Bellman Equation），表示当前状态的值函数可以通过下个状态的值函数来计算．\n\n如果给定策略 $\\pi(a \\mid s)$ ，状态转移概率 $p\\left(s^{\\prime} \\mid s, a\\right)$ 和奖励 $r\\left(s, a, s^{\\prime}\\right)$ ，我们就可以通过迭代的方式来计算 $V^{\\pi}(s)$ 。由于存在折扣率，迭代一定步数后，每个状态的值函数就会固定不变．",
        "总结": "- 状态值函数 $V^{\\pi}(s)$ 定义为从状态 $s$ 开始，执行策略 $\\pi$ 的期望总回报。  \n- 状态值函数通过期望回报的分解，将策略的期望回报转化为对每个状态的期望值。  \n- 贝尔曼方程（Bellman Equation）表示当前状态的值函数可以通过下一个状态的值函数计算得出。  \n- 公式（14.18）是贝尔曼方程的具体形式，即 $V^{\\pi}(s) = \\mathbb{E}_{a \\sim \\pi(a \\mid s)} \\mathbb{E}_{s' \\sim p(s' \\mid s, a)} [r(s, a, s') + \\gamma V^{\\pi}(s')]$.  \n- 状态值函数可以通过迭代计算，当折扣率存在时，迭代一定步数后，每个状态的值函数会收敛到稳定值。"
      },
      {
        "段落": "### 14．1．5．2 状态－动作值函数\n\n公式（14．18）中的第二个期望是指初始状态为 $s$ 并进行动作 $a$ ，然后执行策略 $\\pi$ 得到的期望总回报，称为状态－动作值函数（State－Action Value Function），\n\n$$\n\\begin{equation*}\nQ^{\\pi}(s, a)=\\mathbb{E}_{s^{\\prime} \\sim p\\left(s^{\\prime} \\mid s, a\\right)}\\left[r\\left(s, a, s^{\\prime}\\right)+\\gamma V^{\\pi}\\left(s^{\\prime}\\right)\\right] \\tag{14.19}\n\\end{equation*}\n$$\n\n状态－动作值函数也经常称为 $Q$ 函数（Q－Function）。\n状态值函数 $V^{\\pi}(s)$ 是 Q 函数 $Q^{\\pi}(s, a)$ 关于动作 $a$ 的期望，\n\n$$\n\\begin{equation*}\nV^{\\pi}(s)=\\mathbb{E}_{a \\sim \\pi(a \\mid s)}\\left[Q^{\\pi}(s, a)\\right] \\tag{14.20}\n\\end{equation*}\n$$\n\n结合公式（14．19）和公式（14．20），Q函数可以写为\n\n$$\n\\begin{equation*}\nQ^{\\pi}(s, a)=\\mathbb{E}_{s^{\\prime} \\sim p\\left(s^{\\prime} \\mid s, a\\right)}\\left[r\\left(s, a, s^{\\prime}\\right)+\\gamma \\mathbb{E}_{a^{\\prime} \\sim \\pi\\left(a^{\\prime} \\mid s^{\\prime}\\right)}\\left[Q^{\\pi}\\left(s^{\\prime}, a^{\\prime}\\right)\\right]\\right] \\tag{14.21}\n\\end{equation*}\n$$\n\n这是关于 Q 函数的贝尔曼方程．",
        "总结": "- 状态-动作值函数（Q函数）定义为在状态s执行动作a后，遵循策略π的期望总回报。  \n- Q函数的数学表达式为 $Q^{\\pi}(s, a)=\\mathbb{E}_{s^{\\prime} \\sim p\\left(s^{\\prime} \\mid s, a\\right)}\\left[r\\left(s, a, s^{\\prime}\\right)+\\gamma V^{\\pi}\\left(s^{\\prime}\\right)\\right]$。  \n- 状态值函数 $V^{\\pi}(s)$ 是Q函数关于动作a的期望，表达式为 $V^{\\pi}(s)=\\mathbb{E}_{a \\sim \\pi(a \\mid s)}\\left[Q^{\\pi}(s, a)\\right]$。  \n- Q函数也可以通过结合状态值函数的定义，写成包含对下一状态和动作的期望形式。  \n- Q函数满足贝尔曼方程，这是其核心数学性质之一。"
      },
      {
        "段落": "### 14．1．5．3 值函数的作用\n\n值函数可以看作是对策略 $\\pi$ 的评估，因此我们就可以根据值函数来优化策略。假设在状态 $s$ ，有一个动作 $a^{*}$ 使得 $Q^{\\pi}\\left(s, a^{*}\\right)>V^{\\pi}(s)$ ，说明执行动作 $a^{*}$ 的回报比当前的策略 $\\pi(a \\mid s)$ 要高，我们就可以调整参数使得策略中动作 $a^{*}$ 的概率 $p\\left(a^{*} \\mid s\\right)$ 增加。",
        "总结": "- 值函数是对策略 $\\pi$ 的评估，用于优化策略。  \n- 在状态 $s$ 中，若存在动作 $a^{*}$ 使得 $Q^{\\pi}(s, a^{*}) > V^{\\pi}(s)$，说明该动作的回报高于当前策略的平均回报。  \n- 可通过调整策略参数，增加动作 $a^{*}$ 在状态 $s$ 下的概率 $p(a^{*} \\mid s)$。"
      },
      {
        "段落": "## 14．1．6 深度强化学习\n\n在强化学习中，一般需要建模策略 $\\pi(a \\mid s)$ 和值函数 $V^{\\pi}(s), Q^{\\pi}(s, a)$ 。早期的强化学习算法主要关注状态和动作都是离散且有限的问题，可以使用表格来记录这些概率。但在很多实际问题中，有些任务的状态和动作的数量非常多。比如围棋的棋局有 $3^{361} \\approx 10^{170}$ 种状态，动作（即落子位置）数量为 361 。还有些任务的状态和动作是连续的。比如在自动驾驶中，智能体感知到的环境状态是各种传感器数据，一般都是连续的。动作是操作方向盘的方向（ -90 度 $\\sim 90$ 度）和速度控制（ $0 \\sim 300$ 公里／小时），也是连续的。\n\n为了有效地解决这些问题，我们可以设计一个更强的策略函数（比如深度神经网络），使得智能体可以应对复杂的环境，学习更优的策略，并具有更好的泛化能力。\n\n深度强化学习（Deep Reinforcement Learning）是将强化学习和深度学习结合在一起，用强化学习来定义问题和优化目标，用深度学习来解决策略和值函数的建模问题，然后使用误差反向传播算法来优化目标函数。深度强化学习在一定程度上具备解决复杂问题的通用智能，并在很多任务上都取得了很大的成功．",
        "总结": "- 概念：深度强化学习是将强化学习与深度学习结合的方法，用于解决复杂问题。\n- 算法：使用深度神经网络建模策略和值函数，并通过误差反向传播算法优化目标函数。\n- 问题背景：传统强化学习适用于离散状态和动作，但面对大规模或连续状态与动作时存在局限。\n- 应用场景：如围棋、自动驾驶等需要处理大量状态和连续动作的任务。\n- 核心优势：通过深度学习提升策略的泛化能力和应对复杂环境的能力。"
      },
      {
        "段落": "## 14.2 基于值函数的学习方法\n\n值函数是对策略 $\\pi$ 的评估。如果策略 $\\pi$ 有限（即状态数和动作数都有限），可以对所有的策略进行评估并选出最优策略 $\\pi^{*}$ ．\n\n$$\n\\begin{equation*}\n\\forall s, \\quad \\pi^{*}=\\underset{\\pi}{\\arg \\max } V^{\\pi}(s) \\tag{14.22}\n\\end{equation*}\n$$\n\n但这种方式在实践中很难实现。假设状态空间 $\\mathcal{S}$ 和动作空间 $\\mathcal{A}$ 都是离散且有限的，策略空间为 $|\\mathcal{A}|^{|\\mathcal{S}|}$ ，往往也非常大。\n\n一种可行的方式是通过迭代的方法不断优化策略，直到选出最优策略．对于一个策略 $\\pi(a \\mid s)$ ，其 Q 函数为 $Q^{\\pi}(s, a)$ ，我们可以设置一个新的策略 $\\pi^{\\prime}(a \\mid s)$ ，\n\n$$\n\\pi^{\\prime}(a \\mid s)=\\left\\{\\begin{array}{ll}\n1 & \\text { if } a=\\arg \\max _{\\hat{a}} Q^{\\pi}(s, \\hat{a})  \\tag{14.23}\\\\\n0 & \\text { otherwise }\n\\end{array},\\right.\n$$\n\n即 $\\pi^{\\prime}(a \\mid s)$ 为一个确定性的策略，也可以直接写为\n\n$$\n\\begin{equation*}\n\\pi^{\\prime}(s)=\\underset{a}{\\arg \\max } Q^{\\pi}(s, a) . \\tag{14.24}\n\\end{equation*}\n$$\n\n如果执行 $\\pi^{\\prime}$ ，会有\n\n$$\n\\begin{equation*}\n\\forall s, \\quad V^{\\pi^{\\prime}}(s) \\geq V^{\\pi}(s) \\tag{14.25}\n\\end{equation*}\n$$\n\n根据公式（14．25），我们可以通过下面方式来学习最优策略：先随机初始化一个策略，计算该策略的值函数，并根据值函数来设置新的策略，然后一直反复迭代直到收敛。\n\n基于值函数的策略学习方法中最关键的是如何计算策略 $\\pi$ 的值函数，一般有动态规划或蒙特卡罗两种计算方式。",
        "总结": "- 值函数是对策略 $\\pi$ 的评估，用于衡量策略在状态 $s$ 下的预期回报。\n- 最优策略 $\\pi^{*}$ 是所有策略中使值函数 $V^{\\pi}(s)$ 最大的策略，即 $\\pi^{*} = \\arg \\max_{\\pi} V^{\\pi}(s)$。\n- 当状态空间和动作空间有限时，策略空间可能非常庞大，直接评估所有策略不可行。\n- 通过迭代优化策略，可以逐步逼近最优策略。新策略 $\\pi^{\\prime}$ 是基于当前策略 $\\pi$ 的 Q 函数确定的确定性策略。\n- 新策略 $\\pi^{\\prime}$ 满足 $V^{\\pi^{\\prime}}(s) \\geq V^{\\pi}(s)$，即其值函数不小于原策略的值函数。\n- 学习最优策略的方法是：初始化一个随机策略，计算其值函数，并根据值函数更新策略，反复迭代直至收敛。\n- 基于值函数的策略学习方法中，计算值函数是关键步骤，通常采用动态规划或蒙特卡罗方法。"
      },
      {
        "段落": "## 14．2．1 动态规划算法\n\n从贝尔曼方程可知，如果知道马尔可夫决策过程的状态转移概率 $p\\left(s^{\\prime} \\mid s, a\\right)$和奖励 $r\\left(s, a, s^{\\prime}\\right)$ ，我们直接可以通过贝尔曼方程来迭代计算其值函数。这种模型已知的强化学习算法也称为基于模型的强化学习（Model－Based Reinforcement Learning）算法，这里的模型就是指马尔可夫决策过程。\n\n在已知模型时，可以通过动态规划的方法来计算．常用的方法主要有策略迭代算法和值迭代算法。",
        "总结": "- 动态规划算法用于在已知马尔可夫决策过程的模型时计算值函数。  \n- 策略迭代算法和值迭代算法是动态规划的两种常用方法。  \n- 贝尔曼方程是计算值函数的基础，通过迭代方式求解。  \n- 基于模型的强化学习算法利用已知的状态转移概率和奖励函数进行学习。"
      },
      {
        "段落": "### 14．2．1．1 策略迭代算法\n\n策略迭代（Policy Iteration）算法中，每次迭代可以分为两步：\n（1）策略评估（Policy Evaluation）：计算当前策略下每个状态的值函数，即算法14．1中的3－6步．策略评估可以通过贝尔曼方程（公式（14．18））进行迭代计算 $V^{\\pi}(s)$ ．\n\n如果状态数有限，也可以通过直接求解贝尔曼方程来得到 $V^{\\pi}(s)$ ．\n（2）策略改进（Policy Improvement）：根据值函数来更新策略，即算法14．1中的7－8步．\n\n策略迭代算法如算法14．1所示．\n\n```\n算法 14.1: 策略迭代算法\n    输入: MDP 五元组: $\\mathcal{S}, \\mathcal{A}, P, r, \\gamma$;\n    初始化: $\\forall s, \\forall a, \\pi(a \\mid s)=\\frac{1}{|\\mathcal{A}|}$;\n    repeat\n        // 策略评估\n        repeat\n            根据贝尔曼方程 (公式 (14.18) ) , 计算 $V^{\\pi}(s), \\forall s$;\n        until $\\forall s, V^{\\pi}(s)$ 收敛;\n        // 策略改进\n        根据公式 (14.19), 计算 $Q(s, a)$;\n        $\\forall s, \\pi(s)=\\arg \\max _{a} Q(s, a) ;$\n    until $\\forall s, \\pi(s)$ 收敛;\n    输出: 策略 $\\pi$\n```",
        "总结": "- 策略迭代算法：一种用于求解马尔可夫决策过程（MDP）最优策略的算法，包含策略评估和策略改进两个主要步骤。  \n- 策略评估：通过迭代计算当前策略下每个状态的值函数 $V^{\\pi}(s)$，使用贝尔曼方程（公式（14.18））进行计算，直到值函数收敛。  \n- 策略改进：根据计算得到的值函数 $Q(s, a)$ 更新策略，选择使 $Q(s, a)$ 最大的动作作为新策略，即公式（14.19）的应用。  \n- 算法流程：算法14.1描述了策略迭代的具体实现，包括初始化、重复执行策略评估与改进，直到策略收敛，最终输出最优策略 $\\pi$。"
      },
      {
        "段落": "### 14．2．1．2 值迭代算法\n\n策略迭代算法中的策略评估和策略改进是交替轮流进行，其中策略评估也是通过一个内部迭代来进行计算，其计算量比较大．事实上，我们不需要每次计算出 https：／／nndl．github．io／\n\n基于模型的强化学习，也叫做模型相关的强化学习，或有模型的强化学习。\n\n每次策略对应的精确的值函数，也就是说内部迭代不需要执行到完全收玫．\n值迭代（Value Iteration）算法将策略评估和策略改进两个过程合并，来直接计算出最优策略．\n\n最优策略 $\\pi^{*}$ 对应的值函数称为最优值函数，其中包括最优状态值函数 $V^{*}(s)$和最优状态－动作值函数 $Q^{*}(s, a)$ ，它们之间的关系为\n\n$$\n\\begin{equation*}\nV^{*}(s)=\\max _{a} Q^{*}(s, a) \\tag{14.26}\n\\end{equation*}\n$$\n\n根据贝尔曼方程，我们可以通过迭代的方式来计算最优状态值函数 $V^{*}(s)$ 和最优状态－动作值函数 $Q^{*}(s, a)$ ：\n\n$$\n\\begin{align*}\nV^{*}(s) & =\\max _{a} \\mathbb{E}_{S^{\\prime} \\sim p\\left(s^{\\prime} \\mid s, a\\right)}\\left[r\\left(s, a, s^{\\prime}\\right)+\\gamma V^{*}\\left(s^{\\prime}\\right)\\right]  \\tag{14.27}\\\\\nQ^{*}(s, a) & =\\mathbb{E}_{S^{\\prime} \\sim p\\left(s^{\\prime} \\mid s, a\\right)}\\left[r\\left(s, a, s^{\\prime}\\right)+\\gamma \\max _{a^{\\prime}} Q^{*}\\left(s^{\\prime}, a^{\\prime}\\right)\\right] \\tag{14.28}\n\\end{align*}\n$$\n\n这两个公式称为贝尔曼最优方程（Bellman Optimality Equation）。\n参见习题14－2．\n值迭代算法通过直接优化贝尔曼最优方程（见公式（14．27）），迭代计算最优值函数．值迭代算法如算法14．2所示．\n\n```\n算法 14.2: 值迭代算法\n    输入: MDP五元组: $\\mathcal{S}, \\mathcal{A}, P, r, \\gamma$;\n    初始化: $\\forall s \\in \\mathcal{S}, V(s)=0$;\n    repeat\n        $\\forall s, V(s) \\leftarrow \\max _{a} \\mathbb{E}_{S^{\\prime} \\sim p\\left(s^{\\prime} \\mid s, a\\right)}\\left[r\\left(s, a, s^{\\prime}\\right)+\\gamma V\\left(s^{\\prime}\\right)\\right] ;$\n    until $\\forall s, V(s)$ 收敛;\n    根据公式 (14.19) 计算 $Q(s, a)$;\n    $\\forall s, \\pi(s)=\\arg \\max _{a} Q(s, a) ;$\n    输出: 策略 $\\pi$\n```\n\n策略迭代算法 VS 值迭代算法 在策略迭代算法中，每次迭代的时间复杂度最大为 $O\\left(|\\mathcal{S}|^{3}|\\mathcal{A}|^{3}\\right)$ ，最大迭代次数为 $|\\mathcal{A}|^{|\\mathcal{S}|}$ 。而在值迭代算法中，每次迭代的时间复杂度最大为 $O\\left(|\\mathcal{S}|^{2}|\\mathcal{A}|\\right)$ ，但迭代次数要比策略迭代算法更多。\n\n策略迭代算法是根据贝尔曼方程来更新值函数，并根据当前的值函数来改进策略。而值迭代算法是直接使用贝尔曼最优方程来更新值函数，收玫时的值函数就是最优的值函数，其对应的策略也就是最优的策略．\n\n值迭代算法和策略迭代算法都需要经过非常多的迭代次数才能完全收玫。在实际应用中，可以不必等到完全收玫。这样，当状态和动作数量有限时，经过有限次迭代就可以收玫到近似最优策略。\n\n基于模型的强化学习算法实际上是一种动态规划方法．在实际应用中有以下两点限制：\n\n1．要求模型已知，即要给出马尔可夫决策过程的状态转移概率 $p\\left(s^{\\prime} \\mid s, a\\right)$ 和奖励函数 $r\\left(s, a, s^{\\prime}\\right)$ ，这个要求很难满足。如果我们事先不知道模型，那么可以先让智能体与环境交互来估计模型，即估计状态转移概率和奖励函数。一个简单的估计模型的方法为 R－max［Brafman et al．，2002］，通过随机游走的方法来探索环境。每次随机一个策略并执行，然后收集状态转移和奖励的样本。在收集一定的样本后，就可以通过统计或监督学习来重构出马尔可夫决策过程。但是，这种基于采样的重构过程的复杂度也非常高，只能应用于状态数非常少的场合。\n\n2．效率问题，即当状态数量较多时，算法效率比较低．但在实际应用中，很多问题的状态数量和动作数量非常多。比如，围棋有 $19 \\times 19=361$ 个位置，每个位置有黑子、白子或无子三种状态，整个棋局有 $3^{361} \\approx 10^{170}$ 种状态。动作（即落子位置）数量为 361 ．不管是值迭代还是策略迭代，以当前计算机的计算能力，根本无法计算。一种有效的方法是通过一个函数（比如神经网络）来近似计算值函数，以减少复杂度，并提高泛化能力。",
        "总结": "- 值迭代算法将策略评估和策略改进合并，直接计算最优策略  \n- 最优策略 $\\pi^{*}$ 对应的值函数称为最优值函数，包括 $V^{*}(s)$ 和 $Q^{*}(s, a)$  \n- $V^{*}(s) = \\max_{a} Q^{*}(s, a)$  \n- 贝尔曼最优方程包括 $V^{*}(s)$ 和 $Q^{*}(s, a)$ 的迭代计算公式  \n- 值迭代算法通过直接优化贝尔曼最优方程迭代计算最优值函数  \n- 算法14.2展示了值迭代算法的步骤，包括初始化、迭代更新值函数、收敛后计算策略  \n- 策略迭代与值迭代在时间复杂度和迭代次数上有差异，值迭代每次迭代复杂度较低但次数更多  \n- 值迭代算法收敛时的值函数为最优值函数，对应的策略为最优策略  \n- 基于模型的强化学习是动态规划方法，但存在模型已知和效率问题两大限制  \n- 模型已知要求提供状态转移概率和奖励函数，若未知可通过采样估计模型  \n- 状态数量多时算法效率低，可通过神经网络等函数近似值函数以提高效率"
      },
      {
        "段落": "## 14．2．2 蒙特卡罗方法\n\n在很多应用场景中，马尔可夫决策过程的状态转移概率 $p\\left(s^{\\prime} \\mid s, a\\right)$ 和奖励函数 $r\\left(s, a, s^{\\prime}\\right)$ 都是未知的。在这种情况下，我们一般需要智能体和环境进行交互，并收集一些样本，然后再根据这些样本来求解马尔可夫决策过程最优策略。这种模型未知，基于采样的学习算法也称为模型无关的强化学习（Model－Free Reinforce－ ment Learning）算法．\n\nQ 函数 $Q^{\\pi}(s, a)$ 为初始状态为 $s$ ，并执行动作 $a$ 后所能得到的期望总回报，可以写为\n\n$$\n\\begin{equation*}\nQ^{\\pi}(s, a)=\\mathbb{E}_{\\tau \\sim p(\\tau)}\\left[G\\left(\\tau_{s_{0}=s, a_{0}=a}\\right)\\right] \\tag{14.29}\n\\end{equation*}\n$$\n\n其中 $\\tau_{s_{0}=s, a_{0}=a}$ 表示轨迹 $\\tau$ 的起始状态和动作为 $s, a$ ．\n如果模型未知，Q函数可以通过采样来进行计算，这就是蒙特卡罗方法．对于一个策略 $\\pi$ ，智能体从状态 $s$ ，执行动作 $a$ 开始，然后通过随机游走的方法来探索环境，并计算其得到的总回报。假设我们进行 $N$ 次试验，得到 $N$ 个轨迹 $\\tau^{(1)}, \\tau^{(2)}, \\cdots, \\tau^{(N)}$ ，其总回报分别为 $G\\left(\\tau^{(1)}\\right), G\\left(\\tau^{(2)}\\right), \\cdots, G\\left(\\tau^{(N)}\\right)$ 。Q函数可以近似为\n\n$$\n\\begin{equation*}\nQ^{\\pi}(s, a) \\approx \\hat{Q}^{\\pi}(s, a)=\\frac{1}{N} \\sum_{n=1}^{N} G\\left(\\tau_{s_{0}=s, a_{0}=a}^{(n)}\\right) \\tag{14.30}\n\\end{equation*}\n$$\n\n当 $N \\rightarrow \\infty$ 时，$Q^{\\pi}(s, a) \\rightarrow Q^{\\pi}(s, a)$ ．\nhttps：／／nndl．github．io／\n\n参见第14．2．4节．\n\n模型无关的强化学习也叫做无模型的强化学习。\n\n参见公式（14．19）．\n\n在近似估计出 Q 函数 $\\hat{Q}^{\\pi}(s, a)$ 之后，就可以进行策略改进．然后在新的策略下重新通过采样来估计 Q 函数，并不断重复，直至收敛。\n\n利用和探索 但在蒙特卡罗方法中，如果采用确定性策略 $\\pi$ ，每次试验得到的轨迹是一样的，只能计算出 $Q^{\\pi}(s, \\pi(s))$ ，而无法计算其他动作 $a^{\\prime}$ 的 Q函数，因此也无法进一步改进策略。这样情况仅仅是对当前策略的利用（exploitation），而缺失了对环境的探索（exploration），即试验的轨迹应该尽可能覆盖所有的状态和动作，以找到更好的策略。\n\n为了平衡利用和探索，我们可以采用 $\\epsilon$－贪心法（ $\\epsilon$－greedy Method）。对于一个目标策略 $\\pi$ ，其对应的 $\\epsilon$－贪心法策略为\n\n$$\n\\pi^{\\epsilon}(s)=\\left\\{\\begin{array}{cc}\n\\pi(s), & \\text { 按概率 } 1-\\epsilon,  \\tag{14.31}\\\\\n\\text { 随机选择 } \\mathcal{A} \\text { 中的动作, } & \\text { 按概率 } \\epsilon .\n\\end{array}\\right.\n$$\n\n这样，$\\epsilon$－贪心法将一个仅利用的策略转为带探索的策略。每次选择动作 $\\pi(s)$ 的概率为 $1-\\epsilon+\\frac{\\epsilon}{|\\mathcal{A}|}$ ，其他动作的概率为 $\\frac{\\epsilon}{|\\mathcal{A}|}$ ．\n\n同策略 在蒙特卡罗方法中，如果采样策略是 $\\pi^{\\epsilon}(s)$ ，不断改进策略也是 $\\pi^{\\epsilon}(s)$ 而不是目标策略 $\\pi(s)$ 。这种采样与改进策略相同（即都是 $\\pi^{\\epsilon}(s)$ ）的强化学习方法叫做同策略（On－Policy）方法。\n\n异策略 如果采样策略是 $\\pi^{\\epsilon}(s)$ ，而优化目标是策略 $\\pi$ ，可以通过重要性采样，引入重要性权重来实现对目标策略 $\\pi$ 的优化。这种采样与改进分别使用不同策略的强化学习方法叫做异策略（Off－Policy）方法。",
        "总结": "- 蒙特卡罗方法：用于在模型未知的情况下，通过采样轨迹来估计Q函数，进而求解最优策略。  \n- Q函数定义：表示在状态s执行动作a后所能得到的期望总回报，公式为 $Q^{\\pi}(s, a)=\\mathbb{E}_{\\tau \\sim p(\\tau)}\\left[G\\left(\\tau_{s_{0}=s, a_{0}=a}\\right)\\right]$。  \n- 蒙特卡罗估计：通过多次试验得到的总回报的平均值来近似Q函数，公式为 $\\hat{Q}^{\\pi}(s, a)=\\frac{1}{N} \\sum_{n=1}^{N} G\\left(\\tau_{s_{0}=s, a_{0}=a}^{(n)}\\right)$。  \n- 利用与探索：蒙特卡罗方法中若使用确定性策略，只能计算当前策略的动作Q值，无法探索其他动作，因此需要引入探索机制。  \n- ε-贪心法：通过以概率 $1-\\epsilon$ 选择当前策略动作，以概率 $\\epsilon$ 随机选择动作，实现利用与探索的平衡。  \n- 同策略方法：采样与改进策略相同，均为 $\\pi^{\\epsilon}(s)$ 的强化学习方法。  \n- 异策略方法：采样策略与改进策略不同，通过重要性采样和权重调整实现对目标策略的优化。"
      },
      {
        "段落": "## 14．2．3 时序差分学习方法\n\n蒙特卡罗方法一般需要拿到完整的轨迹，才能对策略进行评估并更新模型，因此效率也比较低。\n\n时序差分学习（Temporal－Difference Learning）方法是蒙特卡罗方法的一种改进，通过引入动态规划算法来提高学习效率［Sutton et al．，2018］．时序差分学习方法是模拟一段轨迹，每行动一步（或者几步），就利用贝尔曼方程来评估行动前状态的价值。当时序差分学习方法中每次更新的动作数为最大步数时，就等价于蒙特卡罗方法。\n\n首先，将蒙特卡罗方法中 Q 函数 $\\hat{Q}^{\\pi}(s, a)$ 的估计改为增量计算的方式，假设第 $N$ 次试验后值函数 $\\hat{Q}_{N}^{\\pi}(s, a)$ 的平均为\n\n$$\n\\begin{equation*}\n\\hat{Q}_{N}^{\\pi}(s, a)=\\frac{1}{N} \\sum_{n=1}^{N} G\\left(\\tau_{s_{0}=s, a_{0}=a}^{(n)}\\right) \\tag{14.32}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n这也可以看作是一个多臂赌博机问题。\n\n重要性采样参见第 11．5．3节．\n\n$$\n\\begin{align*}\n& =\\frac{1}{N}\\left(G\\left(\\tau_{s_{0}=s, a_{0}=a}^{(N)}\\right)+\\sum_{n=1}^{N-1} G\\left(\\tau_{s_{0}=s, a_{0}=a}^{(n)}\\right)\\right)  \\tag{14.33}\\\\\n& =\\frac{1}{N}\\left(G\\left(\\tau_{s_{0}=s, a_{0}=a}^{(N)}+(N-1) \\hat{Q}_{N-1}^{\\pi}(s, a)\\right)\\right.  \\tag{14.34}\\\\\n& =\\hat{Q}_{N-1}^{\\pi}(s, a)+\\frac{1}{N}\\left(G\\left(\\tau_{s_{0}=s, a_{0}=a}^{(N)}\\right)-\\hat{Q}_{N-1}^{\\pi}(s, a)\\right), \\tag{14.35}\n\\end{align*}\n$$\n\n其中 $\\tau_{S_{0}=s, a_{0}=a}$ 表示轨迹 $\\tau$ 的起始状态和动作为 $s, a$ ．\n值函数 $\\hat{Q}^{\\pi}(s, a)$ 在第 $N$ 试验后的平均等于第 $N-1$ 试验后的平均加上一个增量．更一般性地，我们将权重系数 $\\frac{1}{N}$ 改为一个比较小的正数 $\\alpha$ ．这样每次采用一个新的轨迹 $\\tau_{s_{0}=s, a_{0}=a}$ ，就可以更新 $\\hat{Q}^{\\pi}(s, a)$ ．\n\n$$\n\\begin{equation*}\n\\hat{Q}^{\\pi}(s, a) \\leftarrow \\hat{Q}^{\\pi}(s, a)+\\alpha\\left(G\\left(\\tau_{s_{0}=s, a_{0}=a}\\right)-\\hat{Q}^{\\pi}(s, a)\\right), \\tag{14.36}\n\\end{equation*}\n$$\n\n其中增量 $\\delta \\triangleq G\\left(\\tau_{s_{0}=s, a_{0}=a}\\right)-\\hat{Q}^{\\pi}(s, a)$ 称为蒙特卡罗误差，表示当前轨迹的真实回报 $G\\left(\\tau_{S_{0}=s, a_{0}=a}\\right)$ 与期望回报 $\\hat{Q}^{\\pi}(s, a)$ 之间的差距．\n\n在公式（14．36）中，$G\\left(\\tau_{s_{0}=s, a_{0}=a}\\right)$ 为一次试验的完整轨迹所得到的总回报。为了提高效率，可以借助动态规划的方法来计算 $G\\left(\\tau_{s_{0}=s, a_{0}=a}\\right)$ ，而不需要得到完整的轨迹。从 $s, a$ 开始，采样下一步的状态和动作（ $s^{\\prime}, a^{\\prime}$ ），并得到奖励 $r\\left(s, a, s^{\\prime}\\right)$ ，然后利用贝尔曼方程来近似估计 $G\\left(\\tau_{S_{0}=s, a_{0}=a}\\right)$ ，\n\n$$\n\\begin{align*}\nG\\left(\\tau_{s_{0}=s, a_{0}=a, s_{1}=s^{\\prime}, a_{1}=a^{\\prime}}\\right) & =r\\left(s, a, s^{\\prime}\\right)+\\gamma G\\left(\\tau_{s_{0}=s^{\\prime}, a_{0}=a^{\\prime}}\\right)  \\tag{14.37}\\\\\n& \\cong r\\left(s, a, s^{\\prime}\\right)+\\gamma \\hat{Q}^{\\pi}\\left(s^{\\prime}, a^{\\prime}\\right), \\tag{14.38}\n\\end{align*}\n$$\n\n其中 $\\hat{Q}^{\\pi}\\left(s^{\\prime}, a^{\\prime}\\right)$ 是当前的 Q 函数的近似估计．\n\n贝尔曼方程参见公式（14．21）。\n\n参见习题14－3．\n\n结合公式（14．36）和公式（14．38），有\n\n$$\n\\begin{equation*}\n\\hat{Q}^{\\pi}(s, a) \\leftarrow \\hat{Q}^{\\pi}(s, a)+\\alpha\\left(r\\left(s, a, s^{\\prime}\\right)+\\gamma \\hat{Q}^{\\pi}\\left(s^{\\prime}, a^{\\prime}\\right)-\\hat{Q}^{\\pi}(s, a)\\right), \\tag{14.39}\n\\end{equation*}\n$$\n\n因此，更新 $\\hat{Q}^{\\pi}(s, a)$ 只需要知道当前状态 $s$ 和动作 $a$ 、奖励 $r\\left(s, a, s^{\\prime}\\right)$ 、下一步的状态 $s^{\\prime}$ 和动作 $a^{\\prime}$ 。这种策略学习方法称为SARSA算法（State Action Reward State Action，SARSA ）［Rummery et al．，1994］．\n\nSARSA 算法的学习过程如算法14．3所示，其采样和优化的策略都是 $\\pi^{\\epsilon}$ ，因此是一种同策略算法。为了提高计算效率，我们不需要对环境中所有的 $s, a$ 组合进行穷举，并计算值函数．只需要将当前的探索（ $s, a, r, s^{\\prime}, a^{\\prime}$ ）中 $s^{\\prime}, a^{\\prime}$ 作为下一次估计的起始状态和动作。\n\n时序差分学习是强化学习的主要学习方法，其关键步骤就是在每次迭代中优化 Q 函数来减少现实 $r+\\gamma Q\\left(s^{\\prime}, a^{\\prime}\\right)$ 和预期 $Q(s, a)$ 的差距．这和动物学习的机制十分相像．在大脑神经元中，多巴胺的释放机制和时序差分学习十分吻合．［Schultz， 1998］的一个实验中，通过监测猴子大脑释放的多巴胺浓度，发现如果猴子获得比 https：／／nndl．github．io／\n\n```\n算法 14.3: SARSA: 一种同策略的时序差分学习算法\n    输入: 状态空间 $\\mathcal{S}$, 动作空间 $\\mathcal{A}$, 折扣率 $\\gamma$, 学习率 $\\alpha$\n    随机初始化 $Q(s, a)$;\n    $\\forall s, \\forall a, \\pi(a \\mid s)=\\frac{1}{|\\mathcal{A}|} ;$\n    repeat\n        初始化起始状态 $s$;\n        选择动作 $a=\\pi^{\\epsilon}(s)$;\n        repeat\n            执行动作 $a$, 得到即时奖励 $r$ 和新状态 $s^{\\prime}$;\n            在状态 $s^{\\prime}$, 选择动作 $a^{\\prime}=\\pi^{\\epsilon}\\left(s^{\\prime}\\right)$;\n            $Q(s, a) \\leftarrow Q(s, a)+\\alpha\\left(r+\\gamma Q\\left(s^{\\prime}, a^{\\prime}\\right)-Q(s, a)\\right) ;$\n            更新策略: $\\pi(s)=\\arg \\max _{a \\in|\\mathcal{A}|} Q(s, a)$;\n            $s \\leftarrow s^{\\prime}, a \\leftarrow a^{\\prime} ;$\n        until $s$ 为终止状态;\n    until $\\forall s, a, Q(s, a)$ 收敛;\n    输出: 策略 $\\pi(s)$\n```\n\n预期更多的果汁，或者在没有预想到的时间喝到果汁，多巴胺释放大增．如果没有喝到本来预期的果汁，多巴胺的释放就会大减。多巴胺的释放，来自对于实际奖励和预期奖励的差异，而不是奖励本身。\n\n时序差分学习方法和蒙特卡罗方法的主要不同为：蒙特卡罗方法需要一条完整的路径才能知道其总回报，也不依赖马尔可夫性质；而时序差分学习方法只需要一步，其总回报需要通过马尔可夫性质来进行近似估计。",
        "总结": "- 时序差分学习（Temporal-Difference Learning）是蒙特卡罗方法的改进，结合动态规划思想，通过每步更新来提高学习效率  \n- 时序差分学习利用贝尔曼方程对状态-动作对的价值进行增量更新，而不是等待完整轨迹  \n- Q函数的更新公式为：$\\hat{Q}^{\\pi}(s, a) \\leftarrow \\hat{Q}^{\\pi}(s, a)+\\alpha\\left(G(\\tau)-\\hat{Q}^{\\pi}(s, a)\\right)$，其中 $G(\\tau)$ 是轨迹的总回报，$\\alpha$ 是学习率  \n- 通过动态规划近似估计总回报，公式为：$G \\cong r + \\gamma \\hat{Q}^{\\pi}(s', a')$，其中 $r$ 是即时奖励，$\\gamma$ 是折扣因子  \n- SARSA算法是时序差分学习的一种具体实现，采用同策略方法，更新公式为：$\\hat{Q}^{\\pi}(s, a) \\leftarrow \\hat{Q}^{\\pi}(s, a)+\\alpha\\left(r+\\gamma \\hat{Q}^{\\pi}(s', a')-\\hat{Q}^{\\pi}(s, a)\\right)$  \n- SARSA算法在每次迭代中使用当前状态、动作、奖励、下一步状态和动作进行更新，不需要完整轨迹  \n- 时序差分学习的关键在于利用马尔可夫性质近似估计总回报，而蒙特卡罗方法依赖完整轨迹  \n- 多巴胺释放机制与时序差分学习中的奖励预测误差机制相似，反映了实际奖励与预期奖励的差异"
      },
      {
        "段落": "### 14．2．3．1 Q 学习\n\n$Q$ 学习（Q－Learning）算法［Watkins et al．，1992］是一种异策略的时序差分学习方法．在 Q 学习中，Q 函数的估计方法为\n\n$$\n\\begin{equation*}\nQ(s, a) \\leftarrow Q(s, a)+\\alpha\\left(r+\\gamma \\max _{a^{\\prime}} Q\\left(s^{\\prime}, a^{\\prime}\\right)-Q(s, a)\\right), \\tag{14.40}\n\\end{equation*}\n$$\n\n相当于让 $Q(s, a)$ 直接去估计最优状态值函数 $Q^{*}(s, a)$ ．\n与 SARSA 算法不同，Q 学习算法不通过 $\\pi^{\\epsilon}$ 来选下一步的动作 $a^{\\prime}$ ，而是直接选最优的 Q 函数，因此更新后的 Q 函数是关于策略 $\\pi$ 的，而不是策略 $\\pi^{\\epsilon}$ 的．\n\n算法14．4给出了 Q 学习的学习过程．\n\n多巴胺是一种神经传导物质，传递开心、兴奋有关的信息。\n\n事实上，Q学习算法被提出的时间更早， SARSA 算法是 Q 学习算法的改进．\n\n```\n算法 14.4: Q 学习: 一种异策略的时序差分学习算法\n    输入: 状态空间 $\\mathcal{S}$, 动作空间 $\\mathcal{A}$, 折扣率 $\\gamma$, 学习率 $\\alpha$\n    随机初始化 $Q(s, a)$;\n    $\\forall s, \\forall a, \\pi(a \\mid s)=\\frac{1}{|\\mathcal{A}|} ;$\n    repeat\n        初始化起始状态 $s$;\n        repeat\n            在状态 $s$, 选择动作 $a=\\pi^{\\epsilon}(s)$;\n            执行动作 $a$, 得到即时奖励 $r$ 和新状态 $s^{\\prime}$;\n            $Q(s, a) \\leftarrow Q(s, a)+\\alpha\\left(r+\\gamma \\max _{a^{\\prime}} Q\\left(s^{\\prime}, a^{\\prime}\\right)-Q(s, a)\\right) ;$\n            $s \\leftarrow s^{\\prime} ;$\n        until $s$ 为终止状态;\n    until $\\forall s, a, Q(s, a)$ 收敛;\n    输出: 策略 $\\pi(s)=\\arg \\max _{a \\in|\\mathcal{A}|} Q(s, a)$\n```",
        "总结": "- Q学习是一种异策略的时序差分学习方法，直接估计最优状态值函数Q*(s, a)。  \n- Q学习的更新公式为：Q(s, a) ← Q(s, a) + α(r + γ maxₐ' Q(s', a') - Q(s, a))。  \n- 与SARSA不同，Q学习不依赖策略π^ε选择下一步动作，而是直接选择最优Q函数。  \n- 算法14.4描述了Q学习的过程，包括初始化、状态转移、奖励获取和Q值更新。  \n- Q学习的策略π是基于最终的Q函数确定的，即π(s) = arg maxₐ Q(s, a)。  \n- 多巴胺在神经传导中传递与开心、兴奋相关的信息。  \n- Q学习提出时间早于SARSA，SARSA是Q学习的改进版本。"
      },
      {
        "段落": "## 14．2．4 深度 Q 网络\n\n为了在连续的状态和动作空间中计算值函数 $Q^{\\pi}(s, a)$ ，我们可以用一个函数 $Q_{\\phi}(\\boldsymbol{s}, \\boldsymbol{a})$ 来表示近似计算，称为值函数近似（Value Function Approximation）。\n\n$$\n\\begin{equation*}\nQ_{\\phi}(\\boldsymbol{s}, \\boldsymbol{a}) \\approx Q^{\\pi}(s, a) \\tag{14.41}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{s}, \\boldsymbol{a}$ 分别是状态 $s$ 和动作 $a$ 的向量表示；函数 $Q_{\\phi}(\\boldsymbol{s}, \\boldsymbol{a})$ 通常是一个参数为 $\\phi$ 的函数，比如神经网络，输出为一个实数，称为 $Q$ 网络（Q－network）。\n\n如果动作为有限离散的 $M$ 个动作 $a_{1}, \\cdots, a_{M}$ ，我们可以让 Q 网络输出一个 $M$维向量，其中第 $m$ 维表示 $Q_{\\phi}\\left(\\boldsymbol{s}, a_{m}\\right)$ ，对应值函数 $Q^{\\pi}\\left(s, a_{m}\\right)$ 的近似值．\n\n$$\nQ_{\\phi}(\\boldsymbol{s})=\\left[\\begin{array}{c}\nQ_{\\phi}\\left(\\boldsymbol{s}, a_{1}\\right)  \\tag{14.42}\\\\\n\\vdots \\\\\nQ_{\\phi}\\left(\\boldsymbol{s}, a_{M}\\right)\n\\end{array}\\right] \\approx\\left[\\begin{array}{c}\nQ^{\\pi}\\left(s, a_{1}\\right) \\\\\n\\vdots \\\\\nQ^{\\pi}\\left(s, a_{M}\\right)\n\\end{array}\\right]\n$$\n\n我们需要学习一个参数 $\\phi$ 来使得函数 $Q_{\\phi}(\\boldsymbol{s}, \\boldsymbol{a})$ 可以逼近值函数 $Q^{\\pi}(s, a)$ 。如果采用蒙特卡罗方法，就直接让 $Q_{\\phi}(\\boldsymbol{s}, \\boldsymbol{a})$ 去逼近平均的总回报 $\\hat{Q}^{\\pi}(s, a)$ ；如果采用时序差分学习方法，就让 $Q_{\\phi}(\\boldsymbol{s}, \\boldsymbol{a})$ 去逼近 $\\mathbb{E}_{\\boldsymbol{s}^{\\prime}, \\boldsymbol{a}^{\\prime}}\\left[r+\\gamma Q_{\\phi}\\left(\\boldsymbol{s}^{\\prime}, \\boldsymbol{a}^{\\prime}\\right)\\right]$ ．\n\n以 $Q$ 学习为例，采用随机梯度下降，目标函数为\n\n$$\n\\begin{equation*}\n\\mathcal{L}\\left(s, a, s^{\\prime} \\mid \\phi\\right)=\\left(r+\\gamma \\max _{a^{\\prime}} Q_{\\phi}\\left(\\boldsymbol{s}^{\\prime}, \\boldsymbol{a}^{\\prime}\\right)-Q_{\\phi}(\\boldsymbol{s}, \\boldsymbol{a})\\right)^{2} \\tag{14.43}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n其中 $\\boldsymbol{s}^{\\prime}, \\boldsymbol{a}^{\\prime}$ 是下一时刻的状态 $s^{\\prime}$ 和动作 $a^{\\prime}$ 的向量表示．\n然而，这个目标函数存在两个问题：一是目标不稳定，参数学习的目标依赖于参数本身；二是样本之间有很强的相关性．为了解决这两个问题，［Mnih et al．， 2015］提出了一种深度 Q 网络（Deep Q－Networks，DQN）。深度 Q 网络采取两个措施：一是目标网络冻结（Freezing Target Networks），即在一个时间段内固定目标中的参数，来稳定学习目标；二是经验回放（Experience Replay），即构建一个经验池（Replay Buffer）来去除数据相关性。经验池是由智能体最近的经历组\n\n经验回放可以形象地理解为在回忆中学习。成的数据集．\n\n训练时，随机从经验池中抽取样本来代替当前的样本用来进行训练。这样，就打破了和相邻训练样本的相似性，避免模型陷入局部最优。经验回放在一定程度上类似于监督学习。先收集样本，然后在这些样本上进行训练。深度 Q 网络的学习过程如算法14．5所示．\n\n```\n算法 14.5: 带经验回放的深度 Q 网络\n    输入: 状态空间 $\\mathcal{S}$, 动作空间 $\\mathcal{A}$, 折扣率 $\\gamma$, 学习率 $\\alpha$, 参数更新间隔 $C$;\n    初始化经验池 $\\mathcal{D}$, 容量为 $N$;\n    随机初始化 $Q$ 网络的参数 $\\phi$;\n    随机初始化目标 $Q$ 网络的参数 $\\hat{\\phi}=\\phi$;\n    repeat\n        初始化起始状态 $s$;\n        repeat\n            在状态 $s$, 选择动作 $a=\\pi^{\\epsilon}$;\n            执行动作 $a$, 观测环境, 得到即时奖励 $r$ 和新的状态 $s^{\\prime}$;\n            将 $s, a, r, s^{\\prime}$ 放入 $\\mathcal{D}$ 中;\n            从 $\\mathcal{D}$ 中采样 $s s, a a, r r, s s^{\\prime}$;\n            $y=\\left\\{\\begin{array}{cc}r r, & s s^{\\prime} \\text { 为终止状态, } \\\\ r r+\\gamma \\max _{a^{\\prime}} Q_{\\hat{\\phi}}\\left(\\mathbf{s s}^{\\prime}, \\boldsymbol{a}^{\\prime}\\right), & \\text { 否则 }\\end{array}\\right.$;\n            以 $\\left(y-Q_{\\phi}(\\boldsymbol{s} \\boldsymbol{s}, \\boldsymbol{a} \\boldsymbol{a})\\right)^{2}$ 为损失函数来训练 $Q$ 网络;\n            $s \\leftarrow s^{\\prime}$;\n            每隔 $C$ 步, $\\hat{\\phi} \\leftarrow \\phi$;\n        until $s$ 为终止状态;\n    until $\\forall s, a, Q_{\\phi}(\\boldsymbol{s}, \\boldsymbol{a})$ 收敛;\n    输出: $Q$ 网络 $Q_{\\phi}(\\boldsymbol{s}, \\boldsymbol{a})$\n```\n\n整体上，在基于值函数的学习方法中，策略一般为确定性策略．策略优化通常都依赖于值函数，比如贪心策略 $\\pi(s)=\\arg \\max _{a} Q(s, a)$ 。最优策略一般需要遍历当前状态 s 下的所有动作，并找出最优的 $Q(s, a)$ 。当动作空间离散但是很大时，遍历求最大需要很高的时间复杂度；当动作空间是连续的并且 $Q(s, a)$ 非凸时，也 https：／／nndl．github．io／\n\n很难求解出最佳的策略．",
        "总结": "- 值函数近似：使用函数 $Q_{\\phi}(\\boldsymbol{s}, \\boldsymbol{a})$ 近似计算值函数 $Q^{\\pi}(s, a)$，通常采用神经网络作为 $Q$ 网络。  \n- Q 网络输出结构：当动作是有限离散的 $M$ 个时，Q 网络输出一个 $M$ 维向量，每个维度对应一个动作的近似值函数。  \n- 学习目标：通过最小化目标函数 $\\mathcal{L}(s, a, s^{\\prime} \\mid \\phi)$ 来学习参数 $\\phi$，该目标函数基于时序差分学习方法。  \n- 目标函数问题：目标不稳定和样本相关性强，导致学习困难。  \n- 深度 Q 网络（DQN）：提出两个解决方案：目标网络冻结和经验回放。  \n- 目标网络冻结：在一段时间内固定目标网络的参数以稳定学习目标。  \n- 经验回放：通过构建经验池（Replay Buffer）来减少样本相关性，类似于监督学习中的数据收集与训练过程。  \n- 算法 14.5：描述了带经验回放的深度 Q 网络的训练过程，包括初始化、经验存储、采样、损失计算与参数更新等步骤。  \n- 确定性策略：基于值函数的学习方法中，策略通常为确定性策略，如贪心策略 $\\pi(s)=\\arg \\max _{a} Q(s, a)$。  \n- 最优策略挑战：当动作空间很大或连续时，求解最优策略面临高时间复杂度或非凸问题的挑战。"
      },
      {
        "段落": "## 14.3 基于策略函数的学习方法\n\n强化学习的目标是学习到一个策略 $\\pi_{\\theta}(a \\mid s)$ 来最大化期望回报。 一种直接的方法是在策略空间直接搜索来得到最佳策略，称为策略搜索（Policy Search）。策略搜索本质是一个优化问题，可以分为基于梯度的优化和无梯度优化。策略搜索和基于值函数的方法相比，策略搜索可以不需要值函数，直接优化策略．参数化的策略能够处理连续状态和动作，可以直接学出随机性策略。\n\n策略梯度（Policy Gradient）是一种基于梯度的强化学习方法。假设 $\\pi_{\\theta}(a \\mid s)$是一个关于 $\\theta$ 的连续可微函数，我们可以用梯度上升的方法来优化参数 $\\theta$ 使得目标函数 $\\mathcal{J}(\\theta)$ 最大。\n\n目标函数 $\\mathcal{F}(\\theta)$ 关于策略参数 $\\theta$ 的导数为\n\n目标函数 $\\mathcal{J}(\\theta)$ 参见公式（14．11）。\n\n$$\n\\begin{align*}\n\\frac{\\partial \\mathcal{J}(\\theta)}{\\partial \\theta} & =\\frac{\\partial}{\\partial \\theta} \\int p_{\\theta}(\\tau) G(\\tau) \\mathrm{d} \\tau  \\tag{14.44}\\\\\n& =\\int\\left(\\frac{\\partial}{\\partial \\theta} p_{\\theta}(\\tau)\\right) G(\\tau) \\mathrm{d} \\tau  \\tag{14.45}\\\\\n& =\\int p_{\\theta}(\\tau)\\left(\\frac{1}{p_{\\theta}(\\tau)} \\frac{\\partial}{\\partial \\theta} p_{\\theta}(\\tau)\\right) G(\\tau) \\mathrm{d} \\tau  \\tag{14.46}\\\\\n& =\\int p_{\\theta}(\\tau)\\left(\\frac{\\partial}{\\partial \\theta} \\log p_{\\theta}(\\tau)\\right) G(\\tau) \\mathrm{d} \\tau  \\tag{14.47}\\\\\n& =\\mathbb{E}_{\\tau \\sim p_{\\theta}(\\tau)}\\left[\\frac{\\partial}{\\partial \\theta} \\log p_{\\theta}(\\tau) G(\\tau)\\right] \\tag{14.48}\n\\end{align*}\n$$\n\n其中 $\\frac{\\partial}{\\partial \\theta} \\log p_{\\theta}(\\tau)$ 为函数 $\\log p_{\\theta}(\\tau)$ 关于 $\\theta$ 的偏导数。从公式（14．48）中可以看出，参数 $\\theta$ 优化的方向是使得总回报 $G(\\tau)$ 越大的轨迹 $\\tau$ 的概率 $p_{\\theta}(\\tau)$ 也越大。\n\n$$\n\\begin{align*}\n& \\frac{\\partial}{\\partial \\theta} \\log p_{\\theta}(\\tau) \\text { 可以进一步分解为 } \\\\\n& \\frac{\\partial}{\\partial \\theta} \\log p_{\\theta}(\\tau)=\\frac{\\partial}{\\partial \\theta} \\log \\left(p\\left(s_{0}\\right) \\prod_{t=0}^{T-1} \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right) p\\left(s_{t+1} \\mid s_{t}, a_{t}\\right)\\right)  \\tag{14.49}\\\\\n& \\quad=\\frac{\\partial}{\\partial \\theta}\\left(\\log p\\left(s_{0}\\right)+\\sum_{t=0}^{T-1} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right)+\\sum_{t=0}^{T-1} \\log p\\left(s_{t+1} \\mid s_{t}, a_{t}\\right)\\right)  \\tag{14.50}\\\\\n& \\quad=\\sum_{t=0}^{T-1} \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right) . \\tag{14.51}\n\\end{align*}\n$$\n\n可以看出，$\\frac{\\partial}{\\partial \\theta} \\log p_{\\theta}(\\tau)$ 是和状态转移概率无关，只和策略函数相关．\n\n因此，策略梯度 $\\frac{\\partial J(\\theta)}{\\partial \\theta}$ 可写为\n\n$$\n\\begin{align*}\n\\frac{\\partial \\mathcal{J}(\\theta)}{\\partial \\theta} & =\\mathbb{E}_{\\tau \\sim p_{\\theta}(\\tau)}\\left[\\left(\\sum_{t=0}^{T-1} \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right)\\right) G(\\tau)\\right]  \\tag{14.52}\\\\\n& =\\mathbb{E}_{\\tau \\sim p_{\\theta}(\\tau)}\\left[\\left(\\sum_{t=0}^{T-1} \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right)\\right)\\left(G\\left(\\tau_{0: t-1}\\right)+\\gamma^{t} G\\left(\\tau_{t: T}\\right)\\right)\\right]  \\tag{14.53}\\\\\n& =\\mathbb{E}_{\\tau \\sim p_{\\theta}(\\tau)}\\left[\\sum_{t=0}^{T-1}\\left(\\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right) \\gamma^{t} G\\left(\\tau_{t: T}\\right)\\right)\\right] \\tag{14.54}\n\\end{align*}\n$$\n\n参见习题14－5．\n\n其中 $G\\left(\\tau_{t: T}\\right)$ 为从时刻 $t$ 作为起始时刻收到的总回报\n\n$$\n\\begin{equation*}\nG\\left(\\tau_{t: T}\\right)=\\sum_{t^{\\prime}=t}^{T-1} \\gamma^{t^{\\prime}-t} r_{t^{\\prime}+1} \\tag{14.55}\n\\end{equation*}\n$$",
        "总结": "- 策略搜索：一种直接在策略空间中搜索最佳策略的方法，无需值函数，可处理连续状态和动作，直接学习随机性策略。  \n- 策略梯度：基于梯度的强化学习方法，通过优化策略参数 $\\theta$ 来最大化目标函数 $\\mathcal{J}(\\theta)$。  \n- 策略梯度公式推导：通过数学推导得到策略梯度的表达式，其核心是期望值形式，包含对数策略概率的梯度与总回报的乘积。  \n- 对数策略概率的梯度分解：推导出对数策略概率的梯度仅与策略函数相关，与状态转移概率无关。  \n- 策略梯度的最终形式：将总回报分解为即时奖励和未来奖励的加权和，进一步简化了策略梯度的计算。  \n- 总回报定义：从时刻 $t$ 开始的总回报 $G(\\tau_{t: T})$ 定义为未来奖励的加权和。"
      },
      {
        "段落": "## 14．3．1 REINFORCE 算法\n\n公式（14．54）中，期望可以通过采样的方法来近似。根据当前策略 $\\pi_{\\theta}$ ，通过随机游走的方式来采集多个轨迹 $\\tau^{(1)}, \\tau^{(2)}, \\cdots, \\tau^{(N)}$ ，其中每一条轨迹 $\\tau^{(n)}=$ $s_{0}^{(n)}, a_{0}^{(n)}, s_{1}^{(n)}, a_{1}^{(n)}, \\cdots$ ．这样，策略梯度 $\\frac{\\partial J(\\theta)}{\\partial \\theta}$ 可以写为\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{J}(\\theta)}{\\partial \\theta} \\approx \\frac{1}{N} \\sum_{n=1}^{N}\\left(\\sum_{t=0}^{T-1} \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t}^{(n)} \\mid s_{t}^{(n)}\\right) \\gamma^{t} G_{\\tau_{t: T}^{(n)}}\\right) \\tag{14.56}\n\\end{equation*}\n$$\n\n结合随机梯度上升算法，我们可以每次采集一条轨迹，计算每个时刻的梯度并更新参数，这称为REINFORCE算法［Williams，1992］，如算法14．6所示．\n\n```\n算法 14.6: REINFORCE 算法\n    输入: 状态空间 $\\mathcal{S}$, 动作空间 $\\mathcal{A}$, 可微分的策略函数 $\\pi_{\\theta}(a \\mid s)$, 折扣率 $\\gamma$, 学习率 $\\alpha$;\n    随机初始化参数 $\\theta$;\n    repeat\n        根据策略 $\\pi_{\\theta}(a \\mid s)$ 生成一条轨迹\n            $\\tau=s_{0}, a_{0}, s_{1}, a_{1}, \\cdots, s_{T-1}, a_{T-1}, s_{T} ;$\n        for $t=0$ to $T$ do\n            计算 $G\\left(\\tau_{t: T}\\right)$;\n            // 更新策略函数参数\n            $\\theta \\leftarrow \\theta+\\alpha \\gamma^{t} G\\left(\\tau_{t: T}\\right) \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right) ;$\n        end\n    until $\\pi_{\\theta}$ 收敛;\n    输出: 策略 $\\pi_{\\theta}$\n```",
        "总结": "- 概念：REINFORCE算法是一种策略梯度方法，通过采样轨迹来估计策略梯度，从而更新策略参数。\n- 算法：REINFORCE算法通过随机游走生成轨迹，计算每个时间步的回报，并利用梯度上升更新策略参数。\n- 公式：策略梯度近似公式为 $\\frac{\\partial \\mathcal{J}(\\theta)}{\\partial \\theta} \\approx \\frac{1}{N} \\sum_{n=1}^{N}\\left(\\sum_{t=0}^{T-1} \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t}^{(n)} \\mid s_{t}^{(n)}\\right) \\gamma^{t} G_{\\tau_{t: T}^{(n)}}\\right)$。\n- 数学推导：通过采样轨迹并计算每个时间步的梯度，结合随机梯度上升方法，逐步更新策略参数以最大化期望回报。"
      },
      {
        "段落": "## 14．3．2 带基准线的 REINFORCE 算法\n\nREINFORCE算法的一个主要缺点是不同路径之间的方差很大，导致训练不稳定，这是在高维空间中使用蒙特卡罗方法的通病。一种减少方差的通用方法是引入一个控制变量。假设要估计函数 $f$ 的期望，为了减少 $f$ 的方差，我们引入一个已知期望的函数 $g$ ，令\n\n$$\n\\begin{equation*}\n\\hat{f}=f-\\alpha(g-\\mathbb{E}[g]) \\tag{14.57}\n\\end{equation*}\n$$\n\n因为 $\\mathbb{E}[\\hat{f}]=\\mathbb{E}[f]$ ，我们可以用 $\\hat{f}$ 的期望来估计函数 $f$ 的期望，同时利用函数 $g$ 来减小 $\\hat{f}$ 的方差．\n\n函数 $\\hat{f}$ 的方差为\n\n$$\n\\begin{equation*}\n\\operatorname{var}(\\hat{f})=\\operatorname{var}(f)-2 \\alpha \\operatorname{cov}(f, g)+\\alpha^{2} \\operatorname{var}(g) \\tag{14.58}\n\\end{equation*}\n$$\n\n其中 $\\operatorname{var}(\\cdot)$ 和 $\\operatorname{cov}(\\cdot, \\cdot)$ 分别表示方差和协方差．\n如果要使得 $\\operatorname{var}(\\hat{f})$ 最小，令 $\\frac{\\partial \\operatorname{var}(\\hat{f})}{\\partial \\alpha}=0$ ，得到\n\n$$\n\\begin{equation*}\n\\alpha=\\frac{\\operatorname{cov}(f, g)}{\\operatorname{var}(g)} \\tag{14.59}\n\\end{equation*}\n$$\n\n因此，\n\n$$\n\\begin{align*}\n\\operatorname{var}(\\hat{f}) & =\\left(1-\\frac{\\operatorname{cov}(f, g)^{2}}{\\operatorname{var}(g) \\operatorname{var}(f)}\\right) \\operatorname{var}(f)  \\tag{14.60}\\\\\n& =\\left(1-\\operatorname{cor}(f, g)^{2}\\right) \\operatorname{var}(f) \\tag{14.61}\n\\end{align*}\n$$\n\n其中 $\\operatorname{corr}(f, g)$ 为函数 $f$ 和 $g$ 的相关性．如果相关性越高，则 $\\hat{f}$ 的方差越小．\n带基准线的 REINFORCE 算法 在每个时刻 $t$ ，其策略梯度为\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{J}_{t}(\\theta)}{\\partial \\theta}=\\mathbb{E}_{S_{t}}\\left[\\mathbb{E}_{a_{t}}\\left[\\gamma^{t} G\\left(\\tau_{t: T}\\right) \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right)\\right]\\right] \\tag{14.62}\n\\end{equation*}\n$$\n\n为了减小策略梯度的方差，我们引入一个和 $a_{t}$ 无关的基准函数 $b\\left(s_{t}\\right)$ ，\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\hat{J}_{t}(\\theta)}{\\partial \\theta}=\\mathbb{E}_{s_{t}}\\left[\\mathbb{E}_{a_{t}}\\left[\\gamma^{t}\\left(G\\left(\\tau_{t: T}\\right)-b\\left(s_{t}\\right)\\right) \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right)\\right]\\right] . \\tag{14.63}\n\\end{equation*}\n$$\n\n因为 $b\\left(s_{t}\\right)$ 和 $a_{t}$ 无关，有\n\n$$\n\\begin{align*}\n\\mathbb{E}_{a_{t}}\\left[b\\left(s_{t}\\right) \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right)\\right] & =\\int_{a_{t}}\\left(b\\left(s_{t}\\right) \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right)\\right) \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right) \\mathrm{d} a_{t}  \\tag{14.64}\\\\\n& \\left.=\\int_{a_{t}} b\\left(s_{t}\\right) \\frac{\\partial}{\\partial \\theta} \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right)\\right) d a_{t}  \\tag{14.65}\\\\\n& \\left.=\\frac{\\partial}{\\partial \\theta} b\\left(s_{t}\\right) \\int_{a_{t}} \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right)\\right) \\mathrm{d} a_{t}  \\tag{14.66}\\\\\n& =\\frac{\\partial}{\\partial \\theta}\\left(b\\left(s_{t}\\right) \\cdot 1\\right)=0 \\tag{14.67}\n\\end{align*}\n$$\n\nhttps：／／nndl．github．io／\n\n因此，$\\frac{\\partial \\hat{\\mathcal{J}}_{t}(\\theta)}{\\partial \\theta}=\\frac{\\partial \\mathcal{J}_{t}(\\theta)}{\\partial \\theta}$ ．\n为了有效减小方差，$b\\left(s_{t}\\right)$ 和 $G\\left(\\tau_{t: T}\\right)$ 越相关越好，一个很自然的选择是令 $b\\left(s_{t}\\right)$ 为值函数 $V^{\\pi_{\\theta}}\\left(s_{t}\\right)$ 。但是由于值函数未知，我们可以用一个可学习的函数 $V_{\\phi}\\left(s_{t}\\right)$ 来近似值函数，目标函数为\n\n$$\n\\begin{equation*}\n\\mathcal{L}\\left(\\phi \\mid s_{t}, \\pi_{\\theta}\\right)=\\left(V^{\\pi_{\\theta}}\\left(s_{t}\\right)-V_{\\phi}\\left(s_{t}\\right)\\right)^{2} \\tag{14.68}\n\\end{equation*}\n$$\n\n其中 $V^{\\pi_{\\theta}}\\left(s_{t}\\right)=\\mathbb{E}\\left[G\\left(\\tau_{t: T}\\right)\\right]$ 也用蒙特卡罗方法进行估计。采用随机梯度下降法，参数 $\\phi$ 的梯度为\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\mathcal{L}\\left(\\phi \\mid s_{t}, \\pi_{\\theta}\\right)}{\\partial \\phi}=-\\left(G\\left(\\tau_{t: T}\\right)-V_{\\phi}\\left(s_{t}\\right)\\right) \\frac{\\partial V_{\\phi}\\left(s_{t}\\right)}{\\partial \\phi} \\tag{14.69}\n\\end{equation*}\n$$\n\n策略函数参数 $\\theta$ 的梯度为\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\hat{\\mathcal{J}}_{t}(\\theta)}{\\partial \\theta}=\\mathbb{E}_{S_{t}}\\left[\\mathbb{E}_{a_{t}}\\left[\\gamma^{t}\\left(G\\left(\\tau_{t: T}\\right)-V_{\\phi}\\left(s_{t}\\right)\\right) \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right)\\right]\\right] . \\tag{14.70}\n\\end{equation*}\n$$\n\n算法14．7给出了带基准线的 REINFORCE 算法．\n\n```\n算法 14.7: 带基准线的 REINFORCE 算法\n    输入: 状态空间 $\\mathcal{S}$, 动作空间 $\\mathcal{A}$, 可微分的策略函数 $\\pi_{\\theta}(a \\mid s)$, 可微分的状态值函\n            数 $V_{\\phi}(s)$, 折扣率 $\\gamma$, 学习率 $\\alpha, \\beta$;\n    随机初始化参数 $\\theta, \\phi$;\n    repeat\n        根据策略 $\\pi_{\\theta}(a \\mid s)$ 生成一条轨迹\n            $\\tau=s_{0}, a_{0}, s_{1}, a_{1}, \\cdots, s_{T-1}, a_{T-1}, s_{T} ;$\n        for $t=0$ to $T$ do\n            计算 $G\\left(\\tau_{t: T}\\right)$;\n            $\\delta \\leftarrow G\\left(\\tau_{t: T}\\right)-V_{\\phi}\\left(s_{t}\\right) ;$\n            // 更新值函数参数\n            $\\phi \\leftarrow \\phi+\\beta \\delta \\frac{\\partial}{\\partial \\phi} V_{\\phi}\\left(s_{t}\\right) ;$\n            // 更新策略函数参数\n            $\\theta \\leftarrow \\theta+\\alpha \\gamma^{t} \\delta \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right) ;$\n        end\n    until $\\pi_{\\theta}$ 收敛;\n    输出: 策略 $\\pi_{\\theta}$\n```",
        "总结": "- 引入基准线（baseline）以减少REINFORCE算法中策略梯度的方差  \n- 基准线函数 $b(s_t)$ 与回报 $G(\\tau_{t:T})$ 越相关，方差减少效果越显著  \n- 使用值函数 $V^\\pi(s_t)$ 作为基准线的理论依据，但实际用可学习的函数 $V_\\phi(s_t)$ 近似  \n- 基准线的更新通过最小化误差平方损失 $\\mathcal{L}(\\phi \\mid s_t, \\pi_\\theta) = (V^\\pi(s_t) - V_\\phi(s_t))^2$ 实现  \n- 策略梯度更新公式为 $\\frac{\\partial \\hat{\\mathcal{J}}_t(\\theta)}{\\partial \\theta} = \\mathbb{E}_{s_t,a_t}[\\gamma^t (G(\\tau_{t:T}) - V_\\phi(s_t)) \\frac{\\partial}{\\partial \\theta} \\log \\pi_\\theta(a_t \\mid s_t)]$  \n- 算法流程包括生成轨迹、计算回报、更新值函数参数和策略函数参数，直到策略收敛"
      },
      {
        "段落": "## 14.4 演员－评论员算法\n\n在 REINFORCE 算法中，每次需要根据一个策略采集一条完整的轨迹，并计算这条轨迹上的回报。这种采样方式的方差比较大，学习效率也比较低。我们可 https：／／nndl．github．io／\n\n以借鉴时序差分学习的思想，使用动态规划方法来提高采样的效率，即从状态 $s$开始的总回报可以通过当前动作的即时奖励 $r\\left(s, a, s^{\\prime}\\right)$ 和下一个状态 $s^{\\prime}$ 的值函数来近似估计。\n\n演员－评论员算法（Actor－Critic Algorithm）是一种结合策略梯度和时序差分学习的强化学习方法。其中演员（Actor）是指策略函数 $\\pi_{\\theta}(a \\mid s)$ ，即学习一个策略来得到尽量高的回报，评论员（Critic）是指值函数 $V_{\\phi}(s)$ ，对当前策略的值函数进行估计，即评估演员的好坏。借助于值函数，演员－评论员算法可以进行单步更新参数，不需要等到回合结束才进行更新。\n\n在演员－评论员算法中的策略函数 $\\pi_{\\theta}(s, a)$ 和值函数 $V_{\\phi}(s)$ 都是待学习的函数，需要在训练过程中同时学习。\n\n假设从时刻 $t$ 开始的回报 $G\\left(\\tau_{t: T}\\right)$ ，我们用下面公式近似计算。\n\n$$\n\\begin{equation*}\n\\hat{G}\\left(\\tau_{t: T}\\right)=r_{t+1}+\\gamma V_{\\phi}\\left(s_{t+1}\\right) \\tag{14.71}\n\\end{equation*}\n$$\n\n其中 $s_{t+1}$ 是 $t+1$ 时刻的状态，$r_{t+1}$ 是即时奖励．\n在每步更新中，分别进行策略函数 $\\pi_{\\theta}(s, a)$ 和值函数 $V_{\\phi}(s)$ 的学习。 一方面，更新参数 $\\phi$ 使得值函数 $V_{\\phi}\\left(s_{t}\\right)$ 接近于估计的真实回报 $\\hat{G}\\left(\\tau_{t: T}\\right)$ ，\n\n$$\n\\begin{equation*}\n\\min _{\\phi}\\left(\\hat{G}\\left(\\tau_{t: T}\\right)-V_{\\phi}\\left(s_{t}\\right)\\right)^{2}, \\tag{14.72}\n\\end{equation*}\n$$\n\n另一方面，将值函数 $V_{\\phi}\\left(s_{t}\\right)$ 作为基线函数来更新参数 $\\theta$ ，减少策略梯度的方差．\n\n$$\n\\begin{equation*}\n\\theta \\leftarrow \\theta+\\alpha \\gamma^{t}\\left(\\hat{G}\\left(\\tau_{t: T}\\right)-V_{\\phi}\\left(s_{t}\\right)\\right) \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right) . \\tag{14.73}\n\\end{equation*}\n$$\n\n在每步更新中，演员根据当前的环境状态 $s$ 和策略 $\\pi_{\\theta}(a \\mid s)$ 去执行动作 $a$ ，环境状态变为 $s^{\\prime}$ ，并得到即时奖励 $r$ 。评论员（值函数 $V_{\\phi}(s)$ ）根据环境给出的真实奖励和之前标准下的打分 $\\left(r+\\gamma V_{\\phi}\\left(s^{\\prime}\\right)\\right)$ ，来调整自己的打分标准，使得自己的评分更接近环境的真实回报。演员则跟据评论员的打分，调整自己的策略 $\\pi_{\\theta}$ ，争取下次做得更好。开始训练时，演员随机表演，评论员随机打分。通过不断的学习，评论员的评分越来越准，演员的动作越来越好。\n\n虽然带基准线的 REINFORCE 算法也同时学习策略函数和值函数，但是它并不是一种演员－评论员算法。因为其中值函数只是用作基线函数以减少方差，并不用来估计回报（即评论员的角色）。\n\n算法14．8给出了演员－评论员算法的训练过程．\n\n```\n算法 14.8: 演员-评论员算法\n    输入: 状态空间 $\\mathcal{S}$, 动作空间 $\\mathcal{A}$;\n    可微分的策略函数 $\\pi_{\\theta}(a \\mid s)$;\n    可微分的状态值函数 $V_{\\phi}(s)$;\n    折扣率 $\\gamma$, 学习率 $\\alpha>0, \\beta>0$;\n    随机初始化参数 $\\theta, \\phi$;\n    repeat\n        初始化起始状态 $s$;\n        $\\lambda=1 ;$\n        repeat\n            在状态 $s$, 选择动作 $a=\\pi_{\\theta}(a \\mid s)$;\n            执行动作 $a$, 得到即时奖励 $r$ 和新状态 $s^{\\prime}$;\n            $\\delta \\leftarrow r+\\gamma V_{\\phi}\\left(s^{\\prime}\\right)-V_{\\phi}(s) ;$\n            $\\phi \\leftarrow \\phi+\\beta \\delta \\frac{\\partial}{\\partial \\phi} V_{\\phi}(s) ;$\n            $\\theta \\leftarrow \\theta+\\alpha \\lambda \\delta \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}(a \\mid s) ;$\n            $\\lambda \\leftarrow \\gamma \\lambda ;$\n            $s \\leftarrow s^{\\prime} ;$\n        until $s$ 为终止状态;\n    until $\\theta$ 收敛;\n    输出: 策略 $\\pi_{\\theta}$\n```",
        "总结": "- 演员－评论员算法是一种结合策略梯度和时序差分学习的强化学习方法  \n- 演员（Actor）负责策略函数 $\\pi_{\\theta}(a \\mid s)$，用于选择动作以最大化回报  \n- 评论员（Critic）负责值函数 $V_{\\phi}(s)$，用于评估当前策略的值函数  \n- 算法通过同时学习策略函数和值函数来提高学习效率  \n- 使用值函数作为基线函数减少策略梯度的方差  \n- 回报 $\\hat{G}(\\tau_{t:T})$ 通过即时奖励 $r_{t+1}$ 和下一个状态的值函数估计  \n- 值函数更新公式为 $\\min_{\\phi} (\\hat{G}(\\tau_{t:T}) - V_{\\phi}(s_t))^2$  \n- 策略更新公式为 $\\theta \\leftarrow \\theta + \\alpha \\gamma^t (\\hat{G}(\\tau_{t:T}) - V_{\\phi}(s_t)) \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}(a_t \\mid s_t)$  \n- 算法流程包括初始化状态、选择动作、计算误差 $\\delta$、更新值函数和策略参数、更新 $\\lambda$ 并转移状态，直到终止状态或策略收敛"
      },
      {
        "段落": "## 14.5 总结和深入阅读\n\n强化学习是一种十分吸引人的机器学习方法，通过智能体不断与环境进行交互，并根据经验调整其策略来最大化其长远的所有奖励的累积值．相比其他机器学习方法，强化学习更接近生物学习的本质，可以应对多种复杂的场景，从而更接近通用人工智能系统的目标。\n\n强化学习和监督学习的区别在于：（1）强化学习的样本通过不断与环境进行交互产生，即试错学习，而监督学习的样本由人工收集并标注；（2）强化学习的反馈信息只有奖励，并且是延迟的，而监督学习需要明确的指导信息（每一个状态对应的动作）。\n\n现代强化学习可以追溯到两个来源：一个是心理学中的行为主义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能获得最大利益的习惯性行为；另一个是控制论领域的最优控制问题，即在满足一定约束条件下，寻求最优控制策略，使得性能指标取极大值或极小值。\n\n强化学习的算法非常多，大体上可以分为基于值函数的方法（包括动态规\n\n划、时序差分学习等）、基于策略函数的方法（包括策略梯度等）以及融合两者的方法．不同算法之间的关系如图14．4所示．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-363.jpg?height=603&width=1040&top_left_y=251&top_left_x=140)\n\n图 14.4 不同强化学习算法之间的关系\n\n一般而言，基于值函数的方法在策略更新时可能会导致值函数的改变比较大，对收玫性有一定影响，而基于策略函数的方法在策略更新时更加更平稳些。但后者因为策略函数的解空间比较大，难以进行充分的采样，导致方差较大，并容易收玫到局部最优解．演员－评论员算法通过融合两种方法，取长补短，有着更好的收玫性。\n\n这些不同的强化学习算法的优化步骤都可以分为三步：（1）执行策略，生成样本；（2）估计回报；（3）更新策略。表14．1给出了四种典型的强化学习算法 （SARSA、Q学习、REINFORCE、演员－评论员算法）优化步骤的比较。\n\n强化学习的主要参考文献为《Reinforcement Learning：An Introduction》 ［Sutton et al．，2018］．\n\n在深度强化学习方面，DeepMind 的Mnih et al．在2013年提出了第一个强化学习和深度学习结合的模型：深度 $Q$ 网络（DQN）［Mnih et al．，2015］．虽然DQN模型相对比较简单，只是面向有限的动作空间，但依然在 Atari 游戏上取得了很大的成功，超越了人类水平．之后，深度强化学习开始快速发展．一些基于 DQN的改进包括双 Q 网络［Van Hasselt et al．，2016］、优先级经验回放［Schaul et al．， 2015］、决斗网络［Wang et al．，2015］等．\n\n目前，深度强化学习更多是同时使用策略网络和值网络来近似策略函数和值函数．在演员－评论员算法的基础上，［Silver et al．，2014］将策略梯度的思想推广到确定性的策略上，提出了确定性策略梯度（Deterministic Policy Gradient， DPG）算法．策略函数为状态到动作的映射 $a=\\pi_{\\theta}(s)$ ．采用确定性策略的一个\n\n表14．1四种强化学习算法优化步骤的比较\n\n| 算法 | 步骤 |\n| :--- | :--- |\n| SARSA | （1）执行策略，生成样本：$s, a, r, s^{\\prime}, a^{\\prime}$ <br> （2）估计回报：$Q(s, a) \\leftarrow Q(s, a)+\\alpha\\left(r+\\gamma Q\\left(s^{\\prime}, a^{\\prime}\\right)-Q(s, a)\\right)$ <br> （3）更新策略：$\\pi(s)=\\arg \\max _{a \\in\\|\\mathcal{A}\\|} Q(s, a)$ |\n|  |  |\n| Q学习 | （1）执行策略，生成样本：$s, a, r, s^{\\prime}$ <br> （2）估计回报：$Q(s, a) \\leftarrow Q(s, a)+\\alpha\\left(r+\\gamma \\max _{a^{\\prime}} Q\\left(s^{\\prime}, a^{\\prime}\\right)-Q(s, a)\\right)$ <br> （3）更新策略：$\\pi(s)=\\arg \\max _{a \\in\\|\\mathcal{A}\\|} Q(s, a)$ |\n| REINFORCE | （2）估计回报：$G(\\tau)=\\sum_{t=0}^{T-1} r_{t+1}$ <br> （3）更新策略：$\\theta \\leftarrow \\theta+\\sum_{t=0}^{T-1}\\left(\\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}\\left(a_{t} \\mid s_{t}\\right) \\gamma^{t} G\\left(\\tau_{t: T}\\right)\\right)$ |\n| 演员－评论员 | （1）执行策略，生成样本：$s, a, s^{\\prime}, r$ <br> （2）估计回报：$G(s)=r+\\gamma V_{\\phi}\\left(s^{\\prime}\\right)$ $\\phi \\leftarrow \\phi+\\beta\\left(G(s)-V_{\\phi}(s)\\right) \\frac{\\partial}{\\partial \\phi} V_{\\phi}(s)$ <br> （3）更新策略：$\\lambda \\leftarrow \\gamma \\lambda$ <br> $\\theta \\leftarrow \\theta+\\alpha \\lambda\\left(G(s)-V_{\\phi}(s)\\right) \\frac{\\partial}{\\partial \\theta} \\log \\pi_{\\theta}(a \\mid s)$ |\n\n好处是方差会变得很小，提高收玫性。确定性策略的缺点是对环境的探索不足，这可以通过异策略的方法解决．［Lillicrap et al．，2015］进一步在 DPG 算法的基础上，利用 DQN 来估计值函数，提出深度确定性策略梯度（Deep Determinis－ tic Policy Gradient，DDPG）算法。DDPG 算法可以适合连续的状态和动作空间．［Mnih et al．，2016］利用分布式计算的思想提出了异步优势的演员－评论员 （Asynchronous Advantage Actor－Critic，A3C）算法。在 A3C 算法中，有多个并行的环境，每个环境中都有一个智能体执行各自的动作并计算累计的参数梯度。在一定步数后进行累计，利用累计的参数梯度去更新所有智能体共享的全局参数。因为不同环境中的智能体可以使用不同的探索策略，会导致经验样本之间的相关性较小，所以能够提高学习效率。\n\n除了本章中介绍的标准强化学习之外，还存在一些更加泛化的强化学习问题．\n\n部分可观测马尔可夫决策过程 部分可观测马尔可夫决策过程（Partially Observ－ able Markov Decision Processes，POMDP）是一个马尔可夫决策过程的泛化。\nhttps：／／nndl．github．io／\n\nPOMDP 依然具有马尔可夫性质，但是假设智能体无法感知环境的状态 $s$ ，只能知道部分观测值 $o$ 。比如在自动驾驶中，智能体只能感知传感器采集的有限的环境信息。\n\nPOMDP 可以用一个 7 元组描述：$(\\mathcal{S}, \\mathcal{A}, T, R, \\Omega, \\mathcal{O}, \\gamma)$ ，其中 $\\mathcal{S}$ 表示状态空间，为隐变量， $\\mathcal{A}$ 为动作空间，$T\\left(s^{\\prime} \\mid s, a\\right)$ 为状态转移概率，$R$ 为奖励函数，$\\Omega(o \\mid s, a)$ 为观测概率， $\\mathcal{O}$ 为观测空间，$\\gamma$ 为折扣系数．\n\n逆向强化学习 强化学习的基础是智能体可以和环境进行交互，得到奖励。但在某些情况下，智能体无法从环境得到奖励，只有一组轨迹示例（Demonstration）。比如在自动驾驶中，我们可以得到司机的一组轨迹数据，但并不知道司机在每个时刻得到的即时奖励。虽然我们可以用监督学习来解决，称为行为克隆。但行为克隆只是学习司机的行为，并没有深究司机行为的动机．\n\n逆向强化学习（Inverse Reinforcement Learning，IRL）就是指一个不带奖励的马尔可夫决策过程，通过给定的一组专家（或教师）的行为轨迹示例来逆向估计出奖励函数 $r\\left(s, a, s^{\\prime}\\right)$ 来解释专家的行为，然后再进行强化学习。\n\n分层强化学习 分层强化学习（Hierarchical Reinforcement Learning，HRL）是指将一个复杂的强化学习问题分解成多个小的、简单的子问题［Barto et al．， 2003］，每个子问题都可以单独用马尔可夫决策过程来建模。这样，我们可以将智能体的策略分为高层次策略和低层次策略，高层次策略根据当前状态决定如何执行低层次策略．这样，智能体就可以解决一些非常复杂的任务．",
        "总结": "- 强化学习是一种通过智能体与环境交互，最大化长期奖励累积的机器学习方法，更接近生物学习本质，适用于复杂场景。\n- 强化学习与监督学习的区别在于样本生成方式（试错 vs 人工标注）和反馈信息（延迟奖励 vs 明确指导）。\n- 现代强化学习源于行为主义理论和最优控制问题，前者关注刺激与行为的关联，后者寻求最优控制策略。\n- 强化学习算法分为基于值函数（动态规划、时序差分）、基于策略函数（策略梯度）及融合方法，不同算法关系如图14.4所示。\n- 基于值函数的方法更新策略时值函数变化较大，可能影响收敛性；基于策略函数的方法更新更平稳但方差大，易收敛到局部最优。\n- 演员－评论员算法融合两种方法，具有更好的收敛性。\n- 所有强化学习算法优化步骤可归纳为：执行策略生成样本、估计回报、更新策略。\n- 表14.1比较了SARSA、Q学习、REINFORCE和演员－评论员算法的优化步骤。\n- 《Reinforcement Learning：An Introduction》是强化学习的主要参考文献。\n- 深度强化学习结合深度学习与强化学习，DQN是首个成功应用于Atari游戏的模型，后续改进包括双Q网络、优先级经验回放等。\n- 当前深度强化学习多使用策略网络和值网络近似策略和值函数，如确定性策略梯度（DPG）和深度确定性策略梯度（DDPG）。\n- A3C算法利用分布式计算并行处理多个环境，提升学习效率。\n- 部分可观测马尔可夫决策过程（POMDP）是马尔可夫决策过程的泛化，智能体仅能感知部分观测信息。\n- POMDP由7元组描述：状态空间、动作空间、状态转移概率、奖励函数、观测概率、观测空间和折扣系数。\n- 逆向强化学习（IRL）通过专家轨迹示例逆向估计奖励函数，解释专家行为，并用于后续强化学习。\n- 分层强化学习（HRL）将复杂任务分解为子问题，采用高低层次策略协同完成任务。"
      },
      {
        "段落": "## 习题\n\n习题14－1 证明公式（14．25）。\n习题14－2 证明公式（14．27）和公式（14．28）会收敛到最优解．\n习题14－3 比较证明公式（14．21）和公式（14．38）的不同之处．\n习题 14－4 分析 SARSA 算法和 Q 学习算法的不同．\n习题14－5证明公式（14．54）．",
        "总结": "- 提出了需要证明的公式（14．25）、（14．27）、（14．28）和（14．54）。  \n- 提出了需要比较的公式（14．21）和（14．38）。  \n- 提出了需要分析的SARSA算法和Q学习算法的不同之处。  \n- 习题要求读者进行数学推导和算法对比分析。"
      },
      {
        "段落": "## 参考文献\n\nBarto A G，Mahadevan S．Recent advances in hierarchical reinforcement learning［J］．Discrete Event Dynamic Systems，2003，13（4）：341－379．\nBrafman R I，Tennenholtz M．R－max－a general polynomial time algorithm for near－optimal rein－ forcement learning［J］．Journal of Machine Learning Research，2002，3（Oct）：213－231．\n\nLillicrap T P，Hunt J J，Pritzel A，et al．Continuous control with deep reinforcement learning［J］． arXiv preprint arXiv：1509．02971， 2015.\nMinsky M．Steps toward artificial intelligence［J］．Proceedings of the IRE，1961，49（1）：8－30．\nMnih V，Kavukcuoglu K，Silver D，et al．Human－level control through deep reinforcement learning ［J］．Nature，2015，518（7540）：529－533．\nMnih V，Badia A P，Mirza M，et al．Asynchronous methods for deep reinforcement learning［C］／／ Proceedings of International Conference on Machine Learning．2016：1928－1937．\nRummery G A，Niranjan M．On－line q－learning using connectionist systems［R］．Department of Engineering，University of Cambridge， 1994.\nSchaul T，Quan J，Antonoglou I，et al．Prioritized experience replay［J］．arXiv preprint arXiv：1511．05952， 2015.\nSchultz W．Predictive reward signal of dopamine neurons［J］．Journal of neurophysiology，1998， 80 （1）：1－27．\nSilver D，Lever G，Heess N，et al．Deterministic policy gradient algorithms［C］／／Proceedings of International Conference on Machine Learning．2014：387－395．\nSutton R S，Barto A G．Reinforcement learning：An introduction［M］．MIT press， 2018.\nVan Hasselt H，Guez A，Silver D．Deep reinforcement learning with double q－learning［C］／／AAAI． 2016：2094－2100．\nWang Z，Schaul T，Hessel M，et al．Dueling network architectures for deep reinforcement learning ［J］．arXiv preprint arXiv：1511．06581， 2015.\nWatkins C J，Dayan P．Q－learning［J］．Machine learning，1992，8（3）：279－292．\nWilliams R J．Simple statistical gradient－following algorithms for connectionist reinforcement learning［J］．Machine learning，1992，8（3－4）：229－256．",
        "总结": "- 参考文献部分列出了多篇与深度强化学习、强化学习算法及理论相关的研究论文和书籍，涵盖从早期的Q学习到现代的深度强化学习方法。  \n- 包括了如Q-learning、R-Max算法、深度强化学习在连续控制中的应用、双重Q学习、优先经验回放等关键算法和技术。  \n- 提到了一些重要理论基础，如多巴胺神经元的预测奖励信号、确定性策略梯度算法等。  \n- 引用了经典教材《Reinforcement Learning: An Introduction》以及多篇在机器学习和人工智能领域有影响力的论文。"
      },
      {
        "段落": "## 第15章 序列生成模型\n\n> 人类语言似乎是一种独特的现象，在动物世界中没有显著类似的存在。\n\n—诺姆•乔姆斯基（Noam Chomsky）\n美国语言学家、哲学家\n\n在深度学习的应用中，有很多数据是以序列的形式存在，比如声音、语言、视频、DNA 序列或者其他的时序数据等。以自然语言为例，一个句子可以看作是符合一定自然语言规则的词（word）的序列。在认知心理学上有一个经典的实验，让一个人看下面两个句子：\n\n> 面包上涂黄油，面包上涂袜子。\n\n后一个句子在人脑的语义整合时需要更多的处理时间，说明后一个句子更不符合自然语言规则。这些语言规则包含非常复杂的语法和语义的组合关系，我们很难显式地建模这些规则。为了有效地描述自然语言规则，我们可以从统计的角度来建模。一个长度为 $T$ 的文本序列看作是一个随机事件 $X_{1: T}=\\left\\langle X_{1}, \\cdots, X_{T}\\right\\rangle$ ，其中每个位置上的变量 $X_{t}$ 的样本空间为一个给定的词表（vocabulary） $\\mathcal{V}$ ，整个序列 $\\boldsymbol{x}_{1: T}$ 的样本空间为 $|\\mathcal{V}|^{T}$ 。在某种程度上，自然语言也确实有很多随机因素。比如当我们称赞一个人漂亮时，可以说＂美丽＂、＂帅＂或者＂好看＂等。当不指定使用场合时，这几个词可以交替使用，具体使用哪个词可以看作是一个随机事件。一个文本序列的概率大小可以用来评估它符合自然语言规则的程度。\n\n给定一个序列样本 $\\boldsymbol{x}_{1: T}=x_{1}, x_{2}, \\cdots, x_{T}$ ，其概率可以看出是 $T$ 个词的联合概率\n\n$$\n\\begin{align*}\np\\left(\\boldsymbol{x}_{1: T}\\right) & \\triangleq P\\left(\\boldsymbol{X}_{1: T}=\\boldsymbol{x}_{1: T}\\right)  \\tag{15.1}\\\\\n& =P\\left(X_{1}=x_{1}, X_{2}=x_{2}, \\cdots, X_{T}=x_{T}\\right) \\tag{15.2}\n\\end{align*}\n$$\n\n这里假定语言的最基本单位为词（word），当然也可以为字或字母（ character ）．\n\n在本章中，我们用 $X_{t}$表示位置 $t$ 上的随机变量，$x_{1: T}$ 表示一个序列样本，$x_{t}$ 表示一个序列样本在位置 $t$ 上的值．\n\n和一般的概率模型类似，序列概率模型有两个基本问题：（1）概率密度估计：给定一组序列数据，估计这些数据背后的概率分布；（2）样本生成：从已知的序列分布中生成新的序列样本．\n\n序列数据一般可以通过概率图模型来建模序列中不同变量之间的依赖关系。本章主要介绍在序列数据上经常使用的一种模型：自回归生成模型（AutoRe－ gressive Generative Model）．",
        "总结": "- 概念：序列生成模型，用于处理以序列形式存在的数据，如自然语言、声音等。\n- 概念：自然语言作为序列，由词构成，具有复杂的语法和语义规则。\n- 概念：概率模型用于描述序列的概率分布，通过联合概率评估序列符合自然语言规则的程度。\n- 概念：自回归生成模型（AutoRegressive Generative Model），用于建模序列数据中的依赖关系。\n- 算法：概率密度估计和样本生成是序列概率模型的两个基本问题。\n- 数学推导：序列的概率定义为联合概率 $ p(\\boldsymbol{x}_{1:T}) = P(X_1=x_1, X_2=x_2, \\cdots, X_T=x_T) $。"
      },
      {
        "段落": "## 15.1 序列概率模型\n\n序列数据有两个特点：（1）样本是变长的；（2）样本空间非常大．对于一个长度为 $T$ 的序列，其样本空间为 $|\\mathcal{V}|^{T}$ 。因此，我们很难用已知的概率模型来直接建模整个序列的概率。\n\n根据概率的乘法公式，序列 $\\boldsymbol{x}_{1: T}$ 的概率可以写为\n\n$$\n\\begin{align*}\np\\left(\\boldsymbol{x}_{1: T}\\right) & =p\\left(x_{1}\\right) p\\left(x_{2} \\mid x_{1}\\right) p\\left(x_{3} \\mid \\boldsymbol{x}_{1: 2}\\right) \\cdots p\\left(x_{t} \\mid \\boldsymbol{x}_{1:(t-1)}\\right)  \\tag{15.3}\\\\\n& =\\prod_{t=1}^{T} p\\left(x_{t} \\mid \\boldsymbol{x}_{1:(t-1)}\\right), \\tag{15.4}\n\\end{align*}\n$$\n\n其中 $x_{t} \\in \\mathcal{V}, t \\in\\{1, \\cdots, T\\}$ 为词表 $\\mathcal{V}$ 中的一个词，$p\\left(x_{1} \\mid x_{0}\\right)=p\\left(x_{1}\\right)$ ．\n因此，序列数据的概率密度估计问题可以转换为单变量的条件概率估计问题，即给定 $\\boldsymbol{x}_{1:(t-1)}$ 时 $x_{t}$ 的条件概率 $p\\left(x_{t} \\mid \\boldsymbol{x}_{1:(t-1)}\\right)$ ．\n\n给定一个包含 $N$ 个序列数据的数据集 $\\mathcal{D}=\\left\\{\\boldsymbol{x}_{1: T_{n}}^{(n)}\\right\\}_{n=1}^{N}$ ，序列概率模型需要学习一个模型 $p_{\\theta}\\left(x \\mid \\boldsymbol{x}_{1:(t-1)}\\right)$ 来最大化整个数据集的对数似然函数，即\n\n$$\n\\begin{equation*}\n\\max _{\\theta} \\sum_{n=1}^{N} \\log p_{\\theta}\\left(\\boldsymbol{x}_{1: T_{n}}^{(n)}\\right)=\\max _{\\theta} \\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}} \\log p_{\\theta}\\left(x_{t}^{(n)} \\mid \\boldsymbol{x}_{1:(t-1)}^{(n)}\\right) . \\tag{15.5}\n\\end{equation*}\n$$\n\n在这种序列模型方式中，每一步都需要将前面的输出作为当前步的输入，是一种自回归（AutoRegressive）的方式。因此这一类模型也称为自回归生成模型 （AutoRegressive Generative Model）．\n\n由于 $X_{t} \\in \\mathcal{V}$ 为离散变量，我们可以假设条件概率 $p_{\\theta}\\left(x_{t} \\mid \\boldsymbol{x}_{1:(t-1)}\\right)$ 服从多项分布，然后通过不同的模型来估计。本章主要介绍两种比较主流的自回归生成模型：$N$ 元统计模型和深度序列模型．\n\n不失一般性，本章以自然语言为例来介绍序列概率模型。\n\n自回归模型参见第 6．1．2节。\n\n多 项 分 布 参 见 第 D．2．2．1 节．",
        "总结": "- 序列数据的两个特点：样本是变长的，样本空间非常大。  \n- 序列概率的乘法公式：将序列概率分解为一系列条件概率的乘积。  \n- 序列概率模型的目标：通过最大化对数似然函数来学习模型参数。  \n- 自回归生成模型的定义：每一步使用前面的输出作为当前步的输入，是一种自回归方式。  \n- 条件概率的分布假设：对于离散变量，假设条件概率服从多项分布。  \n- 本章介绍的两种主流自回归生成模型：N元统计模型和深度序列模型。  \n- 自回归模型参考章节：第6.1.2节。  \n- 多项分布参考章节：第D.2.2.1节。"
      },
      {
        "段落": "## 15．1．1 序列生成\n\n一旦通过最大似然估计训练了模型 $p_{\\theta}\\left(x \\mid \\boldsymbol{x}_{1:(t-1)}\\right)$ ，就可以通过时间顺序来生成一个完整的序列样本。令 $\\hat{x}_{t}$ 为在第 $t$ 步根据分布 $p_{\\theta}\\left(x \\mid \\hat{\\boldsymbol{x}}_{1:(t-1)}\\right)$ 生成的词，\n\n$$\n\\begin{equation*}\n\\hat{x}_{t} \\sim p_{\\theta}\\left(x \\mid \\hat{\\boldsymbol{x}}_{1:(t-1)}\\right) \\tag{15.6}\n\\end{equation*}\n$$\n\n其中 $\\hat{\\boldsymbol{x}}_{1:(t-1)}=\\hat{x}_{1}, \\cdots, \\hat{x}_{t-1}$ 为前面 $t-1$ 步中生成的前缀序列．\n自回归的方式可以生成一个无限长度的序列。为了避免这种情况，通常会设置一个特殊的符号 $\\langle E O S\\rangle$ 来表示序列的结束。在训练时，每个序列样本的结尾都加上符号 $\\langle E O S\\rangle$ 。在测试时，一旦生成了符号 $\\langle E O S\\rangle$ ，就中止生成过程．\n\n束搜索 当使用自回归模型生成一个最可能的序列时，生成过程是一种从左到右的贪婪式搜索过程．在每一步都生成最可能的词，\n\n$$\n\\begin{equation*}\n\\hat{x}_{t}=\\underset{x \\in \\mathcal{V}}{\\arg \\max } p_{\\theta}\\left(x \\mid \\hat{\\boldsymbol{x}}_{1:(t-1)}\\right) \\tag{15.7}\n\\end{equation*}\n$$\n\n其中 $\\hat{\\boldsymbol{x}}_{1:(t-1)}=\\hat{x}_{1}, \\cdots, \\hat{x}_{t-1}$ 为前面 $t-1$ 步中生成的前缀序列．\n这种贪婪式的搜索方式是次优的，生成的序列 $\\hat{\\boldsymbol{x}}_{1: T}$ 并不保证是全局最优的。\n\n$$\n\\begin{equation*}\n\\prod_{t=1}^{T} \\max _{x_{t} \\in \\mathcal{V}} p_{\\theta}\\left(x_{t} \\mid \\hat{\\boldsymbol{x}}_{1:(t-1)}\\right) \\leq \\max _{\\boldsymbol{x}_{1: T} \\in \\mathcal{V}^{T}} \\prod_{t=1}^{T} p_{\\theta}\\left(x \\mid \\boldsymbol{x}_{1:(t-1)}\\right) \\tag{15.8}\n\\end{equation*}\n$$\n\n一种常用的减少搜索错误的启发式方法是束搜索（Beam Search）。在每一步中，生成 $K$ 个最可能的前缀序列，其中 $K$ 为束的大小（Beam Size），是一个超参数．图15．1给出了一个束搜索过程的示例，其中词表 $\\mathcal{V}=\\{A, B, C\\}$ ，束大小为 2 ．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-369.jpg?height=497&width=760&top_left_y=1420&top_left_x=282)\n\n图15．1束搜索过程示例\n\n束搜索的过程如下：在第 1 步时，生成 $K$ 个最可能的词；在后面每一步中，从 $K|\\mathcal{V}|$ 个候选输出中选择 $K$ 个最可能的序列。\n\n束的大小 $K$ 越大，束搜索的复杂度越高，但越有可能生成最优序列。在实际应用中，束搜索可以通过调整束大小 $K$ 来平衡计算复杂度和搜索质量之间的优先级。",
        "总结": "- 序列生成方法：通过最大似然估计训练的模型 $p_{\\theta}(x \\mid \\boldsymbol{x}_{1:(t-1)})$，按时间顺序生成序列样本，每一步根据前缀序列生成下一个词。\n- 生成过程公式：$\\hat{x}_{t} \\sim p_{\\theta}(x \\mid \\hat{\\boldsymbol{x}}_{1:(t-1)})$，表示第 $t$ 步生成的词 $\\hat{x}_{t}$ 服从当前条件分布。\n- 序列结束符号：使用特殊符号 $\\langle E O S\\rangle$ 表示序列结束，训练时在序列末尾添加该符号，测试时生成该符号即停止。\n- 贪婪搜索：每一步选择概率最大的词，即 $\\hat{x}_{t} = \\arg \\max_{x \\in \\mathcal{V}} p_{\\theta}(x \\mid \\hat{\\boldsymbol{x}}_{1:(t-1)})$，但可能无法得到全局最优序列。\n- 贪婪搜索的局限性：$\\prod_{t=1}^{T} \\max_{x_t \\in \\mathcal{V}} p_{\\theta}(x_t \\mid \\hat{\\boldsymbol{x}}_{1:(t-1)})$ 不一定等于全局最优概率。\n- 束搜索（Beam Search）：一种启发式方法，每一步保留 $K$ 个最可能的前缀序列（束大小为 $K$），以减少搜索错误。\n- 束搜索过程：第 1 步生成 $K$ 个最可能词；后续每步从候选中选择 $K$ 个最可能序列。\n- 束大小的影响：束大小 $K$ 越大，搜索质量越高但计算复杂度也越高，实际应用中需权衡。"
      },
      {
        "段落": "### 15.2 N 元统计模型\n\n由于数据稀疏问题，当 $t$ 比较大时，依然很难估计条件概率 $p\\left(x_{t} \\mid \\boldsymbol{x}_{1:(t-1)}\\right)$ 。一个简化的方法是 $N$ 元模型（N－Gram Model），假设每个词 $x_{t}$ 只依赖于其前面的 $N-1$ 个词（ $N$ 阶马尔可夫性质），即\n\n$$\n\\begin{equation*}\np\\left(x_{t} \\mid \\boldsymbol{x}_{1:(t-1)}\\right)=p\\left(x_{t} \\mid \\boldsymbol{x}_{(t-N+1):(t-1)}\\right) \\tag{15.9}\n\\end{equation*}\n$$\n\n当 $N=1$ 时，称为一元（Unigram）模型；当 $N=2$ 时，称为二元（Bigram）模型，以此类推．\n\n一元模型 当 $N=1$ 时，序列 $\\boldsymbol{x}_{1: T}$ 中每个词都和其他词独立，和它的上下文无关。每个位置上的词都是从多项分布独立生成的。在多项分布中，$\\theta=\\left[\\theta_{1}, \\cdots, \\theta_{|\\mathcal{V}|}\\right]$ 为词表中每个词被抽取的概率。\n\n在一元模型中，序列 $\\boldsymbol{x}_{1: T}$ 的概率可以写为\n\n$$\n\\begin{equation*}\np\\left(\\boldsymbol{x}_{1: T} ; \\theta\\right)=\\prod_{t=1}^{T} p\\left(x_{t}\\right)=\\prod_{k=1}^{|\\mathcal{V}|} \\theta_{k}^{m_{k}} \\tag{15.10}\n\\end{equation*}\n$$\n\n其中 $m_{k}$ 为词表中第 $k$ 个词 $v_{k}$ 在序列中出现的次数。公式（15．10）和标准多项分布的区别是没有多项式系数，因为这里词的顺序是给定的．\n\n给定一组训练集 $\\left\\{\\boldsymbol{x}_{1: T_{n}}^{(n)}\\right\\}_{n=1}^{N^{\\prime}}$ ，其对数似然函数为：\n\n$$\n\\begin{align*}\n\\log \\prod_{n=1}^{N^{\\prime}} p\\left(\\boldsymbol{x}_{1: T_{n}}^{(n)} ; \\theta\\right) & =\\log \\prod_{k=1}^{|\\mathcal{V}|} \\theta_{k}^{m_{k}}  \\tag{15.11}\\\\\n& =\\sum_{k=1}^{|\\mathcal{V}|} m_{k} \\log \\theta_{k} \\tag{15.12}\n\\end{align*}\n$$\n\n其中 $m_{k}$ 为第 $k$ 个词在整个训练集中出现的次数．\n这样，一元模型的最大似然估计可以转化为约束优化问题：\n\n$$\n\\begin{align*}\n\\max _{\\theta} & \\sum_{k=1}^{|\\mathcal{V}|} m_{k} \\log \\theta_{k}  \\tag{15.13}\\\\\n\\text { s.t. } & \\sum_{k=1}^{|\\mathcal{V}|} \\theta_{k}=1 \\tag{15.14}\n\\end{align*}\n$$\n\n引入拉格朗日乘子 $\\lambda$ ，定义拉格朗日函数 $\\Lambda(\\theta, \\lambda)$ 为\n\n$$\n\\begin{equation*}\n\\Lambda(\\theta, \\lambda)=\\sum_{k=1}^{|\\mathcal{V}|} m_{k} \\log \\theta_{k}+\\lambda\\left(\\sum_{k=1}^{|\\mathcal{V}|} \\theta_{k}-1\\right) . \\tag{15.15}\n\\end{equation*}\n$$\n\n令\n\n$$\n\\begin{align*}\n& \\frac{\\partial \\Lambda(\\theta, \\lambda)}{\\partial \\theta_{k}}=\\frac{m_{k}}{\\theta_{k}}+\\lambda=0, \\quad k=1,2, \\cdots,|\\mathcal{V}|  \\tag{15.16}\\\\\n& \\frac{\\partial \\Lambda(\\theta, \\lambda)}{\\partial \\lambda}=\\sum_{k=1}^{|\\mathcal{V}|} \\theta_{k}-1=0 . \\tag{15.17}\n\\end{align*}\n$$\n\n求解上述方程得到 $\\lambda=-\\sum_{k=1}^{|V|} m_{k}$ ，进一步得到\n\n$$\n\\begin{equation*}\n\\theta_{k}=\\frac{m_{k}}{\\sum_{k^{\\prime}=1}^{|\\mathcal{V}|} m_{k^{\\prime}}}=\\frac{m_{k}}{\\bar{m}} \\tag{15.18}\n\\end{equation*}\n$$\n\n其中 $\\bar{m}=\\sum_{k^{\\prime}=1}^{|\\mathcal{V}|} m_{k^{\\prime}}$ 为文档集合的长度。由此可见，最大似然估计等价于频率估计。\n$\\mathbf{N}$ 元模型 同理， $\\mathbf{N}$ 元模型中的条件概率 $p\\left(x_{t} \\mid \\boldsymbol{x}_{(t-N+1):(t-1)}\\right)$ 也可以通过最大似然函数得到：\n\n$$\n\\begin{equation*}\np\\left(x_{t} \\mid \\boldsymbol{x}_{(t-N+1):(t-1)}\\right)=\\frac{\\mathrm{m}\\left(\\boldsymbol{x}_{(t-N+1): t}\\right)}{\\mathrm{m}\\left(\\boldsymbol{x}_{(t-N+1):(t-1)}\\right)} \\tag{15.19}\n\\end{equation*}\n$$\n\n其中 $\\mathrm{m}\\left(\\boldsymbol{x}_{(t-N+1): t}\\right)$ 为 $\\boldsymbol{x}_{(t-N+1): t}$ 在数据集中出现的次数。\nN 元模型广泛应用于各种自然语言处理问题，如语音识别、机器翻译、拼音输入法，字符识别等。通过 N 元模型，我们可以计算一个序列的概率，从而判断该序列是否符合自然语言的语法和语义规则。\n\n平滑技术 N 元模型的一个主要问题是数据稀疏问题。数据稀疏问题在基于统计的机器学习中是一个常见的问题，主要是由于训练样本不足而导致密度估计不准确。在一元模型中，如果一个词 $v$ 在训练数据集中不存在，就会导致任何包含 $v$ 的句子的概率都为 0 。同样在 N 元模型中，当一个 N 元组合在训练数据集中不存在时，包含这个组合的句子的概率为 0 ．\n\n数据稀疏问题最直接的解决方法就是增加训练数据集的规模，但其边际效益会随着数据集规模的增加而递减。以自然语言为例，大多数自然语言都服从Zipf定律：＂在一个给定自然语言数据集中，一个单词出现的频率与它在频率表里的排名成反比．出现频率最高的单词的出现频率大约是出现频率第二位的单词的 2倍，大约是出现频率第三位的单词的 3 倍。＂因此，在自然语言中大部分的词都是低频词，很难通过增加数据集来避免数据稀疏问题。\nhttps：／／nndl．github．io／\n\n拉格朗日乘子参见第 C． 3 节。\n\n参见习题15－1．\n\nZipf 定律是美国语言学家 George K．Zipf 提出的实验定律．\n\n数据稀疏问题的一种解决方法是平滑技术（Smoothing），即给一些没有出现的词组合赋予一定先验概率。平滑技术是 N 元模型中一项必不可少的技术，比如加法平滑的计算公式为\n\n$$\n\\begin{equation*}\np\\left(x_{t} \\mid \\boldsymbol{x}_{(t-N+1):(t-1)}\\right)=\\frac{\\mathrm{m}\\left(\\boldsymbol{x}_{(t-N+1): t}\\right)+\\delta}{\\mathrm{m}\\left(\\boldsymbol{x}_{(t-N+1):(t-1)}\\right)+\\delta|\\mathcal{V}|} \\tag{15.20}\n\\end{equation*}\n$$\n\n其中 $\\delta \\in(0,1]$ 为常数．$\\delta=1$ 时，称为加 1 平滑．\n除了加法平滑，还有很多平滑技术，比如 Good－Turing 平滑，Kneser－Ney 平滑等，其基本思想都是增加低频词的频率，而降低高频词的频率。\n\n参见习题15－2．",
        "总结": "- N 元模型（N－Gram Model）假设每个词只依赖于前面的 N-1 个词，即 N 阶马尔可夫性质  \n- 一元模型（Unigram）中每个词与其他词独立，概率由多项分布给出  \n- 一元模型的概率公式为 $ p(\\boldsymbol{x}_{1: T}; \\theta) = \\prod_{k=1}^{|\\mathcal{V}|} \\theta_{k}^{m_{k}} $  \n- 一元模型的最大似然估计通过拉格朗日乘子法求解，得到 $\\theta_{k} = \\frac{m_{k}}{\\bar{m}}$  \n- N 元模型的条件概率公式为 $ p(x_t | \\boldsymbol{x}_{(t-N+1):(t-1)}) = \\frac{m(\\boldsymbol{x}_{(t-N+1):t})}{m(\\boldsymbol{x}_{(t-N+1):(t-1)})} $  \n- N 元模型广泛应用于自然语言处理任务，如语音识别、机器翻译等  \n- 数据稀疏问题导致未出现的词组合概率为 0，影响模型性能  \n- 解决数据稀疏问题的方法包括增加训练数据和使用平滑技术  \n- 平滑技术如加法平滑、Good-Turing 平滑、Kneser-Ney 平滑等，用于调整低频词的概率估计  \n- 加法平滑公式为 $ p(x_t | \\boldsymbol{x}_{(t-N+1):(t-1)}) = \\frac{m(\\boldsymbol{x}_{(t-N+1):t}) + \\delta}{m(\\boldsymbol{x}_{(t-N+1):(t-1)}) + \\delta|\\mathcal{V}|} $，其中 $\\delta$ 为常数"
      },
      {
        "段落": "## 15.3 深度序列模型\n\n深度序列模型（Deep Sequence Model）是指利用神经网络模型来估计条件概率 $p_{\\theta}\\left(x_{t} \\mid \\boldsymbol{x}_{1:(t-1)}\\right)$ ．\n\n假设一个神经网络 $f(\\cdot ; \\theta)$ ，其输入为历史信息 $\\tilde{h}_{t}=\\boldsymbol{x}_{1:(t-1)}$ ，输出为词表 $\\mathcal{V}$中的每个词 $v_{k}(1 \\leq k \\leq|\\mathcal{V}|)$ 出现的概率，并满足\n\n$$\n\\begin{equation*}\n\\sum_{k=1}^{|\\mathcal{V}|} f_{k}\\left(\\boldsymbol{x}_{1:(t-1)} ; \\theta\\right)=1, \\tag{15.21}\n\\end{equation*}\n$$\n\n其中 $\\theta$ 表示网络参数．条件概率 $p_{\\theta}\\left(x_{t} \\mid \\boldsymbol{x}_{1:(t-1)}\\right)$ 可以从神经网络的输出中得到：\n\n$$\n\\begin{equation*}\np_{\\theta}\\left(x_{t} \\mid \\boldsymbol{x}_{1:(t-1)}\\right)=f_{k_{x_{t}}}\\left(\\boldsymbol{x}_{1:(t-1)} ; \\theta\\right) \\tag{15.22}\n\\end{equation*}\n$$\n\n其中 $k_{x_{t}}$ 为 $x_{t}$ 在词表 $\\mathcal{V}$ 中的索引。\n深度序列模型一般可以分为三个部分：嵌入层、特征层、输出层。\n嵌入层 令 $\\tilde{h}_{t}=\\boldsymbol{x}_{1:(t-1)}$ 表示输入的历史信息，一般为符号序列。由于神经网络模型一般要求输入形式为实数向量，因此为了使得神经网络模型能处理符号数据，需要将这些符号转换为向量形式。一种简单的转换方法是通过一个嵌入表 （Embedding Lookup Table）来将每个符号直接映射成向量表示。嵌入表也称为嵌入矩阵或查询表。图15．2是嵌入矩阵的示例。令 $M \\in \\mathbb{R}^{D_{x} \\times|\\mathcal{V}|}$ 为嵌入矩阵，其中第 $k$ 列向量 $\\boldsymbol{m}_{k} \\in \\mathbb{R}^{D_{x}}$ 表示词表中第 $k$ 个词对应的向量表示。\n\n假设词 $x_{t}$ 对应词表中的索引为 $k$ ，则其 one－hot 向量表示为 $\\delta_{t} \\in\\{0,1\\}^{|\\mathcal{V}|}$ ，即第 $k$ 维为 1 ，其余为 0 的 $|\\mathcal{V}|$ 维向量。词 $x_{t}$ 对应的向量表示为\n\n$$\n\\begin{equation*}\n\\boldsymbol{e}_{t}=M \\delta_{t}=\\boldsymbol{m}_{k} . \\tag{15.23}\n\\end{equation*}\n$$\n\n通过上面的映射可以得到序列 $x_{1:(t-1)}$ 对应的向量序列 $\\boldsymbol{e}_{1}, \\cdots, \\boldsymbol{e}_{t-1}$ ．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-373.jpg?height=374&width=828&top_left_y=111&top_left_x=235)\n\n图 15.2 嵌入矩阵\n\n特征层 特征层用于从输入向量序列 $\\boldsymbol{e}_{1}, \\cdots, \\boldsymbol{e}_{t-1}$ 中提取特征，输出为一个可以表示历史信息的向量 $\\boldsymbol{h}_{t}$ 。\n\n特征层可以通过不同类型的神经网络（比如前馈神经网络和循环神经网络等）来实现．常见的网络类型有以下三种：",
        "总结": "- 深度序列模型定义：利用神经网络估计条件概率 $p_{\\theta}(x_t \\mid \\boldsymbol{x}_{1:(t-1)})$，通过神经网络输出词表中每个词出现的概率。  \n- 条件概率计算方式：从神经网络输出中直接获取对应词的概率，即 $p_{\\theta}(x_t \\mid \\boldsymbol{x}_{1:(t-1)}) = f_{k_{x_t}}(\\boldsymbol{x}_{1:(t-1)}; \\theta)$。  \n- 模型结构：分为嵌入层、特征层和输出层三个部分。  \n- 嵌入层功能：将符号序列转换为向量形式，使用嵌入矩阵 $M$ 将每个词映射为向量表示 $\\boldsymbol{e}_t = M \\delta_t$。  \n- 特征层功能：从输入向量序列中提取特征，输出一个表示历史信息的向量 $\\boldsymbol{h}_t$。  \n- 特征层实现方式：可以使用前馈神经网络、循环神经网络等不同类型神经网络。"
      },
      {
        "段落": "## （1）简单平均\n\n历史信息的向量 $\\boldsymbol{h}_{t}$ 为前面 $t-1$ 个词向量的平均，即\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}=\\sum_{i=1}^{t-1} \\alpha_{i} \\boldsymbol{e}_{i} \\tag{15.24}\n\\end{equation*}\n$$\n\n其中 $\\alpha_{i}$ 为每个词的权重．\n权重 $\\alpha_{i}$ 可以和位置 $i$ 及其表示 $\\boldsymbol{e}_{i}$ 相关，也可以无关．为简单起见，可以设置 $\\alpha_{i}=\\frac{1}{t-1}$ ．权重 $\\alpha_{i}$ 也可以通过注意力机制来动态计算．\n\n注意力机制参见第 8.2节。\n\n参见习题15－3．\n（2）前馈神经网络\n前馈神经网络要求输入的大小是固定的。因此，和 N 元模型类似，假设历史信息只包含前面 $N-1$ 个词．首先将这 $N-1$ 个词向量 $\\boldsymbol{e}_{t-N+1}, \\cdots, \\boldsymbol{e}_{t-1}$ 拼接成一 $N$ 为超参数．个 $D_{x} \\times(N-1)$ 维的向量 $\\boldsymbol{h}^{\\prime}$ ，即\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}^{\\prime}=\\boldsymbol{e}_{t-N+1} \\oplus \\cdots \\oplus \\boldsymbol{e}_{t-1} \\tag{15.25}\n\\end{equation*}\n$$\n\n其中 $\\oplus$ 表示向量拼接操作．\n然后将 $\\boldsymbol{h}^{\\prime}$ 输入到由前馈神经网络构成的隐藏层，最后一层隐藏层的输出 $\\boldsymbol{h}_{t}$ ，即\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}=g\\left(\\boldsymbol{h}^{\\prime} ; \\theta_{g}\\right), \\tag{15.26}\n\\end{equation*}\n$$\n\n其中 $g\\left(\\cdot ; \\theta_{g}\\right)$ 可以为全连接的前馈神经网络或卷积神经网络，$\\theta_{g}$ 为网络参数．\nhttps：／／nndl．github．io／\n\n为了增加特征的多样性和提高模型训练效率，前馈神经网络中也可以包含跳层连接（Skip－Layer Connection）［Bengio et al．，2003］，比如\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}=\\boldsymbol{h}^{\\prime} \\oplus g\\left(\\boldsymbol{h}^{\\prime} ; \\theta_{g}\\right) \\tag{15.27}\n\\end{equation*}\n$$",
        "总结": "- 简单平均：历史信息向量 $\\boldsymbol{h}_{t}$ 是前面 $t-1$ 个词向量的平均，权重 $\\alpha_{i}$ 可以是固定值 $\\frac{1}{t-1}$ 或通过注意力机制动态计算。  \n- 前馈神经网络：输入大小固定，历史信息包含前面 $N-1$ 个词向量，拼接成 $D_{x} \\times (N-1)$ 维向量 $\\boldsymbol{h}^{\\prime}$，再通过前馈神经网络或卷积神经网络得到输出 $\\boldsymbol{h}_{t}$。  \n- 跳层连接：前馈神经网络中可加入跳层连接，将输入 $\\boldsymbol{h}^{\\prime}$ 与隐藏层输出 $g(\\boldsymbol{h}^{\\prime}; \\theta_{g})$ 拼接作为最终输出 $\\boldsymbol{h}_{t}$。"
      },
      {
        "段落": "## （3）循环神经网络\n\n和前馈神经网络不同，循环神经网络可以接受变长的输入序列，依次接受输 $\\lambda \\boldsymbol{e}_{1}, \\cdots, \\boldsymbol{e}_{t-1}$ ，得到时刻 $t$ 的隐藏状态\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}=g\\left(\\boldsymbol{h}_{t-1}, \\boldsymbol{e}_{t} ; \\theta_{g}\\right) \\tag{15.28}\n\\end{equation*}\n$$\n\n其中 $g(\\cdot)$ 为一个非线性函数，$\\theta_{g}$ 为循环神经网络的参数， $\\boldsymbol{h}_{0}=0$ ．\n前馈神经网络模型和循环神经网络模型的不同之处在于循环神经网络利用隐藏状态来记录以前所有时刻的信息，而前馈神经网络只能接受前 $N-1$ 个时刻的信息。\n\n输出层 输出层为一般使用 Softmax 分类器，接受历史信息的向量表示 $\\boldsymbol{h}_{t} \\in \\mathbb{R}^{D_{h}}$ ，输出为词表中每个词的后验概率，输出大小为 $|\\mathcal{V}|$ 。\n\n$$\n\\begin{align*}\n\\boldsymbol{o}_{t} & =\\operatorname{softmax}\\left(\\hat{\\boldsymbol{o}}_{t}\\right)  \\tag{15.29}\\\\\n& =\\operatorname{softmax}\\left(\\boldsymbol{W} \\boldsymbol{h}_{t}+\\boldsymbol{b}\\right) \\tag{15.30}\n\\end{align*}\n$$\n\n其中输出向量 $\\boldsymbol{o}_{t} \\in(0,1)^{|\\mathcal{V}|}$ 为预测的概率分布，第 $k$ 维是词表中第 $k$ 个词出现的条件概率；$\\hat{\\boldsymbol{o}}_{t}$ 是未归一化的得分向量； $\\boldsymbol{W} \\in \\mathbb{R}^{|\\mathcal{V}| \\times D_{h}}$ 是最后一层隐藏层到输出层直接的权重矩阵， $\\boldsymbol{b} \\in \\mathbb{R}^{|\\mathcal{V}|}$ 为偏置．\n\n图15．3给出了两种不同的深度序列模型，图15．3a为前馈神经网络模型（虚线边为可选的跳层连接），图 15.3 b 为循环神经网络模型。",
        "总结": "- 循环神经网络（RNN）可以接受变长的输入序列，并通过隐藏状态记录以前所有时刻的信息，与前馈神经网络不同。  \n- 隐藏状态的计算公式为 $\\boldsymbol{h}_{t}=g\\left(\\boldsymbol{h}_{t-1}, \\boldsymbol{e}_{t} ; \\theta_{g}\\right)$，其中 $g(\\cdot)$ 是非线性函数，$\\theta_{g}$ 为模型参数，初始隐藏状态 $\\boldsymbol{h}_{0}=0$。  \n- 输出层使用 Softmax 分类器，输入为隐藏状态 $\\boldsymbol{h}_{t} \\in \\mathbb{R}^{D_{h}}$，输出词表中每个词的后验概率，大小为 $|\\mathcal{V}|$。  \n- 输出公式为 $\\boldsymbol{o}_{t} = \\operatorname{softmax}\\left(\\boldsymbol{W} \\boldsymbol{h}_{t}+\\boldsymbol{b}\\right)$，其中 $\\boldsymbol{W}$ 是权重矩阵，$\\boldsymbol{b}$ 是偏置项。  \n- 图15.3a展示了前馈神经网络模型（含可选跳层连接），图15.3b展示了循环神经网络模型。"
      },
      {
        "段落": "## 15．3．1 参数学习\n\n给定一个训练序列 $\\boldsymbol{x}_{1: T}$ ，深度序列模型的训练目标是找到一组参数 $\\theta$ 使得对数似然函数最大．\n\n$$\n\\begin{equation*}\n\\log p_{\\theta}\\left(\\boldsymbol{x}_{1: T}\\right)=\\sum_{t=1}^{T} \\log p_{\\theta}\\left(x_{t} \\mid \\boldsymbol{x}_{1:(t-1)}\\right) \\tag{15.31}\n\\end{equation*}\n$$\n\n其中 $\\theta$ 表示网络中的所有参数，包括嵌入矩阵 $M$ 以及神经网络的权重和偏置．\n网络参数一般通过梯度上升法来学习，\n\n$$\n\\begin{equation*}\n\\theta \\leftarrow \\theta+\\alpha \\frac{\\partial \\log p_{\\theta}\\left(\\boldsymbol{x}_{1: T}\\right)}{\\partial \\theta} \\tag{15.32}\n\\end{equation*}\n$$\n\n其中 $\\alpha$ 为学习率。\nhttps：／／nndl．github．io／\n\n跳层连接是指前馈神经网络中的某一神经层可以接受来自非相邻的低层信息，其思想和残差网络中的直连边并不完全一样．残差网络参见第 5．4．4 节。\n\n简要起见，这里忽略了正则化项。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-375.jpg?height=1113&width=694&top_left_y=123&top_left_x=302)\n\n图 15.3 深度序列模型",
        "总结": "- 参数学习的目标是通过优化参数 θ 使对数似然函数最大化，其中 θ 包括嵌入矩阵、神经网络的权重和偏置。  \n- 对数似然函数由序列中每个时间步的条件概率对数相加得到，即 $\\log p_{\\theta}(\\boldsymbol{x}_{1:T}) = \\sum_{t=1}^{T} \\log p_{\\theta}(x_t \\mid \\boldsymbol{x}_{1:(t-1)})$。  \n- 参数更新采用梯度上升法，公式为 $\\theta \\leftarrow \\theta + \\alpha \\frac{\\partial \\log p_{\\theta}(\\boldsymbol{x}_{1:T})}{\\partial \\theta}$，其中 α 为学习率。  \n- 跳层连接允许神经网络的某一层接收非相邻层的信息，与残差网络中的直连边思想不同。  \n- 图 15.3 展示了深度序列模型的结构。  \n- 文中简要忽略了正则化项。"
      },
      {
        "段落": "## 15.4 评价方法\n\n构造一个序列生成模型后，需要有一个度量来评价其好坏．",
        "总结": "- 概念：评价方法用于衡量序列生成模型的性能。  \n- 算法：未提及具体算法。  \n- 定理或命题：未提及具体定理或命题。  \n- 数学推导：未提及具体数学推导。"
      },
      {
        "段落": "## 15．4．1 困惑度\n\n给定一个测试文本集合，一个好的序列生成模型应该使得测试集合中的句子的联合概率尽可能高．\n\n困惑度（Perplexity）是信息论的一个概念，可以用来衡量一个分布的不确定性．对于离散随机变量 $X \\in \\mathcal{X}$ ，其概率分布为 $p(x)$ ，困惑度为\n\n$$\n\\begin{equation*}\n2^{H(p)}=2^{-\\sum_{x \\in x} p(x) \\log _{2} p(x)}, \\tag{15.33}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{H}(p)$ 为分布 $p$ 的熵．\n困惑度也可以用来衡量两个分布之间差异．对于一个未知的数据分布 $p_{r}(x)$ https：／／nndl．github．io／\n\n和一个模型分布 $p_{\\theta}(x)$ ，我们从 $p_{r}(x)$ 中采样出一组测试样本 $x^{(1)}, \\cdots, x^{(N)}$ ，模型分布 $p_{\\theta}(x)$ 的困惑度为\n\n$$\n\\begin{equation*}\n2^{H\\left(\\tilde{p}_{r}, p_{\\theta}\\right)}=2^{-\\frac{1}{N} \\sum_{n=1}^{N} \\log _{2} p_{\\theta}\\left(x^{(n)}\\right)} \\tag{15.34}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{H}\\left(\\tilde{p}_{r}, p_{\\theta}\\right)$ 为样本的经验分布 $\\tilde{p}_{r}$ 与模型分布 $p_{\\theta}$ 之间的交叉嫡，也是所有样本上的负对数似然函数．\n\n困惑度可以衡量模型分布与样本经验分布之间的契合程度．困惑度越低则两个分布越接近．因此，模型分布 $p_{\\theta}(x)$ 的好坏可以用困惑度来评价．\n\n假设测试集合有 $N$ 个独立同分布的序列 $\\left\\{\\boldsymbol{x}_{1: T_{n}}^{(n)}\\right\\}_{n=1}^{N}$ 。我们可以用模型 $p_{\\theta}(\\boldsymbol{x})$对每个序列计算其概率 $p_{\\theta}\\left(x_{1: T_{n}}^{(n)}\\right)$ ，整个测试集的联合概率为\n\n$$\n\\begin{equation*}\n\\prod_{n=1}^{N} p_{\\theta}\\left(\\boldsymbol{x}_{1: T_{n}}^{(n)}\\right)=\\prod_{n=1}^{N} \\prod_{t=1}^{T_{n}} p_{\\theta}\\left(x_{t}^{(n)} \\mid \\boldsymbol{x}_{1:(t-1)}^{(n)}\\right) \\tag{15.35}\n\\end{equation*}\n$$\n\n模型 $p_{\\theta}(\\boldsymbol{x})$ 的困惑度定义为\n\n$$\n\\begin{align*}\n\\operatorname{PPL}(\\theta) & =2^{-\\frac{1}{T} \\sum_{n=1}^{N} \\log _{2} p_{\\theta}\\left(\\boldsymbol{x}_{1: T_{n}}^{(n)}\\right)}  \\tag{15.36}\\\\\n& =2^{-\\frac{1}{T} \\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}} \\log _{2} p_{\\theta}\\left(x_{t}^{(n)} \\mid x_{1:(t-1)}^{(n)}\\right)}  \\tag{15.37}\\\\\n& =\\left(\\prod_{n=1}^{N} \\prod_{t=1}^{T_{n}} p_{\\theta}\\left(x_{t}^{(n)} \\mid \\boldsymbol{x}_{1:(t-1)}^{(n)}\\right)\\right)^{-1 / T} \\tag{15.38}\n\\end{align*}\n$$\n\n其中 $T=\\sum_{n=1}^{N} T_{n}$ 为测试数据集中序列的总长度．可以看出，困惑度为每个词条件概率 $p_{\\theta}\\left(x_{t}^{(n)} \\mid \\boldsymbol{x}_{1:(t-1)}^{(n)}\\right)$ 的几何平均数的倒数。测试集中所有序列的概率越大，困惑度越小，模型越好．\n\n假设一个序列模型赋予每个词出现的概率均等，即 $p_{\\theta}\\left(x_{t}^{(n)} \\mid \\boldsymbol{x}_{1:(t-1)}^{(n)}\\right)=\\frac{1}{|\\mathcal{V}|}$ ，则该模型的困惑度为 $|\\mathcal{V}|$ 。以英语为例， N 元模型的困惑度范围一般为 $50 \\sim 1000$\n\n几何平均数是一种求数值平均数的方法，计算公式为： $\\bar{x}=$ $\\sqrt[n]{\\prod_{t=1}^{n} x_{t}}$.之间．",
        "总结": "- 困惑度是信息论中的概念，用于衡量分布的不确定性和模型与数据分布的契合程度  \n- 困惑度的定义基于熵，公式为 $2^{H(p)} = 2^{-\\sum_{x \\in \\mathcal{X}} p(x) \\log_2 p(x)}$  \n- 困惑度也可用于衡量两个分布之间的差异，公式为 $2^{H(\\tilde{p}_r, p_\\theta)} = 2^{-\\frac{1}{N} \\sum_{n=1}^{N} \\log_2 p_\\theta(x^{(n)})}$  \n- 模型困惑度越低，表示模型分布与数据分布越接近，模型性能越好  \n- 模型困惑度的计算公式为 $PPL(\\theta) = 2^{-\\frac{1}{T} \\sum_{n=1}^{N} \\sum_{t=1}^{T_n} \\log_2 p_\\theta(x_t^{(n)} | x_{1:(t-1)}^{(n)})}$  \n- 困惑度是所有词条件概率的几何平均数的倒数，测试集联合概率越大，困惑度越小  \n- 若模型对每个词赋予相等的概率，则困惑度等于词汇表大小 $|\\mathcal{V}|$  \n- 几何平均数的计算公式为 $\\bar{x} = \\sqrt[n]{\\prod_{t=1}^{n} x_t}$"
      },
      {
        "段落": "## 15．4．2 BLEU算法\n\nBLEU（BiLingual Evaluation Understudy）算法是一种衡量模型生成序列和参考序列之间的 N 元词组（N－Gram）重合度的算法，最早用来评价机器翻译模型的质量，目前也广泛应用在各种序列生成任务中。\n\n令 $\\boldsymbol{x}$ 为从模型分布 $p_{\\theta}$ 中生成的一个候选（Candidate）序列， $\\boldsymbol{s}^{(1)}, \\cdots, \\boldsymbol{s}^{(K)}$ 为从真实数据分布中采集的一组参考（Reference）序列， $\\mathcal{W}$ 为从生成的候选序列\n\n中提取所有 $N$ 元组合的集合，这些 N 元组合的精度（Precision）\n\n$$\n\\begin{equation*}\nP_{N}(\\boldsymbol{x})=\\frac{\\sum_{w \\in \\mathcal{W}} \\min \\left(c_{w}(\\boldsymbol{x}), \\max _{k=1}^{K} c_{w}\\left(\\boldsymbol{s}^{(k)}\\right)\\right)}{\\sum_{w \\in \\mathcal{W}} c_{w}(\\boldsymbol{x})} \\tag{15.39}\n\\end{equation*}\n$$\n\n其中 $c_{w}(\\boldsymbol{x})$ 是 N 元组合 $w$ 在生成序列 $\\boldsymbol{x}$ 中出现的次数，$c_{w}\\left(\\boldsymbol{s}^{(k)}\\right)$ 是 N 元组合 $w$ 在参考序列 $\\boldsymbol{s}^{(k)}$ 中出现的次数。 N 元组合的精度 $P_{N}(\\boldsymbol{x})$ 是计算生成序列中的 N 元组合有多少比例在参考序列中出现。\n\n由于精度只衡量生成序列中的 N 元组合是否在参考序列中出现，生成序列越短，其精度会越高，因此可以引入长度惩罚因子（Brevity Penalty）．如果生成序列的长度短于参考序列，就对其进行惩罚。\n\n$$\nb(\\boldsymbol{x})=\\left\\{\\begin{array}{ccc}\n1 & \\text { if } & l_{x}>l_{s}  \\tag{15.40}\\\\\n\\exp \\left(1-l_{s} / l_{x}\\right) & \\text { if } & l_{x} \\leq l_{s}\n\\end{array}\\right.\n$$\n\n其中 $l_{x}$ 为生成序列 $\\boldsymbol{x}$ 的长度，$l_{s}$ 为参考序列的最短长度．\nBLEU 算法是通过计算不同长度的 N 元组合 $(N=1,2, \\cdots)$ 的精度，并进行几何加权平均而得到。\n\n$$\n\\begin{equation*}\n\\operatorname{BLEU}-\\mathrm{N}(\\boldsymbol{x})=b(\\boldsymbol{x}) \\times \\exp \\left(\\sum_{N=1}^{N^{\\prime}} \\alpha_{N} \\log P_{N}\\right) \\tag{15.41}\n\\end{equation*}\n$$\n\n其中 $N^{\\prime}$ 为最长 N 元组合的长度，$\\alpha_{N}$ 为不同 N 元组合的权重，一般设为 $\\frac{1}{N^{\\prime}}$ 。BLEU算法的值域范围是 $[0,1]$ ，越大表明生成的质量越好．但是 BLEU 算法只计算精度，而不关心召回率（即参考序列里的 N 元组合是否在生成序列中出现）。",
        "总结": "- BLEU算法是一种用于衡量生成序列与参考序列之间N元词组重合度的算法，最初用于评估机器翻译质量，现广泛应用于序列生成任务。  \n- 算法通过计算候选序列中N元组合在参考序列中的出现比例来衡量精度，公式为 $P_{N}(\\boldsymbol{x})$。  \n- 为避免生成序列过短导致精度虚高，引入长度惩罚因子 $b(\\boldsymbol{x})$，根据生成序列与参考序列长度关系进行调整。  \n- BLEU算法通过几何加权平均不同长度的N元组合精度来计算最终得分，公式为 $\\operatorname{BLEU}-\\mathrm{N}(\\boldsymbol{x})$。  \n- 算法值域范围为 $[0,1]$，值越大表示生成质量越好，但仅关注精度，未考虑召回率。"
      },
      {
        "段落": "## 15．4．3 ROUGE 算法\n\nROUGE（ Recall－Oriented Understudy for Gisting Evaluation）算法最早应用于文本摘要领域．和 BLEU 算法类似，但 ROUGE 算法计算的是召回率（Re－ call）．\n\n令 $\\boldsymbol{x}$ 为从模型分布 $p_{\\theta}$ 中生成的一个候选序列， $\\boldsymbol{s}^{(1)}, \\cdots, \\boldsymbol{s}^{(K)}$ 为从真实数据分布中采样出的一组参考序列， $\\mathcal{W}$ 为从参考序列中提取 N 元组合的集合，ROUGE－ N 算法的定义为\n\n$$\n\\begin{equation*}\n\\operatorname{ROUGE-N}(\\boldsymbol{x})=\\frac{\\sum_{k=1}^{K} \\sum_{w \\in \\mathcal{W}} \\min \\left(c_{w}(\\boldsymbol{x}), c_{w}\\left(\\boldsymbol{s}^{(k)}\\right)\\right)}{\\sum_{k=1}^{K} \\sum_{w \\in \\mathcal{W}} c_{w}\\left(\\boldsymbol{s}^{(k)}\\right)} \\tag{15.42}\n\\end{equation*}\n$$\n\n其中 $c_{w}(\\boldsymbol{x})$ 是 N 元组合 $w$ 在生成序列 $\\boldsymbol{x}$ 中出现的次数，$c_{w}\\left(\\boldsymbol{s}^{(k)}\\right)$ 是 N 元组合 $w$ 在参考序列 $\\boldsymbol{s}^{(k)}$ 中出现的次数。\nhttps：／／nndl．github．io／",
        "总结": "- ROUGE算法用于文本摘要领域，计算的是召回率（Recall），与BLEU算法类似。\n- ROUGE-N的定义是通过比较候选序列和参考序列中N元组合的重合次数来计算召回率。\n- 公式中分子是候选序列与所有参考序列中N元组合的最小出现次数之和，分母是所有参考序列中N元组合的出现次数之和。\n- $c_{w}(\\boldsymbol{x})$ 表示N元组合$w$在生成序列$\\boldsymbol{x}$中的出现次数。\n- $c_{w}(\\boldsymbol{s}^{(k)})$ 表示N元组合$w$在参考序列$\\boldsymbol{s}^{(k)}$中的出现次数。"
      },
      {
        "段落": "## 15.5 序列生成模型中的学习问题\n\n使用最大似然估计来学习自回归序列生成模型时，会存在以下三个主要问题：曝光偏差问题、训练目标不一致问题和计算效率问题。下面我们分别介绍这三个问题以及解决方法．",
        "总结": "- 概念：介绍了序列生成模型中使用最大似然估计学习时面临的主要问题。  \n- 算法：未提及具体算法，但讨论了最大似然估计在序列生成模型中的应用。  \n- 问题一：曝光偏差问题，指在训练过程中，模型对某些序列的曝光不足，导致学习效果不佳。  \n- 问题二：训练目标不一致问题，指训练目标与实际生成任务之间存在不一致，影响模型性能。  \n- 问题三：计算效率问题，指最大似然估计在序列生成模型中计算成本较高，影响训练效率。  \n- 解决方法：分别针对上述三个问题提出了相应的解决策略，但具体方法未在文中详细展开。"
      },
      {
        "段落": "## 15．5．1 曝光偏差问题\n\n在自回归生成模型中，第 $t$ 步的输入为模型生成的前缀序列 $\\hat{\\boldsymbol{x}}_{1:(t-1)}$ 。而在训练时，我们使用的前缀序列是训练集中的真实数据 $\\boldsymbol{x}_{1:(t-1)}$ ，而不是模型预测的 $\\hat{\\boldsymbol{x}}_{1:(t-1)}$ 。这种学习方式也称为教师强制（Teacher Forcing）［Williams et al．， 1989］．\n\n这种教师强制的学习方式存在协变量偏移问题．在训练时，每步的输入 $\\boldsymbol{x}_{1:(t-1)}$ 来自于真实数据分布 $p_{r}\\left(\\boldsymbol{x}_{1:(t-1)}\\right)$ ；而在测试时，每步的输入 $\\hat{\\boldsymbol{x}}_{1:(t-1)}$ 来自\n\n协变量偏移问题参见第10．4．2节。于模型分布 $p_{\\theta}\\left(\\boldsymbol{x}_{1:(t-1)}\\right)$ 。由于模型分布 $p_{\\theta}\\left(\\boldsymbol{x}_{1:(t-1)}\\right)$ 和真实数据分布 $p_{r}\\left(\\boldsymbol{x}_{1:(t-1)}\\right)$并不严格一致，因此存在协变量偏移问题。一旦在预测前缀 $\\hat{\\boldsymbol{x}}_{1:(t-1)}$ 的过程中存在错误，会导致错误传播，使得后续生成的序列也会偏离真实分布。这个问题称为曝光偏差（Exposure Bias）问题。\n\n计划采样 为了缓解曝光偏差问题，我们可以在训练时混合使用真实数据和模型生成数据．在第 $t$ 步时，模型随机使用真实数据 $x_{t-1}$ 或前一步生成的词 $\\hat{x}_{t-1}$ 作为输入。\n\n令 $\\epsilon \\in[0,1]$ 为一个控制替换率的超参数，在每一步时，以 $\\epsilon$ 的概率使用真实数据 $x_{t-1}$ ，以 $1-\\epsilon$ 的概率来使用生成数据 $\\hat{x}_{t-1}$ 。当令 $\\epsilon=1$ 时，训练和最大似然估计一样，使用真实数据；当令 $\\epsilon=0$ 时，训练时全部使用模型生成数据．\n\n直觉上，如果一开始训练时的 $\\epsilon$ 过小，模型相当于在噪声很大的数据上训练，会导致模型性能变差，并且难以收敛。因此，一个较好的策略是在训练初期赋予 $\\epsilon$ 较大的值，随着训练次数的增加逐步减少 $\\epsilon$ 的取值．这种策略称为计划采样 （ Scheduled Sampling ）［Bengio et al．，2015］．\n\n令 $\\epsilon_{i}$ 为在第 $i$ 次迭代时的替换率，在计划采样中可以通过下面几种方法来逐步降低 $\\epsilon$ 的取值．\n（1）线性衰减：$\\epsilon_{i}=\\max (\\epsilon, k-c i)$ ，其中 $\\epsilon$ 为最小的替换率，$k$ 和 $c$ 分别为初始值和衰减率。\n（2）指数衰减：$\\epsilon_{i}=k^{i}$ ，其中 $k<1$ 为初始替换率．\n（3）逆 Sigmoid 衰减：$\\epsilon_{i}=k /(k+\\exp (i / k))$ ，其中 $k \\geq 1$ 来控制衰减速度．\n\n计划采样的一个缺点是过度纠正，即在每一步中不管输入如何选择，目标输出依然是来自于真实数据。这可能使得模型预测一些不正确的序列。比如一个真实的序列是＂吃饭＂，如果在第一步生成时使用模型预测的词＂喝＂，模型就会强制记住＂喝饭＂这个不正确的序列。",
        "总结": "- 概念：曝光偏差（Exposure Bias）问题，指在自回归生成模型中，由于训练时使用真实数据而非模型生成数据，导致预测错误传播，使得生成序列偏离真实分布的问题。\n- 算法：计划采样（Scheduled Sampling），通过在训练过程中以一定概率混合使用真实数据和模型生成数据，以缓解曝光偏差问题。\n- 方法：替换率控制，通过超参数 $\\epsilon$ 控制每一步使用真实数据或生成数据的概率，初始值较大，随着训练逐步减小。\n- 替换率衰减策略：包括线性衰减、指数衰减和逆 Sigmoid 衰减三种方式，用于逐步降低 $\\epsilon$ 的取值。\n- 问题：计划采样可能存在的过度纠正问题，即目标输出始终基于真实数据，可能导致模型学习不正确的序列。"
      },
      {
        "段落": "## 15．5．2 训练目标不一致问题\n\n序列生成模型的好坏通常采用和任务相关的指标来进行评价，比如 BLEU、 ROUGE 等。然而，在训练时通常是使用最大似然估计来优化模型，这导致训练目标和评价方法不一致。并且这些评价指标一般都是不可微的，无法直接使用基于梯度的方法来进行优化．\n\n基于强化学习的序列生成 为了可以直接优化评价目标，我们可以将自回归序列生成看作是一种马尔可夫决策过程，并使用强化学习的方法来进行训练。\n\n参见第14．1．3节。\n在第 $t$ 步，动作 $a_{t}$ 可以看作是从词表中选择一个词，策略为 $\\pi_{\\theta}\\left(a \\mid s_{t}\\right)$ ，其中状态 $s_{t}$ 为之前步骤中生成的前缀序列 $\\boldsymbol{x}_{1:(t-1)}$ 。一个序列 $\\boldsymbol{x}_{1: T}$ 可以看作是马尔可夫决策过程的一个轨迹（trajectory）\n\n$$\n\\begin{equation*}\n\\tau=\\left\\{s_{1}, a_{1}, s_{2}, a_{2} \\ldots, s_{T}, a_{T}\\right\\} \\tag{15.43}\n\\end{equation*}\n$$\n\n轨迹 $\\tau$ 的概率为\n\n$$\n\\begin{equation*}\np_{\\theta}(\\tau)=\\prod_{t=1}^{T} \\pi_{\\theta}\\left(a_{t}=x_{t} \\mid s_{t}=\\boldsymbol{x}_{1:(t-1)}\\right) \\tag{15.44}\n\\end{equation*}\n$$\n\n其中状态转移概率 $p\\left(s_{t}=\\boldsymbol{x}_{1: t-1} \\mid s_{t-1}=\\boldsymbol{x}_{1:(t-2)}, a_{t-1}=x_{t-1}\\right)=1$ 是确定性的，可以被忽略。\n\n强化学习的目标是学习一个策略 $\\pi_{\\theta}\\left(a \\mid s_{t}\\right)$ 使得期望回报最大，\n\n$$\n\\begin{align*}\n\\mathcal{J}(\\theta) & =\\mathbb{E}_{\\tau \\sim p_{\\theta}(\\tau)}[G(\\tau)]  \\tag{15.45}\\\\\n& =\\mathbb{E}_{\\boldsymbol{x}_{1: T} \\sim p_{\\theta}\\left(\\boldsymbol{x}_{1: T}\\right)}\\left[G\\left(\\boldsymbol{x}_{1: T}\\right)\\right] \\tag{15.46}\n\\end{align*}\n$$\n\n其中 $G\\left(\\boldsymbol{x}_{1: T}\\right)$ 为序列 $\\boldsymbol{x}_{1: T}$ 的总回报，可以为 BLEU、ROUGE 或其他评价指标。\n这样，序列生成问题就转换为强化学习问题，其策略函数 $\\pi_{\\theta}\\left(a \\mid s_{t}\\right)$ 可以通过 REINFORCE 算法或演员－评论员算法来进行学习．为了改进强化学习的效率，策略函数 $\\pi_{\\theta}\\left(a \\mid s_{t}\\right)$ 一般会通过最大似然估计来进行预训练．\n\n基于强化学习的序列生成模型不但可以解决训练和评价目标不一致问题，也可以有效地解决曝光偏差问题．",
        "总结": "- 概念：训练目标不一致问题，指序列生成模型在训练时使用最大似然估计，而评价时使用BLEU、ROUGE等指标，导致训练与评价目标不一致。  \n- 概念：强化学习用于序列生成，将自回归生成过程建模为马尔可夫决策过程，通过优化评价指标来训练模型。  \n- 算法：REINFORCE算法和演员－评论员算法用于学习策略函数 $\\pi_{\\theta}(a \\mid s_t)$。  \n- 算法：策略函数通常通过最大似然估计进行预训练以提高强化学习效率。  \n- 数学推导：轨迹 $\\tau$ 的概率定义为各步骤动作概率的乘积，状态转移概率为确定性，可忽略。  \n- 数学推导：期望回报 $\\mathcal{J}(\\theta)$ 定义为轨迹总回报 $G(\\tau)$ 的期望，用于优化策略。  \n- 命题：基于强化学习的序列生成模型能解决训练与评价目标不一致及曝光偏差问题。"
      },
      {
        "段落": "## 15．5．3 计算效率问题\n\n序列生成模型的输出层为词表中所有词的条件概率，需要 Softmax 归一化。当词表比较大时，计算效率比较低。\n\n在第 $t$ 步时，前缀序列为 $\\tilde{h}_{t}=\\boldsymbol{x}_{1:(t-1)}$ ，词 $x_{t}$ 的条件概率为\n\n$$\n\\begin{align*}\np_{\\theta}\\left(x_{t} \\mid \\tilde{h}_{t}\\right) & =\\operatorname{softmax}\\left(s\\left(x_{t}, \\tilde{h}_{t} ; \\theta\\right)\\right)  \\tag{15.47}\\\\\n& =\\frac{\\exp \\left(s\\left(x_{t}, \\tilde{h}_{t} ; \\theta\\right)\\right)}{\\sum_{v \\in \\mathcal{V}} \\exp \\left(s\\left(v, \\tilde{h}_{t} ; \\theta\\right)\\right)}  \\tag{15.48}\\\\\n& =\\frac{\\exp \\left(s\\left(x_{t}, \\tilde{h}_{t} ; \\theta\\right)\\right)}{Z\\left(\\tilde{h}_{t} ; \\theta\\right)} \\tag{15.49}\n\\end{align*}\n$$\n\n其中 $s\\left(x_{t}, \\tilde{h}_{t} ; \\theta\\right)$ 为未经过 Softmax 归一化的得分函数，$Z\\left(\\tilde{h}_{t} ; \\theta\\right)$ 为配分函数（Par－ tition Function）．\n\n$$\n\\begin{equation*}\nZ\\left(\\tilde{h}_{t} ; \\theta\\right)=\\sum_{v \\in \\mathcal{V}} \\exp \\left(s\\left(v, \\tilde{h}_{t} ; \\theta\\right)\\right) \\tag{15.50}\n\\end{equation*}\n$$\n\n配分函数的计算需要对词表中所有的词 $v$ 计算 $s\\left(v, \\tilde{h}_{t} ; \\theta\\right)$ 并求和．当词表比较大时，计算开销非常大。比如在自然语言中，词表 $\\mathcal{V}$ 的规模一般在 1 万到 10 万之间。在训练时，每个样本都要计算一次配分函数，这样每一轮迭代需要计算 $T$次配分函数（ $T$ 为训练文本长度），导致整个训练过程变得十分耗时。因此在实践中，我们通常采用一些近似估计的方法来加快训练速度。常用的方法可以分为两类：（1）层次化的 Softmax 方法，将标准 Softmax 函数的扁平结构转换为层次化结构；（2）基于采样的方法，通过采样来近似计算更新梯度。\n\n本节介绍三种加速训练速度的方法：层次化 Softmax、重要性采样和噪声对比估计。",
        "总结": "- 提出计算效率问题，指出序列生成模型在输出层使用Softmax归一化时，当词表较大时计算效率较低。  \n- 定义条件概率公式，说明在第 $t$ 步时，词 $x_t$ 的条件概率由未归一化的得分函数和配分函数计算得出。  \n- 配分函数 $Z(\\tilde{h}_t; \\theta)$ 是对词表中所有词的得分函数的指数和，计算复杂度高。  \n- 指出当词表规模较大时，每轮训练需多次计算配分函数，导致训练过程耗时。  \n- 提出两种常用加速方法：层次化Softmax和基于采样的方法（如重要性采样和噪声对比估计）。  \n- 本节介绍三种加速训练速度的方法：层次化Softmax、重要性采样和噪声对比估计。"
      },
      {
        "段落": "### 15．5．3．1 层次化 Softmax\n\n我们先来考虑使用两层的树结构来组织词表，即将词表中的词分成 $K$ 组，并且每一个词只能属于一个分组，每组大小为 $\\frac{|\\mathcal{V}|}{K}$ 。假设词 $w$ 所属的组为 $c(w)$ ，则\n\n$$\n\\begin{align*}\np(w \\mid \\tilde{h}) & =p(w, c(w) \\mid \\tilde{h})  \\tag{15.51}\\\\\n& =p(w \\mid c(w), \\tilde{h}) p(c(w) \\mid \\tilde{h}) \\tag{15.52}\n\\end{align*}\n$$\n\n其中 $p(c(w) \\mid \\tilde{h})$ 是给定历史信息 $\\tilde{h}$ 条件下，类 $c(w)$ 的后验概率，$p(w \\mid c(w), \\tilde{h})$ 是给定历史信息 $\\tilde{h}$ 和类 $c(w)$ 条件下，词 $w$ 的后验概率。因此，一个词的概率可以分解为两个概率 $p(w \\mid c(w), \\tilde{h})$ 和 $p(c(w) \\mid \\tilde{h})$ 的乘积，它们可以分别利用神经网络来估计，这样计算 Softmax 函数时分别只需要做 $\\frac{|\\mathcal{V}|}{K}$ 和 $K$ 次求和，从而大大提高了 Softmax函数的计算速度．\nhttps：／／nndl．github．io／\n\n一般对于词表大小 $|\\mathcal{V}|$ ，我们将词平均分到 $\\sqrt{|\\mathcal{V}|}$ 个分组中，每组 $\\sqrt{|\\mathcal{V}|}$ 个词。这样通过一层的分组，我们可以将 Softmax 计算加速 $\\frac{1}{2} \\sqrt{|\\mathcal{V}|}$ 倍。比如当词表大小为 40,000 时，将词表中所有词分到 200 组，每组 200 个词．这样只需要计算两次 200 类的 Softmax，比直接计算 40,000 类的 Softmax 加快 100 倍．\n\n为了进一步降低 Softmax 函数的计算复杂度，我们可以使用更深层的树结构来组织词汇表。假设用二叉树来组织词表中的所有词，二叉树的叶子节点代表词表中的词，非叶子节点表示不同层次上的类别。图15．4给出了平衡二叉树和霍夫曼编码二叉树的示例。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-381.jpg?height=413&width=900&top_left_y=616&top_left_x=201)\n\n图15．4层次化树结构\n\n如果我们将二叉树上所有左链接标记为 0 ，右链接标记为 1 。每一个词可以用根节点到它所在的叶子之间路径上的标记来进行编码。 图15．4a中所示的四个词的编码分别为：\n\n$$\n\\begin{equation*}\nv_{1}=00, \\quad v_{2}=01, \\quad v_{3}=10, \\quad v_{4}=11 \\tag{15.53}\n\\end{equation*}\n$$\n\n假设词 $v$ 在二叉树上从根节点到其所在叶子节点的路径长度为 $M$ ，其编码可以表示一个位向量（bit vector）：$\\left[b_{1}, \\cdots, b_{M}\\right]^{\\top}$ 。词 $v$ 的条件概率为\n\n$$\n\\begin{align*}\nP(v \\mid \\tilde{h}) & =p\\left(b_{1}, \\cdots, b_{M} \\mid \\tilde{h}\\right)  \\tag{15.54}\\\\\n& =\\prod_{m=1}^{M} p\\left(b_{m} \\mid b_{1}, \\cdots, b_{m-1}, \\tilde{h}\\right)  \\tag{15.55}\\\\\n& =\\prod_{m=1}^{M} p\\left(b_{m} \\mid b_{m-1}, \\tilde{h}\\right) \\tag{15.56}\n\\end{align*}\n$$\n\n由于 $b_{m} \\in\\{0,1\\}$ 为二值变量，$p\\left(b_{m} \\mid b_{m-1}, \\tilde{h}\\right)$ 可以看作是二分类问题，可以使用 logistic 回归来进行预测。\n\n$$\n\\begin{equation*}\np\\left(b_{m}=1 \\mid b_{m-1}, \\tilde{h}\\right)=\\sigma\\left(\\boldsymbol{w}_{n\\left(b_{m-1}\\right)}^{\\top} \\boldsymbol{h}+\\boldsymbol{b}_{n\\left(b_{m-1}\\right)}\\right), \\tag{15.57}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n其中 $n\\left(b_{m-1}\\right)$ 为词 $v$ 在树 $T$ 上的路径上的第 $m-1$ 个节点。\n若使用平衡二叉树来进行分组，则条件概率估计可以转换为 $\\log _{2}|\\mathcal{V}|$ 个二分类问题．这时 Softmax 函数可以用 Logistic 函数代替，计算效率可以加速 $\\frac{|\\mathcal{V}|}{\\log _{2}|\\mathcal{V}|}$倍。\n\n将词表中的词按照树结构进行组织，有以下几种转换方式：\n（1）利用人工整理的词汇层次结构，比如利用 WordNet［Miller，1995］系统中的＂IS－A＂关系（即上下位关系）。例如，＂狗＂是＂动物＂的下位词。因为 WordNet 的层次化结构不是二叉树，因此需要通过进一步聚类来转换为二叉树。\n（2）使用霍夫曼编码（Huffman Coding）。霍夫曼编码对出现概率高的词使用较短的编码，出现概率低的词使用较长的编码．因此训练速度会更快．霍夫曼编码的算法如算法15．1所示。\n\n```\n算法 15.1: 霍夫曼编码树构建算法\n    输入: 词表: $\\mathcal{V}$\n    初始化: 为每个词 $v$ 建立一个叶子节点, 其概率为词的出现频率;\n    将所有的叶子节点放入集合 $\\mathcal{S}$ 中;\n    while $|\\mathcal{S}|>1$ do\n        从集合 $\\mathcal{S}$ 选择两个概率最低的节点 $n_{1}$ 和 $n_{2}$;\n        构建一个新节点 $n^{\\prime}$, 并将 $n_{1}$ 和 $n_{2}$ 作为 $n^{\\prime}$ 的左右子节点;\n        新节点 $n^{\\prime}$ 的概率为 $n_{1}$ 和 $n_{2}$ 的概率之和;\n        将新节点 $n^{\\prime}$ 加入集合 $\\mathcal{S}$ 中, 并把 $n_{1}$ 和 $n_{2}$ 从集合 $\\mathcal{S}$ 中移除;\n    end\n    集合 $\\mathcal{S}$ 中最后一个节点为 $n$;\n    输出: 以 $n$ 为根节点的二叉树 $T$\n```",
        "总结": "- 层次化 Softmax 概念：通过树结构组织词表，将词的概率分解为路径上的二分类概率乘积，从而降低计算复杂度。\n- 两层分组方法：将词表分成 $K$ 组，每组大小为 $\\frac{|\\mathcal{V}|}{K}$，计算时分别对每组和类别进行 Softmax，加速计算。\n- 二叉树结构：使用二叉树组织词表，叶子节点代表词，非叶子节点表示类别，路径上的标记用于编码词。\n- 条件概率分解：词的条件概率可表示为路径上每个二值变量的条件概率乘积，每个变量对应一个二分类问题。\n- Logistic 回归应用：每个二值变量的条件概率使用 logistic 回归估计，形式为 $p(b_m=1 \\mid b_{m-1}, \\tilde{h}) = \\sigma(\\boldsymbol{w}_{n(b_{m-1})}^\\top \\boldsymbol{h} + \\boldsymbol{b}_{n(b_{m-1})})$。\n- 平衡二叉树加速：使用平衡二叉树时，Softmax 可转换为 $\\log_2 |\\mathcal{V}|$ 个二分类问题，计算效率提升 $\\frac{|\\mathcal{V}|}{\\log_2 |\\mathcal{V}|}$ 倍。\n- 词汇层次结构：可利用人工整理的层次结构（如 WordNet 的 IS-A 关系）构建树结构，并通过聚类转换为二叉树。\n- 霍夫曼编码方法：根据词出现频率构建霍夫曼编码树，高频词使用短编码，低频词使用长编码，提高训练效率。"
      },
      {
        "段落": "### 15．5．3．2 重要性采样\n\n另一种加速训练速度的方法是基于采样的方法，即通过采样来近似计算训练时的梯度．\n\n用随机梯度上升来更新参数 $\\theta$ 时，第 $t$ 个样本 $\\left(\\tilde{h}_{t}, x_{t}\\right)$ 的目标函数关于 $\\theta$ 的梯度为\n\n$$\n\\begin{align*}\n& \\frac{\\partial \\log p_{\\theta}\\left(x_{t} \\mid \\tilde{h}_{t}\\right)}{\\partial \\theta}=\\frac{\\partial s\\left(x_{t}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}-\\frac{\\partial \\log \\left(\\sum_{v} \\exp \\left(s\\left(v, \\tilde{h}_{t} ; \\theta\\right)\\right)\\right)}{\\partial \\theta}  \\tag{15.58}\\\\\n& =\\frac{\\partial s\\left(x_{t}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}-\\frac{1}{\\sum_{v} \\exp \\left(s\\left(v, \\tilde{h}_{t} ; \\theta\\right)\\right)} \\frac{\\partial \\sum_{v} \\exp \\left(s\\left(v, \\tilde{h}_{t} ; \\theta\\right)\\right)}{\\partial \\theta} \\tag{15.59}\n\\end{align*}\n$$\n\nhttps：／／nndl．github．io／\n\nWordNet 是按照词义来组织的英语词汇知识库，由普林斯顿大学研发。\n\n霍夫曼编码是 David Huffman 于1952年发明的一种用于无损数据压缩的熵编码算法。\n\n熵编码参见第 E．1．2 节。\n\n参见第11．5节。\n\n$$\n\\begin{align*}\n& =\\frac{\\partial s\\left(x_{t}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}-\\sum_{v} \\frac{1}{\\sum_{w} \\exp \\left(s\\left(w, \\tilde{h}_{t} ; \\theta\\right)\\right)} \\frac{\\partial \\exp \\left(s\\left(v, \\tilde{h}_{t} ; \\theta\\right)\\right)}{\\partial \\theta}  \\tag{15.60}\\\\\n& =\\frac{\\partial s\\left(x_{t}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}-\\sum_{v} \\frac{\\exp \\left(s\\left(v, \\tilde{h}_{t} ; \\theta\\right)\\right)}{\\sum_{w} \\exp \\left(s\\left(w, \\tilde{h}_{t} ; \\theta\\right)\\right)} \\frac{\\partial s\\left(v, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}  \\tag{15.61}\\\\\n& =\\frac{\\partial s\\left(x_{t}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}-\\sum_{v} p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right) \\frac{\\partial s\\left(v, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}  \\tag{15.62}\\\\\n& =\\frac{\\partial s\\left(x_{t}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}-\\mathbb{E}_{p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right)}\\left[\\frac{\\partial s\\left(v, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}\\right] . \\tag{15.63}\n\\end{align*}\n$$\n\n公式（15．63）中最后一项是计算 $\\frac{\\partial}{\\partial \\theta} s\\left(v, \\tilde{h}_{t} ; \\theta\\right)$ 在分布 $p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right)$ 下的期望．从公式（15．61）中可以看出，在计算每个样本的梯度时需要在整个词表上计算两次求和。一次是求配分函数 $\\sum_{w} \\exp \\left(s\\left(w, \\tilde{h}_{t} ; \\theta\\right)\\right)$ ，另一次是计算所有词的梯度的期望 $\\mathbb{E}\\left[\\frac{\\partial}{\\partial \\theta} s\\left(v, \\tilde{h}_{t} ; \\theta\\right)\\right]$ ．由于自然语言中的词表都比较大，训练速度会非常慢．\n\n为了提高训练效率，可以用采样方法来近似地估计公式（15．63）中的期望．但是我们不能直接根据分布 $p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right)$ 进行采样，因为直接采样需要先计算分布 $p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right)$ ，而这正是我们希望避免的。\n\n重要性采样是用一个容易采样的提议分布 $q$ 来近似估计分布 $p$ ．\n\n重要性采样参见第 11．5．3节．\n\n公式（15．63）中最后一项可以写为\n\n$$\n\\begin{align*}\n\\mathbb{E}_{p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right)}\\left[\\frac{\\partial s\\left(v, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}\\right] & =\\sum_{v \\in \\mathcal{V}} p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right) \\frac{\\partial s\\left(v, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}  \\tag{15.64}\\\\\n& =\\sum_{v \\in \\mathcal{V}} q\\left(v \\mid \\tilde{h}_{t}\\right) \\frac{p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right)}{q\\left(v \\mid \\tilde{h}_{t}\\right)} \\frac{\\partial s\\left(v, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}  \\tag{15.65}\\\\\n& =\\mathbb{E}_{q\\left(v \\mid \\tilde{h}_{t}\\right)}\\left[\\frac{p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right)}{q\\left(v \\mid \\tilde{h}_{t}\\right)} \\frac{\\partial s\\left(v, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}\\right] . \\tag{15.66}\n\\end{align*}\n$$\n\n这样，原始分布 $p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right)$ 上的期望转换为提议分布 $q\\left(v \\mid \\tilde{h}_{t}\\right)$ 上的期望．提议分布 $q$需要尽可能和 $p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right)$ 接近，并且从 $q\\left(v \\mid \\tilde{h}_{t}\\right)$ 采样的代价要比较小．在实践中，提议分布 $q\\left(v \\mid \\tilde{h}_{t}\\right)$ 可以采用 N 元模型的分布函数．\n\n根据分布 $q\\left(v \\mid \\tilde{h}_{t}\\right)$ 独立采样 $K$ 个样本 $v_{1}, \\cdots, v_{K}$ 来近似求解公式（15．66），即\n\n$$\n\\begin{equation*}\n\\mathbb{E}_{p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right)}\\left[\\frac{\\partial s\\left(v, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}\\right] \\approx \\frac{1}{K} \\sum_{k=1}^{K} \\frac{p_{\\theta}\\left(v_{k} \\mid \\tilde{h}_{t}\\right)}{q\\left(v_{k} \\mid \\tilde{h}_{t}\\right)} \\frac{\\partial s\\left(v_{k}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta} \\tag{15.67}\n\\end{equation*}\n$$\n\n在公式（15．67）中，依然需要计算每一个抽取样本的概率 $p_{\\theta}\\left(v_{k} \\mid \\tilde{h}_{t}\\right)$ ，即\n\n$$\n\\begin{equation*}\np_{\\theta}\\left(v_{k} \\mid \\tilde{h}_{t}\\right)=\\frac{s\\left(v_{k}, \\tilde{h}_{t} ; \\theta\\right)}{Z\\left(\\tilde{h}_{t}\\right)} \\tag{15.68}\n\\end{equation*}\n$$\n\n其中配分函数 $Z\\left(\\tilde{h}_{t}\\right)=\\sum_{w} \\exp \\left(s\\left(w, \\tilde{h}_{t} ; \\theta\\right)\\right)$ 需要在所有样本上计算 $s\\left(w, \\tilde{h}_{t} ; \\theta\\right)$ 并求和。为了避免这种情况，我们也使用重要性采样来计算配分函数 $Z\\left(\\tilde{h}_{t}\\right)$ ，即\n\n$$\n\\begin{align*}\nZ\\left(\\tilde{h}_{t}\\right) & =\\sum_{w} \\exp \\left(s\\left(w, \\tilde{h}_{t} ; \\theta\\right)\\right)  \\tag{15.69}\\\\\n& =\\sum_{w} q\\left(w \\mid \\tilde{h}_{t}\\right) \\frac{1}{q\\left(w \\mid \\tilde{h}_{t}\\right)} \\exp \\left(s\\left(w, \\tilde{h}_{t} ; \\theta\\right)\\right)  \\tag{15.70}\\\\\n& =\\mathbb{E}_{q\\left(w \\mid \\tilde{h}_{t}\\right)}\\left[\\frac{1}{q\\left(w \\mid \\tilde{h}_{t}\\right)} \\exp \\left(s\\left(w, \\tilde{h}_{t} ; \\theta\\right)\\right)\\right]  \\tag{15.71}\\\\\n& \\approx \\frac{1}{K} \\sum_{k=1}^{K} \\frac{1}{q\\left(v_{k} \\mid \\tilde{h}_{t}\\right)} \\exp \\left(s\\left(v_{k}, \\tilde{h}_{t} ; \\theta\\right)\\right)  \\tag{15.72}\\\\\n& =\\frac{1}{K} \\sum_{k=1}^{K} \\frac{\\exp \\left(s\\left(v_{k}, \\tilde{h}_{t} ; \\theta\\right)\\right)}{q\\left(v_{k} \\mid \\tilde{h}_{t}\\right)}  \\tag{15.73}\\\\\n& =\\frac{1}{K} \\sum_{k=1}^{K} r\\left(v_{k}\\right) \\tag{15.74}\n\\end{align*}\n$$\n\n通过采样近似估计．\n\n其中 $r\\left(v_{k}\\right)=\\frac{\\exp \\left(s\\left(v_{k}, \\tilde{h}_{t} ; \\theta\\right)\\right)}{q\\left(v_{k} \\mid \\tilde{h}_{t}\\right)}, q\\left(v_{k} \\mid \\tilde{h}_{t}\\right)$ 为提议分布。为了提高效率，可以和公式（15．67）中的提议分布设为一致，并复用在上一步中抽取的样本．\n\n在近似估计了配分函数以及梯度期望之后，公式（15．67）可写为\n\n$$\n\\begin{align*}\n& \\mathbb{E}_{p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right)}\\left[\\frac{\\partial s\\left(v, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}\\right] \\approx \\frac{1}{K} \\sum_{k=1}^{K} \\frac{p_{\\theta}\\left(v_{k} \\mid \\tilde{h}_{t}\\right)}{q\\left(v_{k} \\mid \\tilde{h}_{t}\\right)} \\frac{\\partial s\\left(v_{k}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}  \\tag{15.75}\\\\\n& =\\frac{1}{K} \\sum_{k=1}^{K} \\frac{\\exp \\left(s\\left(v_{k}, \\tilde{h}_{t} ; \\theta\\right)\\right)}{Z\\left(\\tilde{h}_{t}\\right)} \\frac{1}{q\\left(v_{k} \\mid \\tilde{h}_{t}\\right)} \\frac{\\partial s\\left(v_{k}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}  \\tag{15.76}\\\\\n& =\\frac{1}{K} \\sum_{k=1}^{K} \\frac{1}{Z\\left(\\tilde{h}_{t}\\right)} r\\left(v_{k}\\right) \\frac{\\partial s\\left(v_{k}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}  \\tag{15.77}\\\\\n& \\approx \\sum_{k=1}^{K} \\frac{r\\left(v_{k}\\right)}{\\sum_{k=1}^{K} r\\left(v_{k}\\right)} \\frac{\\partial s\\left(v_{k}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}  \\tag{15.78}\\\\\n& =\\frac{1}{\\sum_{k=1}^{K} r\\left(v_{k}\\right)} \\sum_{k=1}^{K} r\\left(v_{k}\\right) \\frac{\\partial s\\left(v_{k}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta} \\tag{15.79}\n\\end{align*}\n$$\n\n将公式（15．79）代入公式（15．63），得到每个样本目标函数关于 $\\theta$ 的梯度可以近似为\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\log p_{\\theta}\\left(x_{t} \\mid \\tilde{h}_{t}\\right)}{\\partial \\theta}=\\frac{\\partial s\\left(x_{t}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta}-\\frac{1}{\\sum_{k=1}^{K} r\\left(v_{k}\\right)} \\sum_{k=1}^{K} r\\left(v_{k}\\right) \\frac{\\partial s\\left(v_{k}, \\tilde{h}_{t} ; \\theta\\right)}{\\partial \\theta} \\tag{15.80}\n\\end{equation*}\n$$\n\n其中 $v_{1}, \\cdots, v_{K}$ 是根据提议分布 $q\\left(v \\mid \\tilde{h}_{t}\\right)$ 从词表 $\\mathcal{V}$ 中采样的词。和公式（15．63）相比，重要性采样相当于采样了一个词表的子集 $\\mathcal{V}^{\\prime}=\\left\\{v_{1}, \\cdots, v_{K}\\right\\}$ ，然后在这个子集 https：／／nndl．github．io／\n\n上求梯度 $\\frac{\\partial s\\left(v_{k}, \\tilde{h} ; \\theta\\right)}{\\partial \\theta}$ 的期望；公式（15．63）中分布 $p_{\\theta}\\left(v \\mid \\tilde{h}_{t}\\right)$ 被 $r\\left(v_{k}\\right)$ 所替代。这样目标函数关于 $\\theta$ 的梯度就避免了在词表上对所有词进行计算，只需要计算较少的抽取的样本。采样的样本数量 $K$ 越大，近似越接近正确值。在实际应用中，$K$ 取 100 左右就能够以足够高的精度对期望做出估计。通过重要性采样的方法，训练速度可以加速 $\\frac{|\\mathcal{V}|}{K}$ 倍。\n\n重要性采样的思想和算法都比较简单，但其效果依赖于提议分布 $q\\left(v \\mid \\tilde{h}_{t}\\right)$ 的选取。如果 $q\\left(v \\mid \\tilde{h}_{t}\\right)$ 选取不合适，会造成梯度估计非常不稳定。在实践中，提议分布 $q\\left(v \\mid \\tilde{h}_{t}\\right)$ 经常使用一元模型的分布函数。虽然直观上 $q\\left(v \\mid \\tilde{h}_{t}\\right)$ 采用 N 元模型更加准确，但使用复杂的 N 元模型分布并不能改进性能，原因是 N 元模型的分布和神经网络模型估计的分布之间有很大的差异［Bengio et al．，2008］．",
        "总结": "- 重要性采样是一种通过使用容易采样的提议分布 $ q $ 来近似估计复杂分布 $ p_{\\theta}(v \\mid \\tilde{h}_t) $ 的期望值的方法，从而加速训练过程。\n- 重要性采样通过在提议分布 $ q $ 上采样，计算加权的期望值，其中权重为 $ \\frac{p_{\\theta}(v \\mid \\tilde{h}_t)}{q(v \\mid \\tilde{h}_t)} $。\n- 重要性采样用于近似公式（15.63）中的梯度期望，避免了对整个词表进行求和计算。\n- 配分函数 $ Z(\\tilde{h}_t) $ 也可以通过重要性采样进行近似估计，使用与梯度估计相同的提议分布。\n- 重要性采样的效果依赖于提议分布 $ q(v \\mid \\tilde{h}_t) $ 的选择，若选择不当会导致梯度估计不稳定。\n- 在实践中，提议分布常使用一元模型的分布函数，尽管使用更复杂的 N 元模型并不能显著提升性能。\n- 通过重要性采样，训练速度可以加速 $ \\frac{|\\mathcal{V}|}{K} $ 倍，其中 $ K $ 是采样的样本数量。"
      },
      {
        "段落": "### 15．5．3．3 噪声对比估计\n\n除重要性采样外，噪声对比估计（Noise－Contrastive Estimation，NCE）也是一种常用的近似估计梯度的方法．\n\n噪声对比估计是将密度估计问题转换为二分类问题，从而降低计算复杂度 ［Gutmann et al．，2010］．噪声对比估计的思想在我们日常生活中十分常见．比如我们教小孩认识＂苹果＂，往往会让小孩从一堆各式各样的水果中找出哪个是＂苹果＂。通过不断的对比和纠错，最终小孩会知道＂苹果＂的特征，并很容易识别出 ＂苹果＂。\n\n噪声对比估计的数学描述如下：假设有三个分布，第一个是需要建模真实数据分布 $p_{r}(x)$ ；第二个是模型分布 $p_{\\theta}(x)$ ，并期望调整模型参数 $\\theta$ 使得 $p_{\\theta}(x)$ 可以拟合真实数据分布 $p_{r}(x)$ ；第三个是噪声分布 $q(x)$ ，用来对比学习。给定一个样本 $x$ ，如果 $x$ 是从 $p_{r}(x)$ 中抽取的，称为真实样本，如果 $x$ 是从 $q(x)$ 中抽取的，则称为噪声样本．为了判断样本 $x$ 是真实样本还是噪声样本，引入一个辨别函数D。\n\n噪声对比估计是通过调整模型 $p_{\\theta}(x)$ 使得辨别函数 $D$ 很容易能分别出样本 $x$ 来自哪个分布．令 $y \\in\\{1,0\\}$ 表示一个样本 $x$ 是真实样本或噪声样本，其条件概率为\n\n$$\n\\begin{align*}\n& p(x \\mid y=1)=p_{\\theta}(x)  \\tag{15.81}\\\\\n& p(x \\mid y=0)=q(x) \\tag{15.82}\n\\end{align*}\n$$\n\n一般噪声样本的数量要比真实样本大很多。为了提高近似效率，我们近似假设噪声样本的数量是真实样本的 $K$ 倍，即 $y$ 的先验分布满足\n\n$$\n\\begin{equation*}\np(y=0)=K p(y=1) \\tag{15.83}\n\\end{equation*}\n$$\n\n根据贝叶斯公式，样本 $x$ 来自于真实数据分布的后验概率为\n\n$$\n\\begin{align*}\np(y=1 \\mid x) & =\\frac{p(x \\mid y=1) p(y=1)}{p(x \\mid y=1) p(y=1)+p(x \\mid y=0) p(y=0)}  \\tag{15.84}\\\\\n& =\\frac{p_{\\theta}(x) p(y=1)}{p_{\\theta}(x) p(y=1)+q(x) k p(y=1)}  \\tag{15.85}\\\\\n& =\\frac{p_{\\theta}(x)}{p_{\\theta}(x)+K q(x)} \\tag{15.86}\n\\end{align*}\n$$\n\n相反，样本 $x$ 来自于噪声分布的后验概率为 $p(y=0 \\mid x)=1-p(y=1 \\mid x)$ ．\n从真实分布 $p_{r}(x)$ 中抽取 $N$ 个样本 $x_{1}, \\cdots, x_{N}$ ，将其类别设为 $y=1$ ，然后从噪声分布中抽取 $K N$ 个样本 $x_{1}^{\\prime}, \\cdots, x_{K N}^{\\prime}$ ，将其类别设为 $y=0$ ．噪声对比估计的目标是将真实样本和噪声样本区别开来，可以看作是一个二分类问题．噪声对比估计的损失函数为\n\n$$\n\\begin{equation*}\n\\mathcal{L}(\\theta)=-\\frac{1}{N(K+1)}\\left(\\sum_{n=1}^{N} \\log p\\left(y=1 \\mid x_{n}\\right)+\\sum_{n=1}^{K N} \\log p\\left(y=0 \\mid x_{n}^{\\prime}\\right)\\right) \\tag{15.87}\n\\end{equation*}\n$$\n\n通过不断采样真实样本和噪声样本，并用梯度下降法可以学习参数 $\\theta$ 使得 $p_{\\theta}(x)$逼近于真实分布 $p_{r}(x)$ 。\n\n噪声对比估计相当于用判别式的准则 $\\mathcal{L}(\\theta)$ 来训练一个生成式模型 $p_{\\theta}(x)$ ，使得判别函数 $D$ 很容易能分别出样本 $x$ 来自哪个分布，其思想与生成对抗网络类似。不同之处在于，在噪声对比估计中的判别函数 $D$ 是通过贝叶斯公式计算得到，而生成对抗网络的判别函数 $D$ 是一个需要学习的神经网络．\n\n基于噪声对比估计的序列模型 在计算序列模型的条件概率时，我们也可以利用噪声对比估计的思想来提高计算效率［Mnih et al．，2013，2012］．在序列模型中需要建模的分布是 $p_{\\theta}(v \\mid \\tilde{h})$ ，原则上噪声分布 $q(v \\mid \\tilde{h})$ 应该是依赖于历史信息 $\\tilde{h}$ 的条件分布，但实践中一般使用和历史信息无关的分布 $q(v)$ ，比如一元模型的分布．\n\n给定历史信息 $\\tilde{h}$ ，我们需要判断词表中每一个词 $v$ 是来自于真实分布还是噪声分布．\n\n$$\n\\begin{equation*}\np(y=1 \\mid v, \\tilde{h})=\\frac{p_{\\theta}(v \\mid \\tilde{h})}{p_{\\theta}(v \\mid \\tilde{h})+K q(v)} \\tag{15.88}\n\\end{equation*}\n$$\n\n对于一个训练序列 $\\boldsymbol{x}_{1: T}$ ，将 $\\left\\{\\left(\\tilde{h}_{t}\\right), x_{t}\\right\\}_{t=1}^{T}$ 作为真实样本。对于每一个 $x_{t}$ ，从噪声分布中抽取 $K$ 个噪声样本 $\\left\\{x_{t, 1}^{\\prime}, \\cdots, x_{t, K}^{\\prime}\\right\\}$ ．噪声对比估计的目标函数是\n\n$$\n\\begin{equation*}\n\\mathcal{L}(\\theta)=-\\sum_{t=1}^{T}\\left(\\log p\\left(y=1 \\mid x_{t}, \\tilde{h}_{t}\\right)+\\sum_{k=1}^{K} \\log \\left(1-p\\left(y=1 \\mid x_{t, k}^{\\prime}, \\tilde{h}_{t}\\right)\\right)\\right) \\tag{15.89}\n\\end{equation*}\n$$\n\n虽然通过噪声对比估计，将一个 $|\\mathcal{V}|$ 类的分类问题转换为一个二分类问题，但是依然需要计算 $p_{\\theta}(v \\mid \\tilde{h})$ ，其中仍然涉及配分函数的计算。为了避免计算配分函 https：／／nndl．github．io／\n\n生成对抗网络参见第 13.3 节。\n$p_{\\theta}(v \\mid \\tilde{h})$ 的计算参见公式（15．48）．\n\n$$\n\\tilde{h}_{t}=x_{1:(t-1)} .\n$$\n\n为简单起见，这里省略了系数 $\\frac{1}{T(K+1)}$ ．\n\n数，我们将负对数配分函数 $-\\log Z(\\tilde{h} ; \\theta)$ 作为一个可学习的参数 $z_{\\tilde{h}}$（即每一个 $\\tilde{h}$对应一个参数），这样条件概率 $p_{\\theta}(v \\mid \\tilde{h})$ 重新定义为\n\n$$\n\\begin{equation*}\np_{\\theta}(v \\mid \\tilde{h})=\\exp (s(v, \\tilde{h} ; \\theta)) \\exp \\left(z_{\\tilde{h}}\\right) \\tag{15.90}\n\\end{equation*}\n$$\n\n噪声对比估计方法的一个特点是会促使未归一化分布 $\\exp (s(v, \\tilde{h} ; \\theta))$ 自己学习到一个近似归一化的分布，并接近真实的数据分布 $p_{r}(v \\mid \\tilde{h})$［Gutmann et al．， 2010］．也就是说，学习出来的 $\\exp \\left(z_{\\tilde{h}}\\right) \\approx 1$ ．这样可以直接令 $\\exp \\left(z_{\\tilde{h}}\\right)=1, \\forall \\tilde{h}$ ，并用未归一化的分布 $\\exp (s(v, \\tilde{h} ; \\theta))$ 来代替 $p_{\\theta}(v \\mid \\tilde{h})$ 。\n\n公式（15．88）可以写为\n\n$$\n\\begin{align*}\np(y=1 \\mid v, \\tilde{h}) & =\\frac{\\exp (s(v, \\tilde{h} ; \\theta))}{\\exp (s(v, \\tilde{h} ; \\theta)))+K q(v)}  \\tag{15.91}\\\\\n& =\\frac{1}{1+\\frac{K q(v)}{\\exp (s(v, \\tilde{h} ; \\theta))}}  \\tag{15.92}\\\\\n& =\\frac{1}{1+\\exp (-s(v, \\tilde{h} ; \\theta)-\\log (K q(v)))}  \\tag{15.93}\\\\\n& =\\frac{1}{1+\\exp (-(\\Delta s(v, \\tilde{h} ; \\theta)))}  \\tag{15.94}\\\\\n& =\\sigma(\\Delta s(v, \\tilde{h} ; \\theta)) \\tag{15.95}\n\\end{align*}\n$$\n\n其中 $\\sigma$ 为 Logistic 函数，$\\Delta s(v, \\tilde{h} ; \\theta)=s(v, \\tilde{h} ; \\theta)-\\log (K q(v))$ 为模型打分（未归一化分布）与放大的噪声分布之间的差．\n\n在噪声对比估计中，噪声分布 $q(v)$ 的选取也十分关键．首先是从 $q(v)$ 中采样要十分容易。另外，$q(v)$ 要和真实数据分布 $p_{r}(v \\mid \\tilde{h})$ 比较接近，否则分类问题就变得十分容易，不需要学习到一个接近真实分布的 $p_{\\theta}(v \\mid \\tilde{h})$ 就可以分出数据来源了。对自然语言的序列模型，$q(v)$ 取一元模型的分布是一个很好的选择。每次迭代噪声样本的个数 $K$ 取值在 $25 \\sim 100$ 左右．\n\n总结 基于采样的方法并不改变模型的结构，只是近似计算参数梯度。在训练时可以显著提高模型的训练速度，但是在测试阶段依然需要计算配分函数。而基于层次化 Softmax 的方法改变了模型的结构，在训练和测试时都可以加快计算速度。",
        "总结": "- 噪声对比估计（NCE）是一种近似估计梯度的方法，用于密度估计问题，将问题转换为二分类问题以降低计算复杂度。  \n- NCE通过引入辨别函数D，判断样本来自真实分布还是噪声分布，并通过调整模型参数使D能有效区分样本来源。  \n- 噪声对比估计的损失函数通过真实样本和噪声样本的对数概率进行加权求和，以最小化分类误差。  \n- 在序列模型中，NCE利用条件概率 $p_{\\theta}(v \\mid \\tilde{h})$ 来建模，并通过引入可学习的负对数配分函数 $z_{\\tilde{h}}$ 避免直接计算配分函数。  \n- NCE的目标是让未归一化的分布 $\\exp (s(v, \\tilde{h} ; \\theta))$ 接近真实分布 $p_{r}(v \\mid \\tilde{h})$，从而简化模型训练过程。  \n- NCE与生成对抗网络（GAN）思想类似，但其判别函数是通过贝叶斯公式计算得到，而非由神经网络学习。  \n- 噪声分布 $q(v)$ 的选择需满足采样容易且与真实分布接近，通常采用一元模型的分布作为 $q(v)$。  \n- 在训练过程中，噪声样本数量 $K$ 通常取25到100之间，以提高近似效率。"
      },
      {
        "段落": "## 15.6 序列到序列模型\n\n在序列生成任务中，有一类任务是序列到序列生成任务，即输入一个序列，生成另一个序列，比如机器翻译、语音识别、文本摘要、对话系统、图像标题生成等。\n\n序列到序列（Sequence－to－Sequence，Seq2Seq）是一种条件的序列生成问题，给定一个序列 $\\boldsymbol{x}_{1: S}$ ，生成另一个序列 $\\boldsymbol{y}_{1: T}$ 。输入序列的长度 $S$ 和输出序列的 https：／／nndl．github．io／\n［Mnih et al．，2012］也在实验中证实，直接令 $\\exp \\left(z_{\\tilde{h}}\\right)=1$ 不会影响模型的性能。因为神经网络有大量的参数，这些参数足以让模型学习到一个近似归一化的分布．\n\n长度 $T$ 可以不同。比如在机器翻译中，输入为源语言，输出为目标语言。图15．5给出了基于循环神经网络的序列到序列机器翻译示例，其中 $\\langle E O S\\rangle$ 表示输入序列的结束，虚线表示用上一步的输出作为下一步的输入。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-388.jpg?height=234&width=992&top_left_y=306&top_left_x=142)\n\n图 15.5 基于循环神经网络的序列到序列机器翻译\n\n序列到序列模型的目标是估计条件概率\n\n$$\n\\begin{equation*}\np_{\\theta}\\left(\\boldsymbol{y}_{1: T} \\mid \\boldsymbol{x}_{1: S}\\right)=\\prod_{t=1}^{T} p_{\\theta}\\left(y_{t} \\mid \\boldsymbol{y}_{1:(t-1)}, \\boldsymbol{x}_{1: S}\\right) \\tag{15.96}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{y}_{t} \\in \\mathcal{V}$ 为词表 $\\mathcal{V}$ 中的某个词．\n给定一组训练数据 $\\left\\{\\left(\\boldsymbol{x}_{S_{n}}, \\boldsymbol{y}_{T_{n}}\\right)\\right\\}_{n=1}^{N}$ ，我们可以使用最大似然估计来训练模型参数\n\n$$\n\\begin{equation*}\n\\hat{\\theta}=\\underset{\\theta}{\\arg \\max } \\sum_{n=1}^{N} \\log p_{\\theta}\\left(\\boldsymbol{y}_{1: T_{n}} \\mid \\boldsymbol{x}_{1: S_{n}}\\right) . \\tag{15.97}\n\\end{equation*}\n$$\n\n一旦训练完成，模型就可以根据一个输入序列 $\\boldsymbol{x}$ 来生成最可能的目标序列\n\n$$\n\\begin{equation*}\n\\hat{\\boldsymbol{y}}=\\underset{\\boldsymbol{y}}{\\arg \\max } p_{\\hat{\\theta}}(\\boldsymbol{y} \\mid \\boldsymbol{x}), \\tag{15.98}\n\\end{equation*}\n$$\n\n具体的生成过程可以通过贪婪方法或束搜索来完成。\n和一般的序列生成模型类似，条件概率 $p_{\\theta}\\left(y_{t} \\mid \\boldsymbol{y}_{1:(t-1)}, \\boldsymbol{x}_{1: S}\\right)$ 可以使用各种不同的神经网络来实现。这里我们介绍三种主要的序列到序列模型：基于循环神经网络的序列到序列模型、基于注意力的序列到序列模型、基于自注意力的序列到序列模型。",
        "总结": "- 序列到序列模型（Seq2Seq）是一种条件序列生成问题，输入一个序列生成另一个序列，如机器翻译、语音识别等。  \n- 输入序列长度为 $S$，输出序列长度为 $T$，两者可以不同。  \n- 模型目标是估计条件概率 $p_{\\theta}(\\boldsymbol{y}_{1:T} \\mid \\boldsymbol{x}_{1:S})$，通过逐词生成实现。  \n- 使用最大似然估计训练模型参数 $\\hat{\\theta}$，目标是最大化训练数据的对数似然。  \n- 生成目标序列时使用 $\\hat{\\boldsymbol{y}} = \\arg \\max_{\\boldsymbol{y}} p_{\\hat{\\theta}}(\\boldsymbol{y} \\mid \\boldsymbol{x})$，可通过贪婪方法或束搜索实现。  \n- 条件概率 $p_{\\theta}(y_t \\mid \\boldsymbol{y}_{1:(t-1)}, \\boldsymbol{x}_{1:S})$ 可用不同神经网络实现。  \n- 介绍了三种主要的序列到序列模型：基于循环神经网络、基于注意力和基于自注意力的模型。"
      },
      {
        "段落": "## 15．6．1 基于循环神经网络的序列到序列模型\n\n实现序列到序列的最直接方法是使用两个循环神经网络来分别进行编码和解码，也称为编码器－解码器（Encoder－Decoder）模型。\n\n编码器 首先使用一个循环神经网络 $f_{\\mathrm{enc}}$ 来编码输入序列 $\\boldsymbol{x}_{1: S}$ 得到一个固定维数的向量 $\\boldsymbol{u}, \\boldsymbol{u}$ 一般为编码循环神经网络最后时刻的隐状态。\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}^{\\mathrm{enc}}=f_{\\mathrm{enc}}\\left(\\boldsymbol{h}_{t-1}^{\\mathrm{enc}}, \\boldsymbol{e}_{x_{t-1}}, \\theta_{\\mathrm{enc}}\\right), \\quad \\forall t \\in[1: S], \\tag{15.99}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n$$\n\\begin{equation*}\n\\boldsymbol{u}=\\boldsymbol{h}_{S}^{\\mathrm{enc}} \\tag{15.100}\n\\end{equation*}\n$$\n\n其中 $f_{\\mathrm{enc}}(\\cdot)$ 为编码循环神经网络，可以为 LSTM 或 GRU，其参数为 $\\theta_{\\mathrm{enc}}, \\boldsymbol{e}_{x}$ 为词 $x$的词向量．\n\n解码器 在生成目标序列时，使用另外一个循环神经网络 $f_{\\operatorname{dec}}$ 来进行解码。在解码过程的第 $t$ 步时，已生成前缀序列为 $\\boldsymbol{y}_{1:(t-1)}$ 。令 $\\boldsymbol{h}_{t}^{\\operatorname{dec}}$ 表示在网络 $f_{\\operatorname{dec}}$ 的隐状态， $\\boldsymbol{o}_{t} \\in(0,1)^{|\\mathcal{V}|}$ 为词表中所有词的后验概率，则\n\n$$\n\\begin{align*}\n\\boldsymbol{h}_{0}^{\\mathrm{dec}} & =\\boldsymbol{u}  \\tag{15.101}\\\\\n\\boldsymbol{h}_{t}^{\\mathrm{dec}} & =f_{\\mathrm{dec}}\\left(\\boldsymbol{h}_{t-1}^{\\mathrm{dec}}, \\boldsymbol{e}_{y_{t-1}}, \\theta_{\\mathrm{dec}}\\right)  \\tag{15.102}\\\\\n\\boldsymbol{o}_{t} & =g\\left(\\boldsymbol{h}_{t}^{\\mathrm{dec}}, \\theta_{o}\\right) \\tag{15.103}\n\\end{align*}\n$$\n\n其中 $f_{\\text {dec }}(\\cdot)$ 为解码循环神经网络，$g(\\cdot)$ 为最后一层为 Softmax 函数的前馈神经网络，$\\theta_{\\operatorname{dec}}$ 和 $\\theta_{o}$ 为网络参数， $\\boldsymbol{e}_{y}$ 为 $y$ 的词向量，$y_{0}$ 为一个特殊符号，比如 $\\langle E O S\\rangle$ 。\n\n基于循环神经网络的序列到序列模型的缺点是：（1）编码向量 $\\boldsymbol{u}$ 的容量问题，输入序列的信息很难全部保存在一个固定维度的向量中；（2）当序列很长时，由于循环神经网络的长程依赖问题，容易丢失输入序列的信息。",
        "总结": "- 基于循环神经网络的序列到序列模型使用两个循环神经网络分别进行编码和解码，称为编码器－解码器模型。  \n- 编码器通过循环神经网络 $f_{\\mathrm{enc}}$ 将输入序列 $\\boldsymbol{x}_{1:S}$ 编码为一个固定维数的向量 $\\boldsymbol{u}$，该向量通常为编码网络最后时刻的隐状态。  \n- 解码器使用另一个循环神经网络 $f_{\\mathrm{dec}}$ 生成目标序列，其隐状态 $\\boldsymbol{h}_{t}^{\\mathrm{dec}}$ 在每一步根据已生成的前缀序列 $\\boldsymbol{y}_{1:(t-1)}$ 和词向量 $\\boldsymbol{e}_{y_{t-1}}$ 更新。  \n- 解码器输出 $\\boldsymbol{o}_{t}$ 表示词表中所有词的后验概率，由一个带有 Softmax 函数的前馈神经网络 $g(\\cdot)$ 生成。  \n- 该模型的缺点包括：编码向量 $\\boldsymbol{u}$ 容量有限，难以保存输入序列全部信息；以及循环神经网络在处理长序列时可能丢失信息，因长程依赖问题。"
      },
      {
        "段落": "## 15．6．2 基于注意力的序列到序列模型\n\n为了获取更丰富的输入序列信息，我们可以在每一步中通过注意力机制来从输入序列中选取有用的信息。\n\n在解码过程的第 $t$ 步时，先用上一步的隐状态 $\\boldsymbol{h}_{t-1}^{\\text {dec }}$ 作为查询向量，利用注意力机制从所有输入序列的隐状态 $\\boldsymbol{H}^{\\mathrm{enc}}=\\left[\\boldsymbol{h}_{1}^{\\mathrm{enc}}, \\cdots, \\boldsymbol{h}_{S}^{\\mathrm{enc}}\\right]$ 中选择相关信息\n\n$$\n\\begin{align*}\n\\boldsymbol{c}_{t} & =\\operatorname{att}\\left(\\boldsymbol{H}^{\\mathrm{enc}}, \\boldsymbol{h}_{t-1}^{\\mathrm{dec}}\\right)=\\sum_{i=1}^{S} \\alpha_{i} \\boldsymbol{h}_{i}^{\\mathrm{enc}}  \\tag{15.104}\\\\\n& =\\sum_{i=1}^{S} \\operatorname{softmax}\\left(s\\left(\\boldsymbol{h}_{i}^{\\mathrm{enc}}, \\boldsymbol{h}_{t-1}^{\\mathrm{dec}}\\right)\\right) \\boldsymbol{h}_{i}^{\\mathrm{enc}} \\tag{15.105}\n\\end{align*}\n$$\n\n其中 $s(\\cdot)$ 为注意力打分函数．\n然后，将从输入序列中选择的信息 $\\boldsymbol{c}_{t}$ 也作为解码器 $f_{\\mathrm{dec}}(\\cdot)$ 在第 $t$ 步时的输入，\n\n$$\n\\begin{equation*}\n\\boldsymbol{h}_{t}^{\\mathrm{dec}}=f_{\\mathrm{dec}}\\left(\\boldsymbol{h}_{t-1}^{\\mathrm{dec}},\\left[\\boldsymbol{e}_{y_{t-1}} ; \\boldsymbol{c}_{t}\\right], \\theta_{\\mathrm{dec}}\\right) \\tag{15.106}\n\\end{equation*}\n$$\n\n最后，将 $\\boldsymbol{h}_{t}^{\\mathrm{dec}}$ 输入到分类器 $g(\\cdot)$ 中来预测词表中每个词出现的概率．\n\n长程依赖问题参见第 6.5 节。\n\n注意力机制参见第 8.2节。\n基 于 注 意 力 的序 列 到 序 列 生成 过 程 见https： ／／nndl．github．\nio／v／sgm－seq2seq\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-389.jpg?height=393&width=280&top_left_y=1446&top_left_x=1261)节。",
        "总结": "- 基于注意力的序列到序列模型：通过在每一步解码过程中使用注意力机制，从输入序列中选取有用信息以获取更丰富的输入序列信息。  \n- 注意力机制：在解码第 $t$ 步时，使用上一步的隐状态 $\\boldsymbol{h}_{t-1}^{\\text{dec}}$ 作为查询向量，通过注意力打分函数 $s(\\cdot)$ 计算权重 $\\alpha_i$，加权求和得到上下文向量 $\\boldsymbol{c}_t$。  \n- 上下文向量 $\\boldsymbol{c}_t$：作为解码器 $f_{\\text{dec}}(\\cdot)$ 在第 $t$ 步的输入之一，与前一步的隐状态 $\\boldsymbol{h}_{t-1}^{\\text{dec}}$ 和词嵌入 $\\boldsymbol{e}_{y_{t-1}}$ 一起用于生成当前隐状态 $\\boldsymbol{h}_t^{\\text{dec}}$。  \n- 分类器 $g(\\cdot)$：将最终隐状态 $\\boldsymbol{h}_t^{\\text{dec}}$ 输入分类器以预测词表中每个词的概率。  \n- 长程依赖问题：相关内容见第 6.5 节。  \n- 注意力机制：相关内容见第 8.2 节。  \n- 基于注意力的序列到序列生成过程：详见链接 https://nndl.github.io/v/sgm-seq2seq。"
      },
      {
        "段落": "## 得到第 $t$ 步的隐状态",
        "总结": "- 提出了在第 $t$ 步获取隐状态的方法。  \n- 通过某种算法或数学推导来计算隐状态。  \n- 隐状态的计算可能依赖于前一步的状态和当前输入。  \n- 该过程可能涉及矩阵运算或递归关系。"
      },
      {
        "段落": "## 15．6．3 基于自注意力的序列到序列模型\n\n除长程依赖问题外，基于循环神经网络的序列到序列模型的另一个缺点是无法并行计算。为了提高并行计算效率以及捕捉长距离的依赖关系，我们可以使用自注意力模型（Self－Attention Model）来建立一个全连接的网络结构。本节介绍一个目前非常成功的基于自注意力的序列到序列模型：Transformer［Vaswani et al．，2017］．",
        "总结": "- 提出了基于自注意力的序列到序列模型，用于解决循环神经网络在处理长程依赖和并行计算效率上的不足。  \n- 引入自注意力机制，构建全连接网络结构，以提升模型的并行计算能力和捕捉长距离依赖关系的能力。  \n- 介绍了Transformer模型，该模型在序列到序列任务中表现出色，由Vaswani等人于2017年提出。"
      },
      {
        "段落": "### 15．6．3．1 自注意力\n\n对于一个向量序列 $\\boldsymbol{H}=\\left[\\boldsymbol{h}_{1}, \\cdots, \\boldsymbol{h}_{T}\\right] \\in \\mathbb{R}^{D_{h} \\times T}$ ，首先用自注意力模型来对其进行编码，即\n\n$$\n\\begin{align*}\n& \\text { self-att }(\\boldsymbol{Q}, \\boldsymbol{K}, \\boldsymbol{V})=\\boldsymbol{V} \\text { softmax }\\left(\\frac{\\boldsymbol{K}^{\\top} \\boldsymbol{Q}}{\\sqrt{D_{k}}}\\right)  \\tag{15.107}\\\\\n& \\boldsymbol{Q}=\\boldsymbol{W}_{q} \\boldsymbol{H}, \\boldsymbol{K}=\\boldsymbol{W}_{k} \\boldsymbol{H}, \\boldsymbol{V}=\\boldsymbol{W}_{v} \\boldsymbol{H} \\tag{15.108}\n\\end{align*}\n$$\n\n其中 $D_{k}$ 是输入矩阵 $\\boldsymbol{Q}$ 和 $\\boldsymbol{K}$ 中列向量的维度， $\\boldsymbol{W}_{q} \\in \\mathbb{R}^{D_{k} \\times D_{h}}, \\boldsymbol{W}_{k} \\in \\mathbb{R}^{D_{k} \\times D_{h}}, \\boldsymbol{W}_{v} \\in$ $\\mathbb{R}^{D_{v} \\times D_{h}}$ 为三个投影矩阵。",
        "总结": "- 自注意力模型用于对向量序列进行编码，通过查询（Q）、键（K）和值（V）三个矩阵的交互来实现。  \n- 公式定义了自注意力机制的核心计算过程，包括softmax函数和矩阵乘法操作。  \n- Q、K、V矩阵分别由输入向量序列H通过不同的投影矩阵Wq、Wk、Wv得到。  \n- Dk表示输入矩阵Q和K中列向量的维度，影响注意力权重的缩放。"
      },
      {
        "段落": "### 15．6．3．2 多头自注意力\n\n自注意力模型可以看作是在一个线性投影空间中建立 $\\boldsymbol{H}$ 中不同向量之间的交互关系。为了提取更多的交互信息，我们可以使用多头自注意力（Multi－Head Self－Attention），在多个不同的投影空间中捕捉不同的交互信息。假设在 $M$ 个投影空间中分别应用自注意力模型，有\n\n$$\n\\begin{gather*}\n\\operatorname{MultiHead}(\\boldsymbol{H})=\\boldsymbol{W}_{o}\\left[\\operatorname{head}_{1} ; \\cdots ; \\operatorname{head}_{M}\\right],  \\tag{15.109}\\\\\n\\operatorname{head}{ }_{m}=\\operatorname{self-att}\\left(\\boldsymbol{Q}_{m}, \\boldsymbol{K}_{m}, \\boldsymbol{V}_{m}\\right),  \\tag{15.110}\\\\\n\\forall m \\in\\{1, \\cdots, M\\}, \\quad \\boldsymbol{Q}_{m}=\\boldsymbol{W}_{q}^{m} \\boldsymbol{H}, \\boldsymbol{K}=\\boldsymbol{W}_{k}^{m} \\boldsymbol{H}, \\boldsymbol{V}=\\boldsymbol{W}_{v}^{m} \\boldsymbol{H}, \\tag{15.111}\n\\end{gather*}\n$$\n\n其中 $\\boldsymbol{W}_{o} \\in \\mathbb{R}^{D_{h} \\times M d_{v}}$ 为输出投影矩阵， $\\boldsymbol{W}_{q}^{m} \\in \\mathbb{R}^{D_{k} \\times D_{h}}, \\boldsymbol{W}_{k}^{m} \\in \\mathbb{R}^{D_{k} \\times D_{h}}, \\boldsymbol{W}_{v}^{m} \\in$ $\\mathbb{R}^{D_{v} \\times D_{h}}$ 为投影矩阵，$m \\in\\{1, \\cdots, M\\}$ 。",
        "总结": "- 多头自注意力（Multi-Head Self-Attention）是一种通过多个不同的投影空间来捕捉不同交互信息的自注意力机制。  \n- 每个头 $ \\operatorname{head}_m $ 通过分别对查询 $ \\boldsymbol{Q}_m $、键 $ \\boldsymbol{K}_m $ 和值 $ \\boldsymbol{V}_m $ 进行自注意力计算得到。  \n- 查询、键和值矩阵分别由不同的投影矩阵 $ \\boldsymbol{W}_q^m $、$ \\boldsymbol{W}_k^m $、$ \\boldsymbol{W}_v^m $ 从输入矩阵 $ \\boldsymbol{H} $ 得到。  \n- 最终的输出通过输出投影矩阵 $ \\boldsymbol{W}_o $ 将所有头的结果拼接起来，得到最终的多头自注意力结果。"
      },
      {
        "段落": "### 15．6．3．3 基于自注意力模型的序列编码\n\n对于一个序列 $\\boldsymbol{x}_{1: T}$ ，我们可以构建一个含有多层多头自注意力模块的模型来对其进行编码。由于自注意力模型忽略了序列 $\\boldsymbol{x}_{1: T}$ 中每个 $\\boldsymbol{x}_{t}$ 的位置信息，因此需要在初始的输入序列中加入位置编码（Positional Encoding）来进行修正。对于一个输入序列 $\\boldsymbol{x}_{1: T} \\in \\mathbb{R}^{D \\times T}$ ，令\n\n$$\n\\begin{equation*}\n\\boldsymbol{H}^{(0)}=\\left[\\boldsymbol{e}_{x_{1}}+\\boldsymbol{p}_{1}, \\cdots, \\boldsymbol{e}_{x_{T}}+\\boldsymbol{p}_{T}\\right] \\tag{15.112}\n\\end{equation*}\n$$\n\nhttps：／／nndl．github．io／\n\n其中 $\\boldsymbol{e}_{x_{t}} \\in \\mathbb{R}^{D}$ 为词 $x_{t}$ 的嵌入向量表示， $\\boldsymbol{p}_{t} \\in \\mathbb{R}^{D}$ 为位置 $t$ 的向量表示，即位置编码． $\\boldsymbol{p}_{t}$ 可以作为可学习的参数，也可以通过下面方式进行预定义：\n\n$$\n\\begin{align*}\n\\boldsymbol{p}_{t, 2 i} & =\\sin \\left(t / 10000^{2 i / D}\\right)  \\tag{15.113}\\\\\n\\boldsymbol{p}_{t, 2 i+1} & =\\cos \\left(t / 10000^{2 i / D}\\right) \\tag{15.114}\n\\end{align*}\n$$\n\n其中 $\\boldsymbol{p}_{t, 2 i}$ 表示第 $t$ 个位置的编码向量的第 $2 i$ 维，$D$ 是编码向量的维度．\n给定第 $l-1$ 层的隐状态 $\\boldsymbol{H}^{(l-1)}$ ，第 $l$ 层的隐状态 $\\boldsymbol{H}^{(l)}$ 可以通过一个多头自注意力模块和一个非线性的前馈网络得到。每次计算都需要残差连接以及层归一化操作。具体计算为\n\n$$\n\\begin{align*}\n\\boldsymbol{Z}^{(l)} & =\\operatorname{norm}\\left(\\boldsymbol{H}^{(l-1)}+\\operatorname{MultiHead}\\left(\\boldsymbol{H}^{(l-1)}\\right)\\right),  \\tag{15.115}\\\\\n\\boldsymbol{H}^{(l)} & =\\operatorname{norm}\\left(\\boldsymbol{Z}^{(l)}+\\operatorname{FFN}\\left(\\boldsymbol{Z}^{(l)}\\right)\\right), \\tag{15.116}\n\\end{align*}\n$$\n\n其中 $\\operatorname{norm}(\\cdot)$ 表示层归一化， $\\operatorname{FFN}(\\cdot)$ 表示逐位置的前馈神经网络（Position－wise Feed－Forward Network），是一个简单的两层网络。对于输入序列中每个位置上向量 $\\boldsymbol{z} \\in \\boldsymbol{Z}^{(l)}$ ，\n\n$$\n\\begin{equation*}\n\\operatorname{FFN}(\\boldsymbol{z})=\\boldsymbol{W}_{2} \\operatorname{ReLu}\\left(\\boldsymbol{W}_{1} \\boldsymbol{z}+\\boldsymbol{b}_{1}\\right)+\\boldsymbol{b}_{2}, \\tag{15.117}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{W}_{1}, \\boldsymbol{W}_{2}, \\boldsymbol{b}_{1}, \\boldsymbol{b}_{2}$ 为网络参数。\n基于自注意力模型的序列编码可以看作是一个全连接的前馈神经网络，第 $l$层的每个位置都接受第 $l-1$ 层的所有位置的输出。不同的是，其连接权重是通过注意力机制动态计算得到。",
        "总结": "- 提出基于自注意力模型的序列编码方法，用于对序列 $\\boldsymbol{x}_{1: T}$ 进行编码。  \n- 引入位置编码（Positional Encoding）以补充自注意力模型忽略的位置信息，位置编码可通过可学习参数或预定义方式生成。  \n- 位置编码的预定义方式为：$\\boldsymbol{p}_{t, 2i} = \\sin(t / 10000^{2i/D})$，$\\boldsymbol{p}_{t, 2i+1} = \\cos(t / 10000^{2i/D})$。  \n- 序列编码过程包含多头自注意力模块和非线性前馈网络，每层计算均包含残差连接和层归一化操作。  \n- 多头自注意力模块与前馈网络共同作用，生成第 $l$ 层的隐状态 $\\boldsymbol{H}^{(l)}$。  \n- 前馈网络（FFN）为逐位置的两层网络，形式为 $\\operatorname{FFN}(\\boldsymbol{z}) = \\boldsymbol{W}_2 \\operatorname{ReLU}(\\boldsymbol{W}_1 \\boldsymbol{z} + \\boldsymbol{b}_1) + \\boldsymbol{b}_2$。  \n- 基于自注意力模型的序列编码可视为全连接前馈神经网络的一种变体，其连接权重通过注意力机制动态计算。"
      },
      {
        "段落": "### 15．6．3．4 Transformer 模型\n\nTransformer模型［Vaswani et al．，2017］是一个基于多头自注意力的序列到序列模型，其整个网络结构可以分为两部分：\n\n编码器 编码器只包含多层的多头自注意力（Multi－Head Self－Attention）模块，每一层都接受前一层的输出作为输入。编码器的输入为序列 $\\boldsymbol{x}_{1: S}$ ，输出为一个向量序列 $\\boldsymbol{H}^{\\mathrm{enc}}=\\left[\\boldsymbol{h}_{1}^{\\mathrm{enc}}, \\cdots, \\boldsymbol{h}_{S}^{\\mathrm{enc}}\\right]$ 。然后，用两个矩阵将 $\\boldsymbol{H}^{\\mathrm{enc}}$ 映射到 $\\boldsymbol{K}^{\\mathrm{enc}}$ 和 $\\boldsymbol{V}^{\\mathrm{enc}}$ 作为键值对供解码器使用．\n\n$$\n\\begin{align*}\n& \\boldsymbol{K}^{\\mathrm{enc}}=\\boldsymbol{W}_{k}^{\\prime} \\boldsymbol{H}^{\\mathrm{enc}},  \\tag{15.118}\\\\\n& \\boldsymbol{V}^{\\mathrm{enc}}=\\boldsymbol{W}_{v}^{\\prime} \\boldsymbol{H}^{\\mathrm{enc}}, \\tag{15.119}\n\\end{align*}\n$$\n\n参见习题15－7．\n\n层归一化参见第 7．5．2节。\n\n基于 Transformer的 序列到序列生成过程见\nhttps：／／nndl．\ngithub．io／v／sgm－\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-391.jpg?height=279&width=249&top_left_y=1768&top_left_x=1261)\n\n其中 $\\boldsymbol{W}_{k}^{\\prime}$ 和 $\\boldsymbol{W}_{v}^{\\prime}$ 为线性映射的参数矩阵。\nhttps：／／nndl．github．io／\n\n解码器 解码器是通过自回归的方式来生成目标序列。和编码器不同，解码器由以下三个模块构成：\n（1）掩蔽自注意力模块：第 $t$ 步时，先使用自注意力模型对已生成的前缀序列 $\\boldsymbol{y}_{0:(t-1)}$ 进行编码得到 $\\boldsymbol{H}^{\\mathrm{dec}}=\\left[\\boldsymbol{h}_{1}^{\\mathrm{dec}}, \\cdots, \\boldsymbol{h}_{t}^{\\mathrm{dec}}\\right]$ ．\n（2）解码器到编码器注意力模块：将 $\\boldsymbol{h}_{t}^{d}$ 进行线性映射得到 $\\boldsymbol{q}_{t}^{d}$ 。将 $\\boldsymbol{q}_{t}^{d}$ 作为查询向量，通过键值对注意力机制来从输入（ $\\boldsymbol{K}^{\\text {enc }}, \\boldsymbol{V}^{\\text {enc }}$ ）中选取有用的信息。\n（3）逐位置的前馈神经网络：使用一个前馈神经网络来综合得到所有信息。\n\n将上述三个步骤重复多次，最后通过一个全连接前馈神经网络来计算输出概率。图15．6给出了Transformer的网络结构示例，其中 $N \\times$ 表示重复 $N$ 次，＂Add \\＆ Norm＂表示残差连接和层归一化。在训练时，为了提高效率，我们通常将右移的目标序列（Right－Shifted Output） $\\boldsymbol{y}_{0:(T-1)}$ 作为解码器的输入，即在第 $t$ 个位置的输入为 $y_{t-1}$ 。在这种情况下，可以通过一个掩码（Mask）来阻止每个位置选择其后面的输入信息。这种方式称为掩蔽自注意力（Masked Self－Attention）。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-392.jpg?height=911&width=635&top_left_y=965&top_left_x=327)\n\n图 15．6 Transformer 网络结构，图片来源［Vaswani et al．，2017］",
        "总结": "- Transformer模型是一个基于多头自注意力的序列到序列模型，其结构分为编码器和解码器两部分。  \n- 编码器由多层多头自注意力模块组成，输入为序列$\\boldsymbol{x}_{1:S}$，输出为向量序列$\\boldsymbol{H}^{\\mathrm{enc}}$，并通过矩阵映射生成键值对$\\boldsymbol{K}^{\\mathrm{enc}}$和$\\boldsymbol{V}^{\\mathrm{enc}}$供解码器使用。  \n- 解码器通过自回归方式生成目标序列，包含掩蔽自注意力模块、解码器到编码器注意力模块和逐位置前馈神经网络三个模块。  \n- 掩蔽自注意力模块在每一步使用自注意力模型对已生成的前缀序列进行编码。  \n- 解码器到编码器注意力模块通过线性映射将$\\boldsymbol{h}_{t}^{d}$转换为查询向量$\\boldsymbol{q}_{t}^{d}$，并从输入的键值对中获取信息。  \n- 逐位置前馈神经网络综合所有信息，最终通过全连接前馈神经网络计算输出概率。  \n- 图15.6展示了Transformer的网络结构示例，其中$N \\times$表示重复$N$次，“Add & Norm”表示残差连接和层归一化。  \n- 在训练时，解码器输入为右移的目标序列$\\boldsymbol{y}_{0:(T-1)}$，并通过掩码阻止每个位置选择其后信息，实现掩蔽自注意力。"
      },
      {
        "段落": "## 15.7 总结和深入阅读\n\n序列生成模型主要解决序列数据的密度估计和生成问题，是一种在实际应用中十分重要的模型。目前主流的序列生成模型都是自回归生成模型。\n\n最早的深度序列模型是神经网络语言模型．［Bengio et al．，2003］最早提出了基于前馈神经网络的语言模型，随后［Mikolov et al．，2010］利用循环神经网络来实现语言模型。［Oord et al．，2016］针对语音合成任务提出了 WaveNet，可以生成接近自然人声的语音．\n\n为了解决曝光偏差问题，［Venkatraman et al．，2014］提出了 DAD（Data as Demonstrator）算法，即在训练时混合使用真实数据和模型生成的数据，［Bengio et al．，2015］进一步使用课程学习（Curriculum Learning）控制使用两种数据的比例．［Ranzato et al．，2015］将序列生成看作是强化学习问题，并使用最大似然估计来预训练模型，并逐步将训练目标由最大似然估计切换为最大期望回报。［Yu et al．，2017］进一步利用生成对抗网络的思想来进行文本生成．\n\n由于深度序列模型在输出层使用 Softmax 进行归一化，因此计算代价很高。为了提高效率，［Bengio et al．，2008］提出了利用重要性采样来加速 Softmax 的计算，［Mnih et al．，2013］提出了噪声对比估计来计算非归一化的条件概率，［Morin et al．，2005］使用了层次化 Softmax 函数来近似扁平的 Softmax 函数．\n\n在众多的序列生成任务中，序列到序列生成是一种十分重要的任务类型。 ［Sutskever et al．，2014］开创性地使用基于循环神经网络的序列到序列模型来进行机器翻译，［Bahdanau et al．，2014］使用注意力模型来改进循环神经网络的长程依赖问题，［Gehring et al．，2017］提出了基于卷积神经网络的序列到序列模型．目前最成功的序列到序列模型是全连接的自注意力模型，比如 Trans－ former［Vaswani et al．，2017］．\n\nTexar ${ }^{1}$ 是一个非常好的序列生成框架，提供了很多主流的序列生成模型。",
        "总结": "- 序列生成模型主要用于序列数据的密度估计和生成，在实际应用中非常重要。  \n- 主流的序列生成模型都是自回归生成模型。  \n- 神经网络语言模型是最早的深度序列模型，包括基于前馈神经网络和循环神经网络的语言模型。  \n- WaveNet 是一种针对语音合成任务提出的深度序列模型，能生成接近自然人声的语音。  \n- DAD 算法通过混合真实数据和模型生成数据来解决曝光偏差问题。  \n- 课程学习用于控制真实数据与生成数据的比例，以优化训练过程。  \n- 序列生成被看作强化学习问题，通过最大似然估计预训练，并逐步切换为最大期望回报。  \n- 生成对抗网络的思想被用于文本生成，进一步提升生成质量。  \n- 深度序列模型使用 Softmax 归一化，但计算成本高，因此提出了重要性采样、噪声对比估计和层次化 Softmax 来提高效率。  \n- 序列到序列生成是重要的任务类型，循环神经网络、注意力机制和卷积神经网络被广泛应用于该任务。  \n- Transformer 是目前最成功的序列到序列模型，基于全连接的自注意力机制。  \n- Texar 是一个提供多种主流序列生成模型的框架，适用于实际应用。"
      },
      {
        "段落": "## 习题\n\n习题15－1 证明公式（15．19）。\n习题 15－2 通过文献了解 N 元模型中 Good－Turing 平滑、Kneser－Ney 平滑的原理．\n\n习题15－3 试通过注意力机制来动态计算公式（15．24）中的权重．\n\n[^8]习题15－4 给定一个生成序列＂The cat sat on the mat＂和两个参考序列＂The cat is on the mat＂＂The bird sat on the bush＂，分别计算 BLEU－N 和 ROUGE－N得分（ $N=1$ 或 $N=2$ 时）．\n\n习题15－5 描述束搜索的实现算法．\n习题15－6 根据公式（15．89）和公式（15．95），计算噪声对比估计的参数梯度，并分析其和重要性采样中参数梯度（见公式（15．80））的异同点。\n\n习题15－7 证明公式（15．113）和公式（15．114）中位置编码可以刻画一个序列中任意两个词之间的相对距离．",
        "总结": "- 公式（15．19）的证明  \n- N 元模型中的 Good－Turing 平滑与 Kneser－Ney 平滑原理  \n- 注意力机制用于动态计算公式（15．24）中的权重  \n- BLEU－N 和 ROUGE－N 得分的计算方法（N=1 或 N=2）  \n- 束搜索的实现算法  \n- 噪声对比估计的参数梯度计算及其与重要性采样梯度的异同点  \n- 公式（15．113）和公式（15．114）中位置编码对序列中词间相对距离的刻画证明"
      },
      {
        "段落": "## 参考文献\n\nBahdanau D，Cho K，Bengio Y．Neural machine translation by jointly learning to align and translate ［J］．ArXiv e－prints， 2014.\nBengio S，Vinyals O，Jaitly N，et al．Scheduled sampling for sequence prediction with recurrent neural networks［C］／／Advances in Neural Information Processing Systems．2015：1171－1179．\nBengio Y，Senécal J S．Adaptive importance sampling to accelerate training of a neural probabilistic language model［J］．IEEE Transactions on Neural Networks，2008，19（4）：713－722．\nBengio Y，Ducharme R，Vincent P．A neural probabilistic language model［J］．Journal of Machine Learning Research，2003，3：1137－1155．\nGehring J，Auli M，Grangier D，et al．Convolutional sequence to sequence learning［C］／／Proceedings of the 34th International Conference on Machine Learning．2017：1243－1252．\nGutmann M，Hyvärinen A．Noise－contrastive estimation：A new estimation principle for unnor－ malized statistical models．［C］／／AISTATS． 2010.\nMikolov T，Karafiát M，Burget L，et al．Recurrent neural network based language model．［C］／／ Interspeech：volume 2．2010： 3.\nMiller G A．Wordnet：a lexical database for english［J］．Communications of the ACM，1995，38（11）： 39－41．\nMnih A，Kavukcuoglu K．Learning word embeddings efficiently with noise－contrastive estimation ［C］／／Advances in Neural Information Processing Systems．2013：2265－2273．\nMnih A，Teh Y W．A fast and simple algorithm for training neural probabilistic language models ［J］．arXiv preprint arXiv：1206．6426， 2012.\nMorin F，Bengio Y．Hierarchical probabilistic neural network language model［C］／／Aistats：vol－ ume 5．2005：246－252．\nOord A v d，Dieleman S，Zen H，et al．Wavenet：A generative model for raw audio［J］．arXiv preprint arXiv：1609．03499， 2016.\nRanzato M，Chopra S，Auli M，et al．Sequence level training with recurrent neural networks［J］． arXiv preprint arXiv：1511．06732， 2015.\nSutskever I，Vinyals O，Le Q V．Sequence to sequence learning with neural networks［C］／／Advances in Neural Information Processing Systems．2014：3104－3112．\nVaswani A，Shazeer N，Parmar N，et al．Attention is all you need［C］／／Advances in Neural Infor－ mation Processing Systems．2017：6000－6010．\nVenkatraman A，Boots B，Hebert M，et al．Data as demonstrator with applications to system iden－ tification［C］／／ALR Workshop，NIPS． 2014.\nWilliams R J，Zipser D．A learning algorithm for continually running fully recurrent neural net－ works［J］．Neural computation，1989，1（2）：270－280．\nYu L，Zhang W，Wang J，et al．SeqGAN：Sequence generative adversarial nets with policy gradient ［C］／／Proceedings of Thirty－First AAAI Conference on Artificial Intelligence．2017：2852－2858．",
        "总结": "- 参考文献部分列出了多个与神经网络、语言模型、序列生成和对抗训练相关的研究论文。  \n- 包含了关于神经机器翻译、序列预测、重要性采样、卷积序列到序列学习、噪声对比估计等方法的文献。  \n- 引用了多个在自然语言处理和深度学习领域具有影响力的论文，如注意力机制、WaveNet、SeqGAN等。  \n- 文献覆盖了从基础模型到高级生成模型的多个研究方向，为后续研究提供了理论和方法支持。"
      },
      {
        "段落": "## 附 录",
        "总结": "- 附录部分主要提供了对正文内容的补充说明和参考资料。"
      },
      {
        "段落": "## 数学基础",
        "总结": "- 数学基础部分介绍了数学在计算机科学中的重要性，包括逻辑、集合论、图论等基本概念。  \n- 提到了形式化方法，用于描述和验证算法的正确性。  \n- 引入了数学证明的基本方法，如归纳法和反证法。  \n- 讨论了数学符号和表达式的使用规范，以确保清晰和准确的沟通。  \n- 介绍了数学建模的基本思想，即如何将现实问题抽象为数学问题。"
      },
      {
        "段落": "## 附录 A 线性代数\n\n线性代数主要包含向量、向量空间（或称线性空间）以及向量的线性变换和有限维的线性方程组。",
        "总结": "- 概念：向量  \n- 概念：向量空间（或称线性空间）  \n- 概念：线性变换  \n- 概念：有限维的线性方程组"
      },
      {
        "段落": "## A． 1 向量和向量空间",
        "总结": "- 向量的定义：向量是具有大小和方向的数学对象，通常表示为有序数组或箭头形式。  \n- 向量空间的概念：向量空间是由向量组成的集合，满足加法和标量乘法的封闭性，并遵循一系列公理。  \n- 向量空间的性质：包括加法交换律、结合律，存在零向量，每个向量存在相反向量，标量乘法的分配律等。  \n- 向量空间的例子：实数空间 $ \\mathbb{R}^n $、多项式空间、矩阵空间等。  \n- 向量空间的基与维数：基是向量空间中一组线性无关且能生成整个空间的向量集合，维数是基中向量的个数。"
      },
      {
        "段落": "## A．1．1 向量\n\n标量（Scalar）是一个实数，只有大小，没有方向．标量一般用斜体小写英文字母 $a, b, c$ 来表示。向量（Vector）是由一组实数组成的有序数组，同时具有大小和方向。一个 $N$ 维向量 $\\boldsymbol{a}$ 是由 $N$ 个有序实数组成，表示为\n\n$$\n\\begin{equation*}\n\\boldsymbol{a}=\\left[a_{1}, a_{2}, \\cdots, a_{N}\\right] \\tag{A.1}\n\\end{equation*}\n$$\n\n其中 $a_{n}$ 称为向量 $\\boldsymbol{a}$ 的第 $n$ 个分量，或第 $n$ 维．向量符号一般用黑斜体小写英文字母 $\\boldsymbol{a}, \\boldsymbol{b}, \\boldsymbol{c}$ ，或小写希腊字母 $\\alpha, \\beta, \\gamma$ 等来表示．",
        "总结": "- 标量是仅具有大小的实数，通常用斜体小写字母表示。  \n- 向量是由有序实数组成的数组，具有大小和方向，通常用黑斜体小写字母或小写希腊字母表示。  \n- N维向量由N个有序实数组成，表示为 $ \\boldsymbol{a} = [a_1, a_2, \\cdots, a_N] $。  \n- 向量的每个元素称为分量或维数，分别对应第n个分量和第n维。"
      },
      {
        "段落": "## A．1．2 向量空间\n\n向量空间（Vector Space），也称线性空间（Linear Space），是指由向量组成的集合，并满足以下两个条件：\n（1）向量加法＋：向量空间 $\\mathcal{V}$ 中的两个向量 $\\boldsymbol{a}$ 和 $\\boldsymbol{b}$ ，它们的和 $\\boldsymbol{a}+\\boldsymbol{b}$ 也属于空间 $\\nu$ ；\n（2）标量乘法•：向量空间 $\\mathcal{V}$ 中的任一向量 $\\boldsymbol{a}$ 和任一标量 $c$ ，它们的乘积 $c \\cdot \\boldsymbol{a}$ 也属于空间 $\\mathcal{V}$ 。\n\n欧氏空间 一个常用的线性空间是欧氏空间（Euclidean Space）。一个欧氏空间表示通常为 $\\mathbb{R}^{N}$ ，其中 $N$ 为空间维度（Dimension）。欧氏空间中的向量加法和标量乘法定义为：\n\n$$\n\\begin{align*}\n{\\left[a_{1}, a_{2}, \\cdots, a_{N}\\right]+\\left[b_{1}, b_{2}, \\cdots, b_{N}\\right] } & =\\left[a_{1}+b_{1}, a_{2}+b_{2}, \\cdots, a_{N}+b_{N}\\right]  \\tag{A.2}\\\\\nc \\cdot\\left[a_{1}, a_{2}, \\cdots, a_{N}\\right] & =\\left[c a_{1}, c a_{2}, \\cdots, c a_{N}\\right] \\tag{A.3}\n\\end{align*}\n$$\n\n其中 $a, b, c \\in \\mathbb{R}$ 为标量．\n\n线性子空间 向量空间 $\\mathcal{V}$ 的线性子空间 $\\mathcal{U}$ 是 $\\mathcal{V}$ 的一个子集，并且满足向量空间的条件（向量加法和标量乘法）。\n\n线性无关 线性空间 $\\mathcal{V}$ 中的 $M$ 个向量 $\\left\\{\\boldsymbol{v}_{1}, \\boldsymbol{v}_{2}, \\cdots, \\boldsymbol{v}_{M}\\right\\}$ ，如果对任意的一组标量 $\\lambda_{1}, \\lambda_{2}, \\cdots, \\lambda_{M}$ ，满足 $\\lambda_{1} \\boldsymbol{v}_{1}+\\lambda_{2} \\boldsymbol{v}_{2}+\\cdots+\\lambda_{M} \\boldsymbol{v}_{M}=0$ ，则必然 $\\lambda_{1}=\\lambda_{2}=\\cdots=\\lambda_{M}=0$ ，那么 $\\left\\{\\boldsymbol{v}_{1}, \\boldsymbol{v}_{2}, \\cdots, \\boldsymbol{v}_{M}\\right\\}$ 是线性无关的，也称为线性独立的．\n\n基向量 $N$ 维向量空间 $\\mathcal{V}$ 的基（Base） $\\mathcal{B}=\\left\\{\\boldsymbol{e}_{1}, \\boldsymbol{e}_{2}, \\cdots, \\boldsymbol{e}_{N}\\right\\}$ 是 $\\mathcal{V}$ 的有限子集，其元素之间线性无关。向量空间 $\\mathcal{V}$ 中所有的向量都可以按唯一的方式表达为 $\\mathcal{B}$ 中向量的线性组合。对任意 $v \\in \\mathcal{V}$ ，存在一组标量 $\\left(\\lambda_{1}, \\lambda_{2}, \\cdots, \\lambda_{N}\\right)$ 使得\n\n$$\n\\begin{equation*}\n\\boldsymbol{v}=\\lambda_{1} \\boldsymbol{e}_{1}+\\lambda_{2} \\boldsymbol{e}_{2}+\\cdots+\\lambda_{N} \\boldsymbol{e}_{N} \\tag{A.4}\n\\end{equation*}\n$$\n\n其中基 $\\mathcal{B}$ 中的向量称为基向量（Base Vector）。如果基向量是有序的，则标量 （ $\\lambda_{1}, \\lambda_{2}, \\cdots, \\lambda_{N}$ ）称为向量 $\\boldsymbol{v}$ 关于基 $\\mathcal{B}$ 的坐标（Coordinate）。\n$N$ 维空间 $\\mathcal{V}$ 的一组标准基（Standard Basis）为\n\n$$\n\\begin{align*}\n\\boldsymbol{e}_{1}= & {[1,0,0, \\cdots, 0], }  \\tag{A.5}\\\\\n\\boldsymbol{e}_{2}= & {[0,1,0, \\cdots, 0], }  \\tag{A.6}\\\\\n& \\cdots  \\tag{A.7}\\\\\n\\boldsymbol{e}_{N}= & {[0,0,0, \\cdots, 1], }\n\\end{align*}\n$$\n\n$\\mathcal{V}$ 中的任一向量 $\\boldsymbol{v}=\\left[v_{1}, v_{2}, \\cdots, v_{N}\\right]$ 可以唯一地表示为\n\n$$\n\\begin{equation*}\n\\left[v_{1}, v_{2}, \\cdots, v_{N}\\right]=v_{1} \\boldsymbol{e}_{1}+v_{2} \\boldsymbol{e}_{2}+\\cdots+v_{N} \\boldsymbol{e}_{N} \\tag{A.9}\n\\end{equation*}\n$$\n\n$v_{1}, v_{2}, \\cdots, v_{n}$ 也称为向量 $\\boldsymbol{v}$ 的笛卡尔坐标（Cartesian Coordinate）。\n向量空间中的每个向量可以看作是一个线性空间中的笛卡尔坐标．\n内积 一个 $N$ 维线性空间中的两个向量 $\\boldsymbol{a}$ 和 $\\boldsymbol{b}$ ，其内积（Inner Product）为\n\n$$\n\\begin{equation*}\n\\langle\\boldsymbol{a}, \\boldsymbol{b}\\rangle=\\sum_{n=1}^{N} a_{n} b_{n} \\tag{A.10}\n\\end{equation*}\n$$\n\n内积也称为点积（Dot Product）或标量积（Scalar Product）。\n正交 如果向量空间中两个向量的内积为 0 ，则它们正交（Orthogonal）。如果向量空间中一个向量 $\\boldsymbol{v}$ 与子空间 $u$ 中的每个向量都正交，那么向量 $\\boldsymbol{v}$ 和子空间 $u$ 正交。",
        "总结": "- 向量空间（线性空间）的定义：由向量组成的集合，满足向量加法和标量乘法两个条件。  \n- 欧氏空间：常见的线性空间，表示为 $\\mathbb{R}^N$，向量加法和标量乘法有明确的运算定义。  \n- 线性子空间：向量空间的子集，满足向量加法和标量乘法的条件。  \n- 线性无关：一组向量中不存在非零标量组合使其和为零。  \n- 基向量：向量空间中一组线性无关的向量，能唯一表示空间中所有向量。  \n- 标准基：$N$ 维空间中的一组特殊基向量，每个基向量只有一个分量为 1，其余为 0。  \n- 向量的坐标：向量在基下的唯一线性组合系数。  \n- 内积：两个向量对应分量乘积之和，也称为点积或标量积。  \n- 正交：两个向量内积为 0，或一个向量与子空间中所有向量内积为 0。"
      },
      {
        "段落": "## A．1．3 范数\n\n范数（Norm）是一个表示向量＂长度＂的函数，为向量空间内的所有向量赋予非零的正长度或大小．对于一个 $N$ 维向量 $\\boldsymbol{v}$ ，一个常见的范数函数为 $\\ell_{p}$ 范数，\n\n$$\n\\begin{equation*}\n\\ell_{p}(\\boldsymbol{v}) \\equiv\\|\\boldsymbol{v}\\|_{p}=\\left(\\sum_{n=1}^{N}\\left|v_{n}\\right|^{p}\\right)^{1 / p} \\tag{A.11}\n\\end{equation*}\n$$\n\n其中 $p \\geq 0$ 为一个标量的参数．常用的 $p$ 的取值有 $1,2, \\infty$ 等．\n$\\ell_{1}$ 范数 $\\ell_{1}$ 范数为向量的各个元素的绝对值之和．\n\n$$\n\\begin{equation*}\n\\|\\boldsymbol{v}\\|_{1}=\\sum_{n=1}^{N}\\left|v_{n}\\right| \\tag{A.12}\n\\end{equation*}\n$$\n\n$\\ell_{2}$ 范数 $\\ell_{2}$ 范数为向量的各个元素的平方和再开平方．\n\n$$\n\\begin{equation*}\n\\|\\boldsymbol{v}\\|_{2}=\\sqrt{\\sum_{n=1}^{N} v_{n}^{2}}=\\sqrt{\\boldsymbol{v}^{\\top} \\boldsymbol{v}} \\tag{A.13}\n\\end{equation*}\n$$\n\n$\\ell_{2}$ 范数又称为Euclidean范数或者Frobenius 范数．从几何角度，向量也可以表示为从原点出发的一个带箭头的有向线段，其 $\\ell_{2}$ 范数为线段的长度，也常称为向量的模．\n$\\ell_{\\infty}$ 范数 $\\ell_{\\infty}$ 范数为向量的各个元素的最大绝对值，\n\n$$\n\\begin{equation*}\n\\|\\boldsymbol{v}\\|_{\\infty}=\\max \\left\\{v_{1}, v_{2}, \\cdots, v_{n}\\right\\} \\tag{A.14}\n\\end{equation*}\n$$\n\n图A． 1 给出了常见范数的示例，其中红线表示不同范数的 $\\ell_{p}=1$ 的点．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-398.jpg?height=246&width=1108&top_left_y=1552&top_left_x=104)\n\n图 A． 1 常见的范数",
        "总结": "- 范数是表示向量长度的函数，为向量空间内的向量赋予非零的正长度或大小  \n- $\\ell_p$ 范数是常见的范数函数，定义为向量各元素绝对值的 $p$ 次方和的 $1/p$ 次方  \n- $\\ell_1$ 范数是向量各元素绝对值的和  \n- $\\ell_2$ 范数是向量各元素平方和的平方根，也称为Euclidean范数或Frobenius范数，几何上表示向量的模  \n- $\\ell_\\infty$ 范数是向量各元素绝对值的最大值  \n- 图A.1展示了不同范数下 $\\ell_p = 1$ 的点，用红线表示"
      },
      {
        "段落": "## A．1．4 常见的向量\n\n全 0 向量指所有元素都为 0 的向量，用 $\\mathbf{0}$ 表示．全 0 向量为笛卡尔坐标系中的原点．\n\n全 1 向量指所有元素都为 1 的向量，用 1 表示．\none－hot 向量为有且只有一个元素为 1 ，其余元素都为 0 的向量。 one－hot 向量是在数字电路中的一种状态编码，指对任意给定的状态，状态寄存器中只有 1 位为 1 ，其余位都为 0 。",
        "总结": "- 全 0 向量：所有元素均为 0 的向量，表示笛卡尔坐标系的原点。  \n- 全 1 向量：所有元素均为 1 的向量，用 1 表示。  \n- one-hot 向量：只有一个元素为 1，其余为 0 的向量，用于数字电路中的状态编码。"
      },
      {
        "段落": "## A． 2 矩阵",
        "总结": "- 矩阵的基本概念：矩阵是由排列成矩形阵列的数、符号或表达式组成的二维数组，通常用于表示线性变换或线性方程组。  \n- 矩阵的运算：包括矩阵加法、减法、数乘、矩阵乘法等，这些运算是线性代数中的基础操作。  \n- 矩阵的性质：如交换律不成立（矩阵乘法不满足交换律），以及矩阵的转置、逆矩阵等特殊性质。  \n- 特殊类型的矩阵：如单位矩阵、零矩阵、对角矩阵、三角矩阵等，它们在数学和工程中有广泛应用。  \n- 矩阵的应用：矩阵在解线性方程组、表示线性变换、数据处理和计算机图形学等领域有重要应用。"
      },
      {
        "段落": "## A．2．1 线性映射\n\n线性映射（Linear Mapping）是指从线性空间 $\\mathcal{V}$ 到线性空间 $\\mathcal{W}$ 的一个映射函数 $f: \\mathcal{V} \\rightarrow \\mathcal{W}$ ，并满足：对于 $\\mathcal{V}$ 中任何两个向量 $\\boldsymbol{u}$ 和 $\\boldsymbol{v}$ 以及任何标量 $c$ ，有\n\n$$\n\\begin{align*}\nf(\\boldsymbol{u}+\\boldsymbol{v}) & =f(\\boldsymbol{u})+f(\\boldsymbol{v}),  \\tag{A.15}\\\\\nf(c \\boldsymbol{v}) & =c f(\\boldsymbol{v}) . \\tag{A.16}\n\\end{align*}\n$$\n\n两个有限维欧氏空间的映射函数 $f: \\mathbb{R}^{N} \\rightarrow \\mathbb{R}^{M}$ 可以表示为\n\n$$\n\\boldsymbol{y}=\\boldsymbol{A} \\boldsymbol{x} \\triangleq\\left[\\begin{array}{c}\na_{11} x_{1}+a_{12} x_{2}+\\cdots+a_{1 N} x_{N}  \\tag{A.17}\\\\\na_{21} x_{1}+a_{22} x_{2}+\\cdots+a_{2 N} x_{N} \\\\\n\\vdots \\\\\na_{M 1} x_{1}+a_{M 2} x_{2}+\\cdots+a_{M N} x_{N}\n\\end{array}\\right]\n$$\n\n其中 $\\boldsymbol{A}$ 是一个由 $M$ 行 $N$ 列元素排列成的矩形阵列，称为 $M \\times N$ 的矩阵（Matrix）\n\n$$\n\\boldsymbol{A}=\\left[\\begin{array}{cccc}\na_{11} & a_{12} & \\cdots & a_{1 N}  \\tag{A.18}\\\\\na_{21} & a_{22} & \\cdots & a_{2 N} \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\na_{M 1} & a_{M 2} & \\cdots & a_{M N}\n\\end{array}\\right]\n$$\n\n向量 $\\boldsymbol{x} \\in \\mathbb{R}^{N}$ 和 $\\boldsymbol{y} \\in \\mathbb{R}^{M}$ 为两个空间中的向量． $\\boldsymbol{x}$ 和 $\\boldsymbol{y}$ 可以分别表示为 $N \\times 1$ 的矩阵和 $M \\times 1$ 的矩阵。\n\n$$\n\\boldsymbol{x}=\\left[\\begin{array}{c}\nx_{1}  \\tag{A.19}\\\\\nx_{2} \\\\\n\\vdots \\\\\nx_{N}\n\\end{array}\\right], \\quad \\boldsymbol{y}=\\left[\\begin{array}{c}\ny_{1} \\\\\ny_{2} \\\\\n\\vdots \\\\\ny_{M}\n\\end{array}\\right]\n$$\n\n这种表示形式称为列向量，即只有一列的矩阵。\n为简化书写、方便排版起见，本书约定行向量（即 $1 \\times N$ 的矩阵）用逗号隔离的向量 $\\left[x_{1}, x_{2}, \\cdots, x_{N}\\right]$ 表示；列向量用分号隔开的向量 $\\boldsymbol{x}=\\left[x_{1} ; x_{2} ; \\cdots ; x_{N}\\right]$ 表示，或用行向量的转置 $\\left[x_{1}, x_{2}, \\cdots, x_{N}\\right]^{\\top}$ 表示．\n\n矩阵 $\\boldsymbol{A} \\in \\mathbb{R}^{M \\times N}$ 定义了一个从空间 $\\mathbb{R}^{N}$ 到空间 $\\mathbb{R}^{M}$ 的线性映射。一个矩阵 $\\boldsymbol{A}$从左上角数起的第 $i$ 行第 $j$ 列上的元素称为第 $i, j$ 项，通常记为 $[\\boldsymbol{A}]_{i j}$ 或 $a_{i j}$ 。",
        "总结": "- 线性映射是指从一个线性空间到另一个线性空间的映射函数，满足加法和标量乘法的保持性。  \n- 线性映射的两个基本性质：$ f(\\boldsymbol{u}+\\boldsymbol{v}) = f(\\boldsymbol{u}) + f(\\boldsymbol{v}) $ 和 $ f(c\\boldsymbol{v}) = c f(\\boldsymbol{v}) $。  \n- 有限维欧氏空间之间的线性映射可以表示为矩阵与向量的乘积形式 $ \\boldsymbol{y} = \\boldsymbol{A} \\boldsymbol{x} $。  \n- 矩阵 $ \\boldsymbol{A} $ 是由 $ M $ 行 $ N $ 列元素组成的矩形阵列，表示为 $ M \\times N $ 的矩阵。  \n- 向量 $ \\boldsymbol{x} \\in \\mathbb{R}^N $ 和 $ \\boldsymbol{y} \\in \\mathbb{R}^M $ 分别表示为列向量，即只有一列的矩阵。  \n- 行向量用逗号分隔的表示形式，如 $[x_1, x_2, \\cdots, x_N]$；列向量用分号分隔或行向量转置表示。  \n- 矩阵中的元素称为第 $ i, j $ 项，通常记为 $ [\\boldsymbol{A}]_{ij} $ 或 $ a_{ij} $。"
      },
      {
        "段落": "## A．2．2 矩阵操作\n\n加 如果 $\\boldsymbol{A}$ 和 $\\boldsymbol{B}$ 都为 $M \\times N$ 的矩阵，则 $\\boldsymbol{A}$ 和 $\\boldsymbol{B}$ 的加也是 $M \\times N$ 的矩阵，其每个元素是 A 和 B 相应元素相加。\n\n$$\n\\begin{equation*}\n[\\boldsymbol{A}+\\boldsymbol{B}]_{i j}=a_{i j}+b_{i j} \\tag{A.20}\n\\end{equation*}\n$$\n\n乘积 假设有两个矩阵 $\\boldsymbol{A}$ 和 $\\boldsymbol{B}$ 分别表示两个线性映射 $g: \\mathbb{R}^{M} \\rightarrow \\mathbb{R}^{K}$ 和 $f: \\mathbb{R}^{N} \\rightarrow$ $\\mathbb{R}^{M}$ ，则其复合线性映射\n\n$$\n\\begin{equation*}\n(g \\circ f)(\\boldsymbol{x})=g(f(\\boldsymbol{x}))=g(\\boldsymbol{B} \\boldsymbol{x})=\\boldsymbol{A}(\\boldsymbol{B} \\boldsymbol{x})=(\\boldsymbol{A} \\boldsymbol{B}) \\boldsymbol{x} \\tag{A.21}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{A B}$ 表示矩阵 $\\boldsymbol{A}$ 和 $\\boldsymbol{B}$ 的乘积，定义为\n\n$$\n\\begin{equation*}\n[\\boldsymbol{A B}]_{i j}=\\sum_{k=1}^{m} a_{i k} b_{k j} \\tag{A.22}\n\\end{equation*}\n$$\n\n两个矩阵的乘积仅当第一个矩阵的列数和第二个矩阵的行数相等时才能定义．如 $\\boldsymbol{A}$ 是 $K \\times M$ 矩阵和 $\\boldsymbol{B}$ 是 $M \\times N$ 矩阵，则乘积 $\\boldsymbol{A B}$ 是一个 $K \\times N$ 的矩阵。\n\n矩阵的乘法满足结合律和分配律：\n（1）结合律：$(\\boldsymbol{A B}) \\boldsymbol{C}=\\boldsymbol{A}(\\boldsymbol{B C})$ ，\n（2）分配律：$(\\boldsymbol{A}+\\boldsymbol{B}) \\boldsymbol{C}=\\boldsymbol{A} \\boldsymbol{C}+\\boldsymbol{B} \\boldsymbol{C}, \\boldsymbol{C}(\\boldsymbol{A}+\\boldsymbol{B})=\\boldsymbol{C A}+\\boldsymbol{C B}$ ．\n转置 $M \\times N$ 的矩阵 $\\boldsymbol{A}$ 的转置（Transposition）是一个 $N \\times M$ 的矩阵，记为 $\\boldsymbol{A}^{\\top}, \\boldsymbol{A}^{\\top}$的第 i 行第 j 列的元素是原矩阵 $\\boldsymbol{A}$ 的第 j 行第 i 列的元素，\n\n$$\n\\begin{equation*}\n\\left[\\boldsymbol{A}^{\\top}\\right]_{i j}=[\\boldsymbol{A}]_{j i} \\tag{A.23}\n\\end{equation*}\n$$\n\nHadamard积 矩阵 $\\boldsymbol{A}$ 和矩阵 $\\boldsymbol{B}$ 的Hadamard 积（Hadamard Product）也称为逐点乘积，为 $\\boldsymbol{A}$ 和 $\\boldsymbol{B}$ 中对应的元素相乘．\n\n$$\n\\begin{equation*}\n[\\boldsymbol{A} \\odot \\boldsymbol{B}]_{i j}=a_{i j} b_{i j} \\tag{A.24}\n\\end{equation*}\n$$\n\n一个标量 $c$ 与矩阵 $\\boldsymbol{A}$ 乘积为 $\\boldsymbol{A}$ 的每个元素是 $\\boldsymbol{A}$ 的相应元素与 $c$ 的乘积\n\n$$\n\\begin{equation*}\n[c \\boldsymbol{A}]_{i j}=c a_{i j} \\tag{A.25}\n\\end{equation*}\n$$\n\n如果没有特别说明，本书默认向量为列向量．\n\nKronecker 积 如果 $\\boldsymbol{A}$ 是 $M \\times N$ 的矩阵， $\\boldsymbol{B}$ 是 $p \\times q$ 的矩阵，那么它们的Kronecker积（Kronecker Product）是一个 $m p \\times n q$ 的矩阵：\n\n$$\n[\\boldsymbol{A} \\otimes \\boldsymbol{B}]=\\left[\\begin{array}{cccc}\na_{11} \\boldsymbol{B} & a_{12} \\boldsymbol{B} & \\cdots & a_{1 n} \\boldsymbol{B}  \\tag{A.26}\\\\\na_{21} \\boldsymbol{B} & a_{22} \\boldsymbol{B} & \\cdots & a_{2 n} \\boldsymbol{B} \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\na_{M 1} \\boldsymbol{B} & a_{M 2} \\boldsymbol{B} & \\cdots & a_{m n} \\boldsymbol{B}\n\\end{array}\\right]\n$$\n\n根据 Kronecker 积的定义有 $[\\boldsymbol{A} \\otimes \\boldsymbol{B}]_{p(r-1)+v, q(s-1)+w}=a_{r s} b_{v w}$ ．\n外积 两个向量 $\\boldsymbol{a} \\in \\mathbb{R}^{M}$ 和 $\\boldsymbol{b} \\in \\mathbb{R}^{N}$ 的外积（Outer Product）是一个 $M \\times N$ 的矩阵，定义为\n\n$$\n\\boldsymbol{a} \\otimes \\boldsymbol{b}=\\left[\\begin{array}{cccc}\na_{1} b_{1} & a_{1} b_{2} & \\ldots & a_{1} b_{n}  \\tag{A.27}\\\\\na_{2} b_{1} & a_{2} b_{2} & \\ldots & a_{2} b_{n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{M} b_{1} & a_{M} b_{2} & \\ldots & a_{M} b_{n}\n\\end{array}\\right]=\\boldsymbol{a b}^{\\top}\n$$\n\n其中 $[\\boldsymbol{a} \\otimes \\boldsymbol{b}]_{i j}=a_{i} b_{j}$ ．\n向量化 矩阵的向量化是将矩阵表示为一个列向量．令 $\\boldsymbol{A}=\\left[a_{i j}\\right]_{M \\times N}$ ，向量化算子 $\\operatorname{vec}(\\cdot)$ 定义为\n\n$$\n\\operatorname{vec}(\\boldsymbol{A})=\\left[a_{11}, a_{21}, \\cdots, a_{M 1}, a_{12}, a_{22}, \\cdots, a_{M 2}, \\cdots, a_{1 N}, a_{2 N}, \\cdots, a_{M N}\\right]^{\\top} .\n$$\n\n迹 方块矩阵 $\\boldsymbol{A}$ 的对角线元素之和称为它的迹（Trace），记为 $\\operatorname{tr}(\\boldsymbol{A})$ 。尽管矩阵的乘法不满足交换律，但它们的迹相同，即 $\\operatorname{tr}(\\boldsymbol{A B})=\\operatorname{tr}(\\boldsymbol{B A})$ 。\n\n行列式 方块矩阵 $\\boldsymbol{A}$ 的行列式是一个将其映射到标量的函数，记作 $\\operatorname{det}(\\boldsymbol{A})$ 或 $|\\boldsymbol{A}|$ ．行列式可以看作是有向面积或体积的概念在欧氏空间中的推广。在 $N$ 维欧氏空间中，行列式描述的是一个线性变换对＂体积＂所造成的影响。\n\n一个 $N \\times N$ 的方块矩阵 $\\boldsymbol{A}$ 的行列式定义为：\n\n$$\n\\begin{equation*}\n\\operatorname{det}(\\boldsymbol{A})=\\sum_{\\sigma \\in S_{N}} \\operatorname{sgn}(\\sigma) \\prod_{n=1}^{N} a_{n, \\sigma(n)} \\tag{A.28}\n\\end{equation*}\n$$\n\n其中 $S_{N}$ 是 $\\{1,2, \\cdots, N\\}$ 的所有排列的集合，$\\sigma$ 是其中一个排列，$\\sigma(n)$ 是元素 $n$ 在排列 $\\sigma$ 中的位置， $\\operatorname{sgn}(\\sigma)$ 表示排列 $\\sigma$ 的符号差，定义为\n\n$$\n\\operatorname{sgn}(\\sigma)=\\left\\{\\begin{array}{cl}\n1 & \\sigma \\text { 中的逆序对有偶数个 }  \\tag{A.29}\\\\\n-1 & \\sigma \\text { 中的逆序对有奇数个 }\n\\end{array}\\right.\n$$\n\n外积通常看作是矩阵的 Kronecker 积的一种特例，但两者并不等价。 －既可以表示 Kro－ necker 积，也可以表示外积，其具体含义不同一般需要在上下文中说明．\n\n其中逆序对的定义为：在排列 $\\sigma$ 中，如果有序数对 $(i, j)$ 满足 $1 \\leq i<j \\leq n$ 但 $\\sigma(i)>\\sigma(j)$ ，则其为 $\\sigma$ 的一个逆序对。\n\n秩 一个矩阵 $\\boldsymbol{A}$ 的列秩是 $\\boldsymbol{A}$ 的线性无关的列向量数量，行秩是 $\\boldsymbol{A}$ 的线性无关的行向量数量．一个矩阵的列秩和行秩总是相等的，简称为秩（Rank）。\n\n一个 $M \\times N$ 的矩阵 $\\boldsymbol{A}$ 的秩最大为 $\\min (M, N)$ 。若 $\\operatorname{rank}(\\boldsymbol{A})=\\min (M, N)$ ，则称矩阵为满秩的。如果一个矩阵不满秩，说明其包含线性相关的列向量或行向量，其行列式为 0 。\n\n两个矩阵的乘积 $\\boldsymbol{A B}$ 的秩 $\\operatorname{rank}(\\boldsymbol{A B}) \\leq \\min (\\operatorname{rank}(\\boldsymbol{A}), \\operatorname{rank}(\\boldsymbol{B}))$ ．\n范数 矩阵的范数有很多种形式，其中常用的 $\\ell_{p}$ 范数定义为\n\n$$\n\\begin{equation*}\n\\|\\boldsymbol{A}\\|_{p}=\\left(\\sum_{m=1}^{M} \\sum_{j=1}^{n}\\left|a_{i j}\\right|^{p}\\right)^{1 / p} \\tag{A.30}\n\\end{equation*}\n$$",
        "总结": "- 矩阵加法：两个同维度矩阵对应元素相加，结果为相同维度的矩阵。\n- 矩阵乘法：由两个线性映射的复合定义，乘积矩阵的元素为行与列的点积，要求第一个矩阵的列数等于第二个矩阵的行数。\n- 矩阵乘法性质：满足结合律和分配律。\n- 矩阵转置：将矩阵行列互换，转置矩阵的元素为原矩阵对应位置的元素。\n- Hadamard积：两个同维度矩阵对应元素相乘，结果为相同维度的矩阵。\n- 标量与矩阵乘积：标量与矩阵每个元素相乘，结果为相同维度的矩阵。\n- Kronecker积：两个矩阵对应元素相乘后扩展为大矩阵，结果维度为 $M p \\times N q$。\n- 外积：两个向量相乘得到一个矩阵，每个元素为对应向量元素的乘积。\n- 向量化：将矩阵转换为列向量，按行优先顺序排列所有元素。\n- 迹：方阵对角线元素之和，满足 $\\operatorname{tr}(\\boldsymbol{A B}) = \\operatorname{tr}(\\boldsymbol{B A})$。\n- 行列式：方阵映射到标量的函数，定义为排列和符号差的加权和。\n- 逆序对：排列中满足 $i < j$ 但 $\\sigma(i) > \\sigma(j)$ 的有序对。\n- 矩阵秩：列秩与行秩相等，最大值为 $\\min(M, N)$，满秩表示线性无关的行或列。\n- 矩阵范数：常用 $\\ell_p$ 范数定义为所有元素绝对值 $p$ 次方和的 $1/p$ 次方。"
      },
      {
        "段落": "## A．2．3 矩阵类型\n\n对称矩阵 对称矩阵（Symmetric Matrix）指其转置等于自己的矩阵，即满足 $\\boldsymbol{A}=$ $A^{\\top}$ 。\n\n对角矩阵 对角矩阵（Diagonal Matrix）是一个主对角线之外的元素皆为 0 的矩阵。一个对角矩阵 $\\boldsymbol{A}$ 满足\n\n$$\n\\begin{equation*}\n[\\boldsymbol{A}]_{m n}=0 \\quad \\forall m, n \\in\\{1, \\cdots, N\\}, \\text { and } m \\neq n . \\tag{A.31}\n\\end{equation*}\n$$\n\n对角矩阵通常指方块矩阵，但有时也指矩形对角矩阵（Rectangular Diago－ nal Matrix ），即一个 $M \\times N$ 的矩阵，其除 $a_{i i}$ 之外的元素都为 0 。一个 $N \\times N$ 的对角矩阵 $\\boldsymbol{A}$ 也可以记为 $\\operatorname{diag}(\\boldsymbol{a}), \\boldsymbol{a}$ 为一个 $N$ 维向量，并满足\n\n$$\n\\begin{equation*}\n[\\boldsymbol{A}]_{n n}=a_{n} \\tag{A.32}\n\\end{equation*}\n$$\n\n$N \\times N$ 的对角矩阵 $\\boldsymbol{A}=\\operatorname{diag}(\\boldsymbol{a})$ 和 $N$ 维向量 $\\boldsymbol{b}$ 的乘积为一个 $N$ 维向量\n\n$$\n\\begin{equation*}\n\\boldsymbol{A} \\boldsymbol{b}=\\operatorname{diag}(\\boldsymbol{a}) \\boldsymbol{b}=\\boldsymbol{a} \\odot \\boldsymbol{b} \\tag{A.33}\n\\end{equation*}\n$$\n\n其中 $\\odot$ 表示按元素乘积，即 $[\\boldsymbol{a} \\odot \\boldsymbol{b}]_{n}=a_{n} b_{n}, 1 \\leq n \\leq N$ ．\n单位矩阵 单位矩阵（Identity Matrix）是一种特殊的对角矩阵，其主对角线元素为 1 ，其余元素为 $0 . N$ 阶单位矩阵 $\\boldsymbol{I}_{N}$ ，是一个 $N \\times N$ 的方块矩阵。可以记为 $I_{N}=\\operatorname{diag}(1,1, \\ldots, 1)$.\n\n一个 $M \\times N$ 的矩阵 A 和单位矩阵的乘积等于其本身。\n\n$$\n\\begin{equation*}\n\\boldsymbol{A} \\boldsymbol{I}_{n}=\\boldsymbol{I}_{m} \\boldsymbol{A}=\\boldsymbol{A} . \\tag{A.34}\n\\end{equation*}\n$$\n\n逆矩阵 对于一个 $N \\times N$ 的方块矩阵 $\\boldsymbol{A}$ ，如果存在另一个方块矩阵 $\\boldsymbol{B}$ 使得\n\n$$\n\\begin{equation*}\n\\boldsymbol{A} \\boldsymbol{B}=\\boldsymbol{B} \\boldsymbol{A}=\\boldsymbol{I}_{N} \\tag{A.35}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{I}_{N}$ 为单位阵，则称 $\\boldsymbol{A}$ 是可逆的．矩阵 $\\boldsymbol{B}$ 称为矩阵 $\\boldsymbol{A}$ 的逆矩阵（Inverse Ma－ trix），记为 $\\boldsymbol{A}^{-1}$ 。\n\n一个方阵的行列式等于 0 当且仅当该方阵不可逆．\n正定矩阵 对于一个 $N \\times N$ 的对称矩阵 $\\boldsymbol{A}$ ，如果对于所有的非零向量 $\\boldsymbol{x} \\in \\mathbb{R}^{N}$都满足\n\n$$\n\\begin{equation*}\n\\boldsymbol{x}^{\\top} \\boldsymbol{A} \\boldsymbol{x}>0 \\tag{A.36}\n\\end{equation*}\n$$\n\n则 $\\boldsymbol{A}$ 为正定矩阵（Positive－Definite Matrix）。如果 $\\boldsymbol{x}^{\\top} \\boldsymbol{A} \\boldsymbol{x} \\geq 0$ ，则 $\\boldsymbol{A}$ 是半正定矩阵 （Positive－Semidefinite Matrix）．\n\n正交矩阵 如果一个 $N \\times N$ 的方块矩阵 $\\boldsymbol{A}$ 的逆矩阵等于其转置矩阵，即\n\n$$\n\\begin{equation*}\n\\boldsymbol{A}^{\\top}=\\boldsymbol{A}^{-1} \\tag{A.37}\n\\end{equation*}\n$$\n\n则 $\\boldsymbol{A}$ 为正交矩阵（Orthogonal Matrix）。\n正交矩阵满足 $\\boldsymbol{A}^{\\top} \\boldsymbol{A}=\\boldsymbol{A} \\boldsymbol{A}^{\\top}=\\boldsymbol{I}_{N}$ ，即正交矩阵的每一行（列）向量和自身的内积为 1 ，和其他行（列）向量的内积为 0 。\n\nGram 矩阵 向量空间中一组向量 $\\boldsymbol{a}_{1}, \\boldsymbol{a}_{2}, \\cdots, \\boldsymbol{a}_{N}$ 的Gram矩阵（Gram Matrix） $\\boldsymbol{G}$是内积的对称矩阵，其元素 $\\boldsymbol{G}_{m n}$ 为 $\\boldsymbol{a}_{m}^{\\top} \\boldsymbol{a}_{n}$ 。",
        "总结": "- 对称矩阵：转置等于自身的矩阵，即 $ \\boldsymbol{A} = \\boldsymbol{A}^{\\top} $。\n- 对角矩阵：主对角线外元素全为 0 的矩阵，可表示为 $ \\operatorname{diag}(\\boldsymbol{a}) $，其中非对角线元素为 0。\n- 对角矩阵与向量相乘：结果为向量的按元素乘积，即 $ \\boldsymbol{A} \\boldsymbol{b} = \\boldsymbol{a} \\odot \\boldsymbol{b} $。\n- 单位矩阵：主对角线元素为 1，其余为 0 的特殊对角矩阵，满足 $ \\boldsymbol{A} \\boldsymbol{I}_n = \\boldsymbol{I}_m \\boldsymbol{A} = \\boldsymbol{A} $。\n- 逆矩阵：若存在矩阵 $ \\boldsymbol{B} $ 满足 $ \\boldsymbol{A} \\boldsymbol{B} = \\boldsymbol{B} \\boldsymbol{A} = \\boldsymbol{I}_N $，则称 $ \\boldsymbol{B} $ 为 $ \\boldsymbol{A} $ 的逆矩阵，记为 $ \\boldsymbol{A}^{-1} $。\n- 行列式与可逆性：方阵的行列式等于 0 当且仅当其不可逆。\n- 正定矩阵：对称矩阵满足对所有非零向量 $ \\boldsymbol{x} $ 有 $ \\boldsymbol{x}^{\\top} \\boldsymbol{A} \\boldsymbol{x} > 0 $。\n- 半正定矩阵：对称矩阵满足对所有非零向量 $ \\boldsymbol{x} $ 有 $ \\boldsymbol{x}^{\\top} \\boldsymbol{A} \\boldsymbol{x} \\geq 0 $。\n- 正交矩阵：逆矩阵等于其转置的方阵，满足 $ \\boldsymbol{A}^{\\top} = \\boldsymbol{A}^{-1} $，且有 $ \\boldsymbol{A}^{\\top}\\boldsymbol{A}=I_N $。\n- Gram 矩阵：由一组向量的内积构成的对称矩阵，元素为 $ [\\boldsymbol{G}]_{mn} = \\boldsymbol{a}_m^{\\top}\\boldsymbol{a}_n $。"
      },
      {
        "段落": "## A．2．4 特征值与特征向量\n\n对一个 $N \\times N$ 的矩阵 $\\boldsymbol{A}$ ，如果存在一个标量 $\\lambda$ 和一个非零向量 $\\boldsymbol{v}$ 满足\n\n$$\n\\begin{equation*}\n\\boldsymbol{A} \\boldsymbol{v}=\\lambda \\boldsymbol{v} \\tag{A.38}\n\\end{equation*}\n$$\n\n则 $\\lambda$ 和 $\\boldsymbol{v}$ 分别称为矩阵 $\\boldsymbol{A}$ 的特征值（Eigenvalue）和特征向量（Eigenvector）。\n当用矩阵 $\\boldsymbol{A}$ 对它的特征向量 $\\boldsymbol{v}$ 进行线性映射时，得到的新向量只是在 $\\boldsymbol{v}$ 的长度上缩放 $\\lambda$ 倍。给定一个矩阵的特征值，其对应的特征向量的数量是无限多的。令 $\\boldsymbol{u}$ 和 $\\boldsymbol{v}$ 是矩阵 $\\boldsymbol{A}$ 的特征值 $\\lambda$ 对应的特征向量，则 $\\alpha \\boldsymbol{u}$ 和 $\\boldsymbol{u}+\\boldsymbol{v}$ 也是特征值 $\\lambda$ 对应 $\\alpha$ 为任意实数．的特征向量．\n\n如果矩阵 $\\boldsymbol{A}$ 是一个 $N \\times N$ 的实对称矩阵，则存在实数 $\\lambda_{1}, \\cdots, \\lambda_{N}$ ，以及 $N$个互相正交的单位向量 $\\boldsymbol{v}_{1}, \\cdots, \\boldsymbol{v}_{N}$ ，使得 $\\boldsymbol{v}_{n}$ 为矩阵 $\\boldsymbol{A}$ 的特征值为 $\\lambda_{n}$ 的特征向量单位向量 $\\boldsymbol{v}$ 的模为 1 ，即 $\\boldsymbol{v}^{\\top} \\boldsymbol{v}=1$. （ $1 \\leq n \\leq N$ ）。",
        "总结": "- 特征值与特征向量的定义：对于一个 $N \\times N$ 的矩阵 $\\boldsymbol{A}$，若存在标量 $\\lambda$ 和非零向量 $\\boldsymbol{v}$ 满足 $\\boldsymbol{A} \\boldsymbol{v} = \\lambda \\boldsymbol{v}$，则 $\\lambda$ 和 $\\boldsymbol{v}$ 分别称为矩阵 $\\boldsymbol{A}$ 的特征值和特征向量。\n- 特征向量的性质：给定一个矩阵的特征值，其对应的特征向量有无限多个，例如 $\\alpha \\boldsymbol{u}$ 和 $\\boldsymbol{u} + \\boldsymbol{v}$（其中 $\\alpha$ 为任意实数）也是该特征值对应的特征向量。\n- 实对称矩阵的性质：若矩阵 $\\boldsymbol{A}$ 是 $N \\times N$ 的实对称矩阵，则存在 $N$ 个实数特征值 $\\lambda_1, \\cdots, \\lambda_N$，以及 $N$ 个互相正交的单位特征向量 $\\boldsymbol{v}_1, \\cdots, \\boldsymbol{v}_N$，满足 $\\boldsymbol{v}_n^{\\top} \\boldsymbol{v}_n = 1$（$1 \\leq n \\leq N$）。"
      },
      {
        "段落": "## A．2．5 矩阵分解\n\n一个矩阵通常可以用一些比较＂简单＂的矩阵来表示，称为矩阵分解（Matrix Decomposition，or Matrix Factorization ）．",
        "总结": "- 矩阵分解是指将一个矩阵表示为一些较简单矩阵的组合。  \n- 矩阵分解的目的是简化矩阵的运算或分析。  \n- 矩阵分解在数学和工程中有广泛应用。"
      },
      {
        "段落": "## A．2．5．1 特征分解\n\n一个 $N \\times N$ 的方块矩阵 $\\boldsymbol{A}$ 的特征分解（Eigendecomposition）定义为\n\n$$\n\\begin{equation*}\nA=Q \\mathbf{\\Lambda} Q^{-1} \\tag{A.39}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{Q}$ 为 $N \\times N$ 的方块矩阵，其每一列都为 $\\boldsymbol{A}$ 的特征向量， $\\boldsymbol{\\Lambda}$ 为对角阵，其每一个对角元素分别为 $\\boldsymbol{A}$ 的一个特征值．\n\n如果 $\\boldsymbol{A}$ 为实对称矩阵，那么其不同特征值对应的特征向量相互正交． $\\boldsymbol{A}$ 可以被分解为\n\n$$\n\\begin{equation*}\n\\boldsymbol{A}=\\boldsymbol{Q} \\boldsymbol{\\Lambda} \\boldsymbol{Q}^{\\top} \\tag{A.40}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{Q}$ 为正交阵。",
        "总结": "- 特征分解定义：一个 $N \\times N$ 的方块矩阵 $\\boldsymbol{A}$ 可以分解为 $\\boldsymbol{A} = \\boldsymbol{Q} \\mathbf{\\Lambda} \\boldsymbol{Q}^{-1}$，其中 $\\boldsymbol{Q}$ 是由 $\\boldsymbol{A}$ 的特征向量组成的矩阵，$\\mathbf{\\Lambda}$ 是由对应特征值组成的对角矩阵。  \n- 实对称矩阵的性质：实对称矩阵的不同特征值对应的特征向量相互正交。  \n- 实对称矩阵的特殊分解：实对称矩阵可以分解为 $\\boldsymbol{A} = \\boldsymbol{Q} \\boldsymbol{\\Lambda} \\boldsymbol{Q}^{\\top}$，其中 $\\boldsymbol{Q}$ 是正交矩阵。"
      },
      {
        "段落": "## A．2．5．2 奇异值分解\n\n一个 $M \\times N$ 的矩阵 $\\boldsymbol{A}$ 的奇异值分解（Singular Value Decomposition，SVD）定义为\n\n$$\n\\begin{equation*}\n\\boldsymbol{A}=\\boldsymbol{U} \\Sigma \\boldsymbol{V}^{\\top} \\tag{A.41}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{U}$ 和 $\\boldsymbol{V}$ 分别为 $M \\times M$ 和 $N \\times N$ 的正交矩阵， $\\boldsymbol{\\Sigma}$ 为 $M \\times N$ 的矩形对角矩阵。 $\\boldsymbol{\\Sigma}$对角线上的元素称为奇异值（Singular Value），一般按从大到小排列。\n\n根据公式（A．41）， $\\boldsymbol{A} \\boldsymbol{A}^{\\top}=\\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top} \\boldsymbol{V} \\boldsymbol{\\Sigma} \\boldsymbol{U}^{\\top}=\\boldsymbol{U} \\boldsymbol{\\Sigma}^{2} \\boldsymbol{U}^{\\top}, \\boldsymbol{A}^{\\top} \\boldsymbol{A}=\\boldsymbol{V} \\boldsymbol{\\Sigma} \\boldsymbol{U}^{\\top} \\boldsymbol{U} \\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}=$ $\\boldsymbol{V} \\boldsymbol{\\Sigma}^{2} \\boldsymbol{V}^{\\top}$ 。因此， $\\boldsymbol{U}$ 和 $\\boldsymbol{V}$ 分别为 $\\boldsymbol{A} \\boldsymbol{A}^{\\top}$ 和 $\\boldsymbol{A}^{\\top} \\boldsymbol{A}$ 的特征向量， $\\boldsymbol{A}$ 的非零奇异值为 $\\boldsymbol{A} \\boldsymbol{A}^{\\top}$ 或 $\\boldsymbol{A}^{\\top} \\boldsymbol{A}$ 的非零特征值的平方根．\n\n由于一个大小为 $M \\times N$ 的矩阵 $\\boldsymbol{A}$ 可以表示空间 $\\mathbb{R}^{N}$ 到空间 $\\mathbb{R}^{M}$ 的一种线性映射，因此奇异值分解相当于将这个线性映射分解为 3 个简单操作：（1）先使用 $\\boldsymbol{V}$ 在原始空间中进行坐标旋转。（2）用 $\\boldsymbol{\\Sigma}$ 对旋转后的每一维进行缩放。如果 $M>N$ ，则补 $M-N$ 个 0 ；相反，如果 $M<N$ ，则舍去最后的 $N-M$ 维．（3）使用 $U$ 进行再一次的坐标旋转．\n\n令 $K$ 为矩阵 $\\boldsymbol{A}$ 的非零奇异值的数量，矩阵 $\\boldsymbol{A}$ 可以写为\n\n$$\n\\begin{equation*}\n\\boldsymbol{A}=\\sum_{k=1}^{K} \\sigma_{k} \\boldsymbol{u}_{k} \\boldsymbol{v}_{k}^{\\top}, \\tag{A.42}\n\\end{equation*}\n$$\n\n一个向量 $\\boldsymbol{x} \\in \\mathbb{R}^{N}$ 左乘一个正交矩阵 $U \\in$ $\\mathbb{R}^{N \\times N}$ ，可以看作是对 $\\boldsymbol{x}$ 进行坐标旋转，即 $\\boldsymbol{U}$中的行向量构成一组正交基向量．\n\n矩阵 $\\boldsymbol{A}$ 的非零奇异值数量等于矩阵的秩，即 $K=\\operatorname{rank}(\\boldsymbol{A})<$ $\\min (M, N)$ ．\n\n$$\n\\begin{equation*}\n=\\boldsymbol{U}_{K} \\boldsymbol{\\Sigma}_{K} \\boldsymbol{V}_{K}^{\\top} \\tag{A.43}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{U}_{K}=\\left[\\boldsymbol{u}_{1}, \\cdots, \\boldsymbol{u}_{K}\\right]$ 和 $\\boldsymbol{V}_{K}=\\left[\\boldsymbol{v}_{1}, \\cdots, \\boldsymbol{v}_{K}\\right]$ 分别为 $M \\times K$ 和 $N \\times K$ 的矩阵， $\\boldsymbol{\\Sigma}_{K}=\\operatorname{diag}\\left(\\sigma_{1}, \\cdots, \\sigma_{K}\\right)$ 为 $K \\times K$ 的对角矩阵。公式（A．43）也称为紧凑的奇异值分解 （Compact SVD）。如果令 $K<\\operatorname{rank}(\\boldsymbol{A})$ ，并舍去小的奇异值，则公式（A．43）也称为截断的奇异值分解（Truncated SVD）。在实际应用中，通常使用截断的奇异值分解来提高计算效率，但是截断的奇异值分解只是一种近似的矩阵分解，不能精确重构出原始矩阵。",
        "总结": "- 奇异值分解（SVD）定义为将一个 $M \\times N$ 的矩阵 $\\boldsymbol{A}$ 分解为 $\\boldsymbol{U} \\Sigma \\boldsymbol{V}^{\\top}$，其中 $\\boldsymbol{U}$ 和 $\\boldsymbol{V}$ 是正交矩阵，$\\boldsymbol{\\Sigma}$ 是对角矩阵，其对角线元素为奇异值，按从大到小排列。  \n- 根据 SVD，$\\boldsymbol{A} \\boldsymbol{A}^{\\top}$ 和 $\\boldsymbol{A}^{\\top} \\boldsymbol{A}$ 的特征向量分别为 $\\boldsymbol{U}$ 和 $\\boldsymbol{V}$，非零奇异值是这些矩阵非零特征值的平方根。  \n- 奇异值分解可视为将线性映射分解为三个步骤：坐标旋转、缩放、再次坐标旋转。若 $M > N$，$\\boldsymbol{\\Sigma}$ 中补 $M-N$ 个 0；若 $M < N$，则舍去最后 $N-M$ 维。  \n- 矩阵 $\\boldsymbol{A}$ 可表示为非零奇异值的和：$\\boldsymbol{A} = \\sum_{k=1}^{K} \\sigma_k \\boldsymbol{u}_k \\boldsymbol{v}_k^{\\top}$，其中 $K$ 为非零奇异值的数量。  \n- 正交矩阵 $U$ 对向量 $\\boldsymbol{x}$ 的左乘作用相当于对 $\\boldsymbol{x}$ 进行坐标旋转。  \n- 矩阵 $\\boldsymbol{A}$ 的非零奇异值数量等于其秩 $K = \\operatorname{rank}(\\boldsymbol{A}) < \\min(M, N)$。  \n- 紧凑的 SVD 表示为 $\\boldsymbol{A} = \\boldsymbol{U}_K \\Sigma_K \\boldsymbol{V}_K^{\\top}$，其中 $\\boldsymbol{U}_K$ 和 $\\boldsymbol{V}_K$ 分别由前 $K$ 个奇异向量组成，$\\Sigma_K$ 是对角矩阵。  \n- 截断的 SVD 是通过舍去部分小的奇异值得到的近似分解形式，用于提高计算效率，但不能精确重构原始矩阵。"
      },
      {
        "段落": "## 附录B 微积分\n\n微积分（Calculus）是研究函数的微分（Differentiation）、积分（Integra－ tion）及其相关应用的数学分支．",
        "总结": "- 微积分是研究函数的微分、积分及其相关应用的数学分支。"
      },
      {
        "段落": "## B． 1 微分",
        "总结": "- 微分的概念：微分是描述函数在某一点附近变化率的工具，用于研究函数的局部线性近似。  \n- 微分的定义：若函数 $ f(x) $ 在点 $ x $ 处可微，则其微分为 $ df = f'(x)dx $，其中 $ f'(x) $ 是导数，$ dx $ 是自变量的微小变化。  \n- 微分的几何意义：微分表示函数图像在某一点处的切线斜率与自变量变化量的乘积，反映了函数值的变化量。  \n- 微分的应用：微分可用于近似计算、误差分析以及求解某些类型的微分方程。"
      },
      {
        "段落": "## B．1．1 导数\n\n导数（Derivative）是微积分学中重要的基础概念．\n对于定义域和值域都是实数域的函数 $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ ，若 $f(x)$ 在点 $x_{0}$ 的某个邻域 $\\Delta x$ 内，极限\n\n$$\n\\begin{equation*}\nf^{\\prime}\\left(x_{0}\\right)=\\lim _{\\Delta x \\rightarrow 0} \\frac{f\\left(x_{0}+\\Delta x\\right)-f\\left(x_{0}\\right)}{\\Delta x} \\tag{B.1}\n\\end{equation*}\n$$\n\n存在，则称函数 $f(x)$ 在点 $x_{0}$ 处可导，$f^{\\prime}\\left(x_{0}\\right)$ 称为其导数，或导函数，也可以记为 $\\frac{\\mathrm{d} f\\left(x_{0}\\right)}{\\mathrm{d} x}$ 。\n\n在几何上，导数可以看作函数曲线上的切线斜率．图B． 1 给出了一个函数导数的可视化示例，其中函数 $g(x)$ 的斜率为函数 $f(x)$ 在点 $x$ 的导数，$\\Delta y=f(x+$ $\\Delta x)-f(x)$.\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-406.jpg?height=529&width=543&top_left_y=1428&top_left_x=419)\n\n图 B． 1 函数 $f(x)=\\log (x)+1$ 的导数\n\n表B． 1 给出了几个常见函数的导数．\n\n表 B． 1 几个常见函数的导数\n\n| 函数 | 函数形式 | 导数 |\n| :--- | :--- | :--- |\n| 常函数 | $f(x)=C$ ，其中 $C$ 为常数 | $f^{\\prime}(x)=0$ |\n| 幂函数 | $f(x)=x^{r}$ ，其中 $r$ 是非零实数 | $f^{\\prime}(x)=r x^{r-1}$ |\n| 指数函数 | $f(x)=\\exp (x)$ | $f^{\\prime}(x)=\\exp (x)$ |\n| 对数函数 | $f(x)=\\log (x)$ | $f^{\\prime}(x)=\\frac{1}{x}$ |\n\n高阶导数 对一个函数的导数继续求导，可以得到高阶导数。函数 $f(x)$ 的导数 $f^{\\prime}(x)$ 称为一阶导数，$f^{\\prime}(x)$ 的导数称为二阶导数，记为 $f^{\\prime \\prime}(x)$ 、 $f^{(2)}(x)$ 或 $\\frac{\\mathrm{d}^{2} f(x)}{\\mathrm{d} x^{2}}$ ．\n\n偏导数 对于一个多元变量函数 $f: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ ，它的偏导数（Partial Derivative ）是关于其中一个变量 $x_{i}$ 的导数，而保持其他变量固定，可以记为 $f_{x_{i}}^{\\prime}(\\boldsymbol{x}), \\nabla_{x_{i}} f(\\boldsymbol{x})$ ， $\\frac{\\partial f(x)}{\\partial x_{i}}$ 或 $\\frac{\\partial}{\\partial x_{i}} f(\\boldsymbol{x})$ 。",
        "总结": "- 导数是微积分学中的基础概念，用于描述函数在某一点的瞬时变化率。\n- 导数的定义是通过极限的方式计算，即 $f^{\\prime}(x_0) = \\lim_{\\Delta x \\to 0} \\frac{f(x_0 + \\Delta x) - f(x_0)}{\\Delta x}$。\n- 几何上，导数表示函数曲线在某一点的切线斜率。\n- 图B．1展示了函数 $f(x) = \\log(x) + 1$ 的导数的可视化示例。\n- 表B．1列出了几个常见函数的导数，如常函数、幂函数、指数函数和对数函数。\n- 高阶导数是指对导数继续求导的结果，如二阶导数记为 $f''(x)$ 或 $\\frac{d^2 f(x)}{dx^2}$。\n- 偏导数是针对多元函数中某一变量的导数，其他变量保持不变，记为 $f_{x_i}^{\\prime}(\\boldsymbol{x})$ 或 $\\frac{\\partial f}{\\partial x_i}$。"
      },
      {
        "段落": "## B．1．2 微分\n\n给定一个连续函数，计算其导数的过程称为微分（Differentiation）。若函数 $f(x)$ 在其定义域包含的某区间内每一个点都可导，那么也可以说函数 $f(x)$ 在这个区间内可导．如果一个函数 $f(x)$ 在定义域中的所有点都存在导数，则 $f(x)$为可微函数（Differentiable Function）。可微函数一定连续，但连续函数不一定可微．例如，函数 $|x|$ 为连续函数，但在点 $x=0$ 处不可导．",
        "总结": "- 微分是指计算一个连续函数导数的过程。  \n- 若函数 $f(x)$ 在其定义域内的某区间内每个点都可导，则称 $f(x)$ 在该区间内可导。  \n- 若函数 $f(x)$ 在定义域中的所有点都存在导数，则称 $f(x)$ 为可微函数。  \n- 可微函数一定是连续的，但连续函数不一定是可微的。  \n- 例如，函数 $|x|$ 是连续的，但在 $x=0$ 处不可导。"
      },
      {
        "段落": "## B．1．3 泰勒公式\n\n泰勒公式（Taylor＇s Formula）是一个函数 $f(x)$ 在已知某一点的各阶导数值的情况之下，可以用这些导数值做系数构建一个多项式来近似函数在这一点的邻域中的值．\n\n如果函数 $f(x)$ 在 $a$ 点处 $n$ 次可导 $(n \\geq 1)$ ，在一个包含点 $a$ 的区间上的任意 $x$ ，都有\n\n$$\n\\begin{align*}\nf(x)=f(a)+ & \\frac{1}{1!} f^{\\prime}(a)(x-a)+\\frac{1}{2!} f^{(2)}(a)(x-a)^{2}+\\cdots \\\\\n& +\\frac{1}{n!} f^{(n)}(a)(x-a)^{n}+R_{n}(x) \\tag{B.2}\n\\end{align*}\n$$\n\n其中 $f^{(n)}(a)$ 表示函数 $f(x)$ 在点 $a$ 的 $n$ 阶导数．\n上面公式中的多项式部分称为函数 $f(x)$ 在 $a$ 处的 $n$ 阶泰勒展开式，剩余的 $R_{n}(x)$ 是泰勒公式的余项，是 $(x-a)^{n}$ 的高阶无穷小。",
        "总结": "- 泰勒公式：用函数在某一点的各阶导数值构建多项式来近似函数在该点邻域内的值。\n- 泰勒展开式：多项式部分表示为 $f(a) + \\frac{1}{1!} f^{\\prime}(a)(x-a) + \\frac{1}{2!} f^{(2)}(a)(x-a)^2 + \\cdots + \\frac{1}{n!} f^{(n)}(a)(x-a)^n$。\n- 余项 $R_n(x)$：表示泰勒公式的误差部分，是 $(x-a)^n$ 的高阶无穷小。"
      },
      {
        "段落": "## B． 2 积分\n\n积分（Integration）是微分的逆过程，即如何从导数推算出原函数．积分通常可以分为定积分（Definite Integral）和不定积分（Indefinite Integral）。\n\n函数 $f(x)$ 的不定积分可以写为\n\n$$\n\\begin{equation*}\nF(x)=\\int f(x) \\mathrm{d} x \\tag{B.3}\n\\end{equation*}\n$$\n\n其中 $F(x)$ 称为 $f(x)$ 的原函数或反导函数， $\\mathrm{d} x$ 表示积分变量为 $x$ 。当 $f(x)$ 是 $F(x)$的导数时，$F(x)$ 是 $f(x)$ 的不定积分．根据导数的性质，一个函数 $f(x)$ 的不定积分是不唯一的．若 $F(x)$ 是 $f(x)$ 的不定积分，$F(x)+C$ 也是 $f(x)$ 的不定积分，其中 $C$为一个常数．\n\n给定一个变量为 $x$ 的实值函数 $f(x)$ 和闭区间 $[a, b]$ ，定积分可以理解为在坐标平面上由函数 $f(x)$ ，垂直直线 $x=a, x=b$ 以及 $x$ 轴围起来的区域的带符号的面积，记为\n\n$$\n\\begin{equation*}\n\\int_{a}^{b} f(x) \\mathrm{d} x \\tag{B.4}\n\\end{equation*}\n$$\n\n带符号的面积表示 $x$ 轴以上的面积为正，$x$ 轴以下的面积为负．\n积分的严格定义有很多种，最常见的积分定义之一为黎曼积分（Riemann Integral）。对于闭区间 $[a, b]$ ，我们定义 $[a, b]$ 的一个分割为此区间中取一个有限的点列\n\n$$\na=x_{0}<x_{1}<x_{2}<\\ldots<x_{N}=b\n$$\n\n这些点将区间 $[a, b]$ 分割为 $N$ 个子区间 $\\left[x_{n-1}, x_{n}\\right]$ ，其中 $1 \\leq n \\leq N$ ．每个区间取出一个点 $t_{n} \\in\\left[x_{n-1}, x_{n}\\right]$ 作为代表．\n\n在这个分割上，函数 $f(x)$ 的黎曼和定义为\n\n$$\n\\begin{equation*}\n\\sum_{n=1}^{N} f\\left(t_{n}\\right)\\left(x_{n}-x_{n-1}\\right) \\tag{B.5}\n\\end{equation*}\n$$\n\n即所有子区间的带符号面积之和．\n不同分割的黎曼和不同。当 $\\lambda=\\max _{n=1}^{N}\\left(x_{n}-x_{n-1}\\right)$ 足够小时，如果所有的黎曼和都趋于某个极限，那么这个极限就叫做函数 $f(x)$ 在闭区间 $[a, b]$ 上的黎曼积分．图B． 2 给出了不同分割的黎曼和示例，其中 $N$ 表示分割的子区间数量。\n\n积分符号 $\\int$ 为一个拉长的字母 $S$ ，表示求和 （Sum），和 $\\boldsymbol{\\Sigma}$ 有类似的意义．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-409.jpg?height=487&width=959&top_left_y=149&top_left_x=174)\n\n图 B． 2 不同分割的黎曼和示例",
        "总结": "- 积分是微分的逆过程，用于从导数推算出原函数  \n- 积分分为定积分和不定积分两种类型  \n- 不定积分表示为 $F(x) = \\int f(x) \\, dx$，其中 $F(x)$ 是 $f(x)$ 的原函数  \n- 不定积分不唯一，形式为 $F(x) + C$，其中 $C$ 为任意常数  \n- 定积分表示在区间 $[a, b]$ 内函数围成区域的带符号面积，记为 $\\int_{a}^{b} f(x) \\, dx$  \n- 黎曼积分是积分的一种严格定义方法，通过分割区间并计算黎曼和来逼近积分值  \n- 黎曼和的定义为 $\\sum_{n=1}^{N} f(t_n)(x_n - x_{n-1})$，其中 $t_n$ 是每个子区间的代表点  \n- 当分割的最小区间长度趋于零时，黎曼和的极限即为定积分  \n- 积分符号 $\\int$ 源自拉长的字母 $S$，表示求和的意义"
      },
      {
        "段落": "## B． 3 矩阵微积分\n\n为了书写简便，我们通常把单个函数对多个变量或者多元函数对单个变量的偏导数写成向量和矩阵的形式，使其可以被当成一个整体处理。矩阵微积分 （Matrix Calculus）是多元微积分的一种表达方式，即使用矩阵和向量来表示因变量每个成分关于自变量每个成分的偏导数 ${ }^{1}$ 。\n\n矩阵微积分的表示通常有两种符号约定：分子布局（Numerator Layout）和分母布局（Denominator Layout）。两者的区别是一个标量关于一个向量的导数是写成列向量还是行向量．\n\n标量关于向量的偏导数 对于 $M$ 维向量 $\\boldsymbol{x} \\in \\mathbb{R}^{M}$ 和函数 $y=f(\\boldsymbol{x}) \\in \\mathbb{R}$ ，则 $y$ 关于 $\\boldsymbol{x}$ 的偏导数为\n\n$$\n\\begin{array}{lll}\n\\text { 分母布局 } & \\frac{\\partial y}{\\partial x}=\\left[\\frac{\\partial y}{\\partial x_{1}}, \\cdots, \\frac{\\partial y}{\\partial x_{M}}\\right]^{\\top} & \\in \\mathbb{R}^{M \\times 1}, \\\\\n\\text { 分子布局 } & \\frac{\\partial y}{\\partial x}=\\left[\\frac{\\partial y}{\\partial x_{1}}, \\cdots, \\frac{\\partial y}{\\partial x_{M}}\\right] & \\in \\mathbb{R}^{1 \\times M} . \\tag{B.7}\n\\end{array}\n$$\n\n在分母布局中，$\\frac{\\partial y}{\\partial x}$ 为列向量；而在分子布局中，$\\frac{\\partial y}{\\partial x}$ 为行向量．\n向量关于标量的偏导数 对于标量 $x \\in \\mathbb{R}$ 和函数 $\\boldsymbol{y}=f(x) \\in \\mathbb{R}^{N}$ ，则 $\\boldsymbol{y}$ 关于 $x$ 的偏导数为\n\n$$\n\\begin{array}{lll}\n\\text { 分母布局 } & \\frac{\\partial \\boldsymbol{y}}{\\partial x}=\\left[\\frac{\\partial y_{1}}{\\partial x}, \\cdots, \\frac{\\partial y_{N}}{\\partial x}\\right] & \\in \\mathbb{R}^{1 \\times N}, \\\\\n\\text { 分子布局 } & \\frac{\\partial \\boldsymbol{y}}{\\partial x}=\\left[\\frac{\\partial y_{1}}{\\partial x}, \\cdots, \\frac{\\partial y_{N}}{\\partial x}\\right]^{\\top} & \\in \\mathbb{R}^{N \\times 1} . \\tag{B.9}\n\\end{array}\n$$\n\n在分母布局中，$\\frac{\\partial \\boldsymbol{y}}{\\partial x}$ 为行向量；而在分子布局中，$\\frac{\\partial \\boldsymbol{y}}{\\partial x}$ 为列向量．\n\n[^9]除特别说明外，本书默认采用分母布局．\n\n向量关于向量的偏导数 对于 $M$ 维向量 $\\boldsymbol{x} \\in \\mathbb{R}^{M}$ 和函数 $\\boldsymbol{y}=f(\\boldsymbol{x}) \\in \\mathbb{R}^{N}$ ，则 $f(\\boldsymbol{x})$关于 $\\boldsymbol{x}$ 的偏导数（分母布局）为\n\n$$\n\\frac{\\partial f(\\boldsymbol{x})}{\\partial \\boldsymbol{x}}=\\left[\\begin{array}{ccc}\n\\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{N}}{\\partial x_{1}}  \\tag{B.10}\\\\\n\\vdots & \\vdots & \\vdots \\\\\n\\frac{\\partial y_{1}}{\\partial x_{M}} & \\cdots & \\frac{\\partial y_{N}}{\\partial x_{M}}\n\\end{array}\\right] \\in \\mathbb{R}^{M \\times N}\n$$\n\n为函数 $f(\\boldsymbol{x})$ 的雅可比矩阵（Jacobian Matrix）的转置．\n对于 $M$ 维向量 $\\boldsymbol{x} \\in \\mathbb{R}^{M}$ 和函数 $y=f(\\boldsymbol{x}) \\in \\mathbb{R}$ ，则 $f(\\boldsymbol{x})$ 关于 $\\boldsymbol{x}$ 的二阶偏导数 （分母布局）为\n\n$$\n\\boldsymbol{H}=\\frac{\\partial^{2} f(\\boldsymbol{x})}{\\partial \\boldsymbol{x}^{2}}=\\left[\\begin{array}{ccc}\n\\frac{\\partial^{2} y}{\\partial x_{1}^{2}} & \\cdots & \\frac{\\partial^{2} y}{\\partial x_{1} \\partial x_{M}}  \\tag{B.11}\\\\\n\\vdots & \\vdots & \\vdots \\\\\n\\frac{\\partial^{2} y}{\\partial x_{M} \\partial x_{1}} & \\cdots & \\frac{\\partial^{2} y}{\\partial x_{M}^{2}}\n\\end{array}\\right] \\in \\mathbb{R}^{M \\times M}\n$$\n\n称为函数 $f(\\boldsymbol{x})$ 的Hessian矩阵，其中第 $i, j$ 个元素为 $\\frac{\\partial^{2} y}{\\partial x_{i} \\partial x_{j}}$ ，也写作 $\\nabla^{2} f(\\boldsymbol{x})$ 。",
        "总结": "- 矩阵微积分是多元微积分的一种表达方式，使用矩阵和向量表示因变量关于自变量的偏导数  \n- 矩阵微积分有两种符号约定：分子布局和分母布局，区别在于标量关于向量的导数是列向量还是行向量  \n- 标量关于向量的偏导数在分母布局中为列向量，在分子布局中为行向量  \n- 向量关于标量的偏导数在分母布局中为行向量，在分子布局中为列向量  \n- 向量关于向量的偏导数（分母布局）为雅可比矩阵的转置，是一个 $M \\times N$ 的矩阵  \n- 向量关于向量的二阶偏导数（分母布局）为Hessian矩阵，是一个 $M \\times M$ 的矩阵，其中元素为 $\\frac{\\partial^{2} y}{\\partial x_{i} \\partial x_{j}}$"
      },
      {
        "段落": "## B．3．1 导数法则\n\n复合函数的导数的计算可以通过以下法则来简化．",
        "总结": "- 导数法则：介绍了计算复合函数导数的简化方法。"
      },
      {
        "段落": "## B．3．1．1 加（减）法则\n\n若 $\\boldsymbol{x} \\in \\mathbb{R}^{M}, \\boldsymbol{y}=f(\\boldsymbol{x}) \\in \\mathbb{R}^{N}, \\boldsymbol{z}=g(\\boldsymbol{x}) \\in \\mathbb{R}^{N}$ ，则\n\n$$\n\\begin{equation*}\n\\frac{\\partial(y+z)}{\\partial x}=\\frac{\\partial y}{\\partial x}+\\frac{\\partial z}{\\partial x} \\quad \\in \\mathbb{R}^{M \\times N} \\tag{B.12}\n\\end{equation*}\n$$",
        "总结": "- 加（减）法则：若 $\\boldsymbol{x} \\in \\mathbb{R}^{M}, \\boldsymbol{y}=f(\\boldsymbol{x}) \\in \\mathbb{R}^{N}, \\boldsymbol{z}=g(\\boldsymbol{x}) \\in \\mathbb{R}^{N}$，则 $\\frac{\\partial(y+z)}{\\partial x}=\\frac{\\partial y}{\\partial x}+\\frac{\\partial z}{\\partial x}$，结果属于 $\\mathbb{R}^{M \\times N}$。"
      },
      {
        "段落": "## B．3．1．2 乘法法则\n\n（1）若 $\\boldsymbol{x} \\in \\mathbb{R}^{M}, \\boldsymbol{y}=f(\\boldsymbol{x}) \\in \\mathbb{R}^{N}, \\boldsymbol{z}=g(\\boldsymbol{x}) \\in \\mathbb{R}^{N}$ ，则\n\n$$\n\\begin{equation*}\n\\frac{\\partial y^{\\top} z}{\\partial x}=\\frac{\\partial y}{\\partial x} z+\\frac{\\partial z}{\\partial x} y \\quad \\in \\mathbb{R}^{M} \\tag{B.13}\n\\end{equation*}\n$$\n\n（2）若 $\\boldsymbol{x} \\in \\mathbb{R}^{M}, \\boldsymbol{y}=f(\\boldsymbol{x}) \\in \\mathbb{R}^{S}, \\boldsymbol{z}=g(\\boldsymbol{x}) \\in \\mathbb{R}^{T}, \\boldsymbol{A} \\in \\mathbb{R}^{S \\times T}$ 和 $\\boldsymbol{x}$ 无关，则\n\n$$\n\\begin{equation*}\n\\frac{\\partial \\boldsymbol{y}^{\\top} \\boldsymbol{A z}}{\\partial \\boldsymbol{x}}=\\frac{\\partial \\boldsymbol{y}}{\\partial \\boldsymbol{x}} \\boldsymbol{A z}+\\frac{\\partial \\boldsymbol{z}}{\\partial \\boldsymbol{x}} \\boldsymbol{A}^{\\top} \\boldsymbol{y} \\quad \\in \\mathbb{R}^{M} \\tag{B.14}\n\\end{equation*}\n$$\n\n（3）若 $\\boldsymbol{x} \\in \\mathbb{R}^{M}, y=f(\\boldsymbol{x}) \\in \\mathbb{R}, \\boldsymbol{z}=g(\\boldsymbol{x}) \\in \\mathbb{R}^{N}$ ，则\n\n$$\n\\begin{equation*}\n\\frac{\\partial y z}{\\partial x}=y \\frac{\\partial z}{\\partial x}+\\frac{\\partial y}{\\partial x} z^{\\top} \\in \\mathbb{R}^{M \\times N} \\tag{B.15}\n\\end{equation*}\n$$",
        "总结": "- 乘法法则：介绍了向量函数与向量乘积的导数计算规则，适用于不同维度的向量函数。\n- 公式（B.13）：当两个向量函数 $y$ 和 $z$ 都是关于 $x$ 的函数时，它们的转置乘积对 $x$ 的导数等于各自导数与对方的乘积之和。\n- 公式（B.14）：当存在一个常数矩阵 $A$ 时，向量函数 $y$ 与矩阵乘积 $Az$ 的转置乘积对 $x$ 的导数等于 $y$ 对 $x$ 的导数与 $Az$ 的乘积加上 $z$ 对 $x$ 的导数与 $A^{\\top}y$ 的乘积。\n- 公式（B.15）：当一个向量函数 $y$ 是标量，另一个是向量函数 $z$ 时，它们的乘积对 $x$ 的导数等于标量 $y$ 与 $z$ 对 $x$ 的导数的乘积加上 $y$ 对 $x$ 的导数与 $z^{\\top}$ 的乘积。"
      },
      {
        "段落": "## B．3．1．3 链式法则\n\n链式法则（Chain Rule）是在微积分中求复合函数导数的一种常用方法．\n（1）若 $x \\in \\mathbb{R}, \\boldsymbol{y}=g(x) \\in \\mathbb{R}^{M}, \\boldsymbol{z}=f(\\boldsymbol{y}) \\in \\mathbb{R}^{N}$ ，则\n\n$$\n\\begin{equation*}\n\\frac{\\partial z}{\\partial x}=\\frac{\\partial y}{\\partial x} \\frac{\\partial z}{\\partial y} \\quad \\in \\mathbb{R}^{1 \\times N} \\tag{B.16}\n\\end{equation*}\n$$\n\n（2）若 $\\boldsymbol{x} \\in \\mathbb{R}^{M}, \\boldsymbol{y}=g(\\boldsymbol{x}) \\in \\mathbb{R}^{K}, \\boldsymbol{z}=f(\\boldsymbol{y}) \\in \\mathbb{R}^{N}$ ，则\n\n$$\n\\begin{equation*}\n\\frac{\\partial z}{\\partial x}=\\frac{\\partial y}{\\partial x} \\frac{\\partial z}{\\partial y} \\quad \\in \\mathbb{R}^{M \\times N} \\tag{B.17}\n\\end{equation*}\n$$\n\n（3）若 $X \\in \\mathbb{R}^{M \\times N}$ 为矩阵， $\\boldsymbol{y}=g(X) \\in \\mathbb{R}^{K}, z=f(\\boldsymbol{y}) \\in \\mathbb{R}$ ，则\n\n$$\n\\begin{equation*}\n\\frac{\\partial z}{\\partial X_{i j}}=\\frac{\\partial \\boldsymbol{y}}{\\partial X_{i j}} \\frac{\\partial z}{\\partial \\boldsymbol{y}} \\quad \\in \\mathbb{R} \\tag{B.18}\n\\end{equation*}\n$$",
        "总结": "- 链式法则是微积分中用于求复合函数导数的一种常用方法。  \n- 当 $x \\in \\mathbb{R}, \\boldsymbol{y}=g(x) \\in \\mathbb{R}^{M}, \\boldsymbol{z}=f(\\boldsymbol{y}) \\in \\mathbb{R}^{N}$ 时，导数为 $\\frac{\\partial z}{\\partial x}=\\frac{\\partial y}{\\partial x} \\frac{\\partial z}{\\partial y}$，结果属于 $\\mathbb{R}^{1 \\times N}$。  \n- 当 $\\boldsymbol{x} \\in \\mathbb{R}^{M}, \\boldsymbol{y}=g(\\boldsymbol{x}) \\in \\mathbb{R}^{K}, \\boldsymbol{z}=f(\\boldsymbol{y}) \\in \\mathbb{R}^{N}$ 时，导数为 $\\frac{\\partial z}{\\partial x}=\\frac{\\partial y}{\\partial x} \\frac{\\partial z}{\\partial y}$，结果属于 $\\mathbb{R}^{M \\times N}$。  \n- 当 $X \\in \\mathbb{R}^{M \\times N}$ 为矩阵，$\\boldsymbol{y}=g(X) \\in \\mathbb{R}^{K}, z=f(\\boldsymbol{y}) \\in \\mathbb{R}$ 时，对 $X_{ij}$ 的偏导数为 $\\frac{\\partial z}{\\partial X_{ij}}=\\frac{\\partial \\boldsymbol{y}}{\\partial X_{ij}} \\frac{\\partial z}{\\partial \\boldsymbol{y}}$，结果属于 $\\mathbb{R}$。"
      },
      {
        "段落": "## B． 4 常见函数的导数\n\n这里我们介绍本书中常用的几个函数．",
        "总结": "- 概念：介绍了本书中常用的几个函数。  \n- 内容：包括常见函数的导数，如多项式、三角函数、指数函数和对数函数等。  \n- 目的：为后续内容提供基础，便于读者理解导数的计算方法。"
      },
      {
        "段落": "## B． 4.1 向量函数及其导数\n\n$$\n\\begin{align*}\n\\frac{\\partial x}{\\partial x} & =I  \\tag{B.19}\\\\\n\\frac{\\partial A x}{\\partial x} & =A^{\\top}  \\tag{B.20}\\\\\n\\frac{\\partial x^{\\top} A}{\\partial x} & =A \\tag{B.21}\n\\end{align*}\n$$",
        "总结": "- 向量函数及其导数的概念  \n- 式子 $\\frac{\\partial x}{\\partial x} = I$ 表示向量对自身求导得到单位矩阵  \n- 式子 $\\frac{\\partial A x}{\\partial x} = A^{\\top}$ 表示矩阵与向量乘积对向量求导的结果为矩阵的转置  \n- 式子 $\\frac{\\partial x^{\\top} A}{\\partial x} = A$ 表示向量转置与矩阵乘积对向量求导的结果为矩阵本身"
      },
      {
        "段落": "## B．4． 2 按位计算的向量函数及其导数\n\n假设一个函数 $f(x)$ 的输入是标量 $x$ ．对于一组 $K$ 个标量 $x_{1}, \\cdots, x_{K}$ ，我们可以通过 $f(x)$ 得到另外一组 $K$ 个标量 $z_{1}, \\cdots, z_{K}$ ，\n\n$$\n\\begin{equation*}\nz_{k}=f\\left(x_{k}\\right), \\quad \\forall k=1, \\cdots, K \\tag{B.22}\n\\end{equation*}\n$$\n\n为了简便起见，我们定义 $\\boldsymbol{x}=\\left[x_{1}, \\cdots, x_{K}\\right]^{\\top}, \\boldsymbol{z}=\\left[z_{1}, \\cdots, z_{K}\\right]^{\\top}$ ，\n\n$$\n\\begin{equation*}\nz=f(x) \\tag{B.23}\n\\end{equation*}\n$$\n\n其中 $f(\\boldsymbol{x})$ 是按位运算的，即 $[f(\\boldsymbol{x})]_{i}=f\\left(x_{i}\\right)$ ．\n\n当 $x$ 为标量时，$f(x)$ 的导数记为 $f^{\\prime}(x)$ 。当输入为 $K$ 维向量 $\\boldsymbol{x}=\\left[x_{1}, \\cdots, x_{K}\\right]^{\\top}$时，其导数为一个对角矩阵。\n\n$$\n\\begin{align*}\n\\frac{\\partial f(\\boldsymbol{x})}{\\partial \\boldsymbol{x}} & =\\left[\\frac{\\partial f\\left(x_{j}\\right)}{\\partial x_{i}}\\right]_{K \\times K}  \\tag{B.24}\\\\\n& =\\left[\\begin{array}{cccc}\nf^{\\prime}\\left(x_{1}\\right) & 0 & \\cdots & 0 \\\\\n0 & f^{\\prime}\\left(x_{2}\\right) & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\n0 & 0 & \\cdots & f^{\\prime}\\left(x_{K}\\right)\n\\end{array}\\right]  \\tag{B.25}\\\\\n& =\\operatorname{diag}\\left(f^{\\prime}(\\boldsymbol{x})\\right) . \\tag{B.26}\n\\end{align*}\n$$",
        "总结": "- 概念：按位计算的向量函数，即每个分量独立地对输入向量的对应分量应用同一标量函数。  \n- 算法：定义向量函数 $f(\\boldsymbol{x})$ 为对输入向量 $\\boldsymbol{x}$ 的每个分量单独应用标量函数 $f$。  \n- 数学推导：当输入为 $K$ 维向量时，函数 $f(\\boldsymbol{x})$ 的导数是一个对角矩阵，其对角线元素为 $f$ 在对应输入分量处的导数。  \n- 定理/命题：向量函数 $f(\\boldsymbol{x})$ 的雅可比矩阵为对角矩阵，形式为 $\\operatorname{diag}(f^{\\prime}(\\boldsymbol{x}))$。"
      },
      {
        "段落": "## B．4．2．1 Logistic 函数\n\nLogistic 函数是一种常用的 S 型函数，是比利时数学家 Pierre François Ver－ hulst 在 1844 年～1845 年研究种群数量的增长模型时提出命名的，最初作为一种生态学模型．\n\nLogistic 函数定义为\n\n$$\n\\begin{equation*}\n\\operatorname{logistic}(x)=\\frac{L}{1+\\exp \\left(-K\\left(x-x_{0}\\right)\\right)}, \\tag{B.27}\n\\end{equation*}\n$$\n\n这里 $\\exp (\\cdot)$ 函数表示自然对数，$x_{0}$ 是中心点，$L$ 是最大值，$K$ 是曲线的倾斜度．图B． 3 给出了几种不同参数的 Logistic 函数曲线。当 $x$ 趋向于 $-\\infty$ 时， $\\operatorname{logistic}(x)$接近于 0 ；当 $x$ 趋向于 $+\\infty$ 时， $\\operatorname{logistic}(x)$ 接近于 $L$ ．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-412.jpg?height=457&width=582&top_left_y=1370&top_left_x=362)\n\n图 B． 3 Logistic 函数\n\n当参数为 $\\left(k=1, x_{0}=0, L=1\\right)$ 时，Logistic函数称为标准 Logistic 函数，记为 $\\sigma(x)$ 。\n\n$$\n\\begin{equation*}\n\\sigma(x)=\\frac{1}{1+\\exp (-x)} \\tag{B.28}\n\\end{equation*}\n$$\n\n标准 Logistic 函数在机器学习中使用得非常广泛，经常用来将一个实数空间的数映射到 $(0,1)$ 区间．\n\n标准 Logistic 函数的导数为\n\n$$\n\\begin{equation*}\n\\sigma^{\\prime}(x)=\\sigma(x)(1-\\sigma(x)) \\tag{B.29}\n\\end{equation*}\n$$\n\n当输入为 $K$ 维向量 $\\boldsymbol{x}=\\left[x_{1}, \\cdots, x_{K}\\right]^{\\top}$ 时，其导数为\n\n$$\n\\begin{equation*}\n\\sigma^{\\prime}(\\boldsymbol{x})=\\operatorname{diag}(\\sigma(\\boldsymbol{x}) \\odot(1-\\sigma(\\boldsymbol{x}))) . \\tag{B.30}\n\\end{equation*}\n$$",
        "总结": "- Logistic 函数是一种 S 型函数，由 Pierre François Verhulst 在 1844～1845 年提出，最初用于生态学模型。  \n- Logistic 函数定义为 $\\operatorname{logistic}(x)=\\frac{L}{1+\\exp \\left(-K\\left(x-x_{0}\\right)\\right)}$，其中 $L$ 是最大值，$x_0$ 是中心点，$K$ 是曲线倾斜度。  \n- 当 $x \\to -\\infty$ 时，Logistic 函数接近 0；当 $x \\to +\\infty$ 时，接近 $L$。  \n- 当参数为 $(k=1, x_0=0, L=1)$ 时，Logistic 函数称为标准 Logistic 函数，记为 $\\sigma(x)=\\frac{1}{1+\\exp(-x)}$。  \n- 标准 Logistic 函数常用于机器学习中，将实数映射到 $(0,1)$ 区间。  \n- 标准 Logistic 函数的导数为 $\\sigma'(x) = \\sigma(x)(1 - \\sigma(x))$。  \n- 当输入为 $K$ 维向量 $\\boldsymbol{x}$ 时，其导数为 $\\sigma'(\\boldsymbol{x}) = \\operatorname{diag}(\\sigma(\\boldsymbol{x}) \\odot (1 - \\sigma(\\boldsymbol{x})))$。"
      },
      {
        "段落": "## B．4．2．2 Softmax函数\n\nSoftmax函数可以将多个标量映射为一个概率分布。对于 $K$ 个标量 $x_{1}, \\cdots, x_{K}$ ， Softmax 函数定义为\n\n$$\n\\begin{equation*}\nz_{k}=\\operatorname{softmax}\\left(x_{k}\\right)=\\frac{\\exp \\left(x_{k}\\right)}{\\sum_{i=1}^{K} \\exp \\left(x_{i}\\right)} \\tag{B.31}\n\\end{equation*}\n$$\n\n这样，我们可以将 $K$ 个标量 $x_{1}, \\cdots, x_{K}$ 转换为一个分布：$z_{1}, \\cdots, z_{K}$ ，满足\n\n$$\n\\begin{align*}\n& z_{k} \\in(0,1), \\quad \\forall k,  \\tag{B.32}\\\\\n& \\sum_{k=1}^{K} z_{k}=1 . \\tag{B.33}\n\\end{align*}\n$$\n\n为了简便起见，用 $K$ 维向量 $\\boldsymbol{x}=\\left[x_{1} ; \\cdots ; x_{K}\\right]$ 来表示 Softmax 函数的输入， Softmax 函数可以简写为\n\n$$\n\\begin{align*}\n\\hat{\\boldsymbol{z}} & =\\operatorname{softmax}(\\boldsymbol{x})  \\tag{B.34}\\\\\n& =\\frac{1}{\\sum_{k=1}^{K} \\exp \\left(x_{k}\\right)}\\left[\\begin{array}{c}\n\\exp \\left(x_{1}\\right) \\\\\n\\vdots \\\\\n\\exp \\left(x_{K}\\right)\n\\end{array}\\right]  \\tag{B.35}\\\\\n& =\\frac{\\exp (\\boldsymbol{x})}{\\sum_{k=1}^{K} \\exp \\left(x_{k}\\right)}  \\tag{B.36}\\\\\n& =\\frac{\\exp (\\boldsymbol{x})}{\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})} \\tag{B.37}\n\\end{align*}\n$$\n\n其中 $1_{K}=[1, \\cdots, 1]_{K \\times 1}$ 是 $K$ 维的全 1 向量．\n\nSoftmax 函数的导数为\n\n$$\n\\begin{align*}\n& \\frac{\\partial \\operatorname{softmax}(\\boldsymbol{x})}{\\partial \\boldsymbol{x}}=\\frac{\\partial\\left(\\frac{\\exp (\\boldsymbol{x})}{\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})}\\right)}{\\partial \\boldsymbol{x}}  \\tag{B.38}\\\\\n& =\\frac{1}{\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})} \\frac{\\partial \\exp (\\boldsymbol{x})}{\\partial \\boldsymbol{x}}+\\frac{\\partial\\left(\\frac{1}{\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})}\\right)}{\\partial \\boldsymbol{x}}(\\exp (\\boldsymbol{x}))^{\\top}  \\tag{B.39}\\\\\n& =\\frac{\\operatorname{diag}(\\exp (\\boldsymbol{x}))}{\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})}-\\left(\\frac{1}{\\left(\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})\\right)^{2}}\\right) \\frac{\\partial\\left(\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})\\right)}{\\partial \\boldsymbol{x}}(\\exp (\\boldsymbol{x}))^{\\top}  \\tag{B.40}\\\\\n& =\\frac{\\operatorname{diag}(\\exp (\\boldsymbol{x}))}{\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})}-\\left(\\frac{1}{\\left(\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})\\right)^{2}}\\right) \\operatorname{diag}(\\exp (\\boldsymbol{x})) \\mathbf{1}_{K}(\\exp (\\boldsymbol{x}))^{\\top}  \\tag{B.41}\\\\\n& =\\frac{\\operatorname{diag}(\\exp (\\boldsymbol{x}))}{\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})}-\\left(\\frac{1}{\\left(\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})\\right)^{2}}\\right) \\exp (\\boldsymbol{x})(\\exp (\\boldsymbol{x}))^{\\top}  \\tag{B.42}\\\\\n& =\\operatorname{diag}\\left(\\frac{\\exp (\\boldsymbol{x})}{\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})}\\right)-\\frac{\\exp (\\boldsymbol{x})}{\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})} \\frac{(\\exp (\\boldsymbol{x}))^{\\top}}{\\mathbf{1}_{K}^{\\top} \\exp (\\boldsymbol{x})}  \\tag{B.43}\\\\\n& =\\operatorname{diag}(\\operatorname{softmax}(\\boldsymbol{x}))-\\operatorname{softmax}(\\boldsymbol{x}) \\operatorname{softmax}(\\boldsymbol{x})^{\\top} . \\tag{B.44}\n\\end{align*}\n$$",
        "总结": "- Softmax函数的作用是将多个标量映射为一个概率分布  \n- Softmax函数的数学定义为 $ z_k = \\frac{\\exp(x_k)}{\\sum_{i=1}^{K} \\exp(x_i)} $  \n- 输出结果满足两个条件：每个元素在(0,1)区间内，且所有元素之和为1  \n- 输入可以表示为K维向量，Softmax函数的简写形式为 $ \\hat{\\boldsymbol{z}} = \\frac{\\exp(\\boldsymbol{x})}{\\mathbf{1}_{K}^{\\top} \\exp(\\boldsymbol{x})} $  \n- Softmax函数的导数推导过程涉及矩阵运算和向量求导  \n- 最终导数表达式为 $ \\operatorname{diag}(\\operatorname{softmax}(\\boldsymbol{x})) - \\operatorname{softmax}(\\boldsymbol{x}) \\operatorname{softmax}(\\boldsymbol{x})^{\\top} $"
      },
      {
        "段落": "## 附录 C 数学优化\n\n数学优化（Mathematical Optimization）问题，也叫最优化问题，是指在一定约束条件下，求解一个目标函数的最大值（或最小值）问题．\n\n数学优化问题的定义为：给定一个目标函数（也叫代价函数）$f: \\mathcal{A} \\rightarrow \\mathbb{R}$ ，寻找一个变量（也叫参数） $\\boldsymbol{x}^{*} \\in \\mathcal{D} \\subset \\mathcal{A}$ ，使得对于所有 $\\mathcal{D}$ 中的 $\\boldsymbol{x}$ ，都满足 $f\\left(\\boldsymbol{x}^{*}\\right) \\leq f(\\boldsymbol{x})$（最小化）；或者 $f\\left(\\boldsymbol{x}^{*}\\right) \\geq f(\\boldsymbol{x})$（最大化），其中 $\\mathcal{D}$ 为变量 $\\boldsymbol{x}$ 的约束集，也叫可行域； $\\mathcal{D}$ 中的变量被称为是可行解．",
        "总结": "- 数学优化问题，也称为最优化问题，是在一定约束条件下求解目标函数的最大值或最小值的问题。  \n- 数学优化问题的定义是：给定目标函数 $f: \\mathcal{A} \\rightarrow \\mathbb{R}$，寻找变量 $\\boldsymbol{x}^{*} \\in \\mathcal{D} \\subset \\mathcal{A}$，使得对于所有 $\\mathcal{D}$ 中的 $\\boldsymbol{x}$，满足 $f(\\boldsymbol{x}^{*}) \\leq f(\\boldsymbol{x})$（最小化）或 $f(\\boldsymbol{x}^{*}) \\geq f(\\boldsymbol{x})$（最大化）。  \n- $\\mathcal{D}$ 是变量 $\\boldsymbol{x}$ 的约束集，也称为可行域。  \n- $\\mathcal{D}$ 中的变量被称为可行解。"
      },
      {
        "段落": "## C． 1 数学优化的类型",
        "总结": "- 数学优化的类型是指根据不同的目标函数和约束条件，将优化问题划分为不同的类别，如无约束优化、有约束优化、线性规划、非线性规划等。  \n- 无约束优化是指在没有约束条件下寻找目标函数的极值点。  \n- 有约束优化是指在存在等式或不等式约束条件下寻找目标函数的极值点。  \n- 线性规划是一种特殊的优化问题，其目标函数和约束条件均为线性函数。  \n- 非线性规划是指目标函数或约束条件中至少有一个是非线性函数的优化问题。  \n- 本节简要介绍了数学优化的基本分类，并为后续讨论不同类型的优化方法奠定了基础。"
      },
      {
        "段落": "## C．1．1 离散优化和连续优化\n\n根据输入变量 $\\boldsymbol{X}$ 的值域是否为实数域，数学优化问题可以分为离散优化问题和连续优化问题．",
        "总结": "- 离散优化问题：输入变量的值域为离散集合，即变量只能取有限或可数无限个值。  \n- 连续优化问题：输入变量的值域为实数域，即变量可以在一个区间内连续取值。  \n- 分类依据：根据输入变量的值域是否为实数域，数学优化问题被划分为离散优化和连续优化两类。"
      },
      {
        "段落": "## C．1．1．1 离散优化问题\n\n离散优化（Discrete Optimization）问题是目标函数的输入变量为离散变量，比如为整数或有限集合中的元素．离散优化问题主要有两个分支：\n（1）组合优化（Combinatorial Optimization）：其目标是从一个有限集合中找出使得目标函数最优的元素．在一般的组合优化问题中，集合中的元素之间存在一定的关联，可以表示为图结构。典型的组合优化问题有旅行商问题、最小生成树问题、图着色问题等。很多机器学习问题都是组合优化问题，比如特征选择、聚类问题、超参数优化问题以及结构化学习（Structured Learning）中标签预测问题等。\n（2）整数规划（Integer Programming）：输入变量 $\\boldsymbol{x} \\in \\mathbb{Z}^{d}$ 为整数向量。常见的整数规划问题通常为整数线性规划（Integer Linear Programming，ILP）。整数线性规划的一种最直接的求解方法是：（1）去掉输入必须为整数的限制，将原问题转换为一般的线性规划问题，这个线性规划问题为原问题的松弛问题；（2）求得相应松弛问题的解；（3）把松弛问题的解四舍五入到最接近的整数．但是这种方法得到的解一般都不是最优的，因为原问题的最\n\n优解不一定在松弛问题最优解的附近．另外，这种方法得到的解也不一定满足约束条件。\n\n离散优化问题的求解一般都比较困难，优化算法的复杂度都比较高．",
        "总结": "- 离散优化问题是指目标函数的输入变量为离散变量（如整数或有限集合中的元素）的问题。  \n- 离散优化问题分为两个主要分支：组合优化和整数规划。  \n- 组合优化是从有限集合中寻找使目标函数最优的元素，常见问题包括旅行商问题、最小生成树问题、图着色问题等，许多机器学习问题也属于此类。  \n- 整数规划的输入变量为整数向量，常见的形式是整数线性规划（ILP）。  \n- 解决整数线性规划的一种方法是将其转换为线性规划问题（松弛问题），求解后对结果进行四舍五入，但这种方法通常无法得到最优解，且可能不满足约束条件。  \n- 离散优化问题的求解通常较为困难，优化算法的复杂度较高。"
      },
      {
        "段落": "## C．1．1．2 连续优化问题\n\n连续优化（Continuous Optimization）问题是目标函数的输入变量为连续变量 $\\boldsymbol{x} \\in \\mathbb{R}^{d}$ ，即目标函数为实函数．本节后面的内容主要以连续优化为主．",
        "总结": "- 连续优化问题的定义：目标函数的输入变量为连续变量 $\\boldsymbol{x} \\in \\mathbb{R}^{d}$，即目标函数为实函数。  \n- 本节主要内容：后续内容主要围绕连续优化问题展开讨论。"
      },
      {
        "段落": "## C． 1.2 无约束优化和约束优化\n\n在连续优化问题中，根据是否有变量的约束条件，可以将优化问题分为无约束优化问题和约束优化问题．\n\n无约束优化（Unconstrained Optimization）问题的可行域通常为整个实数域 $\\mathcal{D}=\\mathbb{R}^{d}$ ，可以写为\n\n$$\n\\begin{equation*}\n\\min _{x} f(\\boldsymbol{x}) \\tag{C.1}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{x} \\in \\mathbb{R}^{d}$ 为输入变量，$f: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ 为目标函数．\n约束优化（Constrained Optimization）问题中变量 $\\boldsymbol{x}$ 需要满足一些等式或不等式的约束。约束优化问题通常使用拉格朗日乘数法来进行求解。",
        "总结": "- 无约束优化问题是指没有变量约束条件的优化问题，其可行域为整个实数域 $\\mathbb{R}^{d}$，目标函数为 $f: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$，形式为 $\\min_{x} f(\\boldsymbol{x})$。\n- 约束优化问题是指变量需要满足等式或不等式约束的优化问题，通常使用拉格朗日乘数法进行求解。"
      },
      {
        "段落": "## C．1．3 线性优化和非线性优化\n\n如果在公式（C．1）中，目标函数和所有的约束函数都为线性函数，则该问题为线性规划（Linear Programming）问题。相反，如果目标函数或任何一个约束函数为非线性函数，则该问题为非线性规划（Nonlinear Programming）问题．\n\n在非线性优化问题中，有一类比较特殊的问题是凸优化（Convex Optimiza－ tion）问题。在凸优化问题中，变量 $\\boldsymbol{x}$ 的可行域为凸集，即对于集合中任意两点，它们的连线全部位于集合内部．目标函数 $f$ 也必须为凸函数，即满足\n\n$$\n\\begin{equation*}\nf(\\alpha \\boldsymbol{x}+(1-\\alpha) \\boldsymbol{y}) \\leq \\alpha f(\\boldsymbol{x})+(1-\\alpha) f(\\boldsymbol{y}), \\forall \\alpha \\in[0,1] . \\tag{C.2}\n\\end{equation*}\n$$\n\n凸优化问题是一种特殊的约束优化问题，需满足目标函数为凸函数，并且等式约束函数为线性函数，不等式约束函数为凸函数。",
        "总结": "- 线性优化问题是指目标函数和所有约束函数均为线性函数的优化问题，属于线性规划（Linear Programming）。\n- 非线性优化问题是指目标函数或至少一个约束函数为非线性函数的优化问题，属于非线性规划（Nonlinear Programming）。\n- 凸优化问题是一类特殊的非线性优化问题，其可行域为凸集，即任意两点连线仍在集合内部。\n- 凸优化问题要求目标函数为凸函数，满足 $ f(\\alpha \\boldsymbol{x} + (1-\\alpha) \\boldsymbol{y}) \\leq \\alpha f(\\boldsymbol{x}) + (1-\\alpha) f(\\boldsymbol{y}) $，对所有 $\\alpha \\in [0,1]$ 成立。\n- 凸优化问题还需满足等式约束函数为线性函数，不等式约束函数为凸函数。"
      },
      {
        "段落": "## C． 2 优化算法\n\n优化问题一般都可以通过迭代的方式来求解：通过猜测一个初始的估计 $\\boldsymbol{x}_{0}$ ，然后不断迭代产生新的估计 $\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, \\cdots \\boldsymbol{x}_{t}$ ，希望 $\\boldsymbol{x}_{t}$ 最终收敛到期望的最优解 $\\boldsymbol{x}^{*}$ 。\n\n最优化问题一般可以表示为求最小值问题。求 $f(\\boldsymbol{x})$ 最大值等价于求 $-f(x)$ 的最小值．\n\n拉格朗日乘数法参见第 C． 3 节。\n\n一个好的优化算法应该是在一定的时间或空间复杂度下能够快速准确地找到最优解。同时，好的优化算法受初始猜测点的影响较小，通过迭代能稳定地找到最优解 $\\boldsymbol{x}^{*}$ 的邻域，然后迅速收敛于 $\\boldsymbol{x}^{*}$ 。\n\n优化算法中常用的迭代方法有线性搜索和置信域方法等。线性搜索的策略是寻找方向和步长，具体算法有梯度下降法、牛顿法、共轭梯度法等。",
        "总结": "- 优化问题通常通过迭代方法求解，从初始估计 $\\boldsymbol{x}_{0}$ 开始，不断生成新的估计 $\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, \\cdots$，希望最终收敛到最优解 $\\boldsymbol{x}^{*}$。  \n- 最优化问题通常表示为求最小值问题，求最大值等价于求负函数的最小值。  \n- 优化算法应具备在合理时间或空间复杂度下快速准确找到最优解的能力，并且对初始猜测点不敏感，能稳定收敛到最优解的邻域。  \n- 常用的迭代方法包括线性搜索和置信域方法。线性搜索涉及方向和步长的选择，具体算法有梯度下降法、牛顿法、共轭梯度法等。"
      },
      {
        "段落": "## C．2．1 全局最小解和局部最小解\n\n对于很多非线性优化问题，会存在若干个局部最小值（Local Minima），其对应的解称为局部最小解（Local Minimizer）。局部最小解 $\\boldsymbol{x}^{*}$ 定义为：存在一个 $\\delta>0$ ，对于所有的满足 $\\left\\|\\boldsymbol{x}-\\boldsymbol{x}^{*}\\right\\| \\leq \\delta$ 的 $\\boldsymbol{x}$ ，都有 $f\\left(\\boldsymbol{x}^{*}\\right) \\leq f(\\boldsymbol{x})$ 。也就是说，在 $\\boldsymbol{x}^{*}$的邻域内，所有的函数值都大于或者等于 $f\\left(\\boldsymbol{x}^{*}\\right)$ ．\n\n对于所有的 $\\boldsymbol{x} \\in \\mathcal{D}$ ，都有 $f\\left(\\boldsymbol{x}^{*}\\right) \\leq f(\\boldsymbol{x})$ 成立，则 $\\boldsymbol{x}^{*}$ 为全局最小解（Global Minimizer）．\n\n求局部最小解一般是比较容易的，但很难保证其为全局最小解。对于线性规划或凸优化问题，局部最小解就是全局最小解．\n\n要确认一个点 $\\boldsymbol{x}^{*}$ 是否为局部最小解，通过比较它的邻域内有没有更小的函数值是不现实的。如果函数 $f(\\boldsymbol{x})$ 是二次连续可微的，我们可以通过检查目标函数在点 $\\boldsymbol{x}^{*}$ 的梯度 $\\nabla f\\left(\\boldsymbol{x}^{*}\\right)$ 和 Hessian 矩阵 $\\nabla^{2} f\\left(\\boldsymbol{x}^{*}\\right)$ 来判断。\n\n定理 C． 1 －局部最小解的一阶必要条件：如果 $\\boldsymbol{x}^{*}$ 为局部最小解并且函数 $f$在 $\\boldsymbol{x}^{*}$ 的邻域内一阶可微，则在 $\\nabla f\\left(\\boldsymbol{x}^{*}\\right)=0$ ．\n\n证明．如果函数 $f(\\boldsymbol{x})$ 是连续可微的，根据泰勒公式（Taylor＇s Formula），函数 $f(\\boldsymbol{x})$ 的一阶展开可以近似为\n\n$$\n\\begin{equation*}\nf\\left(\\boldsymbol{x}^{*}+\\Delta \\boldsymbol{x}\\right)=f\\left(\\boldsymbol{x}^{*}\\right)+\\Delta \\boldsymbol{x}^{\\top} \\nabla f\\left(\\boldsymbol{x}^{*}\\right), \\tag{C.3}\n\\end{equation*}\n$$\n\n假设 $\\nabla f\\left(\\boldsymbol{x}^{*}\\right) \\neq 0$ ，则可以找到一个 $\\Delta \\boldsymbol{x}$（比如 $\\Delta \\boldsymbol{x}=-\\alpha \\nabla f\\left(\\boldsymbol{x}^{*}\\right), \\alpha$ 为很小的正数），使得\n\n$$\n\\begin{equation*}\nf\\left(\\boldsymbol{x}^{*}+\\Delta \\boldsymbol{x}\\right)-f\\left(\\boldsymbol{x}^{*}\\right)=\\Delta \\boldsymbol{x}^{\\top} \\nabla f\\left(\\boldsymbol{x}^{*}\\right) \\leq 0 . \\tag{C.4}\n\\end{equation*}\n$$\n\n这和局部最小的定义矛盾．\n\n函数 $f(\\boldsymbol{x})$ 的一阶偏导数为 0 的点也称为驻点（Stationary Point）或临界点 （Critical Point）．驻点不一定为局部最小解．\n\n本书中只介绍梯度下降法．\n\n局部最小解也称为局部最小值点，或更一般性地称为局部最优解．\n\n全局最小解也称为全局最小值点，或更一般性地称为全局最优解．\n\nHessian矩阵参见公式（B．11）。\n\n定理 C．2－局部最小解的二阶必要条件：如果 $\\boldsymbol{x}^{*}$ 为局部最小解并且函数 $f$在 $\\boldsymbol{x}^{*}$ 的邻域内二阶可微，则在 $\\nabla f\\left(\\boldsymbol{x}^{*}\\right)=0, \\nabla^{2} f\\left(\\boldsymbol{x}^{*}\\right)$ 为半正定矩阵。\n\n证明．如果函数 $f(\\boldsymbol{x})$ 是二次连续可微的，函数 $f(\\boldsymbol{x})$ 的二阶展开可以近似为\n\n$$\n\\begin{equation*}\nf\\left(\\boldsymbol{x}^{*}+\\Delta \\boldsymbol{x}\\right)=f\\left(\\boldsymbol{x}^{*}\\right)+\\Delta \\boldsymbol{x}^{\\top} \\nabla f\\left(\\boldsymbol{x}^{*}\\right)+\\frac{1}{2} \\Delta \\boldsymbol{x}^{\\top}\\left(\\nabla^{2} f\\left(\\boldsymbol{x}^{*}\\right)\\right) \\Delta \\boldsymbol{x} \\tag{C.5}\n\\end{equation*}\n$$\n\n由一阶必要性定理可知 $\\nabla f\\left(\\boldsymbol{x}^{*}\\right)=0$ ，则\n\n$$\n\\begin{equation*}\nf\\left(\\boldsymbol{x}^{*}+\\Delta \\boldsymbol{x}\\right)-f\\left(\\boldsymbol{x}^{*}\\right)=\\frac{1}{2} \\Delta \\boldsymbol{x}^{\\top}\\left(\\nabla^{2} f\\left(\\boldsymbol{x}^{*}\\right)\\right) \\Delta \\boldsymbol{x} \\geq 0 \\tag{C.6}\n\\end{equation*}\n$$\n\n即 $\\nabla^{2} f\\left(\\boldsymbol{x}^{*}\\right)$ 为半正定矩阵。",
        "总结": "- 全局最小解是指在定义域内所有点中函数值最小的解，而局部最小解是指在某个邻域内函数值最小的解。  \n- 局部最小解的判定需要检查其邻域内是否存在更小的函数值，但对于二次连续可微函数，可通过梯度和Hessian矩阵判断。  \n- 一阶必要条件：若某点为局部最小解且函数一阶可微，则该点的梯度为零。  \n- 二阶必要条件：若某点为局部最小解且函数二阶可微，则梯度为零且Hessian矩阵为半正定矩阵。  \n- 驻点是梯度为零的点，但不一定是局部最小解。  \n- 梯度下降法是本书中介绍的优化方法。  \n- 全局最优解和局部最优解分别对应全局最小解和局部最小解。  \n- Hessian矩阵在公式（B．11）中定义。"
      },
      {
        "段落": "## C．2．2 梯度下降法\n\n梯度下降法（Gradient Descent Method），也叫最速下降法（Steepest De－ scend Method），经常用来求解无约束优化的最小值问题．\n\n对于函数 $f(\\boldsymbol{x})$ ，如果 $f(\\boldsymbol{x})$ 在点 $\\boldsymbol{x}_{t}$ 附近是连续可微的，那么 $f(\\boldsymbol{x})$ 下降最快的方向是 $f(\\boldsymbol{x})$ 在 $\\boldsymbol{x}_{t}$ 点的梯度方法的反方向。\n\n根据泰勒一阶展开公式，\n\n$$\n\\begin{equation*}\nf\\left(\\boldsymbol{x}_{t+1}\\right)=f\\left(\\boldsymbol{x}_{t}+\\Delta \\boldsymbol{x}\\right) \\approx f\\left(\\boldsymbol{x}_{t}\\right)+\\Delta \\boldsymbol{x}^{\\top} \\nabla f\\left(\\boldsymbol{x}_{t}\\right) . \\tag{C.7}\n\\end{equation*}\n$$\n\n要使得 $f\\left(\\boldsymbol{x}_{t+1}\\right)<f\\left(\\boldsymbol{x}_{t}\\right)$ ，就得使 $\\Delta \\boldsymbol{x}^{\\top} \\nabla f\\left(\\boldsymbol{x}_{t}\\right)<0$ ．我们取 $\\Delta \\boldsymbol{x}=-\\alpha \\nabla f\\left(\\boldsymbol{x}_{t}\\right)$ ．如果 $\\alpha>0$ 为一个够小数值时，那么 $f\\left(\\boldsymbol{x}_{t+1}\\right)<f\\left(\\boldsymbol{x}_{t}\\right)$ 成立．\n\n这样我们就可以从一个初始值 $\\boldsymbol{x}_{0}$ 出发，通过迭代公式\n\n$$\n\\begin{equation*}\n\\boldsymbol{x}_{t+1}=\\boldsymbol{x}_{t}-\\alpha_{t} \\nabla f\\left(\\boldsymbol{x}_{t}\\right), t \\geq 0 . \\tag{C.8}\n\\end{equation*}\n$$\n\n生成序列 $\\boldsymbol{x}_{0}, \\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, \\ldots$ 使得\n\n$$\n\\begin{equation*}\nf\\left(\\boldsymbol{x}_{0}\\right) \\geq f\\left(\\boldsymbol{x}_{1}\\right) \\geq f\\left(\\boldsymbol{x}_{2}\\right) \\geq \\cdots \\tag{С.9}\n\\end{equation*}\n$$\n\n如果顺利的话，序列 $\\left(\\boldsymbol{x}_{n}\\right)$ 收敛到局部最小解 $\\boldsymbol{x}^{*}$ 。注意，每次迭代步长 $\\alpha$ 可以改变，但其取值必须合适，如果过大就不会收玫，如果过小则收敛速度太慢。\n\n梯度下降法的过程如图 C． 1 所示。曲线是等高线（水平集），即函数 $f$ 为不同常数的集合构成的曲线。红色的箭头指向该点梯度的反方向（梯度方向与通过该点的等高线垂直）。沿着梯度下降方向，将最终到达函数 $f$ 值的局部最小解。\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-419.jpg?height=508&width=619&top_left_y=132&top_left_x=342)\n\n图 C． 1 梯度下降法\n\n梯度下降法为一阶收敛算法，当靠近局部最小解时梯度变小，收玫速度会变慢，并且可能以＂之字形＂的方式下降。如果目标函数为二阶连续可微，我们可以采用牛顿法。牛顿法为二阶收玫算法，收玫速度更快，但是每次迭代需要计算 Hessian矩阵的逆矩阵，复杂度较高。\n\n相反，如果我们要求解一个最大值问题，就需要向梯度正方向迭代进行搜索，逐渐接近函数的局部最大解，这个过程则被称为梯度上升法（Gradient Ascent Method）．",
        "总结": "- 梯度下降法是一种用于求解无约束优化问题的算法，通过沿函数梯度的反方向迭代更新参数以寻找最小值。  \n- 梯度下降法在点 $ \\boldsymbol{x}_t $ 处的下降方向为梯度的反方向，即 $ -\\nabla f(\\boldsymbol{x}_t) $。  \n- 使用泰勒一阶展开公式近似函数变化，通过选择适当的步长 $ \\alpha $ 确保函数值递减。  \n- 迭代公式为 $ \\boldsymbol{x}_{t+1} = \\boldsymbol{x}_t - \\alpha_t \\nabla f(\\boldsymbol{x}_t) $，生成递减的函数值序列。  \n- 若步长选择合适，序列将收敛到局部最小解，但步长过大可能导致不收敛，过小则收敛速度慢。  \n- 梯度下降法为一阶收敛算法，在接近局部最小值时收敛速度变慢，并可能以“之字形”路径下降。  \n- 若目标函数为二阶连续可微，可使用牛顿法，其收敛速度更快但计算复杂度更高。  \n- 梯度上升法是梯度下降法的逆过程，用于求解最大值问题，沿梯度正方向迭代更新参数。"
      },
      {
        "段落": "## C． 3 拉格朗日乘数法与KKT条件\n\n拉格朗日乘数法（Lagrange Multiplier）是约束优化问题的一种有效求解方法。约束优化问题可以表示为\n\n以数学家约瑟夫•拉格朗日命名。\n\n$$\n\\begin{array}{ll}\n\\min _{\\boldsymbol{x}} & f(\\boldsymbol{x}) \\\\\n\\text { s.t. } & h_{m}(\\boldsymbol{x})=0, \\quad m=1, \\ldots, M  \\tag{C.10}\\\\\n& g_{n}(\\boldsymbol{x}) \\leq 0, \\quad n=1, \\ldots, N\n\\end{array}\n$$\n\n其中 $h_{m}(\\boldsymbol{x})$ 为等式约束函数，$g_{n}(\\boldsymbol{x})$ 为不等式约束函数． $\\boldsymbol{x}$ 的可行域为\n\n$$\n\\begin{equation*}\n\\mathcal{D}=\\operatorname{dom}(f) \\cap \\bigcap_{m=1}^{M} \\operatorname{dom}\\left(h_{m}\\right) \\cap \\bigcap_{n=1}^{N} \\operatorname{dom}\\left(g_{n}\\right) \\subseteq \\mathbb{R}^{D} \\tag{C.11}\n\\end{equation*}\n$$\n\n其中 $\\operatorname{dom}(f)$ 是函数 $f$ 的定义域．",
        "总结": "- 拉格朗日乘数法用于解决约束优化问题，通过引入乘数将约束条件与目标函数结合。  \n- 约束优化问题包括等式约束 $h_m(\\boldsymbol{x})=0$ 和不等式约束 $g_n(\\boldsymbol{x}) \\leq 0$。  \n- 可行域 $\\mathcal{D}$ 是目标函数和所有约束函数的定义域的交集。"
      },
      {
        "段落": "## C．3．1 等式约束优化问题\n\n如果公式（C．10）中只有等式约束，我们可以构造一个拉格朗日函数 $\\Lambda(\\boldsymbol{x}, \\lambda)$\n\n$$\n\\begin{equation*}\n\\Lambda(\\boldsymbol{x}, \\lambda)=f(\\boldsymbol{x})+\\sum_{m=1}^{M} \\lambda_{m} h_{m}(\\boldsymbol{x}) \\tag{C.12}\n\\end{equation*}\n$$\n\n其中 $\\lambda$ 为拉格朗日乘数，可以是正数或负数。如果 $f\\left(\\boldsymbol{x}^{*}\\right)$ 是原始约束优化问题的局部最优值，那么存在一个 $\\lambda^{*}$ 使得 $\\left(\\boldsymbol{x}^{*}, \\lambda^{*}\\right)$ 为拉格朗日函数 $\\Lambda(\\boldsymbol{x}, \\lambda)$ 的驻点。因此，只需要令 $\\frac{\\partial \\Lambda(x, \\lambda)}{\\partial x}=0$ 和 $\\frac{\\partial \\Lambda(x, \\lambda)}{\\partial \\lambda}=0$ ，得到\n\n$$\n\\begin{align*}\n& \\nabla f(\\boldsymbol{x})+\\sum_{m=1}^{M} \\lambda_{m} \\nabla h_{m}(\\boldsymbol{x})=0  \\tag{C.13}\\\\\n& h_{m}(\\boldsymbol{x})=0, \\quad \\forall m=1, \\cdots, M \\tag{C.14}\n\\end{align*}\n$$\n\n上面方程组的解即为原始问题的可能解。因为驻点不一定是最小解，所以在实际应用中需根据具体问题来验证是否为最小解．\n\n拉格朗日乘数法是将一个有 $D$ 个变量和 $M$ 个等式约束条件的最优化问题转换为一个有 $D+M$ 个变量的函数求平稳点的问题。拉格朗日乘数法所得的驻点会包含原问题的所有最小解，但并不保证每个驻点都是原问题的最小解．",
        "总结": "- 拉格朗日函数的构造：通过引入拉格朗日乘数，将等式约束优化问题转化为无约束优化问题，构造拉格朗日函数 $\\Lambda(\\boldsymbol{x}, \\lambda)=f(\\boldsymbol{x})+\\sum_{m=1}^{M} \\lambda_{m} h_{m}(\\boldsymbol{x})$。  \n- 驻点条件：最优解 $\\boldsymbol{x}^*$ 和对应的拉格朗日乘数 $\\lambda^*$ 满足 $\\nabla f(\\boldsymbol{x})+\\sum_{m=1}^{M} \\lambda_{m} \\nabla h_{m}(\\boldsymbol{x})=0$ 以及 $h_{m}(\\boldsymbol{x})=0$。  \n- 解的性质：驻点可能是原问题的最小解，但不一定保证是最小解，需结合具体问题验证。  \n- 拉格朗日乘数法的作用：将有 $D$ 个变量和 $M$ 个等式约束的问题转化为 $D+M$ 个变量的函数求平稳点的问题。  \n- 解的完备性：拉格朗日乘数法所得的驻点包含原问题的所有最小解，但不保证每个驻点都是最小解。"
      },
      {
        "段落": "## C．3．2 不等式约束优化问题\n\n对于公式（C．10）中定义的一般约束优化问题，其拉格朗日函数为\n\n$$\n\\begin{equation*}\n\\Lambda(\\boldsymbol{x}, \\boldsymbol{a}, \\boldsymbol{b})=f(\\boldsymbol{x})+\\sum_{m=1}^{M} a_{m} h_{m}(\\boldsymbol{x})+\\sum_{j=1}^{n} b_{n} g_{n}(\\boldsymbol{x}), \\tag{C.15}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{a}=\\left[a_{1}, \\cdots, a_{M}\\right]^{\\top}$ 为等式约束的拉格朗日乘数， $\\boldsymbol{b}=\\left[b_{1}, \\cdots, b_{N}\\right]^{\\top}$ 为不等式约束的拉格朗日乘数。\n\n当约束条件不满足时，有 $\\max _{\\boldsymbol{a}, \\boldsymbol{b}} \\Lambda(\\boldsymbol{x}, \\boldsymbol{a}, \\boldsymbol{b})=\\infty$ ；当约束条件满足时并且 $\\boldsymbol{b} \\geq 0$ 时， $\\max _{\\boldsymbol{a}, \\boldsymbol{b}} \\Lambda(\\boldsymbol{x}, \\boldsymbol{a}, \\boldsymbol{b})=f(\\boldsymbol{x})$ 。因此，原始约束优化问题等价于\n\n$$\n\\begin{align*}\n\\min _{\\boldsymbol{x}} \\max _{\\boldsymbol{a}, \\boldsymbol{b}} & \\Lambda(\\boldsymbol{x}, \\boldsymbol{a}, \\boldsymbol{b})  \\tag{C.16}\\\\\n\\text { s.t. } & \\boldsymbol{b} \\geq 0 \\tag{C.17}\n\\end{align*}\n$$\n\n这个 min－max 优化问题称为主问题（Primal Problem）。\n\n对偶问题 主问题的优化一般比较困难，我们可以通过交换 min－max 的顺序来简化．定义拉格朗日对偶函数为\n\n$$\n\\begin{equation*}\n\\Gamma(\\boldsymbol{a}, \\boldsymbol{b})=\\inf _{\\boldsymbol{x} \\in \\mathcal{D}} \\Lambda(\\boldsymbol{x}, \\boldsymbol{a}, \\boldsymbol{b}) \\tag{C.18}\n\\end{equation*}\n$$\n\n不等式约束优化问题中的拉格朗日乘数也称为 $K K T$ 乘数．\n$\\Gamma(\\boldsymbol{a}, \\boldsymbol{b})$ 是一个凹函数，即使 $f(\\boldsymbol{x})$ 是非凸的．\n当 $\\boldsymbol{b} \\geq 0$ 时，对于任意的 $\\tilde{\\boldsymbol{x}} \\in \\mathcal{D}$ ，有\n\n$$\n\\begin{equation*}\n\\Gamma(\\boldsymbol{a}, \\boldsymbol{b})=\\inf _{\\boldsymbol{x} \\in \\mathcal{D}} \\Lambda(\\boldsymbol{x}, \\boldsymbol{a}, \\boldsymbol{b}) \\leq \\Lambda(\\tilde{\\boldsymbol{x}}, \\boldsymbol{a}, \\boldsymbol{b}) \\leq f(\\tilde{\\boldsymbol{x}}) \\tag{C.19}\n\\end{equation*}\n$$\n\n令 $\\boldsymbol{p}^{*}$ 是原问题的最优值，则有\n\n$$\n\\begin{equation*}\n\\Gamma(\\boldsymbol{a}, \\boldsymbol{b}) \\leq \\boldsymbol{p}^{*} \\tag{C.20}\n\\end{equation*}\n$$\n\n即拉格朗日对偶函数 $\\Gamma(\\boldsymbol{a}, \\boldsymbol{b})$ 为原问题最优值的下界．\n优化拉格朗日对偶函数 $\\Gamma(\\boldsymbol{a}, \\boldsymbol{b})$ 并得到原问题的最优下界，称为拉格朗日对偶问题（Lagrange Dual Problem）．\n\n$$\n\\begin{array}{cl}\n\\max _{\\boldsymbol{a}, \\boldsymbol{b}} & \\Gamma(\\boldsymbol{a}, \\boldsymbol{b}) \\\\\n\\text { s.t. } & \\boldsymbol{b} \\geq 0 \\tag{C.22}\n\\end{array}\n$$\n\n拉格朗日对偶函数为凹函数，因此拉格朗日对偶问题为凸优化问题．\n令 $\\boldsymbol{d}^{*}$ 表示拉格朗日对偶问题的最优值，则有 $\\boldsymbol{d}^{*} \\leq \\boldsymbol{p}^{*}$ ，这个性质称为弱对偶性（Weak Duality）。如果 $\\boldsymbol{d}^{*}=\\boldsymbol{p}^{*}$ ，这个性质称为强对偶性（Strong Duality）。\n\n当强对偶性成立时，令 $\\boldsymbol{x}^{*}$ 和 $\\boldsymbol{a}^{*}, \\boldsymbol{b}^{*}$ 分别是原问题和对偶问题的最优解，那么它们满足以下条件：\n\n$$\n\\begin{align*}\n\\nabla f\\left(\\boldsymbol{x}^{*}\\right) & +\\sum_{m=1}^{M} a_{m}^{*} \\nabla h_{m}\\left(\\boldsymbol{x}^{*}\\right)+\\sum_{n=1}^{N} b_{n}^{*} \\nabla g_{n}\\left(\\boldsymbol{x}^{*}\\right)=0  \\tag{C.23}\\\\\nh_{m}\\left(\\boldsymbol{x}^{*}\\right) & =0, \\quad m=1, \\cdots, M  \\tag{C.24}\\\\\ng_{n}\\left(\\boldsymbol{x}^{*}\\right) & \\leq 0, \\quad n=1, \\cdots, N  \\tag{C.25}\\\\\nb_{n}^{*} g_{n}\\left(\\boldsymbol{x}^{*}\\right) & =0, \\quad n=1, \\cdots, N  \\tag{C.26}\\\\\nb_{n}^{*} & \\geq 0, \\quad n=1, \\cdots, N \\tag{С.27}\n\\end{align*}\n$$\n\n这 5 个条件称为不等式约束优化问题的 $K K T$ 条件（Karush－Kuhn－Tucker Condi－ tion）。KKT条件是拉格朗日乘数法在不等式约束优化问题上的泛化。当原问题是凸优化问题时，满足 KKT 条件的解也是原问题和对偶问题的最优解．\n\n在 KKT 条件中，需要关注的是公式（C．26），称为互补松弛（Complementary Slackness）条件。如果最优解 $\\boldsymbol{x}^{*}$ 出现在不等式约束的边界上 $g_{n}(\\boldsymbol{x})=0$ ，则 $b_{n}^{*}>$ 0 ；如果最优解 $\\boldsymbol{x}^{*}$ 出现在不等式约束的内部 $g_{n}(\\boldsymbol{x})<0$ ，则 $b_{n}^{*}=0$ ．互补松弛条件说明当最优解出现在不等式约束的内部，则约束失效．",
        "总结": "- 拉格朗日函数定义：引入拉格朗日乘数 $\\boldsymbol{a}$ 和 $\\boldsymbol{b}$，构造拉格朗日函数 $\\Lambda(\\boldsymbol{x}, \\boldsymbol{a}, \\boldsymbol{b})$，用于处理等式和不等式约束优化问题。  \n- 主问题（Primal Problem）：原问题等价于在满足约束条件 $\\boldsymbol{b} \\geq 0$ 的前提下，最小化关于 $\\boldsymbol{x}$ 的最大值问题。  \n- 对偶问题：通过交换 min-max 顺序，定义拉格朗日对偶函数 $\\Gamma(\\boldsymbol{a}, \\boldsymbol{b})$，并将其最大化作为对偶问题。  \n- $KKT$ 乘数：不等式约束的拉格朗日乘数称为 $KKT$ 乘数。  \n- 拉格朗日对偶函数性质：$\\Gamma(\\boldsymbol{a}, \\boldsymbol{b})$ 是凹函数，即使原目标函数 $f(\\boldsymbol{x})$ 非凸。  \n- 弱对偶性：对偶问题最优值 $\\boldsymbol{d}^{*}$ 是原问题最优值 $\\boldsymbol{p}^{*}$ 的下界。  \n- 强对偶性：当 $\\boldsymbol{d}^{*} = \\boldsymbol{p}^{*}$ 时，称强对偶性成立。  \n- $KKT$ 条件：当强对偶性成立时，原问题和对偶问题的最优解满足梯度条件、约束条件、互补松弛条件等五个条件。  \n- 互补松弛条件：若最优解位于不等式约束边界，则对应的 $KKT$ 乘数大于零；若位于内部，则乘数为零。"
      },
      {
        "段落": "## 附录D 概率论\n\n概率论主要研究大量随机现象中的数量规律，其应用十分广泛，几乎遍及各个领域。",
        "总结": "- 概率论主要研究大量随机现象中的数量规律  \n- 概率论的应用范围非常广泛，几乎涉及各个领域"
      },
      {
        "段落": "## D． 1 样本空间\n\n样本空间是一个随机试验所有可能结果的集合。例如，如果抛掷一枚硬币，那么样本空间就是集合 \\｛正面，反面\\}。如果投掷一个骰子, 那么样本空间就是 $\\{1,2,3,4,5,6\\}$ ．随机试验中的每个可能结果称为样本点．\n\n有些试验有两个或多个可能的样本空间．例如，从 52 张扑克牌中随机抽出一张，样本空间可以是数字（A到K），也可以是花色（黑桃，红桃，梅花，方块）。如果要完整地描述一张牌，就需要同时给出数字和花色，这时样本空间可以通过构建上述两个样本空间的笛卡儿乘积来得到。",
        "总结": "- 样本空间是随机试验所有可能结果的集合  \n- 每个可能的结果称为样本点  \n- 一个试验可能有多个样本空间，例如扑克牌的数字和花色  \n- 若需完整描述结果，可使用两个样本空间的笛卡儿乘积构建新的样本空间"
      },
      {
        "段落": "## 数学小知识 1 笛卡儿乘积\n\n在数学中，两个集合 $x$ 和 $y$ 的笛卡儿乘积（Cartesian product），又称直积，在集合论中表示为 $x \\times y$ ，是所有可能的有序对组成的集合，其中有序对的第一个对象是 $x$ 中的元素，第二个对象是 $y$ 中的元素。\n\n$$\nx \\times y=\\{\\langle x, y\\rangle \\mid x \\in X \\wedge y \\in Y\\} .\n$$\n\n比如在扑克牌的例子中，如果集合 $\\mathcal{X}$ 是 13 个元素的点数集合 $\\{\\mathrm{A}, \\mathrm{K}, \\mathrm{Q}, \\mathrm{J}$ ， $10,9,8,7,6,5,4,3,2\\}$ ，而集合 $y$ 是 4 个元素的花色集合 $\\{\\boldsymbol{\\varphi}, \\boldsymbol{\\vartheta}, \\boldsymbol{\\varphi}, \\boldsymbol{\\varphi}\\}$ ，则这两个集合的笛卡儿积是有 52 个元素的标准扑克牌的集合 $\\{(\\mathrm{A}, \\boldsymbol{\\varphi}),(\\mathrm{K}, \\boldsymbol{\\varphi})$ ， $\\ldots,(2, \\boldsymbol{\\varphi}),(\\mathrm{A}, \\boldsymbol{\\varphi}), \\ldots,(3, \\boldsymbol{\\varphi}),(2, \\boldsymbol{\\varphi})\\}$ ．",
        "总结": "- 笛卡儿乘积是两个集合的所有可能有序对组成的集合，表示为 $x \\times y$。\n- 笛卡儿乘积的定义是：$x \\times y = \\{\\langle x, y\\rangle \\mid x \\in X \\wedge y \\in Y\\}$。\n- 举例说明了扑克牌中点数集合与花色集合的笛卡儿积，结果是标准扑克牌的集合，共有52个元素。"
      },
      {
        "段落": "## D． 2 事件和概率\n\n随机事件（或简称事件）指的是一个被赋予概率的事物集合，也就是样本空间中的一个子集．概率（Probability）表示一个随机事件发生的可能性大小，为 0到 1 之间的实数．比如，一个 0.5 的概率表示一个事件有 $50 \\%$ 的可能性发生．\n\n对于一个机会均等的抛硬币动作来说，其样本空间为＂正面＂或＂反面＂．我们可以定义各个随机事件，并计算其概率。比如，\n（1）\\｛正面\\}, 其概率为 0.5 ；\n（2）\\｛反面\\}, 其概率为 0.5 ；\n（3）空集 $\\varnothing$ ，不是正面也不是反面，其概率为 0 ；\n（4）\\｛正面｜反面\\}, 不是正面就是反面, 其概率为 1 ．",
        "总结": "- 随机事件是指样本空间中的一个子集，表示被赋予概率的事物集合  \n- 概率是描述随机事件发生可能性的数值，范围在 0 到 1 之间  \n- 0 表示事件不可能发生，1 表示事件必然发生  \n- 举例说明了抛硬币实验中的不同随机事件及其对应概率：正面（0.5）、反面（0.5）、空集（0）、全集（1）"
      },
      {
        "段落": "## D．2．1 随机变量\n\n在随机试验中，试验的结果可以用一个数 $X$ 来表示，这个数 $X$ 是随着试验结果的不同而变化的，是样本点的一个函数。我们把这种数称为随机变量（Ran－ dom Variable）。例如，随机掷一个骰子，得到的点数就可以看成一个随机变量 $X, X$ 的取值为 $\\{1,2,3,4,5,6\\}$ ．\n\n如果随机掷两个骰子，整个事件空间 $\\Omega$ 可以由 36 个元素组成：\n\n$$\n\\begin{equation*}\n\\Omega=\\{(i, j) \\mid i=1, \\ldots, 6 ; j=1, \\ldots, 6\\} \\tag{D.1}\n\\end{equation*}\n$$\n\n一个随机事件也可以定义多个随机变量。比如在掷两个骰子的随机事件中，可以定义随机变量 $X$ 为获得的两个骰子的点数和，也可以定义随机变量 $Y$ 为获得的两个骰子的点数差。随机变量 $X$ 可以有 11 个整数值，而随机变量 $Y$ 只有 6 个整数值．\n\n$$\n\\begin{align*}\nX(i, j) & :=i+j, \\quad x=2,3, \\ldots, 12,  \\tag{D.2}\\\\\nY(i, j) & :=|i-j|, \\quad y=0,1,2,3,4,5 . \\tag{D.3}\n\\end{align*}\n$$\n\n其中 $i, j$ 分别为两个骰子的点数．",
        "总结": "- 随机变量的概念：随机变量是样本点的函数，用于表示随机试验的结果，其值会随着试验结果的不同而变化。  \n- 随机变量的示例：掷一个骰子时，点数可以视为一个随机变量，其取值为 {1, 2, 3, 4, 5, 6}。  \n- 事件空间与随机变量：掷两个骰子时，事件空间由 36 个元素组成，每个元素表示两个骰子的点数组合。  \n- 多个随机变量的定义：在掷两个骰子的事件中，可以定义多个随机变量，如点数和 $X$ 和点数差 $Y$。  \n- 随机变量的取值范围：$X$ 的取值为 {2, 3, ..., 12}，共 11 个整数值；$Y$ 的取值为 {0, 1, 2, 3, 4, 5}，共 6 个整数值。  \n- 随机变量的定义方式：$X(i, j) = i + j$，$Y(i, j) = |i - j|$，其中 $i$ 和 $j$ 分别为两个骰子的点数。"
      },
      {
        "段落": "## D．2．1．1 离散随机变量\n\n如果随机变量 $X$ 所可能取的值为有限可列举的，有 $N$ 个有限取值\n\n$$\n\\left\\{x_{1}, \\cdots, x_{N}\\right\\}\n$$\n\n则称 $X$ 为离散随机变量．\n要了解 $X$ 的统计规律，就必须知道它取每种可能值 $x_{n}$ 的概率，即\n\n$$\n\\begin{equation*}\nP\\left(X=x_{n}\\right)=p\\left(x_{n}\\right), \\quad \\forall n \\in\\{1, \\cdots, N\\} \\tag{D.4}\n\\end{equation*}\n$$\n\n一般用大写的字母表示一个随机变量，用小字字母表示该变量的某一个具体的取值。\n\n其中 $p\\left(x_{1}\\right), \\cdots, p\\left(x_{N}\\right)$ 称为离散随机变量 $X$ 的概率分布（Probability Distribution）或分布，并且满足\n\n$$\n\\begin{align*}\n& \\sum_{n=1}^{N} p\\left(x_{n}\\right)=1,  \\tag{D.5}\\\\\n& \\quad p\\left(x_{n}\\right) \\geq 0, \\quad \\forall n \\in\\{1, \\cdots, N\\} . \\tag{D.6}\n\\end{align*}\n$$\n\n常见的离散随机变量的概率分布有：\n伯努利分布 在一次试验中，事件 A 出现的概率为 $\\mu$ ，不出现的概率为 $1-\\mu$ 。若用变量 $X$ 表示事件 $\\boldsymbol{A}$ 出现的次数，则 $X$ 的取值为 0 和 1 ，其相应的分布为\n\n$$\n\\begin{equation*}\np(x)=\\mu^{x}(1-\\mu)^{(1-x)} \\tag{D.7}\n\\end{equation*}\n$$\n\n这个分布称为伯努利分布（Bernoulli Distribution），又名两点分布或者 0－1 分布。\n\n二项分布 在 n 次伯努利试验中，若以变量 $X$ 表示事件 A 出现的次数，则 $X$ 的取值为 $\\{0, \\cdots, N\\}$ ，其相应的分布为二项分布（Binomial Distribution）。\n\n$$\n\\begin{equation*}\nP(X=k)=\\binom{N}{k} \\mu^{k}(1-\\mu)^{N-k}, \\quad k=0 \\cdots, N \\tag{D.8}\n\\end{equation*}\n$$\n\n其中 $\\binom{N}{k}$ 为二项式系数，表示从 $N$ 个元素中取出 $k$ 个元素而不考虑其顺序的组合的总数．",
        "总结": "- 离散随机变量的定义：随机变量 $X$ 若可能取的值为有限可列举的 $N$ 个值，则称为离散随机变量。\n- 概率分布的定义：离散随机变量 $X$ 取每个可能值 $x_n$ 的概率 $p(x_n)$ 构成其概率分布，需满足两个条件：所有概率之和为 1，且每个概率非负。\n- 伯努利分布：在一次试验中，事件 A 出现的概率为 $\\mu$，其对应的随机变量 $X$ 取值为 0 或 1，概率分布为 $p(x) = \\mu^x(1-\\mu)^{1-x}$。\n- 二项分布：在 $n$ 次独立伯努利试验中，事件 A 出现次数 $X$ 的分布为二项分布，其概率公式为 $P(X=k) = \\binom{n}{k} \\mu^k(1-\\mu)^{n-k}$。"
      },
      {
        "段落": "## D．2．1．2 连续随机变量\n\n与离散随机变量不同，一些随机变量 $X$ 的取值是不可列举的，由全部实数或者由一部分区间组成，比如\n\n$$\nX=\\{x \\mid a \\leq x \\leq b\\}, \\quad-\\infty<a<b<\\infty\n$$\n\n则称 $X$ 为连续随机变量．连续随机变量的值是不可数及无穷尽的．\n对于连续随机变量 $X$ ，它取一个具体值 $x_{i}$ 的概率为 0 ，这和离散随机变量截然不同．因此用列举连续随机变量取某个值的概率来描述这种随机变量不但做不到，也毫无意义。\n\n连续随机变量 $X$ 的概率分布一般用概率密度函数（Probability Density Func－ tion， PDF$) ~ p(x)$ 来描述．$p(x)$ 为可积函数，并满足\n\n$$\n\\begin{equation*}\n\\int_{-\\infty}^{+\\infty} p(x) \\mathrm{d} x=1 \\tag{D.9}\n\\end{equation*}\n$$\n\n＂二项分布＂名称的来源是由于其定义形式为二项式 $(p+q)^{N}$ 的展示式中的第 $k$ 项．",
        "总结": "- 连续随机变量的定义：取值为不可数且无穷尽的实数区间，如 $X=\\{x \\mid a \\leq x \\leq b\\}$。\n- 连续随机变量的概率特性：取任一具体值的概率为 0，与离散随机变量不同。\n- 概率密度函数（PDF）：用于描述连续随机变量的概率分布，记作 $p(x)$。\n- PDF 的性质：$p(x)$ 是可积函数，且满足 $\\int_{-\\infty}^{+\\infty} p(x) \\mathrm{d} x=1$。"
      },
      {
        "段落": "## 数学小知识｜排列组合\n\n排列组合是组合学最基本的概念。\n排列是指从给定个数的元素中取出指定个数的元素进行排序。 $N$ 个不同的元素可以有 $N!$ 种不同的排列方式，即 $N$ 的阶乘。\n\n$$\nN!\\triangleq N \\times(N-1) \\times \\cdots \\times 3 \\times 2 \\times 1 .\n$$\n\n如果从 $N$ 个元素中取出 $k$ 个元素，这 $k$ 个元素的排列总数为\n\n$$\nP_{N}^{k} \\triangleq N \\times(N-1) \\times \\cdots \\times(N-k+1)=\\frac{N!}{(N-k)!}\n$$\n\n组合则是指从给定个数的元素中仅仅取出指定个数的元素，不考虑排序。从 $N$ 个元素中取出 $k$ 个元素，这 $k$ 个元素可能出现的组合数为\n\n$$\nC_{N}^{k} \\triangleq\\binom{N}{k}=\\frac{P_{N}^{k}}{k!}=\\frac{N!}{k!(N-k)!}\n$$\n\n$$\n\\begin{equation*}\np(x) \\geq 0 . \\tag{D.10}\n\\end{equation*}\n$$\n\n给定概率密度函数 $p(x)$ ，便可以计算出随机变量落入某一个区域的概率．令 $\\mathcal{R}$ 表示 $x$ 的非常小的邻近区域，$|\\mathcal{R}|$ 表示 $\\mathcal{R}$ 的大小，则 $p(x)|\\mathcal{R}|$ 可以反映随机变量处于区域 $\\mathcal{R}$ 的概率大小。\n\n常见的连续随机变量的概率分布有：\n均匀分布 若 $a, b$ 为有限数，$[a, b]$ 上的均匀分布（Uniform Distribution）的概率密度函数定义为\n\n$$\np(x)=\\left\\{\\begin{array}{cll}\n\\frac{1}{b-a} & , & a \\leq x \\leq b  \\tag{D.11}\\\\\n0 & , & x<a \\text { 或 } x>b\n\\end{array}\\right.\n$$\n\n正态分布 正态分布（Normal Distribution），又名高斯分布（Gaussian Distribu－ tion），是自然界最常见的一种分布，并且具有很多良好的性质，在很多领域都有非常重要的影响力，其概率密度函数为\n\n$$\n\\begin{equation*}\np(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right), \\tag{D.12}\n\\end{equation*}\n$$\n\n其中 $\\sigma>0, \\mu$ 和 $\\sigma$ 均为常数。若随机变量 $X$ 服从一个参数为 $\\mu$ 和 $\\sigma$ 的概率分布，简记为\n\n$$\n\\begin{equation*}\nX \\sim \\mathcal{N}\\left(\\mu, \\sigma^{2}\\right) . \\tag{D.13}\n\\end{equation*}\n$$\n\n当 $\\mu=0, \\sigma=1$ 时，称为标准正态分布（Standard Normal Distribution）。\n图D． 1 a 和D． 1 b 分别显示了均匀分布和正态分布的概率密度函数．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-426.jpg?height=378&width=819&top_left_y=282&top_left_x=248)\n\n图 D． 1 连续随机变量的密度函数",
        "总结": "- 排列是指从N个不同元素中取出k个元素进行排序，其总数为P_N^k = N!/(N-k)!  \n- 组合是指从N个不同元素中取出k个元素不考虑顺序，其总数为C_N^k = N!/(k!(N-k)!)  \n- 均匀分布的概率密度函数在区间[a, b]上为1/(b-a)，其他区域为0  \n- 正态分布的概率密度函数为p(x) = 1/(σ√(2π)) * exp(-(x-μ)^2/(2σ²))，其中μ为均值，σ为标准差  \n- 随机变量X服从正态分布记为X ~ N(μ, σ²)，当μ=0, σ=1时称为标准正态分布  \n- 概率密度函数p(x)在区域R内的概率近似为p(x)|R|，其中|R|表示区域大小"
      },
      {
        "段落": "## D．2．1．3 累积分布函数\n\n对于一个随机变量 $X$ ，其累积分布函数（Cumulative Distribution Function， $\\mathrm{CDF}) ~$ 是随机变量 $X$ 的取值小于等于 $x$ 的概率。\n\n$$\n\\begin{equation*}\n\\operatorname{cdf}(x)=P(X \\leq x) \\tag{D.14}\n\\end{equation*}\n$$\n\n以连续随机变量 $X$ 为例，累积分布函数定义为\n\n$$\n\\begin{equation*}\n\\operatorname{cdf}(x)=\\int_{-\\infty}^{x} p(t) \\mathrm{d} t \\tag{D.15}\n\\end{equation*}\n$$\n\n其中 $p(x)$ 为概率密度函数．图D． 2 给出了标准正态分布的概率密度函数和累计分布函数．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-426.jpg?height=426&width=518&top_left_y=1475&top_left_x=399)\n\n图 D． 2 标准正态分布的概率密度函数和累计分布函数",
        "总结": "- 累积分布函数（CDF）定义为随机变量 $X$ 的取值小于等于 $x$ 的概率，即 $\\operatorname{cdf}(x) = P(X \\leq x)$。  \n- 对于连续随机变量 $X$，其累积分布函数由概率密度函数 $p(t)$ 在区间 $(-\\infty, x]$ 上的积分给出，即 $\\operatorname{cdf}(x) = \\int_{-\\infty}^{x} p(t) \\, \\mathrm{d}t$。  \n- 图D．2展示了标准正态分布的概率密度函数和累积分布函数的图像。"
      },
      {
        "段落": "## D．2．2 随机向量\n\n随机向量是指一组随机变量构成的向量。如果 $X_{1}, X_{2}, \\cdots, X_{K}$ 为 $K$ 个随机变量，那么称 $\\boldsymbol{X}=\\left[X_{1}, X_{2}, \\cdots, X_{K}\\right]$ 为一个 $K$ 维随机向量．一维随机向量称为随机变量。\n\n随机向量也分为离散随机向量和连续随机向量。",
        "总结": "- 随机向量是指由一组随机变量构成的向量，表示为 $\\boldsymbol{X} = [X_1, X_2, \\cdots, X_K]$，其中 $K$ 为随机变量的个数。\n- 一维随机向量即为随机变量。\n- 随机向量可分为离散随机向量和连续随机向量两种类型。"
      },
      {
        "段落": "## D．2．2．1 离散随机向量\n\n离散随机向量的联合概率分布（Joint Probability Distribution）为\n\n$$\nP\\left(X_{1}=x_{1}, X_{2}=x_{2}, \\cdots, X_{K}=x_{K}\\right)=p\\left(x_{1}, x_{2}, \\cdots, x_{K}\\right),\n$$\n\n其中 $x_{k} \\in \\Omega_{k}$ 为变量 $X_{k}$ 的取值，$\\Omega_{k}$ 为变量 $X_{k}$ 的样本空间．\n和离散随机变量类似，离散随机向量的概率分布满足\n\n$$\n\\begin{align*}\n& p\\left(x_{1}, x_{2}, \\cdots, x_{K}\\right) \\geq 0, \\quad \\forall x_{1} \\in \\Omega_{1}, x_{2} \\in \\Omega_{2}, \\cdots, x_{K} \\in \\Omega_{K}  \\tag{D.16}\\\\\n& \\sum_{x_{1} \\in \\Omega_{1}} \\sum_{x_{2} \\in \\Omega_{2}} \\cdots \\sum_{x_{K} \\in \\Omega_{K}} p\\left(x_{1}, x_{2}, \\cdots, x_{K}\\right)=1 \\tag{D.17}\n\\end{align*}\n$$\n\n多项分布 一个最常见的离散向量概率分布为多项分布（Multinomial Distribu－ tion）．多项分布是二项分布在随机向量的推广。假设一个袋子中装了很多球，总共有 $K$ 个不同的颜色。我们从袋子中取出 $N$ 个球。每次取出一个球时，就在袋子中放入一个同样颜色的球。这样保证同一颜色的球在不同试验中被取出的概率是相等的。令 $\\boldsymbol{X}$ 为一个 $K$ 维随机向量，每个元素 $X_{k}(k=1, \\cdots, K)$ 为取出的 $N$ 个球中颜色为 $k$ 的球的数量，则 $X$ 服从多项分布，其概率分布为\n\n$$\n\\begin{equation*}\np\\left(x_{1}, \\ldots, x_{K} \\mid \\mu\\right)=\\frac{N!}{x_{1}!\\cdots x_{K}!} \\mu_{1}^{x_{1}} \\cdots \\mu_{K}^{x_{K}} \\tag{D.18}\n\\end{equation*}\n$$\n\n其中 $\\mu=\\left[\\mu_{1}, \\cdots, \\mu_{K}\\right]^{\\top}$ 分别为每次抽取的球的颜色为 $1, \\cdots, K$ 的概率；$x_{1}, \\cdots, x_{K}$为非负整数，并且满足 $\\sum_{k=1}^{K} x_{k}=N$ 。\n\n多项分布的概率分布也可以用 gamma 函数表示：\n\n$$\n\\begin{equation*}\np\\left(x_{1}, \\cdots, x_{K} \\mid \\mu\\right)=\\frac{\\Gamma\\left(\\sum_{k} x_{k}+1\\right)}{\\prod_{k} \\Gamma\\left(x_{k}+1\\right)} \\prod_{k=1}^{K} \\mu_{k}^{x_{k}} \\tag{D.19}\n\\end{equation*}\n$$\n\n其中 $\\Gamma(z)=\\int_{0}^{\\infty} \\frac{t^{z-1}}{\\exp (t)} \\mathrm{d} t$ 为 gamma 函数。这种表示形式和狄利克雷分布类似，狄利克雷分布参见第 D．2．2．2节．而狄利克雷分布可以作为多项分布的共轭先验。",
        "总结": "- 离散随机向量的联合概率分布定义为 $P(X_1=x_1, X_2=x_2, \\cdots, X_K=x_K) = p(x_1, x_2, \\cdots, x_K)$，其中 $x_k \\in \\Omega_k$ 为变量 $X_k$ 的取值，$\\Omega_k$ 为变量 $X_k$ 的样本空间。  \n- 离散随机向量的概率分布满足两个条件：非负性（$p(x_1, x_2, \\cdots, x_K) \\geq 0$）和归一性（所有可能取值的概率和为1）。  \n- 多项分布是二项分布在随机向量上的推广，用于描述 $K$ 种不同颜色球在 $N$ 次抽取中的出现次数。  \n- 多项分布的概率分布公式为 $p(x_1, \\ldots, x_K \\mid \\mu) = \\frac{N!}{x_1! \\cdots x_K!} \\mu_1^{x_1} \\cdots \\mu_K^{x_K}$，其中 $\\mu_k$ 为每次抽取颜色 $k$ 的概率，且 $\\sum_{k=1}^{K} x_k = N$。  \n- 多项分布的概率分布也可用 gamma 函数表示，形式类似于狄利克雷分布，狄利克雷分布是多项分布的共轭先验。"
      },
      {
        "段落": "## D．2．2．2 连续随机向量\n\n一个 $K$ 维连续随机向量 $\\boldsymbol{X}$ 的联合概率密度函数（Joint Probability Density Function）满足\n\n$$\n\\begin{array}{r}\np(\\boldsymbol{x})=p\\left(x_{1}, \\cdots, x_{K}\\right) \\geq 0 \\\\\n\\int_{-\\infty}^{+\\infty} \\cdots \\int_{-\\infty}^{+\\infty} p\\left(x_{1}, \\cdots, x_{K}\\right) \\mathrm{d} x_{1} \\cdots \\mathrm{~d} x_{K}=1 \\tag{D.21}\n\\end{array}\n$$\n\n多元正态分布 最常用的连续随机向量分布为多元正态分布（Multivariate Nor－ mal Distribution），也称为多元高斯分布（Multivariate Gaussian Distribution） ．若 $K$ 维随机向量 $\\boldsymbol{X}=\\left[X_{1}, \\ldots, X_{K}\\right]^{\\top}$ 服从 $K$ 元正态分布，其密度函数为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x})=\\frac{1}{(2 \\pi)^{n / 2}|\\Sigma|^{1 / 2}} \\exp \\left(-\\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{\\mu})^{\\top} \\Sigma^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu})\\right) \\tag{D.22}\n\\end{equation*}\n$$\n\n其中 $\\mu \\in \\mathbb{R}^{K}$ 为多元正态分布的均值向量，$\\Sigma \\in \\mathbb{R}^{K \\times K}$ 为多元正态分布的协方差矩阵，$|\\Sigma|$ 表示 $\\Sigma$ 的行列式．\n\n各项同性高斯分布 如果一个多元高斯分布的协方差矩阵简化为 $\\boldsymbol{\\Sigma}=\\sigma^{2} \\boldsymbol{I}$ ，即每一个维随机变量都独立并且方差相同，那么这个多元高斯分布称为各项同性高斯分布（Isotropic Gaussian Distribution）。\n\n狄利克雷分布 一个 $K$ 维随机向量 $\\boldsymbol{X}$ 的狄利克雷分布（Dirichlet Distribution）为\n\n$$\n\\begin{equation*}\np(\\boldsymbol{x} \\mid \\boldsymbol{\\alpha})=\\frac{\\Gamma\\left(\\alpha_{0}\\right)}{\\Gamma\\left(\\alpha_{1}\\right) \\cdots \\Gamma\\left(\\alpha_{K}\\right)} \\prod_{k=1}^{K} x_{k}^{\\alpha_{k}-1}, \\tag{D.23}\n\\end{equation*}\n$$\n\n其中 $\\alpha=\\left[\\alpha_{1}, \\ldots, \\alpha_{K}\\right]^{\\top}$ 为狄利克雷分布的参数．",
        "总结": "- 连续随机向量的联合概率密度函数定义，满足非负性和积分等于1的条件。  \n- 多元正态分布的密度函数形式，包含均值向量和协方差矩阵，并涉及行列式运算。  \n- 各项同性高斯分布的定义，其协方差矩阵为标量乘以单位矩阵，表示各维度独立且方差相同。  \n- 狄利克雷分布的概率密度函数形式，参数为α向量，涉及伽马函数和各分量的幂次乘积。"
      },
      {
        "段落": "## D．2．3 边际分布\n\n对于二维离散随机向量 $(X, Y)$ ，假设 $X$ 取值空间为 $\\Omega_{x}, Y$ 取值空间为 $\\Omega_{y}$ ，其联合概率分布满足\n\n$$\n\\begin{equation*}\np(x, y) \\geq 0, \\quad \\sum_{x \\in \\Omega_{x}} \\sum_{y \\in \\Omega_{y}} p(x, y)=1 . \\tag{D.24}\n\\end{equation*}\n$$\n\n对于联合概率分布 $p(x, y)$ ，我们可以分别对 $x$ 和 $y$ 进行求和．\n（1）对于固定的 $x$ ，\n\n$$\n\\begin{equation*}\n\\sum_{y \\in \\Omega_{y}} p(x, y)=p(x) \\tag{D.25}\n\\end{equation*}\n$$\n\n不失一般性，这里以二维随机向量进行讨论，这些结论在多维时依然成立。\n（2）对于固定的 $y$ ，\n\n$$\n\\begin{equation*}\n\\sum_{x \\in \\Omega_{x}} p(x, y)=p(y) \\tag{D.26}\n\\end{equation*}\n$$\n\n由离散随机向量 $(X, Y)$ 的联合概率分布，对 $Y$ 的所有取值进行求和得到 $X$ 的概率分布；而对 $X$ 的所有取值进行求和得到 $Y$ 的概率分布．这里 $p(x)$ 和 $p(y)$ 就称为 $p(x, y)$ 的边际分布（Marginal Distribution）。\n\n对于二维连续随机向量 $(X, Y)$ ，其边际分布为\n\n$$\n\\begin{align*}\n& p(x)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} y  \\tag{D.27}\\\\\n& p(y)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} x \\tag{D.28}\n\\end{align*}\n$$\n\n一个二元正态分布的边际分布仍为正态分布．",
        "总结": "- 边际分布的概念：对于二维离散随机向量 $(X, Y)$，通过对其联合概率分布对另一个变量求和，得到单个变量的概率分布，称为边际分布。  \n- 离散情况下的边际分布公式：对固定 $x$，$\\sum_{y \\in \\Omega_y} p(x, y) = p(x)$；对固定 $y$，$\\sum_{x \\in \\Omega_x} p(x, y) = p(y)$。  \n- 连续情况下的边际分布公式：$p(x) = \\int_{-\\infty}^{+\\infty} p(x, y) \\, dy$，$p(y) = \\int_{-\\infty}^{+\\infty} p(x, y) \\, dx$。  \n- 二元正态分布的性质：其边际分布仍为正态分布。"
      },
      {
        "段落": "## D．2．4 条件概率分布\n\n对于离散随机向量 $(X, Y)$ ，已知 $X=x$ 的条件下，随机变量 $Y=y$ 的条件概率（Conditional Probability）为\n\n$$\n\\begin{equation*}\np(y \\mid x) \\triangleq P(Y=y \\mid X=x)=\\frac{p(x, y)}{p(x)} \\tag{D.29}\n\\end{equation*}\n$$\n\n这个公式定义了随机变量 $Y$ 关于随机变量 $X$ 的条件概率分布（Conditional Prob－ ability Distribution），简称条件分布。\n\n对于二维连续随机向量 $(X, Y)$ ，已知 $X=x$ 的条件下，随机变量 $Y=y$ 的条件概率密度函数（Conditional Probability Density Function）为\n\n$$\n\\begin{equation*}\np(y \\mid x)=\\frac{p(x, y)}{p(x)} . \\tag{D.30}\n\\end{equation*}\n$$\n\n同理，已知 $Y=y$ 的条件下，随机变量 $X=x$ 的条件概率密度函数为\n\n$$\n\\begin{equation*}\np(x \\mid y)=\\frac{p(x, y)}{p(y)} \\tag{D.31}\n\\end{equation*}\n$$",
        "总结": "- 条件概率分布定义了在已知一个随机变量取特定值的条件下，另一个随机变量的概率分布。  \n- 离散随机向量的条件概率公式为 $ p(y \\mid x) = \\frac{p(x, y)}{p(x)} $。  \n- 连续随机向量的条件概率密度函数公式为 $ p(y \\mid x) = \\frac{p(x, y)}{p(x)} $。  \n- 同样地，已知 $ Y=y $ 的条件下，$ X=x $ 的条件概率密度函数为 $ p(x \\mid y) = \\frac{p(x, y)}{p(y)} $。"
      },
      {
        "段落": "## D．2．5 贝叶斯定理\n\n通过公式（D．30）和（D．31），两个条件概率 $p(y \\mid x)$ 和 $p(x \\mid y)$ 之间的关系为\n\n$$\n\\begin{equation*}\np(y \\mid x)=\\frac{p(x \\mid y) p(y)}{p(x)} . \\tag{D.32}\n\\end{equation*}\n$$\n\n这个公式称为贝叶斯定理（Bayes’ Theorem），或贝叶斯公式。",
        "总结": "- 贝叶斯定理描述了两个条件概率 $p(y \\mid x)$ 和 $p(x \\mid y)$ 之间的关系。  \n- 公式为 $p(y \\mid x) = \\frac{p(x \\mid y) p(y)}{p(x)}$，即公式（D.32）。  \n- 该公式也被称为贝叶斯公式。"
      },
      {
        "段落": "## D．2．6 独立与条件独立\n\n对于两个离散（或连续）随机变量 $X$ 和 $Y$ ，如果其联合概率（或联合概率密度函数）$p(x, y)$ 满足\n\n$$\n\\begin{equation*}\np(x, y)=p(x) p(y) \\tag{D.33}\n\\end{equation*}\n$$\n\n则称 $X$ 和 $Y$ 互相独立（Independence），记为 $X \\Perp Y$ 。\n对于三个离散（或连续）随机变量 $X 、 Y$ 和 $Z$ ，如果条件概率（或联合概率密度函数）$p(x, y \\mid z)$ 满足\n\n$$\n\\begin{equation*}\np(x, y \\mid z)=p(x \\mid z) p(y \\mid z) \\tag{D.34}\n\\end{equation*}\n$$\n\n则称在给定变量 $Z$ 时，$X$ 和 $Y$ 条件独立（Conditional Independence），记为 $X \\Perp$ $Y \\mid Z$ ．",
        "总结": "- 独立性定义：两个随机变量 $X$ 和 $Y$ 若满足联合概率 $p(x, y) = p(x)p(y)$，则称它们相互独立，记为 $X \\Perp Y$。\n- 条件独立性定义：三个随机变量 $X$、$Y$ 和 $Z$ 若满足条件概率 $p(x, y \\mid z) = p(x \\mid z)p(y \\mid z)$，则称在给定 $Z$ 的条件下，$X$ 和 $Y$ 条件独立，记为 $X \\Perp Y \\mid Z$。"
      },
      {
        "段落": "## D．2．7 期望和方差\n\n期望 对于 $N$ 个取值的离散变量 $X$ ，其概率分布为 $p\\left(x_{1}\\right), \\cdots, p\\left(x_{N}\\right), X$ 的期望 （Expectation）定义为\n\n$$\n\\begin{equation*}\n\\mathbb{E}[X]=\\sum_{n=1}^{N} x_{n} p\\left(x_{n}\\right) \\tag{D.35}\n\\end{equation*}\n$$\n\n对于连续随机变量 $X$ ，概率密度函数为 $p(x)$ ，其期望定义为\n\n$$\n\\begin{equation*}\n\\mathbb{E}[X]=\\int_{\\mathbb{R}} x p(x) \\mathrm{d} x \\tag{D.36}\n\\end{equation*}\n$$\n\n方差 随机变量 $X$ 的方差（Variance）用来定义它的概率分布的离散程度，定义为\n\n$$\n\\begin{equation*}\n\\operatorname{var}(X)=\\mathbb{E}\\left[(X-\\mathbb{E}[X])^{2}\\right] \\tag{D.37}\n\\end{equation*}\n$$\n\n随机变量 $X$ 的方差也称为它的二阶矩．$\\sqrt{\\operatorname{var}(X)}$ 则称为 $X$ 的根方差或标准差。\n\n协方差 两个连续随机变量 $X$ 和 $Y$ 的协方差（Covariance）用来衡量两个随机变量的分布之间的总体变化性，定义为\n\n$$\n\\begin{equation*}\n\\operatorname{cov}(X, Y)=\\mathbb{E}[(X-\\mathbb{E}[X])(Y-\\mathbb{E}[Y])] \\tag{D.38}\n\\end{equation*}\n$$\n\n协方差经常也用来衡量两个随机变量之间的线性相关性。如果两个随机变量的协方差为 0 ，那么称这两个随机变量是线性不相关。两个随机变量之间没有线性相关性，并非表示它们之间是独立的，可能存在某种非线性的函数关系。反之，如果 $X$ 与 $Y$ 是统计独立的，那么它们之间的协方差一定为 0 ．\n\n这里的线性相关和线性代数中的线性相关含义不同。\n\n协方差矩阵 两个 $M$ 和 $N$ 维的连续随机向量 $\\boldsymbol{X}$ 和 $\\boldsymbol{Y}$ ，它们的协方差（Covariance）为 $M \\times N$ 的矩阵，定义为\n\n$$\n\\begin{equation*}\n\\operatorname{cov}(\\boldsymbol{X}, \\boldsymbol{Y})=\\mathbb{E}\\left[(\\boldsymbol{X}-\\mathbb{E}[\\boldsymbol{X}])(\\boldsymbol{Y}-\\mathbb{E}[\\boldsymbol{Y}])^{\\top}\\right] \\tag{D.39}\n\\end{equation*}\n$$\n\n协方差矩阵 $\\operatorname{cov}(\\boldsymbol{X}, \\boldsymbol{Y})$ 的第 $(m, n)$ 个元素等于随机变量 $X_{m}$ 和 $Y_{n}$ 的协方差．两个随机向量的协方差 $\\operatorname{cov}(\\boldsymbol{X}, \\boldsymbol{Y})$ 与 $\\operatorname{cov}(\\boldsymbol{Y}, \\boldsymbol{X})$ 互为转置关系．\n\n如果两个随机向量的协方差矩阵为对角阵，那么称这两个随机向量是无关的．\n\n单个随机向量 $\\boldsymbol{X}$ 的协方差矩阵定义为\n\n$$\n\\begin{equation*}\n\\operatorname{cov}(\\boldsymbol{X})=\\operatorname{cov}(\\boldsymbol{X}, \\boldsymbol{X}) \\tag{D.40}\n\\end{equation*}\n$$",
        "总结": "- 期望：定义了离散和连续随机变量的期望，分别用求和和积分形式表示。  \n- 方差：衡量随机变量概率分布的离散程度，也称为二阶矩，其平方根称为标准差。  \n- 协方差：衡量两个随机变量之间的总体变化性，若协方差为0，则称线性不相关，但不等同于独立。  \n- 协方差矩阵：描述两个随机向量之间各分量协方差的矩阵，其元素为对应分量的协方差，且与转置矩阵互为转置关系。  \n- 协方差矩阵为对角阵时，表示两个随机向量无关。  \n- 单个随机向量的协方差矩阵定义为其与自身的协方差。"
      },
      {
        "段落": "## D．2．7．1 Jensen 不等式\n\n如果 $X$ 是随机变量，$g$ 是凸函数，则\n\n$$\n\\begin{equation*}\ng(\\mathbb{E}[X]) \\leq \\mathbb{E}[g(X)] \\tag{D.41}\n\\end{equation*}\n$$\n\n等式当且仅当 $X$ 是一个常数或 $g$ 是线性时成立，这个性质称为Jensen不等式．\n特别地，对于凸函数 $g$ 定义域上的任意两点 $x_{1}, x_{2}$ ，以及一个标量 $\\lambda \\in[0,1]$ ，有\n\n$$\n\\begin{equation*}\ng\\left(\\lambda x_{1}+(1-\\lambda) x_{2}\\right) \\leq \\lambda g\\left(x_{1}\\right)+(1-\\lambda) g\\left(x_{2}\\right) \\tag{D.42}\n\\end{equation*}\n$$\n\n即凸函数 $g$ 上的任意两点的连线位于这两点之间函数曲线的上方．",
        "总结": "- Jensen不等式：若X是随机变量，g是凸函数，则g(E[X]) ≤ E[g(X)]，等式当且仅当X是常数或g是线性时成立。  \n- 凸函数的定义：对于凸函数g定义域上的任意两点x₁, x₂及标量λ ∈ [0,1]，有g(λx₁ + (1−λ)x₂) ≤ λg(x₁) + (1−λ)g(x₂)。  \n- 图形解释：凸函数g上的任意两点的连线位于这两点之间函数曲线的上方。"
      },
      {
        "段落": "## D．2．7．2 大数定律\n\n大数定律（Law of Large Numbers）是指 $N$ 个样本 $X_{1}, \\cdots, X_{N}$ 是独立同分布的，即 $\\mathbb{E}\\left[X_{1}\\right]=\\cdots=\\mathbb{E}\\left[X_{N}\\right]=\\mu$ ，那么其均值\n\n$$\n\\begin{equation*}\n\\bar{X}_{N}=\\frac{1}{N}\\left(X_{1}+\\cdots+X_{N}\\right) \\tag{D.43}\n\\end{equation*}\n$$\n\n收玫于期望值 $\\mu$ ，即\n\n$$\n\\begin{equation*}\n\\bar{X}_{N} \\rightarrow \\mu \\quad \\text { for } \\quad N \\rightarrow \\infty . \\tag{D.44}\n\\end{equation*}\n$$",
        "总结": "- 大数定律指出，独立同分布的样本均值会收敛于期望值。  \n- 样本均值定义为 $ \\bar{X}_{N} = \\frac{1}{N}(X_1 + \\cdots + X_N) $。  \n- 当样本数量 $ N $ 趋近于无穷大时，样本均值 $ \\bar{X}_{N} $ 收敛于期望值 $ \\mu $。"
      },
      {
        "段落": "## D． 3 随机过程\n\n随机过程（Stochastic Process）是一组随机变量 $X_{t}$ 的集合，其中 $t$ 属于一个索引（index）集合 $\\mathcal{T}$ 。索引集合 $\\mathcal{J}$ 可以定义在时间域或者空间域，但一般为时间\n\n域，以实数或正数表示．当 $t$ 为实数时，随机过程为连续随机过程；当 $t$ 为整数时，为离散随机过程。日常生活中的很多例子包括股票的波动、语音信号、身高的变化等都可以看作是随机过程。常见的和时间相关的随机过程模型包括伯努利过程、随机游走（Random Walk）、马尔可夫过程等。和空间相关的随机过程通常称为随机场（Random Field）。比如一张二维的图片，每个像素点（变量）通过空间的位置进行索引，这些像素就组成了一个随机过程。",
        "总结": "- 随机过程是一组随机变量 $X_t$ 的集合，其中 $t$ 属于索引集合 $\\mathcal{T}$。  \n- 索引集合 $\\mathcal{T}$ 通常定义在时间域或空间域，但一般为时间域，用实数或正数表示。  \n- 当 $t$ 为实数时，随机过程为连续随机过程；当 $t$ 为整数时，为离散随机过程。  \n- 随机过程的例子包括股票波动、语音信号、身高变化等。  \n- 常见的时间相关随机过程模型有伯努利过程、随机游走、马尔可夫过程等。  \n- 空间相关的随机过程称为随机场，例如二维图片中的像素点构成的随机过程。"
      },
      {
        "段落": "## D．3．1 马尔可夫过程\n\n马尔可夫性质 在随机过程中，马尔可夫性质（Markov Property）是指一个随机过程在给定现在状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态。以离散随机过程为例，假设随机变量 $X_{0}, X_{1}, \\cdots, X_{T}$ 构成一个随机过程．这些随机变量的所有可能取值的集合被称为状态空间（State Space）。如果 $X_{t+1}$ 对于过去状态的条件概率分布仅是 $X_{t}$ 的一个函数，则\n\n$$\n\\begin{equation*}\nP\\left(X_{t+1}=x_{t+1} \\mid X_{0: t}=x_{0: t}\\right)=P\\left(X_{t+1}=x_{t+1} \\mid X_{t}=x_{t}\\right) \\tag{D.45}\n\\end{equation*}\n$$\n\n其中 $X_{0: t}$ 表示变量集合 $X_{0}, X_{1}, \\cdots, X_{t}, x_{0: t}$ 为在状态空间中的状态序列。\n马尔可夫性质也可以描述为给定当前状态时，将来的状态与过去状态是条件独立的．",
        "总结": "- 马尔可夫性质：未来状态的条件概率分布仅依赖于当前状态，而非所有过去状态。  \n- 状态空间：随机过程所有可能取值的集合。  \n- 条件概率公式：$P(X_{t+1}=x_{t+1} \\mid X_{0:t}=x_{0:t}) = P(X_{t+1}=x_{t+1} \\mid X_{t}=x_{t})$。  \n- 条件独立性：给定当前状态时，未来状态与过去状态条件独立。"
      },
      {
        "段落": "## D．3．1．1 马尔可夫链\n\n离散时间的马尔可夫过程也称为马尔可夫链（Markov Chain）。如果一个马尔可夫链的条件概率\n\n$$\n\\begin{equation*}\nP\\left(X_{t+1}=s \\mid X_{t}=s^{\\prime}\\right)=m_{s s^{\\prime}}, \\tag{D.46}\n\\end{equation*}\n$$\n\n只和状态 $s$ 和 $s^{\\prime}$ 相关，和时间 $t$ 无关，则称为时间同质的马尔可夫链（Time－ Homogeneous Markov Chain），其中 $m_{S S^{\\prime}}$ 称为状态转移概率。如果状态空间大小 $K$ 是有限的，状态转移概率可以用一个矩阵 $\\boldsymbol{M} \\in \\mathbb{R}^{K \\times K}$ 表示，称为状态转移矩阵（Transition Matrix），其中元素 $m_{i j}$ 表示状态 $s_{i}$ 转移到状态 $s_{j}$ 的概率。\n\n平稳分布 假设状态空间大小为 $K$ ，向量 $\\pi=\\left[\\pi_{1}, \\cdots, \\pi_{K}\\right]^{\\top}$ 为状态空间中的一个分布，满足 $0 \\leq \\pi_{k} \\leq 1$ 和 $\\sum_{k=1}^{K} \\pi_{k}=1$ 。\n\n对于状态转移矩阵为 $\\boldsymbol{M}$ 的时间同质的马尔可夫链，如果存在一个分布 $\\boldsymbol{\\pi}$ 满足\n\n$$\n\\begin{equation*}\n\\pi=M \\pi, \\tag{D.47}\n\\end{equation*}\n$$\n\n即分布 $\\boldsymbol{\\pi}$ 就称为该马尔可夫链的平稳分布（Stationary Distribution）。根据特征向量的定义可知， $\\boldsymbol{\\pi}$ 为矩阵 $\\boldsymbol{M}$ 的（归一化）的对应特征值为 1 的特征向量。\n\n如果一个马尔可夫链的状态转移矩阵 $\\boldsymbol{M}$ 满足所有状态可遍历性以及非周期性，那么对于任意一个初始状态分布 $\\boldsymbol{\\pi}^{(0)}$ ，在经过一定时间的状态转移之后，都会收敛到平稳分布，即\n\n$$\n\\begin{equation*}\n\\boldsymbol{\\pi}=\\lim _{N \\rightarrow \\infty} \\boldsymbol{M}^{N} \\boldsymbol{\\pi}^{(0)} \\tag{D.48}\n\\end{equation*}\n$$\n\n定理 D． 1 －细致平稳条件（Detailed Balance Condition）：给定一个状态空间中的分布 $\\boldsymbol{\\pi} \\in[0,1]^{K}$ ，如果一个状态转移矩阵为 $\\boldsymbol{M} \\in \\mathbb{R}^{K \\times K}$ 的马尔科夫链满足\n\n$$\n\\begin{equation*}\n\\pi_{i} m_{i j}=\\pi_{j} m_{j i}, \\quad \\forall 1 \\leq i, j \\leq K \\tag{D.49}\n\\end{equation*}\n$$\n\n则该马尔可夫链经过一定时间的状态转移后一定会收玫到分布 $\\pi$ ．\n细致平稳条件只是马尔科夫链收玫的充分条件，不是必要条件。细致平稳条件保证了从状态 $i$ 转移到状态 $j$ 的数量和从状态 $j$ 转移到状态 $i$ 的数量相一致，互相抵消，所以数量不发生改变．",
        "总结": "- 马尔可夫链：离散时间的马尔可夫过程，其条件概率仅依赖于当前状态和下一个状态，与时间无关，称为时间同质的马尔可夫链。  \n- 状态转移概率：表示从状态 $s$ 转移到状态 $s'$ 的概率，记为 $m_{ss'}$。  \n- 状态转移矩阵：当状态空间有限时，用矩阵 $\\boldsymbol{M} \\in \\mathbb{R}^{K \\times K}$ 表示状态转移概率，其中元素 $m_{ij}$ 表示从状态 $s_i$ 转移到 $s_j$ 的概率。  \n- 平稳分布：满足 $\\pi = M\\pi$ 的分布 $\\boldsymbol{\\pi}$，即为马尔可夫链的平稳分布，是矩阵 $\\boldsymbol{M}$ 的归一化特征值为 1 的特征向量。  \n- 收敛性：若马尔可夫链满足所有状态可遍历且非周期，则无论初始分布如何，经过足够多步后会收敛到平稳分布。  \n- 细致平稳条件：若满足 $\\pi_i m_{ij} = \\pi_j m_{ji}$，则马尔可夫链会收敛到分布 $\\pi$。该条件是收敛的充分而非必要条件。"
      },
      {
        "段落": "## D．3．2 高斯过程\n\n高斯过程（Gaussian Process）也是一种应用广泛的随机过程模型。假设有一组连续随机变量 $X_{0}, X_{1}, \\cdots, X_{T}$ ，如果由这组随机变量构成的任一有限集合\n\n$$\nX_{t_{1}, \\cdots, t_{N}}=\\left[X_{t_{1}}, \\cdots, X_{t_{N}}\\right]^{\\top}, \\quad 1 \\leq N \\leq T\n$$\n\n都服从一个多元正态分布，那么这组随机变量为一个随机过程。高斯过程也可以定义为：如果 $X_{t_{1}, \\cdots, t_{N}}$ 的任一线性组合都服从一元正态分布，那么这组随机变量为一个随机过程。\n\n高斯过程回归 高斯过程回归（Gaussian Process Regression）是利用高斯过程来对一个函数分布进行建模．和机器学习中参数化建模（比如贝叶斯线性回归）相比，高斯过程是一种非参数模型，可以拟合一个黑盒函数，并给出拟合结果的置信度［Rasmussen，2003］．\n\n假设一个未知函数 $f(\\boldsymbol{x})$ 服从高斯过程，且为平滑函数。如果两个样本 $\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}$比较接近，那么对应的 $f\\left(\\boldsymbol{x}_{1}\\right), f\\left(\\boldsymbol{x}_{2}\\right)$ 也比较接近。假设从函数 $f(\\boldsymbol{x})$ 中采样有限个样本 $\\boldsymbol{X}=\\left[\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, \\cdots, \\boldsymbol{x}_{N}\\right]$ ，这 $N$ 个点服从一个多元正态分布，\n\n$$\n\\begin{equation*}\n\\left[f\\left(\\boldsymbol{x}_{1}\\right), f\\left(\\boldsymbol{x}_{2}\\right), \\cdots, f\\left(\\boldsymbol{x}_{N}\\right)\\right]^{\\top} \\sim \\mathcal{N}(\\mu(X), K(X, X)), \\tag{D.50}\n\\end{equation*}\n$$\n\n其中 $\\boldsymbol{\\mu}(\\boldsymbol{X})=\\left[\\boldsymbol{\\mu}\\left(\\boldsymbol{x}_{1}\\right), \\boldsymbol{\\mu}\\left(\\boldsymbol{x}_{2}\\right), \\cdots, \\boldsymbol{\\mu}\\left(\\boldsymbol{x}_{N}\\right)\\right]^{\\top}$ 是均值向量， $\\boldsymbol{K}(\\boldsymbol{X}, \\boldsymbol{X})=\\left[k\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right)\\right]_{N \\times N}$ 是协方差矩阵，$k\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right)$ 为核函数，可以衡量两个样本的相似度。\n\n在高斯过程回归中，一个常用的核函数是平方指数（Squared Exponential）函数\n\n$$\n\\begin{equation*}\nk\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right)=\\exp \\left(\\frac{-\\left\\|\\boldsymbol{x}_{i}-\\boldsymbol{x}_{j}\\right\\|^{2}}{2 l^{2}}\\right), \\tag{D.51}\n\\end{equation*}\n$$\n\n其中 $l$ 为超参数。当 $\\boldsymbol{x}_{i}$ 和 $\\boldsymbol{x}_{j}$ 越接近，其核函数的值越大，表明 $f\\left(\\boldsymbol{x}_{i}\\right)$ 和 $f\\left(\\boldsymbol{x}_{j}\\right)$ 越相\n\n在支持向量机中，平方指数核函数也叫高斯核函数或径向基函数。这里为了避免混淆，我们称为平方指数核函数。关。\n\n假设 $f(\\boldsymbol{x})$ 的一组带噪声的观测值为 $\\left\\{\\left(\\boldsymbol{x}_{n}, y_{n}\\right)\\right\\}_{n=1}^{N}$ ，其中 $y_{n} \\sim \\mathcal{N}\\left(f\\left(\\boldsymbol{x}_{n}\\right), \\sigma^{2}\\right)$为 $f\\left(x_{n}\\right)$ 的观测值，服从正态分布，$\\sigma$ 为噪声方差。\n\n对于一个新的样本点 $\\boldsymbol{x}^{*}$ ，我们希望预测 $f\\left(\\boldsymbol{x}^{*}\\right)$ 的观测值 $y^{*}$ ．令向量 $\\boldsymbol{y}=$ $\\left[y_{1}, y_{2}, \\cdots, y_{N}\\right]^{\\top}$ 为已有的观测值，根据高斯过程的假设，$\\left[\\boldsymbol{y} ; y^{*}\\right]$ 满足\n\n$$\n\\left[\\begin{array}{c}\n\\boldsymbol{y}  \\tag{D.52}\\\\\ny^{*}\n\\end{array}\\right] \\sim \\mathcal{N}\\left(\\left[\\begin{array}{l}\n\\mu(\\boldsymbol{X}) \\\\\n\\mu\\left(\\boldsymbol{x}^{*}\\right)\n\\end{array}\\right],\\left[\\begin{array}{cc}\n\\boldsymbol{K}(\\boldsymbol{X}, \\boldsymbol{X})+\\sigma^{2} \\boldsymbol{I} & \\boldsymbol{K}\\left(\\boldsymbol{x}^{*}, \\boldsymbol{X}\\right)^{\\top} \\\\\n\\boldsymbol{K}\\left(\\boldsymbol{x}^{*}, \\boldsymbol{X}\\right) & k\\left(\\boldsymbol{x}^{*}, \\boldsymbol{x}^{*}\\right)\n\\end{array}\\right]\\right)\n$$\n\n其中 $\\boldsymbol{K}\\left(\\boldsymbol{x}^{*}, \\boldsymbol{X}\\right)=\\left[k\\left(\\boldsymbol{x}^{*}, \\boldsymbol{x}_{1}\\right), \\cdots, k\\left(\\boldsymbol{x}^{*}, \\boldsymbol{x}_{n}\\right)\\right]$ ．\n根据上面的联合分布，$y^{*}$ 的后验分布为\n\n$$\n\\begin{equation*}\np\\left(y^{*} \\mid \\boldsymbol{X}, \\boldsymbol{y}\\right)=\\mathcal{N}\\left(\\hat{\\boldsymbol{\\mu}}, \\hat{\\sigma}^{2}\\right) \\tag{D.53}\n\\end{equation*}\n$$\n\n其中均值 $\\hat{\\mu}$ 和方差 $\\hat{\\sigma}$ 为\n\n$$\n\\begin{align*}\n\\hat{\\mu} & =\\boldsymbol{K}\\left(\\boldsymbol{x}^{*}, \\boldsymbol{X}\\right)\\left(\\boldsymbol{K}(\\boldsymbol{X}, \\boldsymbol{X})+\\sigma^{2} \\boldsymbol{I}\\right)^{-1}(\\boldsymbol{y}-\\boldsymbol{\\mu}(\\boldsymbol{X}))+\\boldsymbol{\\mu}\\left(\\boldsymbol{x}^{*}\\right),  \\tag{D.54}\\\\\n\\hat{\\sigma}^{2} & =k\\left(\\boldsymbol{x}^{*}, \\boldsymbol{x}^{*}\\right)-\\boldsymbol{K}\\left(\\boldsymbol{x}^{*}, \\boldsymbol{X}\\right)\\left(\\boldsymbol{K}(\\boldsymbol{X}, \\boldsymbol{X})+\\sigma^{2} \\boldsymbol{I}\\right)^{-1} \\boldsymbol{K}\\left(\\boldsymbol{x}^{*}, \\boldsymbol{X}\\right)^{\\top} . \\tag{D.55}\n\\end{align*}\n$$\n\n从公式（D．54）可以看出，均值函数 $\\boldsymbol{\\mu}(\\boldsymbol{x})$ 可以近似地互相抵消．在实际应用中，一般假设 $\\mu(\\boldsymbol{x})=0$ ，均值 $\\hat{\\mu}$ 可以将简化为\n\n$$\n\\begin{equation*}\n\\hat{\\boldsymbol{\\mu}}=K\\left(\\boldsymbol{x}^{*}, \\boldsymbol{X}\\right)\\left(K(\\boldsymbol{X}, \\boldsymbol{X})+\\sigma^{2} \\boldsymbol{I}\\right)^{-1} \\boldsymbol{y} . \\tag{D.56}\n\\end{equation*}\n$$\n\n高斯过程回归可以认为是一种有效的贝叶斯优化方法，广泛地应用于机器学习中。",
        "总结": "- 高斯过程是一种随机过程模型，其任意有限集合服从多元正态分布  \n- 高斯过程回归是一种非参数建模方法，用于对函数分布进行建模  \n- 高斯过程回归假设未知函数 $f(\\boldsymbol{x})$ 服从高斯过程，且样本点的函数值服从多元正态分布  \n- 核函数用于衡量样本之间的相似度，常用的平方指数核函数为 $k(\\boldsymbol{x}_i, \\boldsymbol{x}_j) = \\exp\\left(-\\frac{\\|\\boldsymbol{x}_i - \\boldsymbol{x}_j\\|^2}{2l^2}\\right)$  \n- 噪声观测值 $y_n$ 服从 $\\mathcal{N}(f(\\boldsymbol{x}_n), \\sigma^2)$，其中 $\\sigma$ 为噪声方差  \n- 对于新样本点 $\\boldsymbol{x}^*$，预测其观测值 $y^*$ 的后验分布为正态分布 $\\mathcal{N}(\\hat{\\mu}, \\hat{\\sigma}^2)$  \n- 均值 $\\hat{\\mu}$ 和方差 $\\hat{\\sigma}^2$ 的计算公式分别由协方差矩阵和观测值决定  \n- 在实际应用中，通常假设均值函数 $\\mu(\\boldsymbol{x}) = 0$，简化计算  \n- 高斯过程回归可视为一种有效的贝叶斯优化方法，广泛应用于机器学习"
      },
      {
        "段落": "## 附录E 信息论\n\n信息论（Information Theory）是数学、物理、统计、计算机科学等多个学科的交叉领域。信息论是由 Claude Shannon 最早提出的，主要研究信息的量化、存储和通信等方法。这里，＂信息＂是指一组消息的集合。假设在一个噪声通道上发送消息，我们需要考虑如何对每一个信息进行编码、传输以及解码，使得接收者可以尽可能准确地重构出消息。\n\n在机器学习相关领域，信息论也有着大量的应用．比如特征抽取、统计推断、自然语言处理等。",
        "总结": "- 信息论是数学、物理、统计、计算机科学等多个学科的交叉领域  \n- 信息论由 Claude Shannon 提出，主要研究信息的量化、存储和通信方法  \n- 信息被定义为一组消息的集合  \n- 在噪声通道上发送消息时，需考虑信息的编码、传输与解码，以实现接收者准确重构消息  \n- 信息论在机器学习中有广泛应用，如特征抽取、统计推断和自然语言处理等"
      },
      {
        "段落": "## E． 1 熵\n\n熵（Entropy）最早是物理学的概念，用于表示一个热力学系统的无序程度。在信息论中，熵用来衡量一个随机事件的不确定性。",
        "总结": "- 熵（Entropy）最初是物理学中的概念，用于表示热力学系统的无序程度。  \n- 在信息论中，熵被用来衡量随机事件的不确定性。  \n- 本节介绍了熵的基本概念及其在信息论中的应用。"
      },
      {
        "段落": "## E．1．1 自信息和嫡\n\n自信息（Self Information）表示一个随机事件所包含的信息量。一个随机事件发生的概率越高，其自信息越低．如果一个事件必然发生，其自信息为 0 。\n\n对于一个随机变量 $X$（取值集合为 $\\mathcal{X}$ ，概率分布为 $p(x), x \\in \\mathcal{X}$ ），当 $X=x$时的自信息（Self Information）$I(x)$ 定义为\n\n$$\n\\begin{equation*}\nI(x)=-\\log p(x) . \\tag{E.1}\n\\end{equation*}\n$$\n\n在自信息的定义中，对数的底可以使用 2 、自然常数 $e$ 或是 10 。当底为 2 时，自信息的单位为 bit；当底为 $e$ 时，自信息的单位为 nat．\n\n对于分布为 $p(x)$ 的随机变量 $X$ ，其自信息的数学期望，即熵 $H(X)$ 定义为\n\n$$\n\\begin{align*}\nH(X) & =\\mathbb{E}_{X}[\\mathrm{I}(x)]  \\tag{E.2}\\\\\n& =\\mathbb{E}_{X}[-\\log p(x)]  \\tag{E.3}\\\\\n& =-\\sum_{x \\in \\mathcal{X}} p(x) \\log p(x), \\tag{E.4}\n\\end{align*}\n$$\n\n其中当 $p\\left(x_{i}\\right)=0$ 时，我们定义 $0 \\log 0=0$ ，这与极限一致， $\\lim _{p \\rightarrow 0+} p \\log p=0$ ．\n\nClaude Shannon（19－ 16～2001），美国数学家、电子工程师和密码学家，被誉为信息论的创始人．\n$H(X)$ 也 经 常 写 作 $H(p)$ ．\n\n熵越高，则随机变量的信息越多；熵越低，则随机变量的信息越少．如果变量 $X$ 当且仅当在 $x$ 时 $p(x)=1$ ，则熵为 0 。也就是说，对于一个确定的信息，其熵为 0 ，信息量也为 0 ．如果其概率分布为一个均匀分布，则熵最大．\n\n假设一个随机变量 $X$ 有三种可能值 $x_{1}, x_{2}, x_{3}$ ，不同概率分布对应的熵如下：\n\n| $p\\left(x_{1}\\right)$ | $p\\left(x_{2}\\right)$ | $p\\left(x_{3}\\right)$ | 熵 |\n| :---: | :---: | :---: | :---: |\n| 1 | 0 | 0 | 0 |\n| $\\frac{1}{2}$ | $\\frac{1}{4}$ | $\\frac{1}{4}$ | $\\frac{3}{2} \\log 2$ |\n| $\\frac{1}{3}$ | $\\frac{1}{3}$ | $\\frac{1}{3}$ | $\\log 3$ |",
        "总结": "- 自信息（Self Information）表示一个随机事件所包含的信息量，其定义为 $I(x) = -\\log p(x)$，单位取决于对数底数（bit、nat 或者其他）。\n- 自信息的数学期望即为熵 $H(X)$，定义为 $H(X) = -\\sum_{x \\in \\mathcal{X}} p(x) \\log p(x)$。\n- 熵 $H(X)$ 衡量随机变量的不确定性，熵越高表示信息越多，熵越低表示信息越少。\n- 当随机变量的概率分布为均匀分布时，熵达到最大值。\n- 熵为 0 表示随机变量确定无疑，其信息量也为 0。\n- 熵的计算示例展示了不同概率分布对应的熵值。"
      },
      {
        "段落": "## E．1．2 熵编码\n\n信息论的研究目标之一是如何用最少的编码表示传递信息。假设我们要传递一段文本信息，这段文本中包含的符号都来自于一个字母表 $\\boldsymbol{A}$ ，我们就需要对字母表 $\\boldsymbol{A}$ 中的每个符号进行编码。以二进制编码为例，我们常用的 ASCII 码就是用固定的 8 bits 来编码每个字母。但这种固定长度的编码方案不是最优的。一种高效的编码原则是字母的出现概率越高，其编码长度越短．比如对字母 $a, b, c$ 分别编码为 $0,10,110$ ．\n\n给定一串要传输的文本信息，其中字母 $x$ 的出现概率为 $p(x)$ ，其最佳编码长度为 $-\\log _{2} p(x)$ ，整段文本的平均编码长度为 $-\\sum_{x} p(x) \\log _{2} p(x)$ ，即底为 2 的熵。\n\n在对分布 $p(x)$ 的符号进行编码时，熵 $H(p)$ 也是理论上最优的平均编码长度，这种编码方式称为熵编码（Entropy Encoding）。\n\n由于每个符号的自信息通常都不是整数，因此在实际编码中很难达到理论上的最优值。霍夫曼编码（Huffman Coding）和算术编码（Arithmetic Coding）是两种最常见的熵编码技术。\n\n霍夫曼编码参见算法 15．1．",
        "总结": "- 熵编码的概念：熵编码是一种基于符号出现概率的编码方法，其平均编码长度理论上最优，等于信息熵。\n- 熵的定义：信息熵 $H(p)$ 是衡量信息不确定性的度量，计算公式为 $-\\sum_{x} p(x) \\log _{2} p(x)$。\n- 编码长度与概率的关系：符号的出现概率越高，其编码长度越短，最佳编码长度为 $-\\log _{2} p(x)$。\n- 熵编码的理论最优性：熵 $H(p)$ 是理论上最优的平均编码长度。\n- 实际编码的限制：由于自信息通常不是整数，实际编码难以达到理论最优值。\n- 常见的熵编码技术：霍夫曼编码和算术编码是两种最常见的熵编码方法。\n- 霍夫曼编码的参考：霍夫曼编码的具体算法参见算法 15．1。"
      },
      {
        "段落": "## E．1．3 联合熵和条件熵\n\n对于两个离散随机变量 $X$ 和 $Y$ ，假设 $X$ 取值集合为 $\\mathcal{X}$ ；$Y$ 取值集合为 $y$ ，其联合概率分布满足为 $p(x, y)$ ，则\n$X$ 和 $Y$ 的联合熵（Joint Entropy）为\n\n$$\n\\begin{equation*}\nH(X, Y)=-\\sum_{x \\in \\mathcal{X}} \\sum_{y \\in \\mathcal{Y}} p(x, y) \\log p(x, y) . \\tag{E.5}\n\\end{equation*}\n$$\n\n$X$ 和 $Y$ 的条件熵（Conditional Entropy）为\n\n$$\n\\begin{align*}\nH(X \\mid Y) & =-\\sum_{x \\in \\mathcal{X}} \\sum_{y \\in y} p(x, y) \\log p(x \\mid y)  \\tag{E.6}\\\\\n& =-\\sum_{x \\in \\mathcal{X}} \\sum_{y \\in y} p(x, y) \\log \\frac{p(x, y)}{p(y)} \\tag{E.7}\n\\end{align*}\n$$\n\n根据其定义，条件熵也可以写为\n\n$$\n\\begin{equation*}\nH(X \\mid Y)=H(X, Y)-H(Y) \\tag{E.8}\n\\end{equation*}\n$$",
        "总结": "- 联合熵定义为两个离散随机变量 $X$ 和 $Y$ 的联合概率分布 $p(x, y)$ 的熵，表示为 $H(X, Y) = -\\sum_{x \\in \\mathcal{X}} \\sum_{y \\in \\mathcal{Y}} p(x, y) \\log p(x, y)$。  \n- 条件熵定义为在已知 $Y$ 的情况下，$X$ 的不确定性，表示为 $H(X \\mid Y) = -\\sum_{x \\in \\mathcal{X}} \\sum_{y \\in \\mathcal{Y}} p(x, y) \\log p(x \\mid y)$。  \n- 条件熵还可以通过联合熵与 $Y$ 的熵之差表示，即 $H(X \\mid Y) = H(X, Y) - H(Y)$。"
      },
      {
        "段落": "## E． 2 互信息\n\n互信息（Mutual Information）是衡量已知一个变量时，另一个变量不确定性的减少程度。两个离散随机变量 $X$ 和 $Y$ 的互信息定义为\n\n$$\n\\begin{equation*}\nI(X ; Y)=\\sum_{x \\in \\mathcal{X}} \\sum_{y \\in \\mathcal{Y}} p(x, y) \\log \\frac{p(x, y)}{p(x) p(y)} \\tag{E.9}\n\\end{equation*}\n$$\n\n互信息的一个性质为\n\n$$\n\\begin{align*}\nI(X ; Y) & =H(X)-H(X \\mid Y)  \\tag{E.10}\\\\\n& =H(Y)-H(Y \\mid X) \\tag{E.11}\n\\end{align*}\n$$\n\n如果变量 $X$ 和 $Y$ 互相独立，它们的互信息为零．",
        "总结": "- 互信息是衡量已知一个变量时，另一个变量不确定性的减少程度  \n- 互信息的定义公式为 $I(X ; Y)=\\sum_{x \\in \\mathcal{X}} \\sum_{y \\in \\mathcal{Y}} p(x, y) \\log \\frac{p(x, y)}{p(x) p(y)}$  \n- 互信息的两个等价表达式为 $I(X ; Y)=H(X)-H(X \\mid Y)$ 和 $I(X ; Y)=H(Y)-H(Y \\mid X)$  \n- 若变量 $X$ 和 $Y$ 互相独立，则它们的互信息为零"
      },
      {
        "段落": "## E． 3 交叉熵和散度",
        "总结": "- 交叉熵是衡量两个概率分布差异的指标，常用于分类任务中评估模型输出与真实标签之间的差距。  \n- 散度（如KL散度）用于衡量两个概率分布之间的差异，但与交叉熵不同，它不具有对称性。  \n- 文中推导了交叉熵与散度之间的关系，指出交叉熵等于散度加上真实分布的熵。  \n- 通过数学公式展示了如何计算交叉熵和散度，并解释了其在机器学习中的应用意义。"
      },
      {
        "段落": "## E．3．1 交叉嫡\n\n对于分布为 $p(x)$ 的随机变量，熵 $H(p)$ 表示其最优编码长度。交叉熵（Cross Entropy）是按照概率分布 $q$ 的最优编码对真实分布为 $p$ 的信息进行编码的长度，定义为\n\n$$\n\\begin{align*}\nH(p, q) & =\\mathbb{E}_{p}[-\\log q(x)]  \\tag{E.12}\\\\\n& =-\\sum_{x} p(x) \\log q(x) \\tag{E.13}\n\\end{align*}\n$$\n\n在给定 $p$ 的情况下，如果 $q$ 和 $p$ 越接近，交叉熵越小；如果 $q$ 和 $p$ 越远，交叉熵就越大．",
        "总结": "- 交叉熵（Cross Entropy）定义为使用分布 $q$ 对真实分布 $p$ 的信息进行编码的期望长度，公式为 $H(p, q) = -\\sum_{x} p(x) \\log q(x)$。  \n- 当 $q$ 与 $p$ 越接近时，交叉熵越小；反之，当 $q$ 与 $p$ 越远离时，交叉熵越大。"
      },
      {
        "段落": "## E．3．2 KL散度\n\n$K L$ 散度（Kullback－Leibler Divergence），也叫 $K L$ 距离或相对熵（Relative Entropy），是用概率分布 $q$ 来近似 $p$ 时所造成的信息损失量。KL散度是按照概率分布 $q$ 的最优编码对真实分布为 $p$ 的信息进行编码，其平均编码长度（即交叉嫡） $H(p, q)$ 和 $p$ 的最优平均编码长度（即熵）$H(p)$ 之间的差异。对于离散概率分布 $p$和 $q$ ，从 $q$ 到 $p$ 的 KL 散度定义为\n\n$$\n\\begin{align*}\n\\mathrm{KL}(p, q) & =H(p, q)-H(p)  \\tag{E.14}\\\\\n& =\\sum_{x} p(x) \\log \\frac{p(x)}{q(x)}, \\tag{E.15}\n\\end{align*}\n$$\n\n其中为了保证连续性，定义 $0 \\log \\frac{0}{0}=0,0 \\log \\frac{0}{q}=0$ ．\nKL 散度总是非负的， $\\mathrm{KL}(p, q) \\geq 0$ ，可以衡量两个概率分布之间的距离． KL散度只有当 $p=q$ 时， $\\mathrm{KL}(p, q)=0$ 。如果两个分布越接近， KL 散度越小；如果两个分布越远，KL散度就越大。但 KL 散度并不是一个真正的度量或距离，一是 KL散度不满足距离的对称性，二是 KL 散度不满足距离的三角不等式性质．",
        "总结": "- KL散度（Kullback-Leibler Divergence），也称为相对熵，用于衡量用概率分布q近似p时造成的信息损失量。  \n- KL散度定义为交叉熵H(p, q)与熵H(p)的差值，即KL(p, q) = H(p, q) - H(p)。  \n- 对于离散概率分布p和q，KL散度的计算公式为$\\sum_{x} p(x) \\log \\frac{p(x)}{q(x)}$。  \n- 为保证连续性，定义了$0 \\log \\frac{0}{0} = 0$和$0 \\log \\frac{0}{q} = 0$。  \n- KL散度总是非负的，且当且仅当p=q时，KL散度为0。  \n- KL散度不满足距离的对称性与三角不等式性质，因此不是真正的度量或距离。"
      },
      {
        "段落": "## E．3．3 JS 散度\n\n$J S$ 散度（Jensen－Shannon Divergence）是一种对称的衡量两个分布相似度的度量方式，定义为\n\n$$\n\\begin{equation*}\n\\mathrm{JS}(p, q)=\\frac{1}{2} \\mathrm{KL}(p, m)+\\frac{1}{2} \\mathrm{KL}(q, m), \\tag{E.16}\n\\end{equation*}\n$$\n\n其中 $m=\\frac{1}{2}(p+q)$ 。\nJS 散度是 KL 散度一种改进。但两种散度都存在一个问题，即如果两个分布 $p, q$ 没有重叠或者重叠非常少时，KL散度和 JS 散度都很难衡量两个分布的距离。",
        "总结": "- JS散度是一种对称的衡量两个分布相似度的度量方式  \n- JS散度定义为两个分布与它们平均分布的KL散度的平均值  \n- 平均分布 $m$ 定义为 $m = \\frac{1}{2}(p + q)$  \n- JS散度是对KL散度的一种改进  \n- 两种散度在两个分布几乎没有重叠时都难以有效衡量分布之间的距离"
      },
      {
        "段落": "## E．3．4 Wasserstein 距离\n\nWasserstein 距离（Wasserstein Distance）也用于衡量两个分布之间的距离。对于两个分布 $q_{1}, q_{2}, p^{\\text {th }}$－Wasserstein 距离定义为\n\n$$\n\\begin{equation*}\nW_{p}\\left(q_{1}, q_{2}\\right)=\\left(\\inf _{\\gamma(x, y) \\in \\Gamma\\left(q_{1}, q_{2}\\right)} \\mathbb{E}_{(x, y) \\sim \\gamma(x, y)}\\left[d(x, y)^{p}\\right]\\right)^{\\frac{1}{p}} \\tag{E.17}\n\\end{equation*}\n$$\n\n其中 $\\Gamma\\left(q_{1}, q_{2}\\right)$ 是边际分布为 $q_{1}$ 和 $q_{2}$ 的所有可能的联合分布集合，$d(x, y)$ 为 $x$ 和 $y$的距离，比如 $\\ell_{p}$ 距离等。\n\n如果将两个分布看作是两个土堆，联合分布 $\\gamma(x, y)$ 看作是从土堆 $q_{1}$ 的位置 $x$ 到土堆 $q_{2}$ 的位置 $y$ 的搬运土的数量，并有\n\n$$\n\\begin{align*}\n& \\sum_{x} \\gamma(x, y)=q_{2}(y),  \\tag{E.18}\\\\\n& \\sum_{y} \\gamma(x, y)=q_{1}(x) . \\tag{E.19}\n\\end{align*}\n$$\n\n$q_{1}$ 和 $q_{2}$ 为 $\\gamma(x, y)$ 的两个边际分布．\n$\\mathbb{E}_{(x, y) \\sim \\gamma(x, y)}\\left[d(x, y)^{p}\\right]$ 可以理解为在联合分布 $\\gamma(x, y)$ 下把形状为 $q_{1}$ 的土堆搬运到形状为 $q_{2}$ 的土堆所需的工作量，\n\n$$\n\\begin{equation*}\n\\mathbb{E}_{(x, y) \\sim \\gamma(x, y)}\\left[d(x, y)^{p}\\right]=\\sum_{(x, y)} \\gamma(x, y) d(x, y)^{p} \\tag{E.20}\n\\end{equation*}\n$$\n\n其中从土堆 $q_{1}$ 中的点 $x$ 到土堆 $q_{2}$ 中的点 $y$ 的移动土的数量和距离分别为 $\\gamma(x, y)$和 $d(x, y)^{p}$ 。 因此，Wasserstein 距离可以理解为搬运土堆的最小工作量，也称为推土机距离（Earth－Mover＇s Distance，EMD）。图E． 1 给出了两个离散变量分布的 Wasserstein 距离示例．图E．1c中同颜色方块表示在分布 $q_{1}$ 中为相同位置．\n![](https://cdn.mathpix.com/cropped/2025_05_23_71fd923698fa049cade8g-439.jpg?height=273&width=1099&top_left_y=1089&top_left_x=104)\n\n图 E． 1 Wasserstein 距离示例\n\nWasserstein 距离相比 KL 散度和 JS 散度的优势在于：即使两个分布没有重叠或者重叠非常少，Wasserstein 距离仍然能反映两个分布的远近．\n\n对于 $\\mathbb{R}^{N}$ 空间中的两个高斯分布 $p=\\mathcal{N}\\left(\\mu_{1}, \\Sigma_{1}\\right)$ 和 $q=\\mathcal{N}\\left(\\mu_{2}, \\Sigma_{2}\\right)$ ，它们的 $2^{\\text {nd }}$－Wasserstein 距离为\n\n$$\n\\begin{equation*}\nW_{2}(p, q)=\\left\\|\\mu_{1}-\\mu_{2}\\right\\|_{2}^{2}+\\operatorname{tr}\\left(\\Sigma_{1}+\\Sigma_{2}-2\\left(\\Sigma_{2}^{1 / 2} \\Sigma_{1} \\Sigma_{2}^{1 / 2}\\right)^{1 / 2}\\right) . \\tag{E.21}\n\\end{equation*}\n$$\n\n当两个分布的方差为 0 时， $2^{\\text {nd }}$－Wasserstein 距离等价于欧氏距离．",
        "总结": "- Wasserstein 距离用于衡量两个分布之间的距离，定义为在所有可能的联合分布中，搬运土堆所需最小工作量的 p 次方根。  \n- Wasserstein 距离的数学表达式为 $W_p(q_1, q_2) = \\left( \\inf_{\\gamma(x, y) \\in \\Gamma(q_1, q_2)} \\mathbb{E}_{(x, y) \\sim \\gamma(x, y)}[d(x, y)^p] \\right)^{1/p}$。  \n- $\\Gamma(q_1, q_2)$ 是边际分布为 $q_1$ 和 $q_2$ 的所有可能联合分布的集合。  \n- 联合分布 $\\gamma(x, y)$ 表示从 $q_1$ 到 $q_2$ 的搬运土的数量，满足 $\\sum_x \\gamma(x, y) = q_2(y)$ 和 $\\sum_y \\gamma(x, y) = q_1(x)$。  \n- $\\mathbb{E}_{(x, y) \\sim \\gamma(x, y)}[d(x, y)^p]$ 表示在联合分布下搬运土堆的工作量，计算公式为 $\\sum_{(x, y)} \\gamma(x, y) d(x, y)^p$。  \n- Wasserstein 距离也被称为推土机距离（Earth-Mover's Distance，EMD）。  \n- Wasserstein 距离相比 KL 散度和 JS 散度的优势在于：即使两个分布没有重叠或重叠很少，仍能反映它们之间的远近。  \n- 对于 $\\mathbb{R}^N$ 空间中的两个高斯分布 $p = \\mathcal{N}(\\mu_1, \\Sigma_1)$ 和 $q = \\mathcal{N}(\\mu_2, \\Sigma_2)$，它们的 2nd-Wasserstein 距离为 $W_2(p, q) = \\| \\mu_1 - \\mu_2 \\|_2^2 + \\operatorname{tr}(\\Sigma_1 + \\Sigma_2 - 2(\\Sigma_2^{1/2} \\Sigma_1 \\Sigma_2^{1/2})^{1/2})$。  \n- 当两个分布的方差为 0 时，Wasserstein 距离等价于欧氏距离。"
      },
      {
        "段落": "## E． 4 总结和深入阅读\n\n本章比较简略地介绍了本书所需要的数学基础知识．若要深入了解这些知识，可以参考这些数学分支的专门书籍。\n\n关于线性代数的知识可以参考 《Introduction to Linear Algebra》［Strang， 2016］、《Differential Equations and Linear Algebra》［Strang，2014］或《Intro－ duction to Applied Linear Algebra：Vectors，Matrices，and Least Squares 》［Boyd et al．，2018］．\n\n关于微积分的知识，可以参考《Calculus》［Stewart，2011］或《Thomas＇Cal－ culus 》［Thomas et al．，2005］．\n\n关于数学优化的知识，可以参考 《Numerical Optimization》［Nocedal et al．， 2006］和 《 Convex Optimization 》［Boyd et al．，2014］．\n\n关于概率论的知识，可以参考《数理统计学教程》［陈希孺，2009b］或《概率论与数理统计》［陈希孺，2009a］．\n\n关于信息论的知识，可以参考《Information Theory，Inference，and Learn－ ing Algorithms 》［MacKay，2003］或 《Elements of Information Theory》［Cover et al．，2006］．",
        "总结": "- 本节总结了本书所需的数学基础知识，并指出若要深入了解这些知识，可参考相关数学分支的专门书籍。  \n- 推荐了线性代数的参考书，包括《Introduction to Linear Algebra》、《Differential Equations and Linear Algebra》和《Introduction to Applied Linear Algebra：Vectors，Matrices，and Least Squares》。  \n- 推荐了微积分的参考书，包括《Calculus》和《Thomas＇Calculus》。  \n- 推荐了数学优化的参考书，包括《Numerical Optimization》和《Convex Optimization》。  \n- 推荐了概率论的参考书，包括《数理统计学教程》和《概率论与数理统计》。  \n- 推荐了信息论的参考书，包括《Information Theory，Inference，and Learning Algorithms》和《Elements of Information Theory》。"
      },
      {
        "段落": "## 参考文献\n\n陈希孺．概率论与数理统计［M］．中国科学技术大学出版社， 2009.\n陈希孺．数理统计学教程［M］．中国科学技术大学出版社， 2009.\nBoyd S，Vandenberghe L．Introduction to applied linear algebra：vectors，matrices，and least squares［M／OL］．Cambridge university press，2018．http：／／vmls－book．stanford．edu／．\nBoyd S P，Vandenberghe L．Convex optimization［M／OL］．Cambridge University Press，2014．https： ／／web．stanford．edu／\\％7Eboyd／cvxbook／．\nCover T M，Thomas J A．Elements of information theory［M／OL］．2nd edition．Wiley，2006．http： ／／www．elementsofinformationtheory．com／．\nMacKay D J C．Information theory，inference，and learning algorithms［M］．Cambridge University Press， 2003.\nNocedal J，Wright S J．Numerical optimization［M］．2nd edition．Springer， 2006.\nRasmussen C E．Gaussian processes in machine learning［C／OL］／／Bousquet O，von Luxburg U， Rätsch G．Lecture Notes in Computer Science：volume 3176 Advanced Lectures on Machine Learning，ML Summer Schools 2003，Canberra，Australia，February 2－14，2003，Tübingen，Ger－ many，August 4－16，2003，Revised Lectures．Springer，2003：63－71．https：／／doi．org／10．1007／978－3－ 540－28650－9＿4．\nStewart J．Calculus［M］．Cengage Learning， 2011.\nStrang G．Differential equations and linear algebra［M／OL］．Wellesley－Cambridge Press， 2014. http：／／math．mit．edu／dela．\nStrang G．Introduction to linear algebra［M／OL］．5th edition．Wellesley－Cambridge Press， 2016. http：／／math．mit．edu／linearalgebra．\nThomas G B，Weir M D，Hass J，et al．Thomas＇calculus［M］．Addison－Wesley， 2005.\n\n\n[^0]:    1 据不完全统计，现有的颜色命名已经有 1300 多种．https：／／en．wikipedia．org／wiki／\n    Lists＿of＿colors\n    https：／／nndl．github．io／\n\n[^1]:    1 图片来源：https：／／commons．wikimedia．org／wiki／File：Neuron＿Hand－tuned．svg https：／／nndl．github．io／\n\n[^2]:    1 更全面的深度学习框架介绍可以参考https：／／en．wikipedia．org／wiki／Comparison＿of＿ deep＿learning＿software．\n    ${ }^{2}$ http：／／www．deeplearning．net／software／theano\n    https：／／nndl．github．io／\n\n[^3]:    ${ }^{1}$ http：／／cs231n．stanford．edu\n    ${ }^{2}$ http：／／web．stanford．edu／class／cs224n／\n    3 http：／／www．iclr．cc\n    4 https：／／nips．cc\n    ${ }^{5}$ https：／／icml．cc\n    https：／／nndl．github．io／\n\n[^4]:    ${ }^{1}$ https：／／www．ijcai．org\n    ${ }^{2}$ http：／／www．aaai．org\n    https：／／nndl．github．io／\n\n[^5]:    $$\n    \\begin{equation*}\n    \\|\\boldsymbol{W}\\|_{F}^{2}=\\sum_{l=1}^{L} \\sum_{i=1}^{M_{l}} \\sum_{j=1}^{M_{l-1}}\\left(w_{i j}^{(l)}\\right)^{2} \\tag{4.44}\n    \\end{equation*}\n    $$\n\n    https：／／nndl．github．io／\n    https：／／nndl．github．io\n\n[^6]:    ${ }^{1}$ http：／／playground．tensorflow．org\n    https：／／nndl．github．io／\n\n[^7]:    1 图片来源：https：／／medium．com／coinmonks／paper－review－of－alexnet－caffenet－ winner－in－ilsvrc－2012－image－classification－b93598314160\n    https：／／nndl．github．io／\n\n[^8]:    ${ }^{1}$ https：／／github．com／asyml／texar\n    https：／／nndl．github．io／\n\n[^9]:    1 详细的矩阵微积分可以参考https：／／en．wikipedia．org／wiki／Matrix＿calculus．",
        "总结": "- 参考文献列出了多本与概率论、数理统计、线性代数、优化理论、信息论和深度学习相关的书籍和在线资源。  \n- 文中引用了陈希孺的两本教材，分别涉及概率论与数理统计以及数理统计学教程。  \n- 引用了Boyd和Vandenberghe的两本关于线性代数和凸优化的书籍，提供了在线访问链接。  \n- Cover和Thomas的信息论教材被引用，且提供了在线资源链接。  \n- MacKay的《信息理论、推理与学习算法》也被提及。  \n- Nocedal和Wright的《数值优化》是另一本被引用的优化理论书籍。  \n- Rasmussen关于高斯过程在机器学习中的应用论文被引用，并附有DOI链接。  \n- Stewart的《微积分》和Strang的多本线性代数教材被引用，均提供在线资源。  \n- Thomas等人的《Thomas微积分》被提及。  \n- 文中包含多个脚注，引用了与颜色命名、神经网络图像、深度学习框架、深度学习课程、会议网站以及矩阵微积分相关的外部链接。  \n- 式(4.44)展示了权重矩阵的Frobenius范数计算公式，用于衡量矩阵元素的平方和。"
      }
    ]
  }
]